# evaluation_storage.py - –ú–µ—Ö–∞–Ω—ñ–∑–º –∑–±–µ—Ä–µ–∂–µ–Ω–Ω—è/–∑–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–Ω—è —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ñ–≤ –æ—Ü—ñ–Ω—é–≤–∞–Ω–Ω—è MPC

import os
import json
import pickle
import pandas as pd
import numpy as np
from datetime import datetime
from typing import Dict, List, Optional, Union, Any
from pathlib import Path
import zipfile
import hashlib
from dataclasses import dataclass, asdict
import logging

# –Ü–º–ø–æ—Ä—Ç—É—î–º–æ —Å—Ç—Ä—É–∫—Ç—É—Ä–∏ –∑ –æ—Å–Ω–æ–≤–Ω–æ–≥–æ –º–æ–¥—É–ª—è
try:
    from evaluation_simple import EvaluationResults
except ImportError:
    # Fallback –¥–ª—è –∞–≤—Ç–æ–Ω–æ–º–Ω–æ–≥–æ –≤–∏–∫–æ—Ä–∏—Å—Ç–∞–Ω–Ω—è
    from dataclasses import dataclass
    
    @dataclass 
    class EvaluationResults:
        """–ö–æ–Ω—Ç–µ–π–Ω–µ—Ä –¥–ª—è –≤—Å—ñ—Ö —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ñ–≤ –æ—Ü—ñ–Ω—é–≤–∞–Ω–Ω—è"""
        # –ú–æ–¥–µ–ª—å (10 –º–µ—Ç—Ä–∏–∫)
        model_rmse_fe: float = 0.0
        model_rmse_mass: float = 0.0
        model_r2_fe: float = 0.0
        model_r2_mass: float = 0.0
        model_bias_fe: float = 0.0
        model_bias_mass: float = 0.0
        model_mae_fe: float = 0.0
        model_mae_mass: float = 0.0
        model_mape_fe: float = 0.0
        model_mape_mass: float = 0.0
        
        # EKF –º–µ—Ç—Ä–∏–∫–∏ (8 –º–µ—Ç—Ä–∏–∫)
        ekf_rmse_fe: float = 0.0
        ekf_rmse_mass: float = 0.0
        ekf_normalized_rmse_fe: float = 0.0
        ekf_normalized_rmse_mass: float = 0.0
        ekf_rmse_total: float = 0.0
        ekf_nees_mean: float = 0.0
        ekf_nis_mean: float = 0.0
        ekf_consistency: float = 0.0
        
        # Trust Region –º–µ—Ç—Ä–∏–∫–∏ (6 –º–µ—Ç—Ä–∏–∫)
        trust_radius_mean: float = 0.0
        trust_radius_std: float = 0.0
        trust_radius_min: float = 0.0
        trust_radius_max: float = 0.0
        trust_adaptivity_coeff: float = 0.0
        trust_stability_index: float = 0.0
        
        # –ß–∞—Å–æ–≤—ñ –º–µ—Ç—Ä–∏–∫–∏ (4 –º–µ—Ç—Ä–∏–∫–∏)
        initial_training_time: float = 0.0
        avg_retraining_time: float = 0.0
        avg_prediction_time: float = 0.0
        total_retraining_count: float = 0.0
        
        # –ö–µ—Ä—É–≤–∞–Ω–Ω—è (13 –º–µ—Ç—Ä–∏–∫)
        tracking_error_fe: float = 0.0
        tracking_error_mass: float = 0.0
        control_smoothness: float = 0.0
        setpoint_achievement_fe: float = 0.0
        setpoint_achievement_mass: float = 0.0
        ise_fe: float = 0.0
        ise_mass: float = 0.0
        iae_fe: float = 0.0
        iae_mass: float = 0.0
        tracking_mae_fe: float = 0.0
        tracking_mae_mass: float = 0.0
        tracking_mape_fe: float = 0.0
        tracking_mape_mass: float = 0.0
        
        # –ó–∞–≥–∞–ª—å–Ω–∞ –µ—Ñ–µ–∫—Ç–∏–≤–Ω—ñ—Å—Ç—å (2 –º–µ—Ç—Ä–∏–∫–∏)
        overall_score: float = 0.0
        process_stability: float = 0.0
        
        # –ê–≥—Ä–µ—Å–∏–≤–Ω—ñ—Å—Ç—å –∫–µ—Ä—É–≤–∞–Ω–Ω—è (11 –º–µ—Ç—Ä–∏–∫)
        control_aggressiveness: float = 0.0
        control_variability: float = 0.0
        control_energy: float = 0.0
        control_stability_index: float = 0.0
        control_utilization: float = 0.0
        significant_changes_frequency: float = 0.0
        significant_changes_count: float = 0.0
        max_control_change: float = 0.0
        directional_switches_per_step: float = 0.0
        directional_switches_count: float = 0.0
        steps_at_max_delta_u: float = 0.0

        def to_dict(self) -> Dict:
            return asdict(self)

# =============================================================================
# === –°–¢–†–£–ö–¢–£–†–ò –î–ê–ù–ò–• –î–õ–Ø –ó–ë–ï–†–ï–ñ–ï–ù–ù–Ø ===
# =============================================================================

@dataclass
class SimulationMetadata:
    """–ú–µ—Ç–∞–¥–∞–Ω—ñ —Å–∏–º—É–ª—è—Ü—ñ—ó –¥–ª—è —ñ–¥–µ–Ω—Ç–∏—Ñ—ñ–∫–∞—Ü—ñ—ó —Ç–∞ –≤—ñ–¥—Ç–≤–æ—Ä–µ–Ω–Ω—è"""
    
    # –û—Å–Ω–æ–≤–Ω–∞ —ñ–Ω—Ñ–æ—Ä–º–∞—Ü—ñ—è
    timestamp: str
    simulation_id: str
    description: str
    version: str = "1.0"
    
    # –ü–∞—Ä–∞–º–µ—Ç—Ä–∏ —Å–∏–º—É–ª—è—Ü—ñ—ó
    simulation_steps: int = 0
    dt: float = 1.0
    ref_fe: float = 53.5
    ref_mass: float = 57.0
    
    # –ü–∞—Ä–∞–º–µ—Ç—Ä–∏ –º–æ–¥–µ–ª—ñ
    model_type: str = "Unknown"
    model_params: Dict[str, Any] = None
    
    # –ü–∞—Ä–∞–º–µ—Ç—Ä–∏ MPC
    horizon: int = 10
    delta_u_max: float = 1.0
    lambda_u: float = 0.1
    
    # –ü–∞—Ä–∞–º–µ—Ç—Ä–∏ EKF
    Q_matrix: List[List[float]] = None
    R_matrix: List[List[float]] = None
    
    # –ü–∞—Ä–∞–º–µ—Ç—Ä–∏ Trust Region
    initial_trust_radius: float = 1.0
    min_trust_radius: float = 0.1
    max_trust_radius: float = 5.0
    
    # –•–µ—à –¥–ª—è –ø–µ—Ä–µ–≤—ñ—Ä–∫–∏ —Ü—ñ–ª—ñ—Å–Ω–æ—Å—Ç—ñ
    data_hash: str = ""
    
    def __post_init__(self):
        if self.model_params is None:
            self.model_params = {}
        if self.Q_matrix is None:
            self.Q_matrix = [[0.01, 0], [0, 0.01]]
        if self.R_matrix is None:
            self.R_matrix = [[0.1, 0], [0, 0.1]]

@dataclass 
class EvaluationPackage:
    """–ü–æ–≤–Ω–∏–π –ø–∞–∫–µ—Ç —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ñ–≤ –æ—Ü—ñ–Ω—é–≤–∞–Ω–Ω—è"""
    
    metadata: SimulationMetadata
    evaluation_results: EvaluationResults
    simulation_data: pd.DataFrame
    analysis_data: Dict[str, Any]
    parameters: Dict[str, Any]
    
    # –î–æ–¥–∞—Ç–∫–æ–≤—ñ –∞–Ω–∞–ª—ñ—Ç–∏—á–Ω—ñ –¥–∞–Ω—ñ
    recommendations: List[str] = None
    performance_summary: str = ""
    
    def __post_init__(self):
        if self.recommendations is None:
            self.recommendations = []

# =============================================================================
# === –ö–õ–ê–°–ò –î–õ–Ø –ó–ë–ï–†–ï–ñ–ï–ù–ù–Ø/–ó–ê–í–ê–ù–¢–ê–ñ–ï–ù–ù–Ø ===
# =============================================================================

class EvaluationStorage:
    """–ú–µ–Ω–µ–¥–∂–µ—Ä –∑–±–µ—Ä–µ–∂–µ–Ω–Ω—è —Ç–∞ –∑–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–Ω—è —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ñ–≤ –æ—Ü—ñ–Ω—é–≤–∞–Ω–Ω—è"""
    
    def __init__(self, base_directory: str = "evaluation_results"):
        """
        –Ü–Ω—ñ—Ü—ñ–∞–ª—ñ–∑–∞—Ü—ñ—è –º–µ–Ω–µ–¥–∂–µ—Ä–∞ –∑–±–µ—Ä–µ–∂–µ–Ω–Ω—è
        
        Args:
            base_directory: –ë–∞–∑–æ–≤–∞ –¥–∏—Ä–µ–∫—Ç–æ—Ä—ñ—è –¥–ª—è –∑–±–µ—Ä–µ–∂–µ–Ω–Ω—è —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ñ–≤
        """
        self.base_dir = Path(base_directory)
        self.base_dir.mkdir(exist_ok=True)
        
        # –ù–∞–ª–∞—à—Ç—É–≤–∞–Ω–Ω—è –ª–æ–≥—É–≤–∞–Ω–Ω—è
        self._setup_logging()
        
        # –ü—ñ–¥—Ç—Ä–∏–º—É–≤–∞–Ω—ñ —Ñ–æ—Ä–º–∞—Ç–∏
        self.supported_formats = {
            'json': self._save_json,
            'pickle': self._save_pickle, 
            'excel': self._save_excel,
            'csv': self._save_csv,
            'zip': self._save_zip_archive
        }
        
        self.load_formats = {
            'json': self._load_json,
            'pickle': self._load_pickle,
            'excel': self._load_excel,
            'csv': self._load_csv,
            'zip': self._load_zip_archive
        }
    
    def _setup_logging(self):
        """–ù–∞–ª–∞—à—Ç—É–≤–∞–Ω–Ω—è —Å–∏—Å—Ç–µ–º–∏ –ª–æ–≥—É–≤–∞–Ω–Ω—è"""
        log_file = self.base_dir / "evaluation_storage.log"
        logging.basicConfig(
            level=logging.INFO,
            format='%(asctime)s - %(levelname)s - %(message)s',
            handlers=[
                logging.FileHandler(log_file),
                logging.StreamHandler()
            ]
        )
        self.logger = logging.getLogger(__name__)
    
    def generate_simulation_id(self, params: Dict) -> str:
        """–ì–µ–Ω–µ—Ä—É—î —É–Ω—ñ–∫–∞–ª—å–Ω–∏–π ID —Å–∏–º—É–ª—è—Ü—ñ—ó –Ω–∞ –æ—Å–Ω–æ–≤—ñ –ø–∞—Ä–∞–º–µ—Ç—Ä—ñ–≤"""
        
        # –ö–ª—é—á–æ–≤—ñ –ø–∞—Ä–∞–º–µ—Ç—Ä–∏ –¥–ª—è —Ö–µ—à—É–≤–∞–Ω–Ω—è
        key_params = {
            'ref_fe': params.get('ref_fe', 53.5),
            'ref_mass': params.get('ref_mass', 57.0),
            'horizon': params.get('horizon', 10),
            'lambda_u': params.get('lambda_u', 0.1),
            'delta_u_max': params.get('delta_u_max', 1.0)
        }
        
        # –°—Ç–≤–æ—Ä—é—î–º–æ —Ö–µ—à
        param_str = json.dumps(key_params, sort_keys=True)
        param_hash = hashlib.md5(param_str.encode()).hexdigest()[:8]
        
        # –î–æ–¥–∞—î–º–æ —á–∞—Å–æ–≤—É –º—ñ—Ç–∫—É
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        
        return f"sim_{timestamp}_{param_hash}"
    
    def calculate_data_hash(self, data: Any) -> str:
        """–û–±—á–∏—Å–ª—é—î —Ö–µ—à –¥–∞–Ω–∏—Ö –¥–ª—è –ø–µ—Ä–µ–≤—ñ—Ä–∫–∏ —Ü—ñ–ª—ñ—Å–Ω–æ—Å—Ç—ñ"""
        
        if isinstance(data, pd.DataFrame):
            # –î–ª—è DataFrame –≤–∏–∫–æ—Ä–∏—Å—Ç–æ–≤—É—î–º–æ –∑–Ω–∞—á–µ–Ω–Ω—è
            data_str = data.to_csv()
        elif isinstance(data, dict):
            # –î–ª—è —Å–ª–æ–≤–Ω–∏–∫–∞ - JSON –ø—Ä–µ–¥—Å—Ç–∞–≤–ª–µ–Ω–Ω—è
            data_str = json.dumps(data, sort_keys=True, default=str)
        else:
            # –î–ª—è —ñ–Ω—à–∏—Ö —Ç–∏–ø—ñ–≤ - —Å—Ç—Ä–æ–∫–æ–≤–µ –ø—Ä–µ–¥—Å—Ç–∞–≤–ª–µ–Ω–Ω—è
            data_str = str(data)
        
        return hashlib.sha256(data_str.encode()).hexdigest()[:16]
    
    def create_evaluation_package(self, 
                                results_df: pd.DataFrame,
                                eval_results: EvaluationResults,
                                analysis_data: Dict,
                                params: Dict,
                                description: str = "",
                                simulation_id: Optional[str] = None) -> EvaluationPackage:
        """
        –°—Ç–≤–æ—Ä—é—î –ø–æ–≤–Ω–∏–π –ø–∞–∫–µ—Ç —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ñ–≤ –æ—Ü—ñ–Ω—é–≤–∞–Ω–Ω—è
        
        Args:
            results_df: DataFrame –∑ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞–º–∏ —Å–∏–º—É–ª—è—Ü—ñ—ó
            eval_results: –†–µ–∑—É–ª—å—Ç–∞—Ç–∏ –æ—Ü—ñ–Ω—é–≤–∞–Ω–Ω—è
            analysis_data: –î–æ–¥–∞—Ç–∫–æ–≤—ñ –¥–∞–Ω—ñ –∞–Ω–∞–ª—ñ–∑—É
            params: –ü–∞—Ä–∞–º–µ—Ç—Ä–∏ —Å–∏–º—É–ª—è—Ü—ñ—ó
            description: –û–ø–∏—Å —Å–∏–º—É–ª—è—Ü—ñ—ó
            simulation_id: ID —Å–∏–º—É–ª—è—Ü—ñ—ó (–≥–µ–Ω–µ—Ä—É—î—Ç—å—Å—è –∞–≤—Ç–æ–º–∞—Ç–∏—á–Ω–æ —è–∫—â–æ –Ω–µ –≤–∫–∞–∑–∞–Ω–æ)
            
        Returns:
            EvaluationPackage –∑ —É—Å—ñ–º–∞ –¥–∞–Ω–∏–º–∏
        """
        
        if simulation_id is None:
            simulation_id = self.generate_simulation_id(params)
        
        # –°—Ç–≤–æ—Ä—é—î–º–æ –º–µ—Ç–∞–¥–∞–Ω—ñ
        metadata = SimulationMetadata(
            timestamp=datetime.now().isoformat(),
            simulation_id=simulation_id,
            description=description,
            simulation_steps=len(results_df),
            dt=params.get('dt', 1.0),
            ref_fe=params.get('ref_fe', 53.5),
            ref_mass=params.get('ref_mass', 57.0),
            model_type=params.get('model_type', 'Unknown'),
            model_params=params.get('model_params', {}),
            horizon=params.get('horizon', 10),
            delta_u_max=params.get('delta_u_max', 1.0),
            lambda_u=params.get('lambda_u', 0.1),
            Q_matrix=params.get('Q_matrix', [[0.01, 0], [0, 0.01]]),
            R_matrix=params.get('R_matrix', [[0.1, 0], [0, 0.1]]),
            initial_trust_radius=params.get('initial_trust_radius', 1.0),
            min_trust_radius=params.get('min_trust_radius', 0.1),
            max_trust_radius=params.get('max_trust_radius', 5.0)
        )
        
        # –û–±—á–∏—Å–ª—é—î–º–æ —Ö–µ—à –¥–∞–Ω–∏—Ö
        combined_data = {
            'results': results_df.to_dict(),
            'evaluation': eval_results.to_dict(),
            'analysis': analysis_data,
            'params': params
        }
        metadata.data_hash = self.calculate_data_hash(combined_data)
        
        # –ì–µ–Ω–µ—Ä—É—î–º–æ —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü—ñ—ó (—è–∫—â–æ –¥–æ—Å—Ç—É–ø–Ω–∞ —Ñ—É–Ω–∫—Ü—ñ—è)
        recommendations = []
        try:
            from evaluation_simple import generate_recommendations
            recommendations = generate_recommendations(eval_results, len(results_df))
        except ImportError:
            self.logger.warning("–ù–µ –≤–¥–∞–ª–æ—Å—è —ñ–º–ø–æ—Ä—Ç—É–≤–∞—Ç–∏ generate_recommendations")
        
        # –°—Ç–≤–æ—Ä—é—î–º–æ —Ä–µ–∑—é–º–µ –ø—Ä–æ–¥—É–∫—Ç–∏–≤–Ω–æ—Å—Ç—ñ
        try:
            from evaluation_simple import get_performance_summary
            performance_summary = get_performance_summary(eval_results)
        except ImportError:
            performance_summary = f"–ó–∞–≥–∞–ª—å–Ω–∞ –æ—Ü—ñ–Ω–∫–∞: {eval_results.overall_score:.1f}/100"
        
        return EvaluationPackage(
            metadata=metadata,
            evaluation_results=eval_results,
            simulation_data=results_df.copy(),
            analysis_data=analysis_data.copy() if analysis_data else {},
            parameters=params.copy(),
            recommendations=recommendations,
            performance_summary=performance_summary
        )
    
    # =============================================================================
    # === –ú–ï–¢–û–î–ò –ó–ë–ï–†–ï–ñ–ï–ù–ù–Ø ===
    # =============================================================================
    
    def save_evaluation(self, 
                       package: EvaluationPackage,
                       format_type: str = 'zip',
                       custom_name: Optional[str] = None) -> str:
        """
        –ó–±–µ—Ä—ñ–≥–∞—î –ø–∞–∫–µ—Ç –æ—Ü—ñ–Ω—é–≤–∞–Ω–Ω—è —É –≤–∫–∞–∑–∞–Ω–æ–º—É —Ñ–æ—Ä–º–∞—Ç—ñ
        
        Args:
            package: –ü–∞–∫–µ—Ç —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ñ–≤ –æ—Ü—ñ–Ω—é–≤–∞–Ω–Ω—è
            format_type: –§–æ—Ä–º–∞—Ç –∑–±–µ—Ä–µ–∂–µ–Ω–Ω—è ('json', 'pickle', 'excel', 'csv', 'zip')
            custom_name: –ö–æ—Ä–∏—Å—Ç—É–≤–∞—Ü—å–∫–µ —ñ–º'—è —Ñ–∞–π–ª—É
            
        Returns:
            –®–ª—è—Ö –¥–æ –∑–±–µ—Ä–µ–∂–µ–Ω–æ–≥–æ —Ñ–∞–π–ª—É
        """
        
        if format_type not in self.supported_formats:
            raise ValueError(f"–ù–µ–ø—ñ–¥—Ç—Ä–∏–º—É–≤–∞–Ω–∏–π —Ñ–æ—Ä–º–∞—Ç: {format_type}. "
                           f"–î–æ—Å—Ç—É–ø–Ω—ñ: {list(self.supported_formats.keys())}")
        
        # –í–∏–∑–Ω–∞—á–∞—î–º–æ —ñ–º'—è —Ñ–∞–π–ª—É
        if custom_name:
            filename = custom_name
        else:
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            filename = f"evaluation_{package.metadata.simulation_id}_{timestamp}"
        
        # –í–∏–∫–ª–∏–∫–∞—î–º–æ –≤—ñ–¥–ø–æ–≤—ñ–¥–Ω–∏–π –º–µ—Ç–æ–¥ –∑–±–µ—Ä–µ–∂–µ–Ω–Ω—è
        filepath = self.supported_formats[format_type](package, filename)
        
        self.logger.info(f"–†–µ–∑—É–ª—å—Ç–∞—Ç–∏ –∑–±–µ—Ä–µ–∂–µ–Ω–æ: {filepath}")
        return str(filepath)
    
    def _save_json(self, package: EvaluationPackage, filename: str) -> Path:
        """–ó–±–µ—Ä–µ–∂–µ–Ω–Ω—è —É JSON —Ñ–æ—Ä–º–∞—Ç—ñ"""
        
        filepath = self.base_dir / f"{filename}.json"
        
        # –ö–æ–Ω–≤–µ—Ä—Ç—É—î–º–æ –≤—Å–µ —É JSON-—Å—É–º—ñ—Å–Ω–∏–π —Ñ–æ—Ä–º–∞—Ç
        json_data = {
            'metadata': asdict(package.metadata),
            'evaluation_results': package.evaluation_results.to_dict(),
            'simulation_data': package.simulation_data.to_dict('records'),
            'analysis_data': self._serialize_analysis_data(package.analysis_data),
            'parameters': package.parameters,
            'recommendations': package.recommendations,
            'performance_summary': package.performance_summary
        }
        
        with open(filepath, 'w', encoding='utf-8') as f:
            json.dump(json_data, f, indent=2, ensure_ascii=False, default=str)
        
        return filepath
    
    def _save_pickle(self, package: EvaluationPackage, filename: str) -> Path:
        """–ó–±–µ—Ä–µ–∂–µ–Ω–Ω—è —É Pickle —Ñ–æ—Ä–º–∞—Ç—ñ (–Ω–∞–π—à–≤–∏–¥—à–∏–π —ñ –Ω–∞–π–ø–æ–≤–Ω—ñ—à–∏–π)"""
        
        filepath = self.base_dir / f"{filename}.pkl"
        
        with open(filepath, 'wb') as f:
            pickle.dump(package, f, protocol=pickle.HIGHEST_PROTOCOL)
        
        return filepath
    
    def _save_excel(self, package: EvaluationPackage, filename: str) -> Path:
        """–ó–±–µ—Ä–µ–∂–µ–Ω–Ω—è —É Excel —Ñ–æ—Ä–º–∞—Ç—ñ –∑ –∫—ñ–ª—å–∫–æ–º–∞ –ª–∏—Å—Ç–∞–º–∏"""
        
        filepath = self.base_dir / f"{filename}.xlsx"
        
        with pd.ExcelWriter(filepath, engine='openpyxl') as writer:
            # –õ–∏—Å—Ç 1: –†–µ–∑—É–ª—å—Ç–∞—Ç–∏ —Å–∏–º—É–ª—è—Ü—ñ—ó
            package.simulation_data.to_excel(writer, sheet_name='Simulation_Data', index=False)
            
            # –õ–∏—Å—Ç 2: –ú–µ—Ç—Ä–∏–∫–∏ –æ—Ü—ñ–Ω—é–≤–∞–Ω–Ω—è
            eval_df = pd.DataFrame([package.evaluation_results.to_dict()]).T
            eval_df.columns = ['Value']
            eval_df.to_excel(writer, sheet_name='Evaluation_Metrics')
            
            # –õ–∏—Å—Ç 3: –ú–µ—Ç–∞–¥–∞–Ω—ñ —Ç–∞ –ø–∞—Ä–∞–º–µ—Ç—Ä–∏
            metadata_df = pd.DataFrame([asdict(package.metadata)]).T
            metadata_df.columns = ['Value']
            metadata_df.to_excel(writer, sheet_name='Metadata')
            
            # –õ–∏—Å—Ç 4: –†–µ–∫–æ–º–µ–Ω–¥–∞—Ü—ñ—ó
            if package.recommendations:
                rec_df = pd.DataFrame(package.recommendations, columns=['Recommendations'])
                rec_df.to_excel(writer, sheet_name='Recommendations', index=False)
            
            # –õ–∏—Å—Ç 5: –ê–Ω–∞–ª—ñ—Ç–∏—á–Ω—ñ –¥–∞–Ω—ñ (—Å–ø—Ä–æ—â–µ–Ω—ñ)
            try:
                analysis_simple = self._simplify_analysis_data(package.analysis_data)
                if analysis_simple:
                    analysis_df = pd.DataFrame([analysis_simple]).T
                    analysis_df.columns = ['Value']
                    analysis_df.to_excel(writer, sheet_name='Analysis_Summary')
            except Exception as e:
                self.logger.warning(f"–ù–µ –≤–¥–∞–ª–æ—Å—è –∑–±–µ—Ä–µ–≥—Ç–∏ –∞–Ω–∞–ª—ñ—Ç–∏—á–Ω—ñ –¥–∞–Ω—ñ –≤ Excel: {e}")
        
        return filepath
    
    def _save_csv(self, package: EvaluationPackage, filename: str) -> Path:
        """–ó–±–µ—Ä–µ–∂–µ–Ω–Ω—è –æ—Å–Ω–æ–≤–Ω–∏—Ö –¥–∞–Ω–∏—Ö —É CSV —Ñ–æ—Ä–º–∞—Ç—ñ"""
        
        # –°—Ç–≤–æ—Ä—é—î–º–æ –¥–∏—Ä–µ–∫—Ç–æ—Ä—ñ—é –¥–ª—è CSV —Ñ–∞–π–ª—ñ–≤
        csv_dir = self.base_dir / f"{filename}_csv"
        csv_dir.mkdir(exist_ok=True)
        
        # –ó–±–µ—Ä—ñ–≥–∞—î–º–æ –¥–∞–Ω—ñ —Å–∏–º—É–ª—è—Ü—ñ—ó
        sim_path = csv_dir / "simulation_data.csv"
        package.simulation_data.to_csv(sim_path, index=False)
        
        # –ó–±–µ—Ä—ñ–≥–∞—î–º–æ –º–µ—Ç—Ä–∏–∫–∏ –æ—Ü—ñ–Ω—é–≤–∞–Ω–Ω—è
        eval_path = csv_dir / "evaluation_metrics.csv"
        eval_df = pd.DataFrame([package.evaluation_results.to_dict()]).T
        eval_df.to_csv(eval_path)
        
        # –ó–±–µ—Ä—ñ–≥–∞—î–º–æ –º–µ—Ç–∞–¥–∞–Ω—ñ
        meta_path = csv_dir / "metadata.csv"
        meta_df = pd.DataFrame([asdict(package.metadata)]).T
        meta_df.to_csv(meta_path)
        
        # –ó–±–µ—Ä—ñ–≥–∞—î–º–æ —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü—ñ—ó
        if package.recommendations:
            rec_path = csv_dir / "recommendations.csv"
            rec_df = pd.DataFrame(package.recommendations, columns=['Recommendations'])
            rec_df.to_csv(rec_path, index=False)
        
        return csv_dir
    
    def _save_zip_archive(self, package: EvaluationPackage, filename: str) -> Path:
        """–ó–±–µ—Ä–µ–∂–µ–Ω–Ω—è —É —Å—Ç–∏—Å–Ω—É—Ç–æ–º—É ZIP –∞—Ä—Ö—ñ–≤—ñ"""
        
        zip_path = self.base_dir / f"{filename}.zip"
        
        with zipfile.ZipFile(zip_path, 'w', zipfile.ZIP_DEFLATED) as zf:
            # JSON –∑ —É—Å—ñ–º–∞ –¥–∞–Ω–∏–º–∏
            json_data = {
                'metadata': asdict(package.metadata),
                'evaluation_results': package.evaluation_results.to_dict(),
                'analysis_data': self._serialize_analysis_data(package.analysis_data),
                'parameters': package.parameters,
                'recommendations': package.recommendations,
                'performance_summary': package.performance_summary
            }
            zf.writestr('evaluation_data.json', 
                       json.dumps(json_data, indent=2, default=str))
            
            # CSV –∑ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞–º–∏ —Å–∏–º—É–ª—è—Ü—ñ—ó
            sim_csv = package.simulation_data.to_csv(index=False)
            zf.writestr('simulation_data.csv', sim_csv)
            
            # Readme —Ñ–∞–π–ª
            readme_content = self._generate_readme(package)
            zf.writestr('README.txt', readme_content)
        
        return zip_path
    
    # =============================================================================
    # === –ú–ï–¢–û–î–ò –ó–ê–í–ê–ù–¢–ê–ñ–ï–ù–ù–Ø ===
    # =============================================================================
    
    def load_evaluation(self, filepath: Union[str, Path]) -> EvaluationPackage:
        """
        –ó–∞–≤–∞–Ω—Ç–∞–∂—É—î –ø–∞–∫–µ—Ç –æ—Ü—ñ–Ω—é–≤–∞–Ω–Ω—è –∑ —Ñ–∞–π–ª—É
        
        Args:
            filepath: –®–ª—è—Ö –¥–æ —Ñ–∞–π–ª—É
            
        Returns:
            EvaluationPackage –∑ –∑–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–∏–º–∏ –¥–∞–Ω–∏–º–∏
        """
        
        filepath = Path(filepath)
        
        if not filepath.exists():
            raise FileNotFoundError(f"–§–∞–π–ª –Ω–µ –∑–Ω–∞–π–¥–µ–Ω–æ: {filepath}")
        
        # –í–∏–∑–Ω–∞—á–∞—î–º–æ —Ñ–æ—Ä–º–∞—Ç –∑–∞ —Ä–æ–∑—à–∏—Ä–µ–Ω–Ω—è–º
        suffix = filepath.suffix.lower()
        
        if suffix == '.json':
            return self._load_json(filepath)
        elif suffix == '.pkl':
            return self._load_pickle(filepath) 
        elif suffix in ['.xlsx', '.xls']:
            return self._load_excel(filepath)
        elif suffix == '.zip':
            return self._load_zip_archive(filepath)
        elif filepath.is_dir():  # CSV –¥–∏—Ä–µ–∫—Ç–æ—Ä—ñ—è
            return self._load_csv(filepath)
        else:
            raise ValueError(f"–ù–µ–ø—ñ–¥—Ç—Ä–∏–º—É–≤–∞–Ω–∏–π —Ñ–æ—Ä–º–∞—Ç —Ñ–∞–π–ª—É: {suffix}")
    
    def _load_json(self, filepath: Path) -> EvaluationPackage:
        """–ó–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–Ω—è –∑ JSON —Ñ–∞–π–ª—É"""
        
        with open(filepath, 'r', encoding='utf-8') as f:
            data = json.load(f)
        
        # –í—ñ–¥–Ω–æ–≤–ª—é—î–º–æ —Å—Ç—Ä—É–∫—Ç—É—Ä–∏ –¥–∞–Ω–∏—Ö
        metadata = SimulationMetadata(**data['metadata'])
        eval_results = EvaluationResults(**data['evaluation_results'])
        simulation_data = pd.DataFrame(data['simulation_data'])
        
        return EvaluationPackage(
            metadata=metadata,
            evaluation_results=eval_results,
            simulation_data=simulation_data,
            analysis_data=data.get('analysis_data', {}),
            parameters=data.get('parameters', {}),
            recommendations=data.get('recommendations', []),
            performance_summary=data.get('performance_summary', '')
        )
    
    def _load_pickle(self, filepath: Path) -> EvaluationPackage:
        """–ó–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–Ω—è –∑ Pickle —Ñ–∞–π–ª—É"""
        
        with open(filepath, 'rb') as f:
            package = pickle.load(f)
        
        return package
    
    def _load_excel(self, filepath: Path) -> EvaluationPackage:
        """–ó–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–Ω—è –∑ Excel —Ñ–∞–π–ª—É"""
        
        # –ß–∏—Ç–∞—î–º–æ —Ä—ñ–∑–Ω—ñ –ª–∏—Å—Ç–∏
        simulation_data = pd.read_excel(filepath, sheet_name='Simulation_Data')
        
        eval_df = pd.read_excel(filepath, sheet_name='Evaluation_Metrics', index_col=0)
        eval_dict = eval_df['Value'].to_dict()
        eval_results = EvaluationResults(**eval_dict)
        
        meta_df = pd.read_excel(filepath, sheet_name='Metadata', index_col=0)
        meta_dict = meta_df['Value'].to_dict()
        metadata = SimulationMetadata(**meta_dict)
        
        # –†–µ–∫–æ–º–µ–Ω–¥–∞—Ü—ñ—ó (—è–∫—â–æ —î)
        recommendations = []
        try:
            rec_df = pd.read_excel(filepath, sheet_name='Recommendations')
            recommendations = rec_df['Recommendations'].tolist()
        except:
            pass
        
        return EvaluationPackage(
            metadata=metadata,
            evaluation_results=eval_results,
            simulation_data=simulation_data,
            analysis_data={},  # –ê–Ω–∞–ª—ñ—Ç–∏—á–Ω—ñ –¥–∞–Ω—ñ –≤—Ç—Ä–∞—á–∞—é—Ç—å—Å—è –≤ Excel
            parameters={},
            recommendations=recommendations,
            performance_summary=""
        )
    
    def _load_csv(self, dirpath: Path) -> EvaluationPackage:
        """–ó–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–Ω—è –∑ CSV –¥–∏—Ä–µ–∫—Ç–æ—Ä—ñ—ó"""
        
        # –ó–∞–≤–∞–Ω—Ç–∞–∂—É—î–º–æ –æ—Å–Ω–æ–≤–Ω—ñ —Ñ–∞–π–ª–∏
        simulation_data = pd.read_csv(dirpath / 'simulation_data.csv')
        
        eval_df = pd.read_csv(dirpath / 'evaluation_metrics.csv', index_col=0)
        eval_dict = eval_df.iloc[:, 0].to_dict()
        eval_results = EvaluationResults(**eval_dict)
        
        meta_df = pd.read_csv(dirpath / 'metadata.csv', index_col=0)
        meta_dict = meta_df.iloc[:, 0].to_dict()
        metadata = SimulationMetadata(**meta_dict)
        
        # –†–µ–∫–æ–º–µ–Ω–¥–∞—Ü—ñ—ó
        recommendations = []
        rec_path = dirpath / 'recommendations.csv'
        if rec_path.exists():
            rec_df = pd.read_csv(rec_path)
            recommendations = rec_df['Recommendations'].tolist()
        
        return EvaluationPackage(
            metadata=metadata,
            evaluation_results=eval_results,
            simulation_data=simulation_data,
            analysis_data={},
            parameters={},
            recommendations=recommendations,
            performance_summary=""
        )
    
    def _load_zip_archive(self, filepath: Path) -> EvaluationPackage:
        """–ó–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–Ω—è –∑ ZIP –∞—Ä—Ö—ñ–≤—É"""
        
        with zipfile.ZipFile(filepath, 'r') as zf:
            # –ó–∞–≤–∞–Ω—Ç–∞–∂—É—î–º–æ JSON –¥–∞–Ω—ñ
            json_content = zf.read('evaluation_data.json').decode('utf-8')
            data = json.loads(json_content)
            
            # –ó–∞–≤–∞–Ω—Ç–∞–∂—É—î–º–æ CSV –∑ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞–º–∏
            csv_content = zf.read('simulation_data.csv').decode('utf-8')
            from io import StringIO
            simulation_data = pd.read_csv(StringIO(csv_content))
        
        # –í—ñ–¥–Ω–æ–≤–ª—é—î–º–æ —Å—Ç—Ä—É–∫—Ç—É—Ä–∏
        metadata = SimulationMetadata(**data['metadata'])
        eval_results = EvaluationResults(**data['evaluation_results'])
        
        return EvaluationPackage(
            metadata=metadata,
            evaluation_results=eval_results,
            simulation_data=simulation_data,
            analysis_data=data.get('analysis_data', {}),
            parameters=data.get('parameters', {}),
            recommendations=data.get('recommendations', []),
            performance_summary=data.get('performance_summary', '')
        )
    
    # =============================================================================
    # === –î–û–ü–û–ú–Ü–ñ–ù–Ü –ú–ï–¢–û–î–ò ===
    # =============================================================================
    
    def _serialize_analysis_data(self, analysis_data: Dict) -> Dict:
        """–°–µ—Ä—ñ–∞–ª—ñ–∑—É—î –∞–Ω–∞–ª—ñ—Ç–∏—á–Ω—ñ –¥–∞–Ω—ñ –¥–ª—è JSON"""
        
        serialized = {}
        
        for key, value in analysis_data.items():
            try:
                if isinstance(value, np.ndarray):
                    serialized[key] = value.tolist()
                elif isinstance(value, pd.DataFrame):
                    serialized[key] = value.to_dict('records')
                elif isinstance(value, (list, dict, str, int, float, bool)):
                    serialized[key] = value
                else:
                    # –î–ª—è —ñ–Ω—à–∏—Ö —Ç–∏–ø—ñ–≤ –≤–∏–∫–æ—Ä–∏—Å—Ç–æ–≤—É—î–º–æ —Å—Ç—Ä–æ–∫–æ–≤–µ –ø—Ä–µ–¥—Å—Ç–∞–≤–ª–µ–Ω–Ω—è
                    serialized[key] = str(value)
            except Exception as e:
                self.logger.warning(f"–ù–µ –≤–¥–∞–ª–æ—Å—è —Å–µ—Ä—ñ–∞–ª—ñ–∑—É–≤–∞—Ç–∏ {key}: {e}")
                serialized[key] = f"<–ù–µ –≤–¥–∞–ª–æ—Å—è —Å–µ—Ä—ñ–∞–ª—ñ–∑—É–≤–∞—Ç–∏: {type(value).__name__}>"
        
        return serialized
    
    def _simplify_analysis_data(self, analysis_data: Dict) -> Dict:
        """–°–ø—Ä–æ—â—É—î –∞–Ω–∞–ª—ñ—Ç–∏—á–Ω—ñ –¥–∞–Ω—ñ –¥–ª—è Excel"""
        
        simplified = {}
        
        for key, value in analysis_data.items():
            try:
                if isinstance(value, np.ndarray):
                    # –î–ª—è –º–∞—Å–∏–≤—ñ–≤ –∑–±–µ—Ä—ñ–≥–∞—î–º–æ —Ç—ñ–ª—å–∫–∏ –æ—Å–Ω–æ–≤–Ω—É —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É
                    if value.size > 0:
                        simplified[f"{key}_mean"] = float(np.mean(value))
                        simplified[f"{key}_std"] = float(np.std(value))
                        simplified[f"{key}_min"] = float(np.min(value))
                        simplified[f"{key}_max"] = float(np.max(value))
                        simplified[f"{key}_size"] = int(value.size)
                elif isinstance(value, (list, tuple)):
                    simplified[f"{key}_length"] = len(value)
                    if len(value) > 0 and isinstance(value[0], (int, float)):
                        simplified[f"{key}_first"] = value[0]
                        simplified[f"{key}_last"] = value[-1]
                elif isinstance(value, dict):
                    simplified[f"{key}_keys_count"] = len(value)
                elif isinstance(value, (str, int, float, bool)):
                    simplified[key] = value
            except Exception as e:
                self.logger.warning(f"–ù–µ –≤–¥–∞–ª–æ—Å—è —Å–ø—Ä–æ—Å—Ç–∏—Ç–∏ {key}: {e}")
        
        return simplified
    
    def _generate_readme(self, package: EvaluationPackage) -> str:
        """–ì–µ–Ω–µ—Ä—É—î README —Ñ–∞–π–ª –¥–ª—è –∞—Ä—Ö—ñ–≤—É"""
        
        readme = f"""
üéØ –†–ï–ó–£–õ–¨–¢–ê–¢–ò –û–¶–Ü–ù–Æ–í–ê–ù–ù–Ø MPC –°–ò–ú–£–õ–Ø–¶–Ü–á
=====================================

–ó–ê–ì–ê–õ–¨–ù–ê –Ü–ù–§–û–†–ú–ê–¶–Ü–Ø:
-------------------
ID –°–∏–º—É–ª—è—Ü—ñ—ó: {package.metadata.simulation_id}
–ß–∞—Å —Å—Ç–≤–æ—Ä–µ–Ω–Ω—è: {package.metadata.timestamp}
–û–ø–∏—Å: {package.metadata.description}
–í–µ—Ä—Å—ñ—è: {package.metadata.version}

–ü–ê–†–ê–ú–ï–¢–†–ò –°–ò–ú–£–õ–Ø–¶–Ü–á:
-------------------
–ö—Ä–æ–∫–∏ —Å–∏–º—É–ª—è—Ü—ñ—ó: {package.metadata.simulation_steps}
–ß–∞—Å –∫—Ä–æ–∫—É (dt): {package.metadata.dt}
–£—Å—Ç–∞–≤–∫–∞ Fe: {package.metadata.ref_fe}%
–£—Å—Ç–∞–≤–∫–∞ Mass: {package.metadata.ref_mass} —Ç/–≥

–ü–ê–†–ê–ú–ï–¢–†–ò MPC:
--------------
–ì–æ—Ä–∏–∑–æ–Ω—Ç: {package.metadata.horizon}
–ú–∞–∫—Å–∏–º–∞–ª—å–Ω–∞ –∑–º—ñ–Ω–∞ –∫–µ—Ä—É–≤–∞–Ω–Ω—è: {package.metadata.delta_u_max}
Lambda —Ä–µ–≥—É–ª—è—Ä–∏–∑–∞—Ü—ñ—è: {package.parameters.get('lambda_u', 'N/A')}

–ü–ê–†–ê–ú–ï–¢–†–ò EKF:
--------------
Q –º–∞—Ç—Ä–∏—Ü—è: {package.metadata.Q_matrix}
R –º–∞—Ç—Ä–∏—Ü—è: {package.metadata.R_matrix}

–ü–ê–†–ê–ú–ï–¢–†–ò TRUST REGION:
----------------------
–ü–æ—á–∞—Ç–∫–æ–≤–∏–π —Ä–∞–¥—ñ—É—Å: {package.metadata.initial_trust_radius}
–ú—ñ–Ω—ñ–º–∞–ª—å–Ω–∏–π —Ä–∞–¥—ñ—É—Å: {package.metadata.min_trust_radius}
–ú–∞–∫—Å–∏–º–∞–ª—å–Ω–∏–π —Ä–∞–¥—ñ—É—Å: {package.metadata.max_trust_radius}

–ö–õ–Æ–ß–û–í–Ü –†–ï–ó–£–õ–¨–¢–ê–¢–ò:
------------------
–ó–∞–≥–∞–ª—å–Ω–∞ –æ—Ü—ñ–Ω–∫–∞: {package.evaluation_results.overall_score:.1f}/100
–°—Ç–∞–±—ñ–ª—å–Ω—ñ—Å—Ç—å –ø—Ä–æ—Ü–µ—Å—É: {package.evaluation_results.process_stability:.3f}

–ú–æ–¥–µ–ª—å Fe:
  - RMSE: {package.evaluation_results.model_rmse_fe:.3f}
  - R¬≤: {package.evaluation_results.model_r2_fe:.3f}
  - MAE: {package.evaluation_results.model_mae_fe:.3f}
  - MAPE: {package.evaluation_results.model_mape_fe:.2f}%

–ú–æ–¥–µ–ª—å Mass:
  - RMSE: {package.evaluation_results.model_rmse_mass:.3f}
  - R¬≤: {package.evaluation_results.model_r2_mass:.3f}
  - MAE: {package.evaluation_results.model_mae_mass:.3f}
  - MAPE: {package.evaluation_results.model_mape_mass:.2f}%

EKF –ï—Ñ–µ–∫—Ç–∏–≤–Ω—ñ—Å—Ç—å:
  - NEES: {package.evaluation_results.ekf_nees_mean:.2f} (—ñ–¥–µ–∞–ª ‚âà 2)
  - NIS: {package.evaluation_results.ekf_nis_mean:.2f} (—ñ–¥–µ–∞–ª ‚âà 2)
  - –ö–æ–Ω—Å–∏—Å—Ç–µ–Ω—Ç–Ω—ñ—Å—Ç—å: {package.evaluation_results.ekf_consistency:.3f}

Trust Region:
  - –°–µ—Ä–µ–¥–Ω—ñ–π —Ä–∞–¥—ñ—É—Å: {package.evaluation_results.trust_radius_mean:.3f}
  - –°—Ç–∞–±—ñ–ª—å–Ω—ñ—Å—Ç—å: {package.evaluation_results.trust_stability_index:.3f}
  - –ê–¥–∞–ø—Ç–∏–≤–Ω—ñ—Å—Ç—å: {package.evaluation_results.trust_adaptivity_coeff:.3f}

–í—ñ–¥—Å—Ç–µ–∂–µ–Ω–Ω—è —É—Å—Ç–∞–≤–æ–∫:
  - Fe –¥–æ—Å—è–≥–Ω–µ–Ω–Ω—è: {package.evaluation_results.setpoint_achievement_fe:.1f}%
  - Mass –¥–æ—Å—è–≥–Ω–µ–Ω–Ω—è: {package.evaluation_results.setpoint_achievement_mass:.1f}%
  - –ó–≥–ª–∞–¥–∂–µ–Ω—ñ—Å—Ç—å –∫–µ—Ä—É–≤–∞–Ω–Ω—è: {package.evaluation_results.control_smoothness:.3f}

–ß–∞—Å–æ–≤—ñ –º–µ—Ç—Ä–∏–∫–∏:
  - –ü–æ—á–∞—Ç–∫–æ–≤–µ –Ω–∞–≤—á–∞–Ω–Ω—è: {package.evaluation_results.initial_training_time:.2f} —Å–µ–∫
  - –°–µ—Ä–µ–¥–Ω—ñ–π —á–∞—Å –ø—Ä–æ–≥–Ω–æ–∑—É–≤–∞–Ω–Ω—è: {package.evaluation_results.avg_prediction_time:.2f} –º—Å
  - –ö—ñ–ª—å–∫—ñ—Å—Ç—å –ø–µ—Ä–µ–Ω–∞–≤—á–∞–Ω—å: {package.evaluation_results.total_retraining_count:.0f}

–ü–†–û–î–£–ö–¢–ò–í–ù–Ü–°–¢–¨:
--------------
{package.performance_summary}

–†–ï–ö–û–ú–ï–ù–î–ê–¶–Ü–á:
------------"""

        if package.recommendations:
            for i, rec in enumerate(package.recommendations, 1):
                readme += f"\n{i}. {rec}"
        else:
            readme += "\n–†–µ–∫–æ–º–µ–Ω–¥–∞—Ü—ñ—ó –Ω–µ –∑–≥–µ–Ω–µ—Ä–æ–≤–∞–Ω–æ"

        readme += f"""

–§–ê–ô–õ–ò –í –ê–†–•–Ü–í–Ü:
--------------
- evaluation_data.json: –ü–æ–≤–Ω—ñ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∏ –æ—Ü—ñ–Ω—é–≤–∞–Ω–Ω—è –≤ JSON —Ñ–æ—Ä–º–∞—Ç—ñ
- simulation_data.csv: –î–∞–Ω—ñ —Å–∏–º—É–ª—è—Ü—ñ—ó –≤ CSV —Ñ–æ—Ä–º–∞—Ç—ñ
- README.txt: –¶–µ–π —Ñ–∞–π–ª –∑ –æ–ø–∏—Å–æ–º

–ü–ï–†–ï–í–Ü–†–ö–ê –¶–Ü–õ–Ü–°–ù–û–°–¢–Ü:
--------------------
–•–µ—à –¥–∞–Ω–∏—Ö: {package.metadata.data_hash}

–í–ò–ö–û–†–ò–°–¢–ê–ù–ù–Ø:
------------
–î–ª—è –∑–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–Ω—è –≤–∏–∫–æ—Ä–∏—Å—Ç–æ–≤—É–π—Ç–µ:

```python
from evaluation_storage import EvaluationStorage

storage = EvaluationStorage()
package = storage.load_evaluation('–ø—É—Ç—å_–∫_—Ñ–∞–π–ª—É.zip')

# –î–æ—Å—Ç—É–ø –¥–æ –¥–∞–Ω–∏—Ö
results_df = package.simulation_data
eval_results = package.evaluation_results
metadata = package.metadata
```

–°—Ç–≤–æ—Ä–µ–Ω–æ –º–æ–¥—É–ª–µ–º evaluation_storage.py
"""
        return readme
    
    # =============================================================================
    # === –ú–ï–¢–û–î–ò –ü–û–®–£–ö–£ –¢–ê –£–ü–†–ê–í–õ–Ü–ù–ù–Ø ===
    # =============================================================================
    
    def list_saved_evaluations(self) -> pd.DataFrame:
        """–ü–æ–≤–µ—Ä—Ç–∞—î —Å–ø–∏—Å–æ–∫ –≤—Å—ñ—Ö –∑–±–µ—Ä–µ–∂–µ–Ω–∏—Ö –æ—Ü—ñ–Ω—é–≤–∞–Ω—å"""
        
        evaluations = []
        
        # –®—É–∫–∞—î–º–æ –≤—Å—ñ –ø—ñ–¥—Ç—Ä–∏–º—É–≤–∞–Ω—ñ —Ñ–æ—Ä–º–∞—Ç–∏
        for file_path in self.base_dir.rglob('*'):
            if file_path.is_file():
                suffix = file_path.suffix.lower()
                if suffix in ['.json', '.pkl', '.xlsx', '.zip']:
                    try:
                        # –°–ø—Ä–æ–±—É—î–º–æ —à–≤–∏–¥–∫–æ –≤–∏—Ç—è–≥—Ç–∏ –º–µ—Ç–∞–¥–∞–Ω—ñ
                        metadata = self._extract_metadata_fast(file_path)
                        if metadata:
                            eval_info = {
                                'filename': file_path.name,
                                'filepath': str(file_path),
                                'format': suffix[1:],
                                'size_mb': file_path.stat().st_size / (1024*1024),
                                'modified': datetime.fromtimestamp(file_path.stat().st_mtime),
                                'simulation_id': metadata.get('simulation_id', 'Unknown'),
                                'description': metadata.get('description', ''),
                                'simulation_steps': metadata.get('simulation_steps', 0),
                                'overall_score': metadata.get('overall_score', 0.0)
                            }
                            evaluations.append(eval_info)
                    except Exception as e:
                        self.logger.warning(f"–ù–µ –≤–¥–∞–ª–æ—Å—è –æ–±—Ä–æ–±–∏—Ç–∏ —Ñ–∞–π–ª {file_path}: {e}")
        
        return pd.DataFrame(evaluations)
    
    def _extract_metadata_fast(self, filepath: Path) -> Optional[Dict]:
        """–®–≤–∏–¥–∫–µ –≤–∏—Ç—è–≥—É–≤–∞–Ω–Ω—è –æ—Å–Ω–æ–≤–Ω–∏—Ö –º–µ—Ç–∞–¥–∞–Ω–∏—Ö –±–µ–∑ –ø–æ–≤–Ω–æ–≥–æ –∑–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–Ω—è"""
        
        try:
            suffix = filepath.suffix.lower()
            
            if suffix == '.json':
                with open(filepath, 'r', encoding='utf-8') as f:
                    data = json.load(f)
                metadata = data.get('metadata', {})
                eval_results = data.get('evaluation_results', {})
                return {**metadata, 'overall_score': eval_results.get('overall_score', 0.0)}
            
            elif suffix == '.zip':
                with zipfile.ZipFile(filepath, 'r') as zf:
                    json_content = zf.read('evaluation_data.json').decode('utf-8')
                    data = json.loads(json_content)
                    metadata = data.get('metadata', {})
                    eval_results = data.get('evaluation_results', {})
                    return {**metadata, 'overall_score': eval_results.get('overall_score', 0.0)}
            
            # –î–ª—è —ñ–Ω—à–∏—Ö —Ñ–æ—Ä–º–∞—Ç—ñ–≤ –ø–æ–≤–µ—Ä—Ç–∞—î–º–æ –±–∞–∑–æ–≤—É —ñ–Ω—Ñ–æ—Ä–º–∞—Ü—ñ—é
            return {'simulation_id': filepath.stem, 'description': '', 'simulation_steps': 0}
            
        except Exception:
            return None
    
    def find_evaluations(self, 
                        simulation_id: Optional[str] = None,
                        min_score: Optional[float] = None,
                        max_score: Optional[float] = None,
                        date_from: Optional[str] = None,
                        date_to: Optional[str] = None) -> pd.DataFrame:
        """
        –ó–Ω–∞—Ö–æ–¥–∏—Ç—å –æ—Ü—ñ–Ω—é–≤–∞–Ω–Ω—è –∑–∞ –∫—Ä–∏—Ç–µ—Ä—ñ—è–º–∏
        
        Args:
            simulation_id: ID —Å–∏–º—É–ª—è—Ü—ñ—ó (—á–∞—Å—Ç–∫–æ–≤–µ —Å–ø—ñ–≤–ø–∞–¥—ñ–Ω–Ω—è)
            min_score: –ú—ñ–Ω—ñ–º–∞–ª—å–Ω–∞ –∑–∞–≥–∞–ª—å–Ω–∞ –æ—Ü—ñ–Ω–∫–∞
            max_score: –ú–∞–∫—Å–∏–º–∞–ª—å–Ω–∞ –∑–∞–≥–∞–ª—å–Ω–∞ –æ—Ü—ñ–Ω–∫–∞  
            date_from: –î–∞—Ç–∞ –≤—ñ–¥ (YYYY-MM-DD)
            date_to: –î–∞—Ç–∞ –¥–æ (YYYY-MM-DD)
            
        Returns:
            DataFrame –∑ –≤—ñ–¥—Ñ—ñ–ª—å—Ç—Ä–æ–≤–∞–Ω–∏–º–∏ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞–º–∏
        """
        
        df = self.list_saved_evaluations()
        
        if df.empty:
            return df
        
        # –§—ñ–ª—å—Ç—Ä–∞—Ü—ñ—è
        if simulation_id:
            df = df[df['simulation_id'].str.contains(simulation_id, case=False, na=False)]
        
        if min_score is not None:
            df = df[df['overall_score'] >= min_score]
        
        if max_score is not None:
            df = df[df['overall_score'] <= max_score]
        
        if date_from:
            date_from_dt = pd.to_datetime(date_from)
            df = df[df['modified'] >= date_from_dt]
        
        if date_to:
            date_to_dt = pd.to_datetime(date_to)
            df = df[df['modified'] <= date_to_dt]
        
        return df.sort_values('overall_score', ascending=False)
    
    def delete_evaluation(self, filepath: Union[str, Path]) -> bool:
        """
        –í–∏–¥–∞–ª—è—î –∑–±–µ—Ä–µ–∂–µ–Ω–µ –æ—Ü—ñ–Ω—é–≤–∞–Ω–Ω—è
        
        Args:
            filepath: –®–ª—è—Ö –¥–æ —Ñ–∞–π–ª—É –∞–±–æ –¥–∏—Ä–µ–∫—Ç–æ—Ä—ñ—ó
            
        Returns:
            True —è–∫—â–æ —É—Å–ø—ñ—à–Ω–æ –≤–∏–¥–∞–ª–µ–Ω–æ
        """
        
        filepath = Path(filepath)
        
        try:
            if filepath.is_file():
                filepath.unlink()
                self.logger.info(f"–§–∞–π–ª –≤–∏–¥–∞–ª–µ–Ω–æ: {filepath}")
                return True
            elif filepath.is_dir():
                import shutil
                shutil.rmtree(filepath)
                self.logger.info(f"–î–∏—Ä–µ–∫—Ç–æ—Ä—ñ—é –≤–∏–¥–∞–ª–µ–Ω–æ: {filepath}")
                return True
            else:
                self.logger.warning(f"–§–∞–π–ª –Ω–µ –∑–Ω–∞–π–¥–µ–Ω–æ: {filepath}")
                return False
        except Exception as e:
            self.logger.error(f"–ü–æ–º–∏–ª–∫–∞ –ø—Ä–∏ –≤–∏–¥–∞–ª–µ–Ω–Ω—ñ {filepath}: {e}")
            return False
    
    def cleanup_old_evaluations(self, days_old: int = 30) -> int:
        """
        –í–∏–¥–∞–ª—è—î —Å—Ç–∞—Ä—ñ –æ—Ü—ñ–Ω—é–≤–∞–Ω–Ω—è
        
        Args:
            days_old: –í–∏–¥–∞–ª–∏—Ç–∏ —Ñ–∞–π–ª–∏ —Å—Ç–∞—Ä—à—ñ –∑–∞ –∫—ñ–ª—å–∫—ñ—Å—Ç—å –¥–Ω—ñ–≤
            
        Returns:
            –ö—ñ–ª—å–∫—ñ—Å—Ç—å –≤–∏–¥–∞–ª–µ–Ω–∏—Ö —Ñ–∞–π–ª—ñ–≤
        """
        
        cutoff_date = datetime.now() - pd.Timedelta(days=days_old)
        df = self.list_saved_evaluations()
        
        old_files = df[df['modified'] < cutoff_date]
        deleted_count = 0
        
        for _, row in old_files.iterrows():
            if self.delete_evaluation(row['filepath']):
                deleted_count += 1
        
        self.logger.info(f"–í–∏–¥–∞–ª–µ–Ω–æ {deleted_count} —Å—Ç–∞—Ä–∏—Ö —Ñ–∞–π–ª—ñ–≤ (—Å—Ç–∞—Ä—à–µ {days_old} –¥–Ω—ñ–≤)")
        return deleted_count
    
    # =============================================================================
    # === –ú–ï–¢–û–î–ò –ü–û–†–Ü–í–ù–Ø–ù–ù–Ø ===
    # =============================================================================
    
    def compare_evaluations_from_files(self, filepaths: List[Union[str, Path]]) -> pd.DataFrame:
        """
        –ü–æ—Ä—ñ–≤–Ω—é—î —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∏ –∑ –∫—ñ–ª—å–∫–æ—Ö —Ñ–∞–π–ª—ñ–≤
        
        Args:
            filepaths: –°–ø–∏—Å–æ–∫ —à–ª—è—Ö—ñ–≤ –¥–æ —Ñ–∞–π–ª—ñ–≤
            
        Returns:
            DataFrame –∑ –ø–æ—Ä—ñ–≤–Ω—è–Ω–Ω—è–º –º–µ—Ç—Ä–∏–∫
        """
        
        packages = {}
        
        for filepath in filepaths:
            try:
                package = self.load_evaluation(filepath)
                name = f"{package.metadata.simulation_id[:8]}..."
                packages[name] = package
            except Exception as e:
                self.logger.error(f"–ù–µ –≤–¥–∞–ª–æ—Å—è –∑–∞–≤–∞–Ω—Ç–∞–∂–∏—Ç–∏ {filepath}: {e}")
        
        if not packages:
            return pd.DataFrame()
        
        return self._create_comparison_dataframe(packages)
    
    def _create_comparison_dataframe(self, packages: Dict[str, EvaluationPackage]) -> pd.DataFrame:
        """–°—Ç–≤–æ—Ä—é—î DataFrame –¥–ª—è –ø–æ—Ä—ñ–≤–Ω—è–Ω–Ω—è —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ñ–≤"""
        
        comparison_data = {}
        
        for name, package in packages.items():
            eval_dict = package.evaluation_results.to_dict()
            comparison_data[name] = eval_dict
        
        df = pd.DataFrame(comparison_data)
        
        # –î–æ–¥–∞—î–º–æ –∫–∞—Ç–µ–≥–æ—Ä—ñ—ó –º–µ—Ç—Ä–∏–∫ –¥–ª—è –∫—Ä–∞—â–æ—ó –æ—Ä–≥–∞–Ω—ñ–∑–∞—Ü—ñ—ó
        metric_categories = {
            '–ú–æ–¥–µ–ª—å Fe': ['model_rmse_fe', 'model_r2_fe', 'model_mae_fe', 'model_mape_fe', 'model_bias_fe'],
            '–ú–æ–¥–µ–ª—å Mass': ['model_rmse_mass', 'model_r2_mass', 'model_mae_mass', 'model_mape_mass', 'model_bias_mass'],
            'EKF': ['ekf_rmse_fe', 'ekf_rmse_mass', 'ekf_nees_mean', 'ekf_nis_mean', 'ekf_consistency'],
            'Trust Region': ['trust_radius_mean', 'trust_radius_std', 'trust_stability_index', 'trust_adaptivity_coeff'],
            '–í—ñ–¥—Å—Ç–µ–∂–µ–Ω–Ω—è': ['tracking_error_fe', 'tracking_error_mass', 'setpoint_achievement_fe', 'setpoint_achievement_mass'],
            '–ö–µ—Ä—É–≤–∞–Ω–Ω—è': ['control_smoothness', 'control_aggressiveness', 'control_stability_index'],
            '–ß–∞—Å': ['initial_training_time', 'avg_retraining_time', 'avg_prediction_time'],
            '–ó–∞–≥–∞–ª—å–Ω–µ': ['overall_score', 'process_stability']
        }
        
        # –†–µ–æ—Ä–≥–∞–Ω—ñ–∑—É—î–º–æ DataFrame –∑–∞ –∫–∞—Ç–µ–≥–æ—Ä—ñ—è–º–∏
        organized_df = pd.DataFrame()
        for category, metrics in metric_categories.items():
            for metric in metrics:
                if metric in df.index:
                    organized_df.loc[f"{category}: {metric}", :] = df.loc[metric, :]
        
        return organized_df
    
    # =============================================================================
    # === –ú–ï–¢–û–î–ò –ï–ö–°–ü–û–†–¢–£ –ó–í–Ü–¢–Ü–í ===
    # =============================================================================
    
    def generate_report(self, package: EvaluationPackage, 
                       report_type: str = 'html') -> str:
        """
        –ì–µ–Ω–µ—Ä—É—î –∑–≤—ñ—Ç –ø—Ä–æ –æ—Ü—ñ–Ω—é–≤–∞–Ω–Ω—è
        
        Args:
            package: –ü–∞–∫–µ—Ç —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ñ–≤
            report_type: –¢–∏–ø –∑–≤—ñ—Ç—É ('html', 'pdf', 'markdown')
            
        Returns:
            –®–ª—è—Ö –¥–æ —Å—Ç–≤–æ—Ä–µ–Ω–æ–≥–æ –∑–≤—ñ—Ç—É
        """
        
        if report_type == 'html':
            return self._generate_html_report(package)
        elif report_type == 'markdown':
            return self._generate_markdown_report(package)
        else:
            raise ValueError(f"–ù–µ–ø—ñ–¥—Ç—Ä–∏–º—É–≤–∞–Ω–∏–π —Ç–∏–ø –∑–≤—ñ—Ç—É: {report_type}")
    
    def _generate_html_report(self, package: EvaluationPackage) -> str:
        """–ì–µ–Ω–µ—Ä—É—î HTML –∑–≤—ñ—Ç"""
        
        html_content = f"""
<!DOCTYPE html>
<html lang="uk">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>–ó–≤—ñ—Ç MPC –û—Ü—ñ–Ω—é–≤–∞–Ω–Ω—è - {package.metadata.simulation_id}</title>
    <style>
        body {{ font-family: Arial, sans-serif; margin: 20px; line-height: 1.6; }}
        .header {{ background: #f4f4f4; padding: 20px; border-radius: 5px; }}
        .metric-group {{ margin: 20px 0; padding: 15px; border: 1px solid #ddd; border-radius: 5px; }}
        .metric {{ display: flex; justify-content: space-between; margin: 5px 0; }}
        .score {{ font-size: 2em; color: #2c3e50; font-weight: bold; }}
        table {{ width: 100%; border-collapse: collapse; margin: 10px 0; }}
        th, td {{ border: 1px solid #ddd; padding: 8px; text-align: left; }}
        th {{ background-color: #f2f2f2; }}
        .good {{ color: #27ae60; }}
        .warning {{ color: #f39c12; }}
        .bad {{ color: #e74c3c; }}
    </style>
</head>
<body>
    <div class="header">
        <h1>üéØ –ó–≤—ñ—Ç MPC –û—Ü—ñ–Ω—é–≤–∞–Ω–Ω—è</h1>
        <p><strong>ID –°–∏–º—É–ª—è—Ü—ñ—ó:</strong> {package.metadata.simulation_id}</p>
        <p><strong>–î–∞—Ç–∞:</strong> {package.metadata.timestamp}</p>
        <p><strong>–û–ø–∏—Å:</strong> {package.metadata.description}</p>
        <div class="score">–ó–∞–≥–∞–ª—å–Ω–∞ –æ—Ü—ñ–Ω–∫–∞: {package.evaluation_results.overall_score:.1f}/100</div>
    </div>
    
    <div class="metric-group">
        <h2>üìä –ö–ª—é—á–æ–≤—ñ –ú–µ—Ç—Ä–∏–∫–∏</h2>
        <div class="metric"><span>–°—Ç–∞–±—ñ–ª—å–Ω—ñ—Å—Ç—å –ø—Ä–æ—Ü–µ—Å—É:</span><span>{package.evaluation_results.process_stability:.3f}</span></div>
        <div class="metric"><span>EKF –ö–æ–Ω—Å–∏—Å—Ç–µ–Ω—Ç–Ω—ñ—Å—Ç—å:</span><span>{package.evaluation_results.ekf_consistency:.3f}</span></div>
        <div class="metric"><span>Trust Region –°—Ç–∞–±—ñ–ª—å–Ω—ñ—Å—Ç—å:</span><span>{package.evaluation_results.trust_stability_index:.3f}</span></div>
    </div>
    
    <div class="metric-group">
        <h2>üéØ –Ø–∫—ñ—Å—Ç—å –ú–æ–¥–µ–ª–µ–π</h2>
        <table>
            <tr><th>–ú–µ—Ç—Ä–∏–∫–∞</th><th>Fe</th><th>Mass</th></tr>
            <tr><td>RMSE</td><td>{package.evaluation_results.model_rmse_fe:.3f}</td><td>{package.evaluation_results.model_rmse_mass:.3f}</td></tr>
            <tr><td>R¬≤</td><td>{package.evaluation_results.model_r2_fe:.3f}</td><td>{package.evaluation_results.model_r2_mass:.3f}</td></tr>
            <tr><td>MAE</td><td>{package.evaluation_results.model_mae_fe:.3f}</td><td>{package.evaluation_results.model_mae_mass:.3f}</td></tr>
            <tr><td>MAPE (%)</td><td>{package.evaluation_results.model_mape_fe:.2f}</td><td>{package.evaluation_results.model_mape_mass:.2f}</td></tr>
        </table>
    </div>
    
    <div class="metric-group">
        <h2>üîç EKF –ê–Ω–∞–ª—ñ–∑</h2>
        <table>
            <tr><th>–ú–µ—Ç—Ä–∏–∫–∞</th><th>–ó–Ω–∞—á–µ–Ω–Ω—è</th><th>–Ü–¥–µ–∞–ª</th></tr>
            <tr><td>NEES</td><td>{package.evaluation_results.ekf_nees_mean:.2f}</td><td>‚âà 2</td></tr>
            <tr><td>NIS</td><td>{package.evaluation_results.ekf_nis_mean:.2f}</td><td>‚âà 2</td></tr>
            <tr><td>–ó–∞–≥–∞–ª—å–Ω–∞ –∫–æ–Ω—Å–∏—Å—Ç–µ–Ω—Ç–Ω—ñ—Å—Ç—å</td><td>{package.evaluation_results.ekf_consistency:.3f}</td><td>> 0.7</td></tr>
        </table>
    </div>
    
    <div class="metric-group">
        <h2>üéõÔ∏è Trust Region</h2>
        <div class="metric"><span>–°–µ—Ä–µ–¥–Ω—ñ–π —Ä–∞–¥—ñ—É—Å:</span><span>{package.evaluation_results.trust_radius_mean:.3f}</span></div>
        <div class="metric"><span>–î—ñ–∞–ø–∞–∑–æ–Ω:</span><span>[{package.evaluation_results.trust_radius_min:.3f}, {package.evaluation_results.trust_radius_max:.3f}]</span></div>
        <div class="metric"><span>–ê–¥–∞–ø—Ç–∏–≤–Ω—ñ—Å—Ç—å:</span><span>{package.evaluation_results.trust_adaptivity_coeff:.3f}</span></div>
    </div>
    
    <div class="metric-group">
        <h2>üéÆ –Ø–∫—ñ—Å—Ç—å –ö–µ—Ä—É–≤–∞–Ω–Ω—è</h2>
        <table>
            <tr><th>–ú–µ—Ç—Ä–∏–∫–∞</th><th>Fe</th><th>Mass</th></tr>
            <tr><td>–î–æ—Å—è–≥–Ω–µ–Ω–Ω—è —É—Å—Ç–∞–≤–∫–∏ (%)</td><td>{package.evaluation_results.setpoint_achievement_fe:.1f}</td><td>{package.evaluation_results.setpoint_achievement_mass:.1f}</td></tr>
            <tr><td>Tracking MAE</td><td>{package.evaluation_results.tracking_mae_fe:.3f}</td><td>{package.evaluation_results.tracking_mae_mass:.3f}</td></tr>
            <tr><td>Tracking MAPE (%)</td><td>{package.evaluation_results.tracking_mape_fe:.2f}</td><td>{package.evaluation_results.tracking_mape_mass:.2f}</td></tr>
        </table>
        <div class="metric"><span>–ó–≥–ª–∞–¥–∂–µ–Ω—ñ—Å—Ç—å –∫–µ—Ä—É–≤–∞–Ω–Ω—è:</span><span>{package.evaluation_results.control_smoothness:.3f}</span></div>
    </div>
    
    <div class="metric-group">
        <h2>‚è±Ô∏è –ü—Ä–æ–¥—É–∫—Ç–∏–≤–Ω—ñ—Å—Ç—å</h2>
        <div class="metric"><span>–ü–æ—á–∞—Ç–∫–æ–≤–µ –Ω–∞–≤—á–∞–Ω–Ω—è:</span><span>{package.evaluation_results.initial_training_time:.2f} —Å–µ–∫</span></div>
        <div class="metric"><span>–ß–∞—Å –ø—Ä–æ–≥–Ω–æ–∑—É–≤–∞–Ω–Ω—è:</span><span>{package.evaluation_results.avg_prediction_time:.2f} –º—Å</span></div>
        <div class="metric"><span>–ö—ñ–ª—å–∫—ñ—Å—Ç—å –ø–µ—Ä–µ–Ω–∞–≤—á–∞–Ω—å:</span><span>{package.evaluation_results.total_retraining_count:.0f}</span></div>
    </div>
    
    <div class="metric-group">
        <h2>üí° –†–µ–∫–æ–º–µ–Ω–¥–∞—Ü—ñ—ó</h2>
        <ul>"""
        
        for rec in package.recommendations:
            html_content += f"<li>{rec}</li>"
        
        html_content += """
        </ul>
    </div>
</body>
</html>"""
        
        # –ó–±–µ—Ä—ñ–≥–∞—î–º–æ —Ñ–∞–π–ª
        report_path = self.base_dir / f"report_{package.metadata.simulation_id}_{datetime.now().strftime('%Y%m%d_%H%M%S')}.html"
        
        with open(report_path, 'w', encoding='utf-8') as f:
            f.write(html_content)
        
        self.logger.info(f"HTML –∑–≤—ñ—Ç —Å—Ç–≤–æ—Ä–µ–Ω–æ: {report_path}")
        return str(report_path)
    
    def _generate_markdown_report(self, package: EvaluationPackage) -> str:
        """–ì–µ–Ω–µ—Ä—É—î Markdown –∑–≤—ñ—Ç"""
        
        md_content = f"""# üéØ –ó–≤—ñ—Ç MPC –û—Ü—ñ–Ω—é–≤–∞–Ω–Ω—è

## –ó–∞–≥–∞–ª—å–Ω–∞ –Ü–Ω—Ñ–æ—Ä–º–∞—Ü—ñ—è
- **ID –°–∏–º—É–ª—è—Ü—ñ—ó:** {package.metadata.simulation_id}
- **–î–∞—Ç–∞:** {package.metadata.timestamp}
- **–û–ø–∏—Å:** {package.metadata.description}
- **–ó–∞–≥–∞–ª—å–Ω–∞ –æ—Ü—ñ–Ω–∫–∞:** **{package.evaluation_results.overall_score:.1f}/100**

## üìä –ö–ª—é—á–æ–≤—ñ –ú–µ—Ç—Ä–∏–∫–∏
- –°—Ç–∞–±—ñ–ª—å–Ω—ñ—Å—Ç—å –ø—Ä–æ—Ü–µ—Å—É: {package.evaluation_results.process_stability:.3f}
- EKF –ö–æ–Ω—Å–∏—Å—Ç–µ–Ω—Ç–Ω—ñ—Å—Ç—å: {package.evaluation_results.ekf_consistency:.3f}
- Trust Region –°—Ç–∞–±—ñ–ª—å–Ω—ñ—Å—Ç—å: {package.evaluation_results.trust_stability_index:.3f}

## üéØ –Ø–∫—ñ—Å—Ç—å –ú–æ–¥–µ–ª–µ–π

| –ú–µ—Ç—Ä–∏–∫–∞ | Fe | Mass |
|---------|-------|-------|
| RMSE | {package.evaluation_results.model_rmse_fe:.3f} | {package.evaluation_results.model_rmse_mass:.3f} |
| R¬≤ | {package.evaluation_results.model_r2_fe:.3f} | {package.evaluation_results.model_r2_mass:.3f} |
| MAE | {package.evaluation_results.model_mae_fe:.3f} | {package.evaluation_results.model_mae_mass:.3f} |
| MAPE (%) | {package.evaluation_results.model_mape_fe:.2f} | {package.evaluation_results.model_mape_mass:.2f} |

## üîç EKF –ê–Ω–∞–ª—ñ–∑

| –ú–µ—Ç—Ä–∏–∫–∞ | –ó–Ω–∞—á–µ–Ω–Ω—è | –Ü–¥–µ–∞–ª |
|---------|----------|-------|
| NEES | {package.evaluation_results.ekf_nees_mean:.2f} | ‚âà 2 |
| NIS | {package.evaluation_results.ekf_nis_mean:.2f} | ‚âà 2 |
| –ö–æ–Ω—Å–∏—Å—Ç–µ–Ω—Ç–Ω—ñ—Å—Ç—å | {package.evaluation_results.ekf_consistency:.3f} | > 0.7 |

## üéõÔ∏è Trust Region
- –°–µ—Ä–µ–¥–Ω—ñ–π —Ä–∞–¥—ñ—É—Å: {package.evaluation_results.trust_radius_mean:.3f}
- –î—ñ–∞–ø–∞–∑–æ–Ω: [{package.evaluation_results.trust_radius_min:.3f}, {package.evaluation_results.trust_radius_max:.3f}]
- –ê–¥–∞–ø—Ç–∏–≤–Ω—ñ—Å—Ç—å: {package.evaluation_results.trust_adaptivity_coeff:.3f}

## üéÆ –Ø–∫—ñ—Å—Ç—å –ö–µ—Ä—É–≤–∞–Ω–Ω—è

| –ú–µ—Ç—Ä–∏–∫–∞ | Fe | Mass |
|---------|-------|-------|
| –î–æ—Å—è–≥–Ω–µ–Ω–Ω—è —É—Å—Ç–∞–≤–∫–∏ (%) | {package.evaluation_results.setpoint_achievement_fe:.1f} | {package.evaluation_results.setpoint_achievement_mass:.1f} |
| Tracking MAE | {package.evaluation_results.tracking_mae_fe:.3f} | {package.evaluation_results.tracking_mae_mass:.3f} |
| Tracking MAPE (%) | {package.evaluation_results.tracking_mape_fe:.2f} | {package.evaluation_results.tracking_mape_mass:.2f} |

- –ó–≥–ª–∞–¥–∂–µ–Ω—ñ—Å—Ç—å –∫–µ—Ä—É–≤–∞–Ω–Ω—è: {package.evaluation_results.control_smoothness:.3f}

## ‚è±Ô∏è –ü—Ä–æ–¥—É–∫—Ç–∏–≤–Ω—ñ—Å—Ç—å
- –ü–æ—á–∞—Ç–∫–æ–≤–µ –Ω–∞–≤—á–∞–Ω–Ω—è: {package.evaluation_results.initial_training_time:.2f} —Å–µ–∫
- –ß–∞—Å –ø—Ä–æ–≥–Ω–æ–∑—É–≤–∞–Ω–Ω—è: {package.evaluation_results.avg_prediction_time:.2f} –º—Å  
- –ö—ñ–ª—å–∫—ñ—Å—Ç—å –ø–µ—Ä–µ–Ω–∞–≤—á–∞–Ω—å: {package.evaluation_results.total_retraining_count:.0f}

## üí° –†–µ–∫–æ–º–µ–Ω–¥–∞—Ü—ñ—ó
"""
        
        for i, rec in enumerate(package.recommendations, 1):
            md_content += f"{i}. {rec}\n"
        
        # –ó–±–µ—Ä—ñ–≥–∞—î–º–æ —Ñ–∞–π–ª
        report_path = self.base_dir / f"report_{package.metadata.simulation_id}_{datetime.now().strftime('%Y%m%d_%H%M%S')}.md"
        
        with open(report_path, 'w', encoding='utf-8') as f:
            f.write(md_content)
        
        self.logger.info(f"Markdown –∑–≤—ñ—Ç —Å—Ç–≤–æ—Ä–µ–Ω–æ: {report_path}")
        return str(report_path)

# =============================================================================
# === –§–£–ù–ö–¶–Ü–á –í–ò–°–û–ö–û–ì–û –†–Ü–í–ù–Ø ===
# =============================================================================

def quick_save(results_df: pd.DataFrame, 
               eval_results: EvaluationResults,
               analysis_data: Dict,
               params: Dict,
               description: str = "",
               base_dir: str = "evaluation_results") -> str:
    """
    –®–≤–∏–¥–∫–µ –∑–±–µ—Ä–µ–∂–µ–Ω–Ω—è —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ñ–≤ —É ZIP —Ñ–æ—Ä–º–∞—Ç—ñ
    
    Args:
        results_df: DataFrame –∑ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞–º–∏ —Å–∏–º—É–ª—è—Ü—ñ—ó
        eval_results: –†–µ–∑—É–ª—å—Ç–∞—Ç–∏ –æ—Ü—ñ–Ω—é–≤–∞–Ω–Ω—è
        analysis_data: –î–æ–¥–∞—Ç–∫–æ–≤—ñ –¥–∞–Ω—ñ –∞–Ω–∞–ª—ñ–∑—É
        params: –ü–∞—Ä–∞–º–µ—Ç—Ä–∏ —Å–∏–º—É–ª—è—Ü—ñ—ó
        description: –û–ø–∏—Å —Å–∏–º—É–ª—è—Ü—ñ—ó
        base_dir: –ë–∞–∑–æ–≤–∞ –¥–∏—Ä–µ–∫—Ç–æ—Ä—ñ—è
        
    Returns:
        –®–ª—è—Ö –¥–æ –∑–±–µ—Ä–µ–∂–µ–Ω–æ–≥–æ —Ñ–∞–π–ª—É
    """
    
    storage = EvaluationStorage(base_dir)
    
    package = storage.create_evaluation_package(
        results_df=results_df,
        eval_results=eval_results,
        analysis_data=analysis_data,
        params=params,
        description=description
    )
    
    return storage.save_evaluation(package, format_type='zip')

def quick_load(filepath: Union[str, Path]) -> EvaluationPackage:
    """
    –®–≤–∏–¥–∫–µ –∑–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–Ω—è —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ñ–≤
    
    Args:
        filepath: –®–ª—è—Ö –¥–æ —Ñ–∞–π–ª—É
        
    Returns:
        EvaluationPackage –∑ –∑–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–∏–º–∏ –¥–∞–Ω–∏–º–∏
    """
    
    storage = EvaluationStorage()
    return storage.load_evaluation(filepath)

def compare_saved_evaluations(filepaths: List[Union[str, Path]]) -> pd.DataFrame:
    """
    –ü–æ—Ä—ñ–≤–Ω—è–Ω–Ω—è –∑–±–µ—Ä–µ–∂–µ–Ω–∏—Ö –æ—Ü—ñ–Ω—é–≤–∞–Ω—å
    
    Args:
        filepaths: –°–ø–∏—Å–æ–∫ —à–ª—è—Ö—ñ–≤ –¥–æ —Ñ–∞–π–ª—ñ–≤
        
    Returns:
        DataFrame –∑ –ø–æ—Ä—ñ–≤–Ω—è–Ω–Ω—è–º
    """
    
    storage = EvaluationStorage()
    return storage.compare_evaluations_from_files(filepaths)

# =============================================================================
# === –ü–†–ò–ö–õ–ê–î –í–ò–ö–û–†–ò–°–¢–ê–ù–ù–Ø ===
# =============================================================================

if __name__ == "__main__":
    print("üîß evaluation_storage.py - –ú–æ–¥—É–ª—å –∑–±–µ—Ä–µ–∂–µ–Ω–Ω—è/–∑–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–Ω—è —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ñ–≤")
    print("\n–û—Å–Ω–æ–≤–Ω—ñ —Ñ—É–Ω–∫—Ü—ñ—ó:")
    print("1. quick_save() - –®–≤–∏–¥–∫–µ –∑–±–µ—Ä–µ–∂–µ–Ω–Ω—è")
    print("2. quick_load() - –®–≤–∏–¥–∫–µ –∑–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–Ω—è")
    print("3. EvaluationStorage() - –ü–æ–≤–Ω–∏–π –º–µ–Ω–µ–¥–∂–µ—Ä")
    print("4. compare_saved_evaluations() - –ü–æ—Ä—ñ–≤–Ω—è–Ω–Ω—è —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ñ–≤")
    
    print("\n–ü—Ä–∏–∫–ª–∞–¥ –≤–∏–∫–æ—Ä–∏—Å—Ç–∞–Ω–Ω—è:")
    print("""
# –ó–±–µ—Ä–µ–∂–µ–Ω–Ω—è —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ñ–≤
from evaluation_storage import quick_save, EvaluationStorage

# –®–≤–∏–¥–∫–µ –∑–±–µ—Ä–µ–∂–µ–Ω–Ω—è
filepath = quick_save(
    results_df=simulation_results,
    eval_results=evaluation_results, 
    analysis_data=analysis_data,
    params=simulation_params,
    description="–¢–µ—Å—Ç –Ω–æ–≤–∏—Ö –ø–∞—Ä–∞–º–µ—Ç—Ä—ñ–≤ MPC"
)

# –†–æ–∑—à–∏—Ä–µ–Ω–µ –∑–±–µ—Ä–µ–∂–µ–Ω–Ω—è –∑ —Ä—ñ–∑–Ω–∏–º–∏ —Ñ–æ—Ä–º–∞—Ç–∞–º–∏
storage = EvaluationStorage("my_results")

package = storage.create_evaluation_package(
    results_df=results_df,
    eval_results=eval_results,
    analysis_data=analysis_data,
    params=params,
    description="–ï–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç –∑ Trust Region"
)

# –ó–±–µ—Ä–µ–∂–µ–Ω–Ω—è —É —Ä—ñ–∑–Ω–∏—Ö —Ñ–æ—Ä–º–∞—Ç–∞—Ö
zip_path = storage.save_evaluation(package, 'zip')
excel_path = storage.save_evaluation(package, 'excel') 
json_path = storage.save_evaluation(package, 'json')

# –ó–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–Ω—è —Ç–∞ –∞–Ω–∞–ª—ñ–∑
loaded_package = storage.load_evaluation(zip_path)
print(f"–ó–∞–≥–∞–ª—å–Ω–∞ –æ—Ü—ñ–Ω–∫–∞: {loaded_package.evaluation_results.overall_score}")

# –ü–æ—à—É–∫ –∑–±–µ—Ä–µ–∂–µ–Ω–∏—Ö —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ñ–≤
saved_evals = storage.list_saved_evaluations()
print(saved_evals)

# –ü–æ—à—É–∫ –∑–∞ –∫—Ä–∏—Ç–µ—Ä—ñ—è–º–∏
good_results = storage.find_evaluations(min_score=80.0)
recent_results = storage.find_evaluations(date_from="2024-01-01")

# –ü–æ—Ä—ñ–≤–Ω—è–Ω–Ω—è —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ñ–≤
comparison = storage.compare_evaluations_from_files([
    "eval1.zip", "eval2.zip", "eval3.zip"
])
print(comparison)

# –ì–µ–Ω–µ—Ä–∞—Ü—ñ—è –∑–≤—ñ—Ç—ñ–≤
html_report = storage.generate_report(package, 'html')
md_report = storage.generate_report(package, 'markdown')

# –û—á–∏—â–µ–Ω–Ω—è —Å—Ç–∞—Ä–∏—Ö —Ñ–∞–π–ª—ñ–≤
deleted_count = storage.cleanup_old_evaluations(days_old=30)
print(f"–í–∏–¥–∞–ª–µ–Ω–æ {deleted_count} —Å—Ç–∞—Ä–∏—Ö —Ñ–∞–π–ª—ñ–≤")
""")
    
    print("\n–ü—ñ–¥—Ç—Ä–∏–º—É–≤–∞–Ω—ñ —Ñ–æ—Ä–º–∞—Ç–∏:")
    print("- ZIP: –ü–æ–≤–Ω–∏–π –∞—Ä—Ö—ñ–≤ –∑ —É—Å—ñ–º–∞ –¥–∞–Ω–∏–º–∏ (—Ä–µ–∫–æ–º–µ–Ω–¥—É—î—Ç—å—Å—è)")
    print("- JSON: –¢–µ–∫—Å—Ç–æ–≤–∏–π —Ñ–æ—Ä–º–∞—Ç, –ª–µ–≥–∫–æ —á–∏—Ç–∞—î—Ç—å—Å—è")
    print("- Pickle: –ù–∞–π—à–≤–∏–¥—à–∏–π, –ø–æ–≤–Ω—ñ—Å—Ç—é –∑–±–µ—Ä—ñ–≥–∞—î Python –æ–±'—î–∫—Ç–∏")
    print("- Excel: –ó—Ä—É—á–Ω–∏–π –¥–ª—è –ø–µ—Ä–µ–≥–ª—è–¥—É, –∫—ñ–ª—å–∫–∞ –ª–∏—Å—Ç—ñ–≤")
    print("- CSV: –ë–∞–∑–æ–≤—ñ –¥–∞–Ω—ñ –≤ –ø–∞–ø—Ü—ñ")
    
    print("\n–ú–æ–∂–ª–∏–≤–æ—Å—Ç—ñ:")
    print("‚úÖ –ê–≤—Ç–æ–º–∞—Ç–∏—á–Ω–∞ –≥–µ–Ω–µ—Ä–∞—Ü—ñ—è ID —Å–∏–º—É–ª—è—Ü—ñ—ó")
    print("‚úÖ –ü–µ—Ä–µ–≤—ñ—Ä–∫–∞ —Ü—ñ–ª—ñ—Å–Ω–æ—Å—Ç—ñ –¥–∞–Ω–∏—Ö (—Ö–µ—à—É–≤–∞–Ω–Ω—è)")
    print("‚úÖ –ú–µ—Ç–∞–¥–∞–Ω—ñ —Ç–∞ –ø–∞—Ä–∞–º–µ—Ç—Ä–∏ —Å–∏–º—É–ª—è—Ü—ñ—ó")
    print("‚úÖ –ü–æ—à—É–∫ —Ç–∞ —Ñ—ñ–ª—å—Ç—Ä–∞—Ü—ñ—è –∑–±–µ—Ä–µ–∂–µ–Ω–∏—Ö —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ñ–≤")
    print("‚úÖ –ü–æ—Ä—ñ–≤–Ω—è–Ω–Ω—è —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ñ–≤ –∑ —Ä—ñ–∑–Ω–∏—Ö –µ–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç—ñ–≤")
    print("‚úÖ –ì–µ–Ω–µ—Ä–∞—Ü—ñ—è HTML/Markdown –∑–≤—ñ—Ç—ñ–≤")
    print("‚úÖ –ê–≤—Ç–æ–º–∞—Ç–∏—á–Ω–µ –æ—á–∏—â–µ–Ω–Ω—è —Å—Ç–∞—Ä–∏—Ö —Ñ–∞–π–ª—ñ–≤")
    print("‚úÖ –õ–æ–≥—É–≤–∞–Ω–Ω—è –≤—Å—ñ—Ö –æ–ø–µ—Ä–∞—Ü—ñ–π")
    print("‚úÖ –ü—ñ–¥—Ç—Ä–∏–º–∫–∞ –≤–µ–ª–∏–∫–∏—Ö —Ñ–∞–π–ª—ñ–≤ —á–µ—Ä–µ–∑ ZIP —Å—Ç–∏—Å–Ω–µ–Ω–Ω—è")
    
    # –î–µ–º–æ–Ω—Å—Ç—Ä–∞—Ü—ñ—è —Å—Ç–≤–æ—Ä–µ–Ω–Ω—è —Ç–µ—Å—Ç–æ–≤–æ–≥–æ –ø–∞–∫–µ—Ç–∞
    try:
        import pandas as pd
        import numpy as np
        
        print("\nüß™ –î–ï–ú–û–ù–°–¢–†–ê–¶–Ü–Ø:")
        
        # –°—Ç–≤–æ—Ä—é—î–º–æ —Ç–µ—Å—Ç–æ–≤—ñ –¥–∞–Ω—ñ
        test_results_df = pd.DataFrame({
            'conc_fe': np.random.normal(53.5, 0.5, 100),
            'conc_mass': np.random.normal(57.0, 1.0, 100),
            'solid_feed_percent': np.random.normal(75.0, 2.0, 100)
        })
        
        test_eval_results = EvaluationResults(
            overall_score=85.2,
            process_stability=0.92,
            model_r2_fe=0.89,
            model_r2_mass=0.91,
            ekf_consistency=0.75,
            trust_stability_index=0.88
        )
        
        test_analysis_data = {
            'timing_metrics': {'initial_training_time': 2.5},
            'trust_region_stats': [{'current_radius': 1.0}] * 50,
            'innovation_seq': np.random.normal(0, 0.1, (100, 2)).tolist()
        }
        
        test_params = {
            'ref_fe': 53.5,
            'ref_mass': 57.0,
            'horizon': 10,
            'lambda_u': 0.1
        }
        
        # –°—Ç–≤–æ—Ä—é—î–º–æ storage
        storage = EvaluationStorage("demo_results")
        
        # –°—Ç–≤–æ—Ä—é—î–º–æ –ø–∞–∫–µ—Ç
        package = storage.create_evaluation_package(
            results_df=test_results_df,
            eval_results=test_eval_results,
            analysis_data=test_analysis_data,
            params=test_params,
            description="–î–µ–º–æ–Ω—Å—Ç—Ä–∞—Ü—ñ–π–Ω–∏–π –µ–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç"
        )
        
        print(f"–°—Ç–≤–æ—Ä–µ–Ω–æ —Ç–µ—Å—Ç–æ–≤–∏–π –ø–∞–∫–µ—Ç:")
        print(f"  ID: {package.metadata.simulation_id}")
        print(f"  –û—Ü—ñ–Ω–∫–∞: {package.evaluation_results.overall_score}")
        print(f"  –ö—Ä–æ–∫–∏: {package.metadata.simulation_steps}")
        
        # –ó–±–µ—Ä–µ–∂–µ–Ω–Ω—è
        saved_path = storage.save_evaluation(package, 'zip')
        print(f"  –ó–±–µ—Ä–µ–∂–µ–Ω–æ: {saved_path}")
        
        # –ó–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–Ω—è
        loaded = storage.load_evaluation(saved_path)
        print(f"  –ó–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–æ, –æ—Ü—ñ–Ω–∫–∞: {loaded.evaluation_results.overall_score}")
        
        print("‚úÖ –î–µ–º–æ–Ω—Å—Ç—Ä–∞—Ü—ñ—è —É—Å–ø—ñ—à–Ω–∞!")
        
    except ImportError as e:
        print(f"‚ö†Ô∏è –î–ª—è –¥–µ–º–æ–Ω—Å—Ç—Ä–∞—Ü—ñ—ó –ø–æ—Ç—Ä—ñ–±–Ω—ñ pandas/numpy: {e}")
    except Exception as e:
        print(f"‚ùå –ü–æ–º–∏–ª–∫–∞ –¥–µ–º–æ–Ω—Å—Ç—Ä–∞—Ü—ñ—ó: {e}")