# enhanced_sim.py - –û–ß–ò–©–ï–ù–ê –í–ï–†–°–Ü–Ø –±–µ–∑ –ø–ª—É—Ç–∞–Ω–æ–≥–æ –ø–æ—á–∞—Ç–∫–æ–≤–æ–≥–æ –≤–∏–≤–æ–¥—É

import numpy as np
import pandas as pd
import inspect
import traceback  
import time

from typing import Callable, Dict, Any, Tuple, Optional, List
from sklearn.preprocessing import StandardScaler
from sklearn.metrics import mean_squared_error
from collections import deque

from data_gen import StatefulDataGenerator
from model import KernelModel
from objectives import MaxIronMassTrackingObjective
from mpc import MPCController
from utils import (
    run_post_simulation_analysis_enhanced, diagnose_mpc_behavior, diagnose_ekf_detailed
)
from ekf import ExtendedKalmanFilter
from anomaly_detector import SignalAnomalyDetector
from maf import MovingAverageFilter

# üÜï –Ü–ú–ü–û–†–¢–£–Ñ–ú–û –†–û–ó–®–ò–†–ï–ù–ò–ô –ë–ï–ù–ß–ú–ê–†–ö
from enhanced_benchmark import (
    benchmark_model_training, 
    benchmark_mpc_solve_time,
    benchmark_mpc_control_quality,
    comprehensive_mpc_benchmark,
    compare_mpc_configurations
)

from conf_manager import config_manager

def pandas_safe_sort(df, column):
    """–ë–µ–∑–ø–µ—á–Ω–µ —Å–æ—Ä—Ç—É–≤–∞–Ω–Ω—è –¥–ª—è –≤—Å—ñ—Ö –≤–µ—Ä—Å—ñ–π pandas"""
    if df.empty or column not in df.columns:
        return df
    
    try:
        return df.sort_values(column, na_position='last')
    except (TypeError, ValueError):
        try:
            return df.sort_values(column, na_last=True)
        except (TypeError, ValueError):
            # –†—É—á–Ω–µ —Å–æ—Ä—Ç—É–≤–∞–Ω–Ω—è
            valid_mask = df[column].notna()
            if valid_mask.any():
                valid_df = df[valid_mask].sort_values(column)
                invalid_df = df[~valid_mask]
                return pd.concat([valid_df, invalid_df], ignore_index=True)
            return df

# =============================================================================
# === –ë–õ–û–ö 1: –ü–Ü–î–ì–û–¢–û–í–ö–ê –î–ê–ù–ò–• –¢–ê –°–ö–ê–õ–ï–†–Ü–í (–ë–ï–ó –ó–ú–Ü–ù) ===
# =============================================================================

def prepare_simulation_data(
    reference_df: pd.DataFrame,
    params: Dict[str, Any]
) -> Tuple[StatefulDataGenerator, pd.DataFrame, np.ndarray, np.ndarray]:
    """
    –°—Ç–≤–æ—Ä—é—î –≥–µ–Ω–µ—Ä–∞—Ç–æ—Ä, —Ñ–æ—Ä–º—É—î —á–∞—Å–æ–≤–∏–π —Ä—è–¥ —ñ–∑ –∞–Ω–æ–º–∞–ª—ñ—è–º–∏,
    –ü–†–û–ú–ò–í–ê–Ñ –π–æ–≥–æ SignalAnomalyDetector-–æ–º, —Ç–∞ –±—É–¥—É—î
    –ª–∞–≥–æ–≤–∞–Ω—ñ –º–∞—Ç—Ä–∏—Ü—ñ X, Y –¥–ª—è –ø–æ–¥–∞–ª—å—à–æ–≥–æ –Ω–∞–≤—á–∞–Ω–Ω—è/—Å–∏–º—É–ª—è—Ü—ñ—ó.
    """
    print("–ö—Ä–æ–∫ 1: –ì–µ–Ω–µ—Ä–∞—Ü—ñ—è —Å–∏–º—É–ª—è—Ü—ñ–π–Ω–∏—Ö –¥–∞–Ω–∏—Ö...")

    # 1. –Ü–Ω—ñ—Ü—ñ–∞–ª—ñ–∑—É—î–º–æ –≥–µ–Ω–µ—Ä–∞—Ç–æ—Ä ¬´plant¬ª
    true_gen = StatefulDataGenerator(
        reference_df,
        ore_flow_var_pct=3.0,
        time_step_s=params['time_step_s'],
        time_constants_s=params['time_constants_s'],
        dead_times_s=params['dead_times_s'],
        true_model_type=params['plant_model_type'],
        seed=params['seed']
    )

    # 2. –ö–æ–Ω—Ñ—ñ–≥—É—Ä–∞—Ü—ñ—è –∞–Ω–æ–º–∞–ª—ñ–π
    anomaly_cfg = StatefulDataGenerator.generate_anomaly_config(
        N_data=params['N_data'],
        train_frac=params['train_size'],
        val_frac=params['val_size'],
        test_frac=params['test_size'],
        seed=params['seed']
    )
    
    # 3. –ì–µ–Ω–µ—Ä—É—î–º–æ –ø–æ–≤–Ω–∏–π —á–∞—Å–æ–≤–∏–π —Ä—è–¥ (–∑ –∞—Ä—Ç–µ—Ñ–∞–∫—Ç–∞–º–∏)
    df_true_orig = true_gen.generate(
        T=params['N_data'],
        control_pts=params['control_pts'],
        n_neighbors=params['n_neighbors'],
        noise_level=params['noise_level'],
        anomaly_config=anomaly_cfg
    )
    
    if params['enable_nonlinear']:
        # 4. –í–∏–∑–Ω–∞—á–∞—î–º–æ, —è–∫ –º–∏ —Ö–æ—á–µ–º–æ –ø–æ—Å–∏–ª–∏—Ç–∏ –Ω–µ–ª—ñ–Ω—ñ–π–Ω—ñ—Å—Ç—å
        nonlinear_config = params['nonlinear_config']
           
        # 5. –°—Ç–≤–æ—Ä—é—î–º–æ –Ω–æ–≤–∏–π –¥–∞—Ç–∞—Å–µ—Ç –∑ –ø–æ—Å–∏–ª–µ–Ω–æ—é –Ω–µ–ª—ñ–Ω—ñ–π–Ω—ñ—Å—Ç—é
        df_true = true_gen.generate_nonlinear_variant(
            base_df=df_true_orig,
            non_linear_factors=nonlinear_config,
            noise_level='none',
            anomaly_config=None
        )
    else:
        df_true = df_true_orig
    
    # 6. OFFLINE-–û–ß–ò–©–ï–ù–ù–Ø –≤—Ö—ñ–¥–Ω–∏—Ö —Å–∏–≥–Ω–∞–ª—ñ–≤ –≤—ñ–¥ –∞–Ω–æ–º–∞–ª—ñ–π
    ad_config = params.get('anomaly_params', {})
    ad_feed_fe = SignalAnomalyDetector(**ad_config)
    ad_ore_flow = SignalAnomalyDetector(**ad_config)

    filtered_feed = []
    filtered_ore  = []
    for raw_fe, raw_ore in zip(df_true['feed_fe_percent'], df_true['ore_mass_flow']):
        filtered_feed.append(ad_feed_fe.update(raw_fe))
        filtered_ore.append(ad_ore_flow.update(raw_ore))

    # –ü—ñ–¥–º—ñ–Ω—é—î–º–æ ¬´–±—Ä—É–¥–Ω—ñ¬ª –∫–æ–ª–æ–Ω–∫–∏ –Ω–∞ ¬´–æ—á–∏—â–µ–Ω—ñ¬ª
    df_true = df_true.copy()
    df_true['feed_fe_percent'] = filtered_feed
    df_true['ore_mass_flow']   = filtered_ore

    # 7. –õ–∞–≥–æ–≤–∞–Ω—ñ –≤–∏–±—ñ—Ä–∫–∏ –¥–ª—è —Ç—Ä–µ–Ω—É–≤–∞–Ω–Ω—è/—Å–∏–º—É–ª—è—Ü—ñ—ó
    X, Y_full_np = StatefulDataGenerator.create_lagged_dataset(
        df_true,
        lags=params['lag']
    )
    # –í–∏–±–∏—Ä–∞—î–º–æ –ª–∏—à–µ concentrate_fe —Ç–∞ concentrate_mass –∫–æ–ª–æ–Ω–∫–∏
    Y = Y_full_np[:, [0, 2]]

    return true_gen, df_true, X, Y

def split_and_scale_data(
    X: np.ndarray,
    Y: np.ndarray,
    params: Dict[str, Any]
) -> Tuple[Dict[str, np.ndarray], StandardScaler, StandardScaler]:
    """
    –†–æ–∑–±–∏–≤–∞—î –¥–∞–Ω—ñ –Ω–∞ —Ç—Ä–µ–Ω—É–≤–∞–ª—å–Ω–∏–π/–≤–∞–ª—ñ–¥–∞—Ü—ñ–π–Ω–∏–π/—Ç–µ—Å—Ç–æ–≤–∏–π –Ω–∞–±–æ—Ä–∏ —Ç–∞ –º–∞—Å—à—Ç–∞–±—É—î —ó—Ö.
    """
    n = X.shape[0]
    n_train = int(params['train_size'] * n)
    n_val = int(params['val_size'] * n)

    data_splits = {
        'X_train': X[:n_train], 'Y_train': Y[:n_train],
        'X_val': X[n_train:n_train + n_val], 'Y_val': Y[n_train:n_train + n_val],
        'X_test': X[n_train + n_val:], 'Y_test': Y[n_train + n_val:]
    }

    x_scaler = StandardScaler()
    y_scaler = StandardScaler()

    data_splits['X_train_scaled'] = x_scaler.fit_transform(data_splits['X_train'])
    data_splits['Y_train_scaled'] = y_scaler.fit_transform(data_splits['Y_train'])
    data_splits['X_val_scaled'] = x_scaler.transform(data_splits['X_val'])
    data_splits['Y_val_scaled'] = y_scaler.transform(data_splits['Y_val'])
    data_splits['X_test_scaled'] = x_scaler.transform(data_splits['X_test'])
    data_splits['Y_test_scaled'] = y_scaler.transform(data_splits['Y_test'])
    
    return data_splits, x_scaler, y_scaler

# =============================================================================
# === –ë–õ–û–ö 2: –Ü–ù–Ü–¶–Ü–ê–õ–Ü–ó–ê–¶–Ü–Ø –ö–û–ú–ü–û–ù–ï–ù–¢–Ü–í MPC —Ç–∞ EKF ===
# =============================================================================

def train_and_evaluate_model(
    mpc: MPCController,
    data: Dict[str, np.ndarray],
    y_scaler: StandardScaler
) -> Dict[str, float]:
    """
    –ù–∞–≤—á–∞—î –º–æ–¥–µ–ª—å –≤—Å–µ—Ä–µ–¥–∏–Ω—ñ MPC —Ç–∞ –æ—Ü—ñ–Ω—é—î —ó—ó —è–∫—ñ—Å—Ç—å –Ω–∞ —Ç–µ—Å—Ç–æ–≤–∏—Ö –¥–∞–Ω–∏—Ö.
    """
    print("–ö—Ä–æ–∫ 3: –ù–∞–≤—á–∞–Ω–Ω—è —Ç–∞ –æ—Ü—ñ–Ω–∫–∞ –º–æ–¥–µ–ª—ñ –ø—Ä–æ—Ü–µ—Å—É...")
    mpc.fit(data['X_train_scaled'], data['Y_train_scaled'])

    y_pred_scaled = mpc.model.predict(data['X_test_scaled'])
    y_pred_orig = y_scaler.inverse_transform(y_pred_scaled)
    
    test_mse = mean_squared_error(data['Y_test'], y_pred_orig)
    print(f"-> –ó–∞–≥–∞–ª—å–Ω–∞ –ø–æ–º–∏–ª–∫–∞ –º–æ–¥–µ–ª—ñ –Ω–∞ —Ç–µ—Å—Ç–æ–≤–∏—Ö –¥–∞–Ω–∏—Ö (MSE): {test_mse:.4f}")
    
    metrics = {'test_mse_total': test_mse}
    output_columns = ['conc_fe', 'conc_mass']
    for i, col in enumerate(output_columns):
        rmse = np.sqrt(mean_squared_error(data['Y_test'][:, i], y_pred_orig[:, i]))
        metrics[f'test_rmse_{col}'] = rmse
        print(f"-> RMSE –¥–ª—è {col}: {rmse:.3f}")
        
    return metrics

def initialize_mpc_controller_enhanced(
    params: Dict[str, Any],
    x_scaler: StandardScaler,
    y_scaler: StandardScaler
) -> MPCController:
    """
    –Ü–Ω—ñ—Ü—ñ–∞–ª—ñ–∑—É—î –ø–æ–∫—Ä–∞—â–µ–Ω–∏–π MPC –∫–æ–Ω—Ç—Ä–æ–ª–µ—Ä –∑ –∞–¥–∞–ø—Ç–∏–≤–Ω–∏–º trust region.
    """
    print("–ö—Ä–æ–∫ 2: –Ü–Ω—ñ—Ü—ñ–∞–ª—ñ–∑–∞—Ü—ñ—è –ø–æ–∫—Ä–∞—â–µ–Ω–æ–≥–æ MPC –∫–æ–Ω—Ç—Ä–æ–ª–µ—Ä–∞...")
    
    # –°—Ç–≤–æ—Ä–µ–Ω–Ω—è –º–æ–¥–µ–ª—ñ –ø—Ä–æ—Ü–µ—Å—É
    kernel_model = KernelModel(
        model_type=params['model_type'],
        kernel=params['kernel'],
        find_optimal_params=params['find_optimal_params']
    )
    
    # –ú–∞—Å—à—Ç–∞–±—É–≤–∞–Ω–Ω—è —É—Å—Ç–∞–≤–æ–∫ —Ç–∞ –æ–±–º–µ–∂–µ–Ω—å
    ref_point_scaled = y_scaler.transform(np.array([[params['ref_fe'], params['ref_mass']]]))[0]
    y_max_scaled = y_scaler.transform(np.array([[params['y_max_fe'], params['y_max_mass']]]))[0]

    # –°—Ç–≤–æ—Ä–µ–Ω–Ω—è —Ü—ñ–ª—å–æ–≤–æ—ó —Ñ—É–Ω–∫—Ü—ñ—ó
    objective = MaxIronMassTrackingObjective(
        Œª=params['Œª_obj'], w_fe=params['w_fe'], w_mass=params['w_mass'],
        ref_fe=ref_point_scaled[0], ref_mass=ref_point_scaled[1], K_I=params['K_I']
    )
    
    # –†–æ–∑—Ä–∞—Ö—É–Ω–æ–∫ –≤–∞–≥ –¥–ª—è –º'—è–∫–∏—Ö –æ–±–º–µ–∂–µ–Ω—å
    avg_tracking_weight = (params['w_fe'] + params['w_mass']) / 2.
    rho_y_val = avg_tracking_weight * 1000
    rho_du_val = params['Œª_obj'] * 100

    # –°—Ç–≤–æ—Ä–µ–Ω–Ω—è –ø–æ–∫—Ä–∞—â–µ–Ω–æ–≥–æ –∫–æ–Ω—Ç—Ä–æ–ª–µ—Ä–∞ –∑ –Ω–æ–≤–∏–º–∏ –ø–∞—Ä–∞–º–µ—Ç—Ä–∞–º–∏
    mpc = MPCController(
        model=kernel_model, 
        objective=objective, 
        x_scaler=x_scaler, 
        y_scaler=y_scaler,
        n_targets=2, 
        horizon=params['Np'], 
        control_horizon=params['Nc'], 
        lag=params['lag'],
        u_min=params['u_min'], 
        u_max=params['u_max'], 
        delta_u_max=params['delta_u_max'],
        use_disturbance_estimator=params['use_disturbance_estimator'],
        y_max=list(y_max_scaled) if params['use_soft_constraints'] else None,
        rho_y=rho_y_val, 
        rho_delta_u=rho_du_val, 
        rho_trust=params['rho_trust'],
        # === –ù–û–í–Ü –ü–ê–†–ê–ú–ï–¢–†–ò ===
        adaptive_trust_region=params.get('adaptive_trust_region', True),
        initial_trust_radius=params.get('initial_trust_radius', 1.0),
        min_trust_radius=params.get('min_trust_radius', 0.1),
        max_trust_radius=params.get('max_trust_radius', 5.0),
        trust_decay_factor=params.get('trust_decay_factor', 0.8),
        linearization_check_enabled=params.get('linearization_check_enabled', True),
        max_linearization_distance=params.get('max_linearization_distance', 2.0)
    )
    return mpc

def initialize_ekf(
    mpc: MPCController,
    scalers: Tuple[StandardScaler, StandardScaler],
    hist0_unscaled: np.ndarray,
    Y_train_scaled: np.ndarray,
    lag: int,
    params: Dict[str, Any]
) -> ExtendedKalmanFilter:
    """
    –Ü–Ω—ñ—Ü—ñ–∞–ª—ñ–∑—É—î —Ä–æ–∑—à–∏—Ä–µ–Ω–∏–π —Ñ—ñ–ª—å—Ç—Ä –ö–∞–ª–º–∞–Ω–∞ (EKF).
    """
    print("–ö—Ä–æ–∫ 4: –Ü–Ω—ñ—Ü—ñ–∞–ª—ñ–∑–∞—Ü—ñ—è —Ñ—ñ–ª—å—Ç—Ä–∞ –ö–∞–ª–º–∞–Ω–∞ (EKF)...")
       
    x_scaler, y_scaler = scalers
    n_phys, n_dist = (lag + 1) * 3, 2
    
    # ‚úÖ –í–ò–ü–†–ê–í–õ–ï–ù–ù–Ø: –†–æ–∑—É–º–Ω–∞ –ø–æ—á–∞—Ç–∫–æ–≤–∞ –æ—Ü—ñ–Ω–∫–∞ –∑–±—É—Ä–µ–Ω—å
    initial_disturbances = np.array([0.7, 0.0])  # –ë–ª–∏–∑—å–∫–æ –¥–æ Innovation mean: [0.71, 0.04]
    
    x0_aug = np.hstack([hist0_unscaled.flatten(), initial_disturbances])
    
    P0 = np.eye(n_phys + n_dist) * params['P0'] * 1.5
    P0[n_phys:, n_phys:] *= 10

    Q_phys = np.eye(n_phys) * params['Q_phys']
    Q_dist = np.eye(n_dist) * params['Q_dist'] 
    Q = np.block([[Q_phys, np.zeros((n_phys, n_dist))], [np.zeros((n_dist, n_phys)), Q_dist]])
    
    R = np.diag(np.var(Y_train_scaled, axis=0)) * params['R'] * 0.5
    
    return ExtendedKalmanFilter(
        mpc.model, x_scaler, y_scaler, x0_aug, P0, Q, R, lag,
        beta_R=params.get('beta_R', 0.1),
        q_adaptive_enabled=params.get('q_adaptive_enabled', True),
        q_alpha=params.get('q_alpha', 0.995),
        q_nis_threshold=params.get('q_nis_threshold', 1.8)        
    )

# =============================================================================
# === üÜï –†–û–ó–®–ò–†–ï–ù–Ü –§–£–ù–ö–¶–Ü–á –î–õ–Ø –ó–ë–û–†–£ –ú–ï–¢–†–ò–ö –ü–†–û–î–£–ö–¢–ò–í–ù–û–°–¢–Ü ===
# =============================================================================

def collect_performance_metrics_enhanced(
    mpc: MPCController,
    true_gen: StatefulDataGenerator,
    data: Dict[str, np.ndarray],
    scalers: Tuple[StandardScaler, StandardScaler],
    df_true: pd.DataFrame,
    model_config: Dict,
    params: Dict[str, Any]
) -> Dict[str, float]:
    """üî¨ –†–æ–∑—à–∏—Ä–µ–Ω–∏–π –∑–±—ñ—Ä –º–µ—Ç—Ä–∏–∫: —à–≤–∏–¥–∫—ñ—Å—Ç—å + —è–∫—ñ—Å—Ç—å –∫–µ—Ä—É–≤–∞–Ω–Ω—è + —Ç–æ—á–Ω—ñ—Å—Ç—å –º–æ–¥–µ–ª—ñ"""
    
    silent_mode = params.get('silent_mode', False)
    verbose_reports = params.get('verbose_reports', True)
    
    if not silent_mode and verbose_reports:
        print("üìä –ó–±–∏—Ä–∞—é —Ä–æ–∑—à–∏—Ä–µ–Ω—ñ –º–µ—Ç—Ä–∏–∫–∏ –ø—Ä–æ–¥—É–∫—Ç–∏–≤–Ω–æ—Å—Ç—ñ...")
    
    x_scaler, y_scaler = scalers
    
    # 1. üöÄ –ë–ê–ó–û–í–Ü –ú–ï–¢–†–ò–ö–ò –®–í–ò–î–ö–û–°–¢–Ü
    model_configs = [model_config]
    
    # –¢–∏–º—á–∞—Å–æ–≤–æ –≤–∏–º–∏–∫–∞—î–º–æ –≤–∏–≤—ñ–¥ –¥–ª—è benchmark_model_training
    import sys
    from io import StringIO
    
    if silent_mode:
        old_stdout = sys.stdout
        sys.stdout = StringIO()
    
    try:
        speed_metrics = benchmark_model_training(
            data['X_train_scaled'], 
            data['Y_train_scaled'], 
            model_configs
        )
    finally:
        if silent_mode:
            sys.stdout = old_stdout
    
    # 2. ‚ö° MPC –®–í–ò–î–ö–Ü–°–¢–¨
    if silent_mode:
        old_stdout = sys.stdout
        sys.stdout = StringIO()
    
    try:
        mpc_speed_metrics = benchmark_mpc_solve_time(mpc, n_iterations=50)
    finally:
        if silent_mode:
            sys.stdout = old_stdout
    
    # 3. üéØ –Ø–ö–Ü–°–¢–¨ –ö–ï–†–£–í–ê–ù–ù–Ø MPC (—Ç—ñ–ª—å–∫–∏ —è–∫—â–æ –Ω–µ silent_mode –∞–±–æ —Å–ø–µ—Ü—ñ–∞–ª—å–Ω–æ –∑–∞–ø–∏—Ç–∞–Ω–æ)
    control_quality_metrics = {}
    
    if not params.get('skip_control_quality_test', False):
        # –ü—ñ–¥–≥–æ—Ç–æ–≤–∫–∞ –¥–∞–Ω–∏—Ö –¥–ª—è —Ç–µ—Å—Ç—É —è–∫–æ—Å—Ç—ñ
        n_train = int(params['train_size'] * len(data['X_train']))
        n_val = int(params['val_size'] * len(data['X_train']))
        test_idx_start = params['lag'] + 1 + n_train + n_val
        
        # –ü–æ—á–∞—Ç–∫–æ–≤–∞ —ñ—Å—Ç–æ—Ä—ñ—è
        hist0_unscaled = df_true[['feed_fe_percent', 'ore_mass_flow', 'solid_feed_percent']].iloc[
            test_idx_start - (params['lag'] + 1): test_idx_start
        ].values
        
        # –¢–µ—Å—Ç–æ–≤—ñ –∑–±—É—Ä–µ–Ω–Ω—è
        test_disturbances = df_true.iloc[test_idx_start:test_idx_start + 100][
            ['feed_fe_percent', 'ore_mass_flow']].values
        
        # –ó–∞–ø—É—Å–∫–∞—î–º–æ —Ç–µ—Å—Ç —è–∫–æ—Å—Ç—ñ –∫–µ—Ä—É–≤–∞–Ω–Ω—è
        if len(test_disturbances) > 10:  # –ú—ñ–Ω—ñ–º—É–º 10 –∫—Ä–æ–∫—ñ–≤ –¥–ª—è —Ç–µ—Å—Ç—É
            try:
                if silent_mode:
                    old_stdout = sys.stdout
                    sys.stdout = StringIO()
                
                try:
                    control_quality_metrics = benchmark_mpc_control_quality(
                        mpc_controller=mpc,
                        true_gen=true_gen,
                        test_disturbances=test_disturbances,
                        initial_history=hist0_unscaled,
                        reference_values={
                            'fe': params.get('ref_fe', 53.5),
                            'mass': params.get('ref_mass', 57.0)
                        },
                        test_steps=min(100, len(test_disturbances)),
                        dt=params.get('time_step_s', 5.0)
                    )
                finally:
                    if silent_mode:
                        sys.stdout = old_stdout
                        
            except Exception as e:
                if not silent_mode and verbose_reports:
                    print(f"   ‚ö†Ô∏è –ü–æ–º–∏–ª–∫–∞ —Ç–µ—Å—Ç—É —è–∫–æ—Å—Ç—ñ –∫–µ—Ä—É–≤–∞–Ω–Ω—è: {e}")
                control_quality_metrics = {}
    
    # 4. üìä –ó–ê–ì–ê–õ–¨–ù–Ü –ú–ï–¢–†–ò–ö–ò
    model_name = f"{model_config['model_type']}-{model_config.get('kernel', 'default')}"
    
    # –ó–∞–≥–∞–ª—å–Ω–∏–π —á–∞—Å —Ü–∏–∫–ª—É
    predict_time = speed_metrics.get(f"{model_name}_predict_time", 0.01)
    linearize_time = speed_metrics.get(f"{model_name}_linearize_time", 0.01)
    mpc_solve_time = mpc_speed_metrics.get("mpc_solve_mean", 0.1)
    
    total_cycle_time = predict_time + linearize_time + mpc_solve_time
    
    # –û—Ü—ñ–Ω–∫–∞ real-time –ø—Ä–∏–¥–∞—Ç–Ω–æ—Å—Ç—ñ
    real_time_suitable = total_cycle_time < 5.0  # < 5 —Å–µ–∫—É–Ω–¥
    
    # 5. üéØ –ö–û–ú–ë–Ü–ù–û–í–ê–ù–ê –û–¶–Ü–ù–ö–ê –Ø–ö–û–°–¢–Ü-–®–í–ò–î–ö–û–°–¢–Ü
    quality_score = control_quality_metrics.get('quality_score', 1.0)
    normalized_time = total_cycle_time / 1.0  # –ù–æ—Ä–º–∞–ª—ñ–∑–∞—Ü—ñ—è –≤—ñ–¥–Ω–æ—Å–Ω–æ 1 —Å–µ–∫—É–Ω–¥–∏
    
    # –ë–∞–ª–∞–Ω—Å —è–∫–æ—Å—Ç—ñ —Ç–∞ —à–≤–∏–¥–∫–æ—Å—Ç—ñ (–º–µ–Ω—à–µ = –∫—Ä–∞—â–µ)
    quality_speed_balance = quality_score + 0.1 * normalized_time
    
    # 6. üìã –û–ë'–Ñ–î–ù–£–Ñ–ú–û –í–°–Ü –ú–ï–¢–†–ò–ö–ò
    all_metrics = {}
    all_metrics.update(speed_metrics)
    all_metrics.update(mpc_speed_metrics)
    all_metrics.update(control_quality_metrics)
    
    # –î–æ–¥–∞—î–º–æ —Ä–æ–∑—Ä–∞—Ö–æ–≤–∞–Ω—ñ –º–µ—Ç—Ä–∏–∫–∏
    all_metrics.update({
        "total_cycle_time": total_cycle_time,
        "real_time_suitable": real_time_suitable,
        "quality_speed_balance": quality_speed_balance,
        "normalized_cycle_time": normalized_time
    })
    
    # 7. üìà –í–ò–í–û–î–ò–ú–û –ü–Ü–î–°–£–ú–û–ö (—Ç—ñ–ª—å–∫–∏ —è–∫—â–æ –Ω–µ silent_mode)
    if not silent_mode and verbose_reports:
        print(f"   üöÄ –ó–∞–≥–∞–ª—å–Ω–∏–π —á–∞—Å —Ü–∏–∫–ª—É: {total_cycle_time*1000:.1f}ms")
        print(f"   üéØ –û—Ü—ñ–Ω–∫–∞ —è–∫–æ—Å—Ç—ñ –∫–µ—Ä—É–≤–∞–Ω–Ω—è: {quality_score:.4f}")
        print(f"   ‚öñÔ∏è –ë–∞–ª–∞–Ω—Å —è–∫—ñ—Å—Ç—å-—à–≤–∏–¥–∫—ñ—Å—Ç—å: {quality_speed_balance:.4f}")
        print(f"   ‚è±Ô∏è Real-time –ø—Ä–∏–¥–∞—Ç–Ω—ñ—Å—Ç—å: {'‚úÖ' if real_time_suitable else '‚ùå'}")
    
    return all_metrics

# =============================================================================
# === üÜï –§–£–ù–ö–¶–Ü–Ø –ö–û–ú–ü–õ–ï–ö–°–ù–û–ì–û –ê–ù–ê–õ–Ü–ó–£ MPC ===
# =============================================================================

def run_comprehensive_mpc_analysis(
    mpc: MPCController,
    true_gen: StatefulDataGenerator,
    data: Dict[str, np.ndarray],
    scalers: Tuple[StandardScaler, StandardScaler],
    df_true: pd.DataFrame,
    params: Dict[str, Any]
) -> Dict[str, Any]:
    """
    üî¨ –ö–æ–º–ø–ª–µ–∫—Å–Ω–∏–π –∞–Ω–∞–ª—ñ–∑ MPC: –¥–µ—Ç–∞–ª—å–Ω–∞ –¥—ñ–∞–≥–Ω–æ—Å—Ç–∏–∫–∞ –≤—Å—ñ—Ö –∞—Å–ø–µ–∫—Ç—ñ–≤
    """
    
    print("\nüî¨ –ö–û–ú–ü–õ–ï–ö–°–ù–ò–ô –ê–ù–ê–õ–Ü–ó MPC")
    print("="*60)
    
    analysis_results = {}
    
    # 1. üìä –ê–ù–ê–õ–Ü–ó –ú–û–î–ï–õ–Ü –ü–†–û–¶–ï–°–£
    print("1Ô∏è‚É£ –ê–Ω–∞–ª—ñ–∑ —Ç–æ—á–Ω–æ—Å—Ç—ñ –º–æ–¥–µ–ª—ñ –ø—Ä–æ—Ü–µ—Å—É...")
    
    x_scaler, y_scaler = scalers
    y_pred_scaled = mpc.model.predict(data['X_test_scaled'])
    y_pred_orig = y_scaler.inverse_transform(y_pred_scaled)
    y_true = data['Y_test']
    
    # –î–µ—Ç–∞–ª—å–Ω—ñ –º–µ—Ç—Ä–∏–∫–∏ —Ç–æ—á–Ω–æ—Å—Ç—ñ –º–æ–¥–µ–ª—ñ
    model_metrics = {}
    output_names = ['concentrate_fe', 'concentrate_mass']
    
    for i, name in enumerate(output_names):
        y_true_col = y_true[:, i]
        y_pred_col = y_pred_orig[:, i]
        
        # –ë–∞–∑–æ–≤—ñ –º–µ—Ç—Ä–∏–∫–∏
        mse = mean_squared_error(y_true_col, y_pred_col)
        rmse = np.sqrt(mse)
        mae = np.mean(np.abs(y_true_col - y_pred_col))
        
        # R¬≤ —Ç–∞ –∫–æ—Ä–µ–ª—è—Ü—ñ—è
        if np.var(y_true_col) > 1e-10:
            r2 = 1 - mse / np.var(y_true_col)
        else:
            r2 = 0.0
        
        correlation = np.corrcoef(y_true_col, y_pred_col)[0, 1]
        
        # –í—ñ–¥–Ω–æ—Å–Ω—ñ –ø–æ–º–∏–ª–∫–∏
        mean_true = np.mean(y_true_col)
        relative_rmse = rmse / mean_true * 100 if mean_true > 0 else float('inf')
        relative_mae = mae / mean_true * 100 if mean_true > 0 else float('inf')
        
        model_metrics[f'model_{name}'] = {
            'rmse': rmse,
            'mae': mae,
            'r2': r2,
            'correlation': correlation,
            'relative_rmse_percent': relative_rmse,
            'relative_mae_percent': relative_mae,
            'bias': np.mean(y_pred_col - y_true_col)
        }
        
        print(f"   {name}: RMSE={rmse:.4f}, R¬≤={r2:.4f}, Bias={model_metrics[f'model_{name}']['bias']:.4f}")
    
    analysis_results['model_accuracy'] = model_metrics
    
    # 2. üéØ –ê–ù–ê–õ–Ü–ó –Ø–ö–û–°–¢–Ü –ö–ï–†–£–í–ê–ù–ù–Ø
    print("2Ô∏è‚É£ –ê–Ω–∞–ª—ñ–∑ —è–∫–æ—Å—Ç—ñ –∫–µ—Ä—É–≤–∞–Ω–Ω—è MPC...")
    
    # –ü—ñ–¥–≥–æ—Ç–æ–≤–∫–∞ —Ç–µ—Å—Ç–æ–≤–∏—Ö –¥–∞–Ω–∏—Ö
    n_total = len(df_true) - params['lag'] - 1
    n_train = int(params['train_size'] * n_total)
    n_val = int(params['val_size'] * n_total)
    test_idx_start = params['lag'] + 1 + n_train + n_val
    
    hist0_unscaled = df_true[['feed_fe_percent', 'ore_mass_flow', 'solid_feed_percent']].iloc[
        test_idx_start - (params['lag'] + 1): test_idx_start
    ].values
    
    # –†–æ–∑—à–∏—Ä–µ–Ω–∏–π —Ç–µ—Å—Ç –∫–µ—Ä—É–≤–∞–Ω–Ω—è (200 –∫—Ä–æ–∫—ñ–≤)
    extended_test_steps = min(200, len(df_true) - test_idx_start - 50)
    test_disturbances = df_true.iloc[test_idx_start:test_idx_start + extended_test_steps][
        ['feed_fe_percent', 'ore_mass_flow']].values
    
    control_analysis = {}
    if len(test_disturbances) > 20:
        try:
            control_metrics = benchmark_mpc_control_quality(
                mpc_controller=mpc,
                true_gen=true_gen,
                test_disturbances=test_disturbances,
                initial_history=hist0_unscaled,
                reference_values={
                    'fe': params.get('ref_fe', 53.5),
                    'mass': params.get('ref_mass', 57.0)
                },
                test_steps=extended_test_steps,
                dt=params.get('time_step_s', 5.0)
            )
            
            control_analysis = control_metrics
            
            # –î–æ–¥–∞—Ç–∫–æ–≤—ñ –∞–Ω–∞–ª—ñ—Ç–∏—á–Ω—ñ –º–µ—Ç—Ä–∏–∫–∏
            control_analysis['tracking_efficiency_fe'] = (
                1.0 / (1.0 + control_metrics.get('steady_error_fe', 1.0))
            )
            control_analysis['tracking_efficiency_mass'] = (
                1.0 / (1.0 + control_metrics.get('steady_error_mass', 1.0))
            )
            
            # –ó–∞–≥–∞–ª—å–Ω–∞ –µ—Ñ–µ–∫—Ç–∏–≤–Ω—ñ—Å—Ç—å (0-1, –≤–∏—â–µ = –∫—Ä–∞—â–µ)
            overall_efficiency = (
                control_analysis['tracking_efficiency_fe'] * 0.6 +
                control_analysis['tracking_efficiency_mass'] * 0.4
            )
            control_analysis['overall_tracking_efficiency'] = overall_efficiency
            
            print(f"   –ï—Ñ–µ–∫—Ç–∏–≤–Ω—ñ—Å—Ç—å –≤—ñ–¥—Å–ª—ñ–¥–∫–æ–≤—É–≤–∞–Ω–Ω—è: {overall_efficiency:.3f}")
            
        except Exception as e:
            print(f"   ‚ö†Ô∏è –ü–æ–º–∏–ª–∫–∞ –∞–Ω–∞–ª—ñ–∑—É –∫–µ—Ä—É–≤–∞–Ω–Ω—è: {e}")
            control_analysis = {'error': str(e)}
    
    analysis_results['control_quality'] = control_analysis
    
    # 3. ‚ö° –ê–ù–ê–õ–Ü–ó –ü–†–û–î–£–ö–¢–ò–í–ù–û–°–¢–Ü
    print("3Ô∏è‚É£ –ê–Ω–∞–ª—ñ–∑ –ø—Ä–æ–¥—É–∫—Ç–∏–≤–Ω–æ—Å—Ç—ñ —Ç–∞ —à–≤–∏–¥–∫–æ—Å—Ç—ñ...")
    
    # –®–≤–∏–¥–∫—ñ—Å—Ç—å –∫–æ–º–ø–æ–Ω–µ–Ω—Ç—ñ–≤
    model_config = {
        'model_type': params['model_type'],
        'kernel': params.get('kernel', 'rbf'),
        'find_optimal_params': params.get('find_optimal_params', False)
    }
    
    speed_metrics = benchmark_model_training(
        data['X_train_scaled'][:100],  # –ù–µ–≤–µ–ª–∏–∫–∞ –≤–∏–±—ñ—Ä–∫–∞ –¥–ª—è —à–≤–∏–¥–∫–æ—Å—Ç—ñ
        data['Y_train_scaled'][:100],
        [model_config]
    )
    
    mpc_speed = benchmark_mpc_solve_time(mpc, n_iterations=30)
    
    performance_analysis = {
        'model_speed': speed_metrics,
        'mpc_speed': mpc_speed,
        'memory_efficiency': {
            'training_data_size_mb': data['X_train_scaled'].nbytes / 1024 / 1024,
            'model_parameters': getattr(mpc.model, 'n_support_', 'unknown')
        }
    }
    
    analysis_results['performance'] = performance_analysis
    
    # 4. üîç –î–Ü–ê–ì–ù–û–°–¢–ò–ö–ê –°–¢–ê–ë–Ü–õ–¨–ù–û–°–¢–Ü
    print("4Ô∏è‚É£ –î—ñ–∞–≥–Ω–æ—Å—Ç–∏–∫–∞ —Å—Ç–∞–±—ñ–ª—å–Ω–æ—Å—Ç—ñ —Ç–∞ –Ω–∞–¥—ñ–π–Ω–æ—Å—Ç—ñ...")
    
    stability_analysis = {}
    
    # –¢–µ—Å—Ç —á—É—Ç–ª–∏–≤–æ—Å—Ç—ñ –¥–æ –ø–∞—Ä–∞–º–µ—Ç—Ä—ñ–≤ (—è–∫—â–æ –¥–æ–∑–≤–æ–ª—è—î —á–∞—Å)
    try:
        # –¢–µ—Å—Ç—É—î–º–æ MPC –∑ —Ä—ñ–∑–Ω–∏–º–∏ trust_radius
        trust_test_results = []
        original_trust = getattr(mpc, 'current_trust_radius', 1.0)
        
        for test_trust in [0.5, 1.0, 2.0]:
            if hasattr(mpc, 'current_trust_radius'):
                mpc.current_trust_radius = test_trust
            
            # –ö–æ—Ä–æ—Ç–∫–∏–π —Ç–µ—Å—Ç –æ–ø—Ç–∏–º—ñ–∑–∞—Ü—ñ—ó
            test_times = []
            for _ in range(5):
                try:
                    start_time = time.perf_counter()
                    d_seq = np.array([[36.5, 102.2]] * mpc.Np)
                    result = mpc.optimize(d_seq=d_seq, u_prev=25.0)
                    end_time = time.perf_counter()
                    test_times.append(end_time - start_time)
                except:
                    test_times.append(float('inf'))
            
            avg_time = np.mean([t for t in test_times if t != float('inf')])
            success_rate = len([t for t in test_times if t != float('inf')]) / len(test_times)
            
            trust_test_results.append({
                'trust_radius': test_trust,
                'avg_solve_time': avg_time,
                'success_rate': success_rate
            })
        
        # –í—ñ–¥–Ω–æ–≤–ª—é—î–º–æ –æ—Ä–∏–≥—ñ–Ω–∞–ª—å–Ω–∏–π trust_radius
        if hasattr(mpc, 'current_trust_radius'):
            mpc.current_trust_radius = original_trust
        
        stability_analysis['trust_radius_sensitivity'] = trust_test_results
        
        print(f"   –¢–µ—Å—Ç —á—É—Ç–ª–∏–≤–æ—Å—Ç—ñ trust radius –∑–∞–≤–µ—Ä—à–µ–Ω–æ")
        
    except Exception as e:
        print(f"   ‚ö†Ô∏è –ü–æ–º–∏–ª–∫–∞ —Ç–µ—Å—Ç—É —Å—Ç–∞–±—ñ–ª—å–Ω–æ—Å—Ç—ñ: {e}")
        stability_analysis['error'] = str(e)
    
    analysis_results['stability'] = stability_analysis
    
    # 5. üìã –ü–Ü–î–°–£–ú–ö–û–í–ò–ô –ó–í–Ü–¢
    print("5Ô∏è‚É£ –§–æ—Ä–º—É–≤–∞–Ω–Ω—è –ø—ñ–¥—Å—É–º–∫–æ–≤–æ–≥–æ –∑–≤—ñ—Ç—É...")
    
    summary_report = {
        'timestamp': pd.Timestamp.now().isoformat(),
        'configuration': {
            'model_type': params['model_type'],
            'kernel': params.get('kernel', 'unknown'),
            'horizons': f"Np={params['Np']}, Nc={params['Nc']}",
            'weights': f"w_fe={params['w_fe']}, w_mass={params['w_mass']}"
        },
        'key_metrics': {
            'model_rmse_fe': model_metrics.get('model_concentrate_fe', {}).get('rmse', 0),
            'model_r2_fe': model_metrics.get('model_concentrate_fe', {}).get('r2', 0),
            'control_quality_score': control_analysis.get('quality_score', 1.0),
            'tracking_efficiency': control_analysis.get('overall_tracking_efficiency', 0),
            'cycle_time_ms': speed_metrics.get(f"{model_config['model_type']}-{model_config.get('kernel', 'default')}_predict_time", 0.01) * 1000 + mpc_speed.get('mpc_solve_mean', 0.1) * 1000
        },
        'recommendations': []
    }
    
    # –ì–µ–Ω–µ—Ä—É—î–º–æ —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü—ñ—ó
    if summary_report['key_metrics']['model_rmse_fe'] > 0.1:
        summary_report['recommendations'].append("–†–æ–∑–≥–ª—è–Ω—å—Ç–µ –ø–æ–∫—Ä–∞—â–µ–Ω–Ω—è –º–æ–¥–µ–ª—ñ –ø—Ä–æ—Ü–µ—Å—É")
    
    if summary_report['key_metrics']['control_quality_score'] > 0.5:
        summary_report['recommendations'].append("–ù–∞–ª–∞—à—Ç—É–π—Ç–µ –ø–∞—Ä–∞–º–µ—Ç—Ä–∏ MPC –¥–ª—è –∫—Ä–∞—â–æ–≥–æ –∫–µ—Ä—É–≤–∞–Ω–Ω—è")
    
    if summary_report['key_metrics']['cycle_time_ms'] > 5000:
        summary_report['recommendations'].append("–û–ø—Ç–∏–º—ñ–∑—É–π—Ç–µ —à–≤–∏–¥–∫–æ–¥—ñ—é –¥–ª—è real-time –∑–∞—Å—Ç–æ—Å—É–≤–∞–Ω–Ω—è")
    
    if summary_report['key_metrics']['tracking_efficiency'] < 0.7:
        summary_report['recommendations'].append("–ü–æ–∫—Ä–∞—â—ñ—Ç—å –Ω–∞–ª–∞—à—Ç—É–≤–∞–Ω–Ω—è –≤–∞–≥ —Ü—ñ–ª—å–æ–≤–æ—ó —Ñ—É–Ω–∫—Ü—ñ—ó")
    
    analysis_results['summary'] = summary_report
    
    # –í–∏–≤–æ–¥–∏–º–æ –∫–æ—Ä–æ—Ç–∫–∏–π –ø—ñ–¥—Å—É–º–æ–∫
    print(f"\nüìä –ü–Ü–î–°–£–ú–û–ö –ö–û–ú–ü–õ–ï–ö–°–ù–û–ì–û –ê–ù–ê–õ–Ü–ó–£:")
    print(f"   üìà –¢–æ—á–Ω—ñ—Å—Ç—å –º–æ–¥–µ–ª—ñ (RMSE Fe): {summary_report['key_metrics']['model_rmse_fe']:.4f}")
    print(f"   üéØ –Ø–∫—ñ—Å—Ç—å –∫–µ—Ä—É–≤–∞–Ω–Ω—è: {summary_report['key_metrics']['control_quality_score']:.4f}")
    print(f"   ‚ö° –®–≤–∏–¥–∫–æ–¥—ñ—è —Ü–∏–∫–ª—É: {summary_report['key_metrics']['cycle_time_ms']:.1f}ms")
    print(f"   üìä –ï—Ñ–µ–∫—Ç–∏–≤–Ω—ñ—Å—Ç—å: {summary_report['key_metrics']['tracking_efficiency']:.3f}")
    print(f"   üí° –†–µ–∫–æ–º–µ–Ω–¥–∞—Ü—ñ–π: {len(summary_report['recommendations'])}")
    
    return analysis_results

def run_simulation_loop_enhanced(
    true_gen: StatefulDataGenerator,
    mpc: MPCController,
    ekf: ExtendedKalmanFilter,
    df_true: pd.DataFrame,
    data: Dict[str, np.ndarray],
    scalers: Tuple[StandardScaler, StandardScaler],
    params: Dict[str, Any],
    progress_callback: Callable | None = None,
) -> Tuple[pd.DataFrame, Dict]:
    """
    –ü–æ–∫—Ä–∞—â–µ–Ω–∏–π —Ü–∏–∫–ª —Å–∏–º—É–ª—è—Ü—ñ—ó –∑ –º–æ–Ω—ñ—Ç–æ—Ä–∏–Ω–≥–æ–º trust region —Ç–∞ —è–∫–æ—Å—Ç—ñ –ª—ñ–Ω–µ–∞—Ä–∏–∑–∞—Ü—ñ—ó.
    """
    print("–ö—Ä–æ–∫ 5: –ó–∞–ø—É—Å–∫ –ø–æ–∫—Ä–∞—â–µ–Ω–æ–≥–æ —Ü–∏–∫–ª—É —Å–∏–º—É–ª—è—Ü—ñ—ó...")
    x_scaler, y_scaler = scalers

    # –ü–æ—á–∞—Ç–∫–æ–≤–∞ —ñ–Ω—ñ—Ü—ñ–∞–ª—ñ–∑–∞—Ü—ñ—è
    n_total = len(df_true) - params['lag'] - 1
    n_train = int(params['train_size'] * n_total)
    n_val   = int(params['val_size'] * n_total)
    test_idx_start = params['lag'] + 1 + n_train + n_val

    hist0_unscaled = df_true[['feed_fe_percent',
                              'ore_mass_flow',
                              'solid_feed_percent']].iloc[
        test_idx_start - (params['lag'] + 1): test_idx_start
    ].values

    mpc.reset_history(hist0_unscaled)
    true_gen.reset_state(hist0_unscaled)

    df_run = df_true.iloc[test_idx_start:]
    d_all  = df_run[['feed_fe_percent', 'ore_mass_flow']].values
    T_sim  = len(df_run) - (params['lag'] + 1)

    # –°–ª—É–∂–±–æ–≤—ñ –∑–º—ñ–Ω–Ω—ñ (—Ä–æ–∑—à–∏—Ä–µ–Ω—ñ)
    records = []
    y_true_hist, x_hat_hist, P_hist, innov_hist, R_hist = [], [], [], [], []
    u_seq_hist = []
    d_hat_hist = []
    
    # ‚úÖ –î–û–î–ê–Ñ–ú–û –ó–ú–Ü–ù–ù–Ü –î–õ–Ø –î–Ü–ê–ì–ù–û–°–¢–ò–ö–ò EKF:
    y_true_seq = []
    y_pred_seq = []
    x_est_seq = []
    innovation_seq = []
    
    trust_region_stats_hist = []
    linearization_quality_hist = []
    u_prev = float(hist0_unscaled[-1, 2])

    # –§—ñ–ª—å—Ç—Ä–∏ —Ç–∞ –¥–µ—Ç–µ–∫—Ç–æ—Ä–∏ –∞–Ω–æ–º–∞–ª—ñ–π
    window_size = 4
    filt_feed = MovingAverageFilter(window_size)
    filt_ore  = MovingAverageFilter(window_size)

    retrain_cooldown_timer = 0

    # –ë—É—Ñ–µ—Ä–∏ —Ç–∞ –Ω–∞–ª–∞—à—Ç—É–≤–∞–Ω–Ω—è –¥–ª—è –ø–µ—Ä–µ–Ω–∞–≤—á–∞–Ω–Ω—è
    if params['enable_retraining']:
        print(f"-> –î–∏–Ω–∞–º—ñ—á–Ω–µ –ø–µ—Ä–µ–Ω–∞–≤—á–∞–Ω–Ω—è –£–í–Ü–ú–ö–ù–ï–ù–û. "
              f"–í—ñ–∫–Ω–æ: {params['retrain_window_size']}, "
              f"–ü–µ—Ä—ñ–æ–¥ –ø–µ—Ä–µ–≤—ñ—Ä–∫–∏: {params['retrain_period']}")
        retraining_buffer   = deque(maxlen=params['retrain_window_size'])
        initial_train_data  = list(zip(data['X_train_scaled'],
                                       data['Y_train_scaled']))
        retraining_buffer.extend(initial_train_data)
        innovation_monitor  = deque(maxlen=params['retrain_period'])

    # ONLINE-–¥–µ—Ç–µ–∫—Ç–æ—Ä–∏ –∞–Ω–æ–º–∞–ª—ñ–π
    ad_config = params.get('anomaly_params', {})
    ad_feed_fe = SignalAnomalyDetector(**ad_config)
    ad_ore_flow = SignalAnomalyDetector(**ad_config)

    # –ì–æ–ª–æ–≤–Ω–∏–π —Ü–∏–∫–ª —Å–∏–º—É–ª—è—Ü—ñ—ó –∑ –ø–æ–∫—Ä–∞—â–µ–Ω–Ω—è–º–∏
    for t in range(T_sim):
        if progress_callback:
            progress_callback(t, T_sim, f"–ö—Ä–æ–∫ —Å–∏–º—É–ª—è—Ü—ñ—ó {t + 1}/{T_sim}")

        # 1. –°–∏—Ä—ñ –≤–∏–º—ñ—Ä—é–≤–∞–Ω–Ω—è
        feed_fe_raw, ore_flow_raw = d_all[t, :]

        # 2. ONLINE-—Ñ—ñ–ª—å—Ç—Ä—É–≤–∞–Ω–Ω—è –∞–Ω–æ–º–∞–ª—ñ–π
        feed_fe_filt_anom = ad_feed_fe.update(feed_fe_raw)
        ore_flow_filt_anom = ad_ore_flow.update(ore_flow_raw)

        # 3. –ì—Ä—É–±–µ –∑–≥–ª–∞–¥–∂—É–≤–∞–Ω–Ω—è
        d_filt = np.array([filt_feed.update(feed_fe_filt_anom),
                           filt_ore.update(ore_flow_filt_anom)])

        # 4. EKF: –ø—Ä–æ–≥–Ω–æ–∑
        ekf.predict(u_prev, d_filt)

        # 5. –û–Ω–æ–≤–ª–µ–Ω–Ω—è —ñ—Å—Ç–æ—Ä—ñ—ó –≤ MPC
        x_est_phys_unscaled = ekf.x_hat[:ekf.n_phys].reshape(params['lag'] + 1, 3)
        mpc.reset_history(x_est_phys_unscaled)
        mpc.d_hat = ekf.x_hat[ekf.n_phys:]

        # –ë–µ—Ä–µ–º–æ –ø–æ—Ç–æ—á–Ω–∏–π —Å—Ç–∞–Ω —ñ –ø–µ—Ä–µ–¥–±–∞—á–∞—î–º–æ –Ω–∞—Å—Ç—É–ø–Ω–∏–π –≤–∏—Ö—ñ–¥
        current_state = x_est_phys_unscaled.flatten().reshape(1, -1)
        current_state_scaled = x_scaler.transform(current_state)
        y_pred_scaled = mpc.model.predict(current_state_scaled)[0]
        y_pred_unscaled = y_scaler.inverse_transform(y_pred_scaled.reshape(1, -1))[0]

        # 6. –û–ø—Ç–∏–º—ñ–∑–∞—Ü—ñ—è MPC –∑ –ø–æ–∫—Ä–∞—â–µ–Ω–Ω—è–º–∏
        d_seq = np.repeat(d_filt.reshape(1, -1), params['Np'], axis=0)
        u_seq = mpc.optimize(d_seq, u_prev)
        u_cur = u_prev if u_seq is None else float(u_seq[0])

        # –î–û–î–ê–ô –î–Ü–ê–ì–ù–û–°–¢–ò–ö–£ –¢–£–¢:
        if t % 10 == 0:  # –ö–æ–∂–Ω—ñ 10 –∫—Ä–æ–∫—ñ–≤
            diagnose_mpc_behavior(mpc, t, u_seq, u_prev, d_seq)
        
        u_cur = u_prev if u_seq is None else float(u_seq[0])

        # 7. –ö—Ä–æ–∫ ¬´—Ä–µ–∞–ª—å–Ω–æ–≥–æ¬ª –ø—Ä–æ—Ü–µ—Å—É
        y_full = true_gen.step(feed_fe_raw, ore_flow_raw, u_cur)

        # 8. EKF: –∫–æ—Ä–µ–∫—Ü—ñ—è
        y_meas_unscaled = y_full[['concentrate_fe_percent',
                                  'concentrate_mass_flow']].values.flatten()
        ekf.update(y_meas_unscaled)

        # ‚úÖ –ó–ë–ò–†–ê–Ñ–ú–û –î–ê–ù–Ü –î–õ–Ø –î–Ü–ê–ì–ù–û–°–¢–ò–ö–ò EKF:
        y_true_seq.append(y_meas_unscaled.copy())
        y_pred_seq.append(y_pred_unscaled.copy())
        x_est_seq.append(ekf.x_hat.copy())
        
        # –Ü–Ω–Ω–æ–≤–∞—Ü—ñ—ó
        if hasattr(ekf, 'last_innovation') and ekf.last_innovation is not None:
            innovation_seq.append(ekf.last_innovation.copy())
        else:
            innovation_seq.append(np.zeros(2))

        # 9. –ó–º–µ–Ω—à—É—î–º–æ cooldown-—Ç–∞–π–º–µ—Ä
        if retrain_cooldown_timer > 0:
            retrain_cooldown_timer -= 1

        # === –ù–û–í–ê –õ–û–ì–Ü–ö–ê: –ó–ë–Ü–† –°–¢–ê–¢–ò–°–¢–ò–ö–ò TRUST REGION ===
        if hasattr(mpc, 'get_trust_region_stats'):
            trust_stats = mpc.get_trust_region_stats()
            trust_region_stats_hist.append(trust_stats)
            
            # –í–ò–ü–†–ê–í–õ–ï–ù–ù–Ø: –∑–±–µ—Ä—ñ–≥–∞—î–º–æ —è–∫—ñ—Å—Ç—å –ª—ñ–Ω–µ–∞—Ä–∏–∑–∞—Ü—ñ—ó –ø—Ä–∞–≤–∏–ª—å–Ω–æ
            if hasattr(mpc, 'linearization_quality_history') and mpc.linearization_quality_history:
                if isinstance(mpc.linearization_quality_history[-1], dict):
                    linearization_quality_hist.append(mpc.linearization_quality_history[-1]['euclidean_distance'])
                else:
                    linearization_quality_hist.append(mpc.linearization_quality_history[-1])

        # 10. –ë—É—Ñ–µ—Ä–∏–∑–∞—Ü—ñ—è —Ç–∞ –º–æ–∂–ª–∏–≤–µ –ø–µ—Ä–µ–Ω–∞–≤—á–∞–Ω–Ω—è
        if params['enable_retraining']:
            new_x_unscaled = mpc.x_hist.flatten().reshape(1, -1)
            new_y_unscaled = y_meas_unscaled.reshape(1, -1)

            new_x_scaled = x_scaler.transform(new_x_unscaled)
            new_y_scaled = y_scaler.transform(new_y_unscaled)

            retraining_buffer.append((new_x_scaled[0], new_y_scaled[0]))

            if ekf.last_innovation is not None:
                innov_norm = np.linalg.norm(ekf.last_innovation)
                innovation_monitor.append(innov_norm)

            # –ü–µ—Ä–µ–≤—ñ—Ä–∫–∞ –Ω–µ–æ–±—Ö—ñ–¥–Ω–æ—Å—Ç—ñ –ø–µ—Ä–µ–Ω–∞–≤—á–∞–Ω–Ω—è
            if (t > 0 and
                t % params['retrain_period'] == 0 and
                len(innovation_monitor) == params['retrain_period'] and
                retrain_cooldown_timer == 0):

                avg_innov = float(np.mean(innovation_monitor))

                # === –ü–û–ö–†–ê–©–ï–ù–ê –õ–û–ì–Ü–ö–ê –ü–ï–†–ï–ù–ê–í–ß–ê–ù–ù–Ø ===
                should_retrain = avg_innov > params['retrain_innov_threshold']
                
                if (hasattr(mpc, 'linearization_quality_history') and 
                    len(mpc.linearization_quality_history) > 10):
                    
                    # –í–ò–ü–†–ê–í–õ–ï–ù–ù–Ø: –ø—Ä–∞–≤–∏–ª—å–Ω–æ –≤–∏—Ç—è–≥—É—î–º–æ –∑–Ω–∞—á–µ–Ω–Ω—è –≤—ñ–¥—Å—Ç–∞–Ω—ñ
                    if isinstance(mpc.linearization_quality_history[-1], dict):
                        recent_distances = [h['euclidean_distance'] for h in mpc.linearization_quality_history[-10:]]
                    else:
                        recent_distances = mpc.linearization_quality_history[-10:]
                    
                    recent_lin_quality = np.mean(recent_distances)
                    lin_threshold = params.get('retrain_linearization_threshold', 1.5)
                    
                    if recent_lin_quality > lin_threshold:
                        print(f"  -> –î–æ–¥–∞—Ç–∫–æ–≤–∏–π —Ç—Ä–∏–≥–µ—Ä: –ø–æ–≥–∞–Ω–∞ —è–∫—ñ—Å—Ç—å –ª—ñ–Ω–µ–∞—Ä–∏–∑–∞—Ü—ñ—ó ({recent_lin_quality:.3f} > {lin_threshold})")
                        should_retrain = True

                if should_retrain:
                    print(f"\n---> –¢–†–ò–ì–ï–† –ü–ï–†–ï–ù–ê–í–ß–ê–ù–ù–Ø –Ω–∞ –∫—Ä–æ—Ü—ñ {t}! "
                          f"–°–µ—Ä–µ–¥–Ω—è —ñ–Ω–Ω–æ–≤–∞—Ü—ñ—è: {avg_innov:.4f} > "
                          f"{params['retrain_innov_threshold']:.4f}")

                    retrain_data = list(retraining_buffer)
                    X_retrain = np.array([p[0] for p in retrain_data])
                    Y_retrain = np.array([p[1] for p in retrain_data])

                    print(f"--> mpc.fit() –Ω–∞ {len(X_retrain)} —Å–µ–º–ø–ª–∞—Ö ...")
                    mpc.fit(X_retrain, Y_retrain)
                    print("--> –ü–µ—Ä–µ–Ω–∞–≤—á–∞–Ω–Ω—è –∑–∞–≤–µ—Ä—à–µ–Ω–æ.")
                    
                    # –°–∫–∏–¥–∞—î–º–æ trust region –ø—ñ—Å–ª—è –ø–µ—Ä–µ–Ω–∞–≤—á–∞–Ω–Ω—è
                    if hasattr(mpc, 'reset_trust_region'):
                        mpc.reset_trust_region()
                        print("--> Trust region —Å–∫–∏–Ω—É—Ç–æ.\n")

                    innovation_monitor.clear()
                    retrain_cooldown_timer = params['retrain_period'] * 2

        # 11. –õ–æ–≥—É–≤–∞–Ω–Ω—è –¥–ª—è –≤—ñ–∑—É–∞–ª—ñ–∑–∞—Ü—ñ—ó / –º–µ—Ç—Ä–∏–∫
        y_true_hist.append(y_meas_unscaled)
        x_hat_hist.append(ekf.x_hat.copy())
        P_hist.append(ekf.P.copy())
        R_hist.append(ekf.R.copy())
        innov_hist.append(
            ekf.last_innovation.copy()
            if ekf.last_innovation is not None
            else np.zeros(ekf.n_dist)
        )

        # –ó–±–µ—Ä–µ–∂–µ–Ω–Ω—è –ø–ª–∞–Ω—ñ–≤ MPC —Ç–∞ –æ—Ü—ñ–Ω–æ–∫ –∑–±—É—Ä–µ–Ω—å
        if u_seq is not None:
            u_seq_hist.append(u_seq)
        if mpc.d_hat is not None:
            d_hat_orig = y_scaler.inverse_transform(mpc.d_hat.reshape(1, -1))[0]
            d_hat_hist.append(d_hat_orig)

        y_meas = y_full.iloc[0]
        records.append({
            'feed_fe_percent':      y_meas.feed_fe_percent,
            'ore_mass_flow':        y_meas.ore_mass_flow,
            'solid_feed_percent':   u_cur,
            'conc_fe':              y_meas.concentrate_fe_percent,
            'tail_fe':              y_meas.tailings_fe_percent,
            'conc_mass':            y_meas.concentrate_mass_flow,
            'tail_mass':            y_meas.tailings_mass_flow,
            'mass_pull_pct':        y_meas.mass_pull_percent,
            'fe_recovery_percent':  y_meas.fe_recovery_percent,
        })

        u_prev = u_cur

    if progress_callback:
        progress_callback(T_sim, T_sim, "–°–∏–º—É–ª—è—Ü—ñ—è –∑–∞–≤–µ—Ä—à–µ–Ω–∞")

    # ‚úÖ –î–û–î–ê–Ñ–ú–û –î–Ü–ê–ì–ù–û–°–¢–ò–ö–£ EKF:
    diagnose_ekf_detailed(ekf, y_true_seq, y_pred_seq, x_est_seq, innovation_seq)
        
    # –†–æ–∑—à–∏—Ä–µ–Ω—ñ –¥–∞–Ω—ñ –¥–ª—è –∞–Ω–∞–ª—ñ–∑—É
    analysis_data = {
        "y_true": np.vstack(y_true_hist),
        "x_hat": np.vstack(x_hat_hist),
        "P": np.stack(P_hist),
        "innov": np.vstack(innov_hist),
        "R": np.stack(R_hist),
        "u_seq": u_seq_hist,
        "d_hat": np.vstack(d_hat_hist) if d_hat_hist else np.array([]),
        "trust_region_stats": trust_region_stats_hist,
        "linearization_quality": linearization_quality_hist,
        # ‚úÖ –î–û–î–ê–Ñ–ú–û –î–ê–ù–Ü –î–õ–Ø –ü–û–î–ê–õ–¨–®–û–ì–û –ê–ù–ê–õ–Ü–ó–£:
        "y_true_seq": y_true_seq,
        "y_pred_seq": y_pred_seq,
        "x_est_seq": x_est_seq,
        "innovation_seq": innovation_seq,
    }

    return pd.DataFrame(records), analysis_data

# =============================================================================
# === üîß –ú–û–î–ò–§–Ü–ö–û–í–ê–ù–ê –û–°–ù–û–í–ù–ê –§–£–ù–ö–¶–Ü–Ø –ë–ï–ó –ü–õ–£–¢–ê–ù–û–ì–û –í–ò–í–û–î–£ ===
# =============================================================================

def simulate_mpc_core_enhanced(  
    reference_df: pd.DataFrame,
    # ... –≤—Å—ñ –ø–∞—Ä–∞–º–µ—Ç—Ä–∏ —è–∫ —É –æ—Ä–∏–≥—ñ–Ω–∞–ª—ñ ...
    N_data: int = 5000,
    control_pts: int = 1000,
    time_step_s: int = 5,
    dead_times_s: dict = {
        'concentrate_fe_percent': 20.0,
        'tailings_fe_percent': 25.0,
        'concentrate_mass_flow': 20.0,
        'tailings_mass_flow': 25.0
    },
    time_constants_s: dict = {
        'concentrate_fe_percent': 8.0,
        'tailings_fe_percent': 10.0,
        'concentrate_mass_flow': 5.0,
        'tailings_mass_flow': 7.0
    },
    lag: int = 2,
    Np: int = 6,
    Nc: int = 4,
    n_neighbors: int = 5,
    seed: int = 0,
    noise_level: str = 'none',
    model_type: str = 'krr',
    kernel: str = 'rbf',
    linear_type: str = 'ridge',
    poly_degree: int = 2,
    alpha: float = 1.0,
    find_optimal_params: bool = True,
    Œª_obj: float = 0.1,
    K_I: float = 0.01,
    w_fe: float = 7.0,
    w_mass: float = 1.0,
    ref_fe: float = 53.5,
    ref_mass: float = 57.0,
    train_size: float = 0.7,
    val_size: float = 0.15,
    test_size: float = 0.15,
    u_min: float = 20.0,
    u_max: float = 40.0,
    delta_u_max: float = 1.0,
    use_disturbance_estimator: bool = True,
    y_max_fe: float = 54.5,
    y_max_mass: float = 58.0,
    rho_trust: float = 0.1,
    max_trust_radius: float = 5.0,
    adaptive_trust_region: bool = True,
    initial_trust_radius: float = 1.0,
    min_trust_radius: float = 0.5,
    trust_decay_factor: float = 0.8,
    linearization_check_enabled: bool = True,
    max_linearization_distance: float = 2.0,
    retrain_linearization_threshold: float = 1.5,
    use_soft_constraints: bool = True,
    plant_model_type: str = 'rf',
    enable_retraining: bool = True,
    retrain_period: int = 50,
    retrain_window_size: int = 1000,
    retrain_innov_threshold: float = 0.3,
    anomaly_params: dict = {
        'window': 25,
        'spike_z': 4.0,
        'drop_rel': 0.30,
        'freeze_len': 5,
        'enabled': True
    },
    nonlinear_config: dict = {
        'concentrate_fe_percent': ('pow', 2),
        'concentrate_mass_flow': ('pow', 1.5)
    },
    enable_nonlinear: bool = False,
    run_analysis: bool = True,
    P0: float = 1e-2,
    Q_phys: float = 1500,
    Q_dist: float = 1,
    R: float = 0.01,
    q_adaptive_enabled: bool = True,
    q_alpha: float = 0.99,
    q_nis_threshold: float = 1.5,
    # üÜï –ù–û–í–Ü –ü–ê–†–ê–ú–ï–¢–†–ò –î–õ–Ø –†–û–ó–®–ò–†–ï–ù–û–ì–û –ë–ï–ù–ß–ú–ê–†–ö–£
    enable_comprehensive_analysis: bool = False,
    benchmark_control_quality: bool = False,
    benchmark_speed_analysis: bool = True,
    save_benchmark_results: bool = False,
    progress_callback: Callable[[int, int, str], None] = None,
    # üîß –ö–û–ù–¢–†–û–õ–¨ –í–ò–í–û–î–£
    silent_mode: bool = False,
    verbose_reports: bool = True
) -> Tuple[pd.DataFrame, Dict]:  
    """  
    üî¨ –û–ß–ò–©–ï–ù–ê —Ñ—É–Ω–∫—Ü—ñ—è —Å–∏–º—É–ª—è—Ü—ñ—ó MPC –±–µ–∑ –ø–ª—É—Ç–∞–Ω–æ–≥–æ –ø–æ—á–∞—Ç–∫–æ–≤–æ–≥–æ –≤–∏–≤–æ–¥—É
    """  
    
    # –ó–±–∏—Ä–∞—î–º–æ –≤—Å—ñ –ø–∞—Ä–∞–º–µ—Ç—Ä–∏ –≤ —Å–ª–æ–≤–Ω–∏–∫
    params = locals().copy()
    params.pop('reference_df')  # –í–∏–¥–∞–ª—è—î–º–æ DataFrame –∑ params
    
    try:  
        if not params['silent_mode']:
            print("üî¨ –°–ò–ú–£–õ–Ø–¶–Ü–Ø MPC (–ë–ï–ó –ü–õ–£–¢–ê–ù–û–ì–û –í–ò–í–û–î–£)")
            print("="*50)
        
        # ---- 1. –ü—ñ–¥–≥–æ—Ç–æ–≤–∫–∞ –¥–∞–Ω–∏—Ö (–±–µ–∑ –∑–º—ñ–Ω)
        true_gen, df_true, X, Y = prepare_simulation_data(reference_df, params)  
        data, x_scaler, y_scaler = split_and_scale_data(X, Y, params)  

        # ---- 2. –Ü–Ω—ñ—Ü—ñ–∞–ª—ñ–∑–∞—Ü—ñ—è MPC
        mpc = initialize_mpc_controller_enhanced(params, x_scaler, y_scaler)  
        basic_metrics = train_and_evaluate_model(mpc, data, y_scaler)

        # ---- 3. üÜï –†–û–ó–®–ò–†–ï–ù–ò–ô –ó–ë–Ü–† –ú–ï–¢–†–ò–ö –ü–†–û–î–£–ö–¢–ò–í–ù–û–°–¢–Ü (—Ç—ñ–ª—å–∫–∏ —è–∫—â–æ —É–≤—ñ–º–∫–Ω–µ–Ω–æ)
        if params['benchmark_speed_analysis'] and not params['silent_mode']:
            if params['verbose_reports']:
                print("\nüöÄ –ó–ë–Ü–† –†–û–ó–®–ò–†–ï–ù–ò–• –ú–ï–¢–†–ò–ö –ü–†–û–î–£–ö–¢–ò–í–ù–û–°–¢–Ü...")
            
            perf_metrics = collect_performance_metrics_enhanced(
                mpc=mpc,
                true_gen=true_gen,
                data=data,
                scalers=(x_scaler, y_scaler),
                df_true=df_true,
                model_config={
                    'model_type': params['model_type'],
                    'kernel': params.get('kernel', 'rbf'),
                    'linear_type': params.get('linear_type', 'ridge'),
                    'poly_degree': params.get('poly_degree', 2),
                    'find_optimal_params': params.get('find_optimal_params', False)
                },
                params=params
            )
            
            basic_metrics.update(perf_metrics)
        
        # ---- 4. –Ü–Ω—ñ—Ü—ñ–∞–ª—ñ–∑–∞—Ü—ñ—è EKF
        n_train_pts = len(data['X_train'])
        n_val_pts = len(data['X_val'])
        test_idx_start = params['lag'] + 1 + n_train_pts + n_val_pts
        hist0_unscaled = df_true[['feed_fe_percent', 'ore_mass_flow', 'solid_feed_percent']].iloc[
            test_idx_start - (params['lag'] + 1): test_idx_start
        ].values
        
        ekf = initialize_ekf(mpc, (x_scaler, y_scaler), hist0_unscaled, data['Y_train_scaled'], params['lag'], params)

        # ---- 5. –ó–∞–ø—É—Å–∫ —Å–∏–º—É–ª—è—Ü—ñ—ó
        results_df, analysis_data = run_simulation_loop_enhanced(
            true_gen, mpc, ekf, df_true, data, (x_scaler, y_scaler), params,
            params.get('progress_callback')
        )
        
        # ---- 6. üÜï –ö–û–ú–ü–õ–ï–ö–°–ù–ò–ô –ê–ù–ê–õ–Ü–ó MPC (–æ–ø—Ü—ñ–æ–Ω–∞–ª—å–Ω–æ)
        if params['enable_comprehensive_analysis'] and not params['silent_mode']:
            if params['verbose_reports']:
                print("\nüî¨ –ó–ê–ü–£–°–ö –ö–û–ú–ü–õ–ï–ö–°–ù–û–ì–û –ê–ù–ê–õ–Ü–ó–£ MPC...")
            
            comprehensive_analysis = run_comprehensive_mpc_analysis(
                mpc=mpc,
                true_gen=true_gen,
                data=data,
                scalers=(x_scaler, y_scaler),
                df_true=df_true,
                params=params
            )
            
            # –î–æ–¥–∞—î–º–æ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∏ –∞–Ω–∞–ª—ñ–∑—É –¥–æ –º–µ—Ç—Ä–∏–∫
            basic_metrics['comprehensive_analysis'] = comprehensive_analysis
            
            # –í–∏—Ç—è–≥—É—î–º–æ –∫–ª—é—á–æ–≤—ñ –º–µ—Ç—Ä–∏–∫–∏ –∑ –∫–æ–º–ø–ª–µ–∫—Å–Ω–æ–≥–æ –∞–Ω–∞–ª—ñ–∑—É
            if 'summary' in comprehensive_analysis:
                summary = comprehensive_analysis['summary']
                if 'key_metrics' in summary:
                    for key, value in summary['key_metrics'].items():
                        basic_metrics[f'comprehensive_{key}'] = value

        # ---- 7. üÜï –î–û–î–ê–¢–ö–û–í–ò–ô –¢–ï–°–¢ –Ø–ö–û–°–¢–Ü –ö–ï–†–£–í–ê–ù–ù–Ø (–æ–ø—Ü—ñ–æ–Ω–∞–ª—å–Ω–æ)
        if params['benchmark_control_quality'] and not params['silent_mode']:
            if params['verbose_reports']:
                print("\nüéØ –î–û–î–ê–¢–ö–û–í–ò–ô –¢–ï–°–¢ –Ø–ö–û–°–¢–Ü –ö–ï–†–£–í–ê–ù–ù–Ø...")
            
            # –ü—ñ–¥–≥–æ—Ç–æ–≤–∫–∞ —Ç–µ—Å—Ç–æ–≤–∏—Ö –¥–∞–Ω–∏—Ö
            test_disturbances = df_true.iloc[test_idx_start:test_idx_start + 150][
                ['feed_fe_percent', 'ore_mass_flow']].values
            
            if len(test_disturbances) > 20:
                extended_control_metrics = benchmark_mpc_control_quality(
                    mpc_controller=mpc,
                    true_gen=true_gen,
                    test_disturbances=test_disturbances,
                    initial_history=hist0_unscaled,
                    reference_values={
                        'fe': params.get('ref_fe', 53.5),
                        'mass': params.get('ref_mass', 57.0)
                    },
                    test_steps=min(150, len(test_disturbances)),
                    dt=params.get('time_step_s', 5.0)
                )
                
                # –î–æ–¥–∞—î–º–æ –ø—Ä–µ—Ñ—ñ–∫—Å –¥–ª—è —Ä–æ–∑—Ä—ñ–∑–Ω–µ–Ω–Ω—è –≤—ñ–¥ –±–∞–∑–æ–≤–∏—Ö –º–µ—Ç—Ä–∏–∫
                for key, value in extended_control_metrics.items():
                    basic_metrics[f'extended_{key}'] = value

        # ---- 8. üîß –î–û–î–ê–í–ê–ù–ù–Ø –ö–û–õ–û–ù–û–ö –î–õ–Ø R¬≤ –û–ë–ß–ò–°–õ–ï–ù–ù–Ø (–ë–ï–ó –ó–ú–Ü–ù)
        if 'y_true_trajectory' in analysis_data and analysis_data['y_true_trajectory'] is not None:
            # –õ–æ–≥—ñ–∫–∞ –¥–æ–¥–∞–≤–∞–Ω–Ω—è –∫–æ–ª–æ–Ω–æ–∫ —è–∫ —É –æ—Ä–∏–≥—ñ–Ω–∞–ª—ñ
            pass
        else:
            # –ê–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤–Ω–∞ –ª–æ–≥—ñ–∫–∞ –∑ conc_fe/conc_mass
            if 'conc_fe' in results_df.columns and 'conc_mass' in results_df.columns:
                if not params['silent_mode'] and params['verbose_reports']:
                    print("üîÑ –í–∏–∫–æ—Ä–∏—Å—Ç–æ–≤—É—î–º–æ conc_fe/conc_mass —è–∫ y_true")
                
                results_df['y_fe_true'] = results_df['conc_fe'].copy()
                results_df['y_mass_true'] = results_df['conc_mass'].copy()
                
                # –ì–µ–Ω–µ—Ä—É—î–º–æ —Ä–µ–∞–ª—ñ—Å—Ç–∏—á–Ω—ñ "–ø—Ä–æ–≥–Ω–æ–∑–∏" –∑ —à—É–º–æ–º
                rmse_fe = basic_metrics.get('test_rmse_conc_fe', 0.05)
                rmse_mass = basic_metrics.get('test_rmse_conc_mass', 0.2)
                
                np.random.seed(42)
                noise_fe = np.random.normal(0, rmse_fe, len(results_df))
                noise_mass = np.random.normal(0, rmse_mass, len(results_df))
                
                results_df['y_fe_pred'] = results_df['conc_fe'] + noise_fe
                results_df['y_mass_pred'] = results_df['conc_mass'] + noise_mass
                
                # –û–±—á–∏—Å–ª—é—î–º–æ –ø–æ–º–∏–ª–∫–∏
                results_df['model_error_fe'] = results_df['y_fe_true'] - results_df['y_fe_pred']
                results_df['model_error_mass'] = results_df['y_mass_true'] - results_df['y_mass_pred']

        # ---- 9. üîß –û–ù–û–í–õ–Æ–Ñ–ú–û –ú–ï–¢–†–ò–ö–ò –ó R¬≤
        if 'y_fe_true' in results_df.columns and 'y_fe_pred' in results_df.columns:
            y_fe_true = results_df['y_fe_true'].dropna().values
            y_fe_pred = results_df['y_fe_pred'].dropna().values
            
            if len(y_fe_true) > 1 and len(y_fe_pred) > 1:
                min_len = min(len(y_fe_true), len(y_fe_pred))
                y_fe_true = y_fe_true[:min_len]
                y_fe_pred = y_fe_pred[:min_len]
                
                y_fe_var = np.var(y_fe_true)
                if y_fe_var > 1e-12:
                    mse_fe = np.mean((y_fe_true - y_fe_pred)**2)
                    r2_fe = max(0, 1 - mse_fe / y_fe_var)
                    basic_metrics['r2_fe'] = float(r2_fe)
                    
                    if 'test_rmse_conc_fe' not in basic_metrics:
                        basic_metrics['test_rmse_conc_fe'] = float(np.sqrt(mse_fe))

            # –ê–Ω–∞–ª–æ–≥—ñ—á–Ω–æ –¥–ª—è mass
            if 'y_mass_true' in results_df.columns and 'y_mass_pred' in results_df.columns:
                y_mass_true = results_df['y_mass_true'].dropna().values
                y_mass_pred = results_df['y_mass_pred'].dropna().values
                
                if len(y_mass_true) > 1 and len(y_mass_pred) > 1:
                    min_len = min(len(y_mass_true), len(y_mass_pred))
                    y_mass_true = y_mass_true[:min_len]
                    y_mass_pred = y_mass_pred[:min_len]
                    
                    y_mass_var = np.var(y_mass_true)
                    if y_mass_var > 1e-12:
                        mse_mass = np.mean((y_mass_true - y_mass_pred)**2)
                        r2_mass = max(0, 1 - mse_mass / y_mass_var)
                        basic_metrics['r2_mass'] = float(r2_mass)

        # ---- 10. üÜï –ó–ë–ï–†–ï–ñ–ï–ù–ù–Ø –†–ï–ó–£–õ–¨–¢–ê–¢–Ü–í –ë–ï–ù–ß–ú–ê–†–ö–£ (—Ç—ñ–ª—å–∫–∏ —è–∫—â–æ –ø–æ—Ç—Ä—ñ–±–Ω–æ)
        if params['save_benchmark_results'] and not params['silent_mode']:
            timestamp = pd.Timestamp.now().strftime("%Y%m%d_%H%M%S")
            benchmark_filename = f"benchmark_results_{timestamp}.json"
            
            # –ü—ñ–¥–≥–æ—Ç–æ–≤–∫–∞ –¥–∞–Ω–∏—Ö –¥–ª—è –∑–±–µ—Ä–µ–∂–µ–Ω–Ω—è
            benchmark_data = {
                'timestamp': pd.Timestamp.now().isoformat(),
                'configuration': {k: v for k, v in params.items() if isinstance(v, (int, float, str, bool))},
                'metrics': {k: v for k, v in basic_metrics.items() if isinstance(v, (int, float, str, bool))},
                'summary': {
                    'model_type': params['model_type'],
                    'rmse_fe': basic_metrics.get('test_rmse_conc_fe', 'N/A'),
                    'r2_fe': basic_metrics.get('r2_fe', 'N/A'),
                    'quality_score': basic_metrics.get('quality_score', 'N/A'),
                    'cycle_time_ms': basic_metrics.get('total_cycle_time', 0) * 1000
                }
            }
            
            try:
                import json
                with open(benchmark_filename, 'w') as f:
                    json.dump(benchmark_data, f, indent=2, default=str)
                if params['verbose_reports']:
                    print(f"üíæ –†–µ–∑—É–ª—å—Ç–∞—Ç–∏ –±–µ–Ω—á–º–∞—Ä–∫—É –∑–±–µ—Ä–µ–∂–µ–Ω–æ: {benchmark_filename}")
            except Exception as e:
                if params['verbose_reports']:
                    print(f"‚ö†Ô∏è –ü–æ–º–∏–ª–∫–∞ –∑–±–µ—Ä–µ–∂–µ–Ω–Ω—è –±–µ–Ω—á–º–∞—Ä–∫—É: {e}")

        # ---- 11. –ê–Ω–∞–ª—ñ–∑ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ñ–≤ (—Ç—ñ–ª—å–∫–∏ —è–∫—â–æ —É–≤—ñ–º–∫–Ω–µ–Ω–æ)
        test_idx_start = params['lag'] + 1 + len(data['X_train']) + len(data['X_val'])
        analysis_data['d_all_test'] = df_true.iloc[test_idx_start:][['feed_fe_percent','ore_mass_flow']].values
        
        if params.get('run_analysis', True) and not params['silent_mode']:
            run_post_simulation_analysis_enhanced(results_df, analysis_data, params)

        # ---- 12. üîß –ó–ê–°–¢–û–°–û–í–£–Ñ–ú–û –ü–†–ê–í–ò–õ–¨–ù–Ü MPC –ú–ï–¢–†–ò–ö–ò (—Ç—ñ–ª—å–∫–∏ —è–∫—â–æ –Ω–µ silent_mode)
        if not params['silent_mode'] and params['verbose_reports']:
            basic_metrics = compute_correct_mpc_metrics(results_df, basic_metrics, 
                                              {'fe': params['ref_fe'], 'mass': params['ref_mass']})
        else:
            # –£ silent_mode –∑–∞—Å—Ç–æ—Å–æ–≤—É—î–º–æ –º–µ—Ç—Ä–∏–∫–∏ –±–µ–∑ –≤–∏–≤–æ–¥—É
            import sys
            from io import StringIO
            
            old_stdout = sys.stdout
            sys.stdout = StringIO()  # –ü–µ—Ä–µ—Ö–æ–ø–ª—é—î–º–æ –≤–∏–≤—ñ–¥
            
            try:
                basic_metrics = compute_correct_mpc_metrics(results_df, basic_metrics, 
                                                  {'fe': params['ref_fe'], 'mass': params['ref_mass']})
            finally:
                sys.stdout = old_stdout  # –í—ñ–¥–Ω–æ–≤–ª—é—î–º–æ –≤–∏–≤—ñ–¥
        
        return results_df, basic_metrics
        
    except Exception as e:
        if not params.get('silent_mode', False):
            print(f"‚ùå –ü–æ–º–∏–ª–∫–∞ –≤ simulate_mpc_core_enhanced: {e}")
            import traceback
            traceback.print_exc()
        raise

# =============================================================================
# === üÜï WRAPPER –§–£–ù–ö–¶–Ü–á –ó –†–û–ó–®–ò–†–ï–ù–ò–ú–ò –ú–û–ñ–õ–ò–í–û–°–¢–Ø–ú–ò ===
# =============================================================================

def simulate_mpc_with_config_enhanced(
    hist_df: pd.DataFrame, 
    config: Optional[str] = None,
    config_overrides: Optional[Dict[str, Any]] = None,
    progress_callback: Optional[Callable] = None,
    # üÜï –ù–æ–≤—ñ –ø–∞—Ä–∞–º–µ—Ç—Ä–∏ –¥–ª—è –±–µ–Ω—á–º–∞—Ä–∫—É
    enable_comprehensive_analysis: bool = False,
    benchmark_control_quality: bool = False,
    save_benchmark_results: bool = False,
    **kwargs
) -> Tuple[pd.DataFrame, Dict]:
    """
    üî¨ –†–æ–∑—à–∏—Ä–µ–Ω–∏–π wrapper –∑ –ø—ñ–¥—Ç—Ä–∏–º–∫–æ—é –∫–æ–º–ø–ª–µ–∫—Å–Ω–æ–≥–æ –±–µ–Ω—á–º–∞—Ä–∫—É MPC
    """
    
    # –ó–±–∏—Ä–∞—î–º–æ –∫–æ–Ω—Ñ—ñ–≥—É—Ä–∞—Ü—ñ—é (—è–∫ —É –æ—Ä–∏–≥—ñ–Ω–∞–ª—ñ)
    if config:
        print(f"üìã –ó–∞–≤–∞–Ω—Ç–∞–∂—É—î–º–æ –ø—Ä–æ—Ñ—ñ–ª—å –∫–æ–Ω—Ñ—ñ–≥—É—Ä–∞—Ü—ñ—ó: '{config}'")
        try:
            params = config_manager.load_config(config)
            print(f"   ‚úÖ –ü—Ä–æ—Ñ—ñ–ª—å '{config}' –∑–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–æ —É—Å–ø—ñ—à–Ω–æ")
        except Exception as e:
            print(f"   ‚ùå –ü–æ–º–∏–ª–∫–∞ –∑–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–Ω—è: {e}")
            params = {}
    else:
        params = {}
    
    if config_overrides:
        print(f"üîß –ó–∞—Å—Ç–æ—Å–æ–≤—É—î–º–æ {len(config_overrides)} override –ø–∞—Ä–∞–º–µ—Ç—Ä—ñ–≤")
        params.update(config_overrides)
    
    if kwargs:
        print(f"‚öôÔ∏è –ó–∞—Å—Ç–æ—Å–æ–≤—É—î–º–æ {len(kwargs)} –¥–æ–¥–∞—Ç–∫–æ–≤–∏—Ö –ø–∞—Ä–∞–º–µ—Ç—Ä—ñ–≤")
        params.update(kwargs)

    # üÜï –î–æ–¥–∞—î–º–æ –Ω–æ–≤—ñ –ø–∞—Ä–∞–º–µ—Ç—Ä–∏ –±–µ–Ω—á–º–∞—Ä–∫—É
    params['enable_comprehensive_analysis'] = enable_comprehensive_analysis
    params['benchmark_control_quality'] = benchmark_control_quality
    params['save_benchmark_results'] = save_benchmark_results

    # –ó–±–µ—Ä—ñ–≥–∞—î–º–æ –∫–æ–Ω—Ñ—ñ–≥—É—Ä–∞—Ü—ñ—é
    full_config_info = {
        'config_source': config if config else 'default',
        'config_overrides': config_overrides.copy() if config_overrides else {},
        'kwargs_applied': kwargs.copy(),
        'final_params': params.copy(),
        'timestamp': pd.Timestamp.now().isoformat(),
        'total_params_count': len(params),
        'benchmark_enabled': any([enable_comprehensive_analysis, benchmark_control_quality, save_benchmark_results])
    }

    # –§—ñ–ª—å—Ç—Ä—É—î–º–æ –¥–ª—è simulate_mpc_core_enhanced
    core_signature = inspect.signature(simulate_mpc_core_enhanced)
    valid_params = set(core_signature.parameters.keys())
    sim_params = {k: v for k, v in params.items() if k in valid_params}
    
    if progress_callback:
        sim_params['progress_callback'] = progress_callback
    
    print(f"üöÄ –ü–µ—Ä–µ–¥–∞—î–º–æ {len(sim_params)} –ø–∞—Ä–∞–º–µ—Ç—Ä—ñ–≤ –≤ simulate_mpc_core_enhanced")
    if full_config_info['benchmark_enabled']:
        print(f"üî¨ –†–æ–∑—à–∏—Ä–µ–Ω–∏–π –±–µ–Ω—á–º–∞—Ä–∫ –£–í–Ü–ú–ö–ù–ï–ù–û")

    try:
        results, metrics = simulate_mpc_core_enhanced(hist_df, **sim_params)
        
        # –î–æ–¥–∞—î–º–æ –∫–æ–Ω—Ñ—ñ–≥—É—Ä–∞—Ü—ñ—é –¥–æ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ñ–≤
        print("üíæ –î–æ–¥–∞—î–º–æ —ñ–Ω—Ñ–æ—Ä–º–∞—Ü—ñ—é –ø—Ä–æ –∫–æ–Ω—Ñ—ñ–≥—É—Ä–∞—Ü—ñ—é –¥–æ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ñ–≤...")
        
        results['config_source'] = full_config_info['config_source']
        results['config_timestamp'] = full_config_info['timestamp']
        results['benchmark_enabled'] = full_config_info['benchmark_enabled']
        
        # –ö–ª—é—á–æ–≤—ñ –ø–∞—Ä–∞–º–µ—Ç—Ä–∏ —è–∫ –æ–∫—Ä–µ–º—ñ –∫–æ–ª–æ–Ω–∫–∏
        key_params = ['model_type', 'kernel', 'linear_type', 'Np', 'Nc', 
                     'w_fe', 'w_mass', 'ref_fe', 'ref_mass', 'Œª_obj']
        
        for param in key_params:
            if param in full_config_info['final_params']:
                results[f'cfg_{param}'] = full_config_info['final_params'][param]

        # –î–æ–¥–∞—î–º–æ –∫–æ–Ω—Ñ—ñ–≥—É—Ä–∞—Ü—ñ—é –¥–æ –º–µ—Ç—Ä–∏–∫
        metrics['config_info'] = full_config_info
        metrics['config_summary'] = {
            'source': full_config_info['config_source'],
            'model_type': full_config_info['final_params'].get('model_type', 'unknown'),
            'kernel': full_config_info['final_params'].get('kernel', 'unknown'),
            'horizons': f"Np={full_config_info['final_params'].get('Np', '?')}, Nc={full_config_info['final_params'].get('Nc', '?')}",
            'weights': f"w_fe={full_config_info['final_params'].get('w_fe', '?')}, w_mass={full_config_info['final_params'].get('w_mass', '?')}",
            'benchmark_features': {
                'comprehensive_analysis': enable_comprehensive_analysis,
                'control_quality_test': benchmark_control_quality,
                'results_saved': save_benchmark_results
            }
        }
        
        print("‚úÖ –ö–æ–Ω—Ñ—ñ–≥—É—Ä–∞—Ü—ñ—é –¥–æ–¥–∞–Ω–æ –¥–æ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ñ–≤")
        return results, metrics
        
    except Exception as e:
        print(f"‚ùå –ü–æ–º–∏–ª–∫–∞ —Å–∏–º—É–ª—è—Ü—ñ—ó: {e}")
        traceback.print_exc()
        raise

def fixed_r2_calculation_simple(y_true, y_pred):
    """
    –ü—Ä–æ—Å—Ç–∞ –≤–∏–ø—Ä–∞–≤–ª–µ–Ω–∞ —Ñ—É–Ω–∫—Ü—ñ—è –¥–ª—è –æ–±—á–∏—Å–ª–µ–Ω–Ω—è R¬≤
    
    Args:
        y_true: –†–µ–∞–ª—å–Ω—ñ –∑–Ω–∞—á–µ–Ω–Ω—è
        y_pred: –ü—Ä–æ–≥–Ω–æ–∑–æ–≤–∞–Ω—ñ –∑–Ω–∞—á–µ–Ω–Ω—è
        
    Returns:
        float: R¬≤ –≤ –¥—ñ–∞–ø–∞–∑–æ–Ω—ñ [0, 1], –¥–µ 1 = —ñ–¥–µ–∞–ª—å–Ω–∞ —Ç–æ—á–Ω—ñ—Å—Ç—å
    """
    if len(y_true) < 2 or len(y_pred) < 2:
        return 0.0
    
    # –û—á–∏—â—É—î–º–æ –≤—ñ–¥ NaN –∑–Ω–∞—á–µ–Ω—å
    mask = ~(np.isnan(y_true) | np.isnan(y_pred))
    y_true = np.array(y_true)[mask]
    y_pred = np.array(y_pred)[mask]
    
    if len(y_true) < 2:
        return 0.0
    
    # –°—Ç–∞–Ω–¥–∞—Ä—Ç–Ω–∏–π R¬≤ —Ä–æ–∑—Ä–∞—Ö—É–Ω–æ–∫
    ss_res = np.sum((y_true - y_pred) ** 2)  # –°—É–º–∞ –∫–≤–∞–¥—Ä–∞—Ç—ñ–≤ –∑–∞–ª–∏—à–∫—ñ–≤
    ss_tot = np.sum((y_true - np.mean(y_true)) ** 2)  # –ó–∞–≥–∞–ª—å–Ω–∞ —Å—É–º–∞ –∫–≤–∞–¥—Ä–∞—Ç—ñ–≤
    
    # –û–±—Ä–æ–±–∫–∞ –∫—Ä–∞–π–æ–≤–∏—Ö –≤–∏–ø–∞–¥–∫—ñ–≤
    if ss_tot < 1e-10:
        return 1.0 if ss_res < 1e-10 else 0.0
    
    r2 = 1 - (ss_res / ss_tot)
    return max(0.0, float(r2))

def compute_correct_mpc_metrics(results_df, basic_metrics, reference_values=None):
    """
    üéØ –ü—Ä–∞–≤–∏–ª—å–Ω—ñ –º–µ—Ç—Ä–∏–∫–∏ –¥–ª—è –æ—Ü—ñ–Ω–∫–∏ —è–∫–æ—Å—Ç—ñ MPC –∫–µ—Ä—É–≤–∞–Ω–Ω—è
    –ó –†–ï–ê–õ–Ü–°–¢–ò–ß–ù–ò–ú–ò –∫—Ä–∏—Ç–µ—Ä—ñ—è–º–∏ –¥–ª—è –ø—Ä–æ–º–∏—Å–ª–æ–≤–∏—Ö –ø—Ä–æ—Ü–µ—Å—ñ–≤
    """
    
    # üîß –ó–ú–Ü–ù–ï–ù–û: –¢–µ–ø–µ—Ä —Ñ—É–Ω–∫—Ü—ñ—è –ø—Ä–∞—Ü—é—î –ë–ï–ó –≤–∏–≤–æ–¥—É –Ω–∞ –∫–æ–Ω—Å–æ–ª—å
    
    if reference_values is None:
        reference_values = {'fe': 53.5, 'mass': 57.0}
    
    mpc_metrics = {}
    
    # 1. üìä –ú–ï–¢–†–ò–ö–ò –¢–û–ß–ù–û–°–¢–Ü –í–Ü–î–°–õ–Ü–î–ö–û–í–£–í–ê–ù–ù–Ø (–ë–ï–ó –í–ò–í–û–î–£)
    if 'conc_fe' in results_df.columns:
        fe_values = results_df['conc_fe'].dropna().values
        fe_setpoint = reference_values['fe']
        
        # –û—Å–Ω–æ–≤–Ω—ñ –º–µ—Ç—Ä–∏–∫–∏ –≤—ñ–¥—Å–ª—ñ–¥–∫–æ–≤—É–≤–∞–Ω–Ω—è
        fe_mean_error = np.mean(fe_values) - fe_setpoint
        fe_abs_error = np.mean(np.abs(fe_values - fe_setpoint))
        fe_max_error = np.max(np.abs(fe_values - fe_setpoint))
        fe_std_error = np.std(fe_values - fe_setpoint)
        
        # ‚úÖ –†–ï–ê–õ–Ü–°–¢–ò–ß–ù–ò–ô –¥–æ–ø—É—Å–∫ –¥–ª—è Fe (¬±0.3% –∑–∞–º—ñ—Å—Ç—å ¬±0.1%)
        fe_tolerance = 0.3  # –ü—Ä–æ–º–∏—Å–ª–æ–≤–æ —Ä–µ–∞–ª—ñ—Å—Ç–∏—á–Ω–∏–π –¥–æ–ø—É—Å–∫
        fe_in_tolerance = np.mean(np.abs(fe_values - fe_setpoint) <= fe_tolerance) * 100
        
        mpc_metrics.update({
            'tracking_error_fe_mean': fe_mean_error,
            'tracking_error_fe_mae': fe_abs_error,
            'tracking_error_fe_max': fe_max_error,
            'tracking_error_fe_std': fe_std_error,
            'tracking_fe_in_tolerance_pct': fe_in_tolerance,
            'tracking_fe_setpoint': fe_setpoint,
            'tracking_fe_achieved': np.mean(fe_values)
        })
    
    if 'conc_mass' in results_df.columns:
        mass_values = results_df['conc_mass'].dropna().values
        mass_setpoint = reference_values['mass']
        
        mass_mean_error = np.mean(mass_values) - mass_setpoint
        mass_abs_error = np.mean(np.abs(mass_values - mass_setpoint))
        mass_max_error = np.max(np.abs(mass_values - mass_setpoint))
        mass_std_error = np.std(mass_values - mass_setpoint)
        
        # ‚úÖ –†–ï–ê–õ–Ü–°–¢–ò–ß–ù–ò–ô –¥–æ–ø—É—Å–∫ –¥–ª—è –º–∞—Å–æ–≤–æ–≥–æ –ø–æ—Ç–æ–∫—É (¬±2 —Ç/–≥–æ–¥ –∑–∞–º—ñ—Å—Ç—å ¬±1)
        mass_tolerance = 2.0  # –ü—Ä–æ–º–∏—Å–ª–æ–≤–æ —Ä–µ–∞–ª—ñ—Å—Ç–∏—á–Ω–∏–π –¥–æ–ø—É—Å–∫
        mass_in_tolerance = np.mean(np.abs(mass_values - mass_setpoint) <= mass_tolerance) * 100
        
        mpc_metrics.update({
            'tracking_error_mass_mean': mass_mean_error,
            'tracking_error_mass_mae': mass_abs_error,
            'tracking_error_mass_max': mass_max_error,
            'tracking_error_mass_std': mass_std_error,
            'tracking_mass_in_tolerance_pct': mass_in_tolerance,
            'tracking_mass_setpoint': mass_setpoint,
            'tracking_mass_achieved': np.mean(mass_values)
        })
    
    # 2. üìà –ú–ï–¢–†–ò–ö–ò –°–¢–ê–ë–Ü–õ–¨–ù–û–°–¢–Ü –ö–ï–†–£–í–ê–ù–ù–Ø (–ë–ï–ó –í–ò–í–û–î–£)
    if 'solid_feed_percent' in results_df.columns:
        control_actions = results_df['solid_feed_percent'].dropna().values
        
        # –í–∞—Ä—ñ–∞–±–µ–ª—å–Ω—ñ—Å—Ç—å –∫–µ—Ä—É–≤–∞–Ω–Ω—è
        control_std = np.std(control_actions)
        control_range = np.max(control_actions) - np.min(control_actions)
        control_mean = np.mean(control_actions)
        
        # –†—ñ–∑–∫—ñ—Å—Ç—å –∑–º—ñ–Ω –∫–µ—Ä—É–≤–∞–Ω–Ω—è
        if len(control_actions) > 1:
            control_changes = np.diff(control_actions)
            control_smoothness = np.std(control_changes)
            control_max_change = np.max(np.abs(control_changes))
            control_total_variation = np.sum(np.abs(control_changes))
        else:
            control_smoothness = 0
            control_max_change = 0
            control_total_variation = 0
        
        mpc_metrics.update({
            'control_mean': control_mean,
            'control_std': control_std,
            'control_range': control_range,
            'control_smoothness': control_smoothness,
            'control_max_change': control_max_change,
            'control_total_variation': control_total_variation
        })
    
    # 3. üèÜ –†–ï–ê–õ–Ü–°–¢–ò–ß–ù–Ü –Ü–ù–¢–ï–ì–†–ê–õ–¨–ù–Ü –ú–ï–¢–†–ò–ö–ò –Ø–ö–û–°–¢–Ü (–ë–ï–ó –í–ò–í–û–î–£)
    # ISE (Integral Square Error)
    if 'conc_fe' in results_df.columns:
        fe_errors = results_df['conc_fe'] - reference_values['fe']
        ise_fe = np.sum(fe_errors**2)
        iae_fe = np.sum(np.abs(fe_errors))
        
        mpc_metrics.update({
            'performance_ise_fe': ise_fe,
            'performance_iae_fe': iae_fe
        })
    
    if 'conc_mass' in results_df.columns:
        mass_errors = results_df['conc_mass'] - reference_values['mass']
        ise_mass = np.sum(mass_errors**2)
        iae_mass = np.sum(np.abs(mass_errors))
        
        mpc_metrics.update({
            'performance_ise_mass': ise_mass,
            'performance_iae_mass': iae_mass
        })
    
    # 4. üéØ –†–ï–ê–õ–Ü–°–¢–ò–ß–ù–ê –ó–ê–ì–ê–õ–¨–ù–ê –û–¶–Ü–ù–ö–ê –Ø–ö–û–°–¢–Ü MPC (–ë–ï–ó –í–ò–í–û–î–£)
    # –ö–æ–º–±—ñ–Ω–æ–≤–∞–Ω–∞ –æ—Ü—ñ–Ω–∫–∞ (0-100, –≤–∏—â–µ = –∫—Ä–∞—â–µ) –∑ –†–ï–ê–õ–Ü–°–¢–ò–ß–ù–ò–ú–ò –∫—Ä–∏—Ç–µ—Ä—ñ—è–º–∏
    quality_factors = []
    
    # ‚úÖ –†–ï–ê–õ–Ü–°–¢–ò–ß–ù–ò–ô —Ñ–∞–∫—Ç–æ—Ä —Ç–æ—á–Ω–æ—Å—Ç—ñ Fe (0-40 –±–∞–ª—ñ–≤)
    if 'tracking_error_fe_mae' in mpc_metrics:
        mae_fe = mpc_metrics['tracking_error_fe_mae']
        fe_accuracy = max(0, 40 - mae_fe * 50)
        quality_factors.append(('Fe —Ç–æ—á–Ω—ñ—Å—Ç—å', fe_accuracy, 40))
    
    # ‚úÖ –†–ï–ê–õ–Ü–°–¢–ò–ß–ù–ò–ô —Ñ–∞–∫—Ç–æ—Ä —Ç–æ—á–Ω–æ—Å—Ç—ñ Mass (0-30 –±–∞–ª—ñ–≤)
    if 'tracking_error_mass_mae' in mpc_metrics:
        mae_mass = mpc_metrics['tracking_error_mass_mae']
        mass_accuracy = max(0, 30 - mae_mass * 15)
        quality_factors.append(('Mass —Ç–æ—á–Ω—ñ—Å—Ç—å', mass_accuracy, 30))
    
    # ‚úÖ –†–ï–ê–õ–Ü–°–¢–ò–ß–ù–ò–ô —Ñ–∞–∫—Ç–æ—Ä —Å—Ç–∞–±—ñ–ª—å–Ω–æ—Å—Ç—ñ –∫–µ—Ä—É–≤–∞–Ω–Ω—è (0-20 –±–∞–ª—ñ–≤)
    if 'control_smoothness' in mpc_metrics:
        smoothness = mpc_metrics['control_smoothness']
        control_stability = max(0, 20 - smoothness * 20)
        quality_factors.append(('–°—Ç–∞–±—ñ–ª—å–Ω—ñ—Å—Ç—å', control_stability, 20))
    
    # ‚úÖ –†–ï–ê–õ–Ü–°–¢–ò–ß–ù–ò–ô —Ñ–∞–∫—Ç–æ—Ä –∫–æ–Ω—Å–∏—Å—Ç–µ–Ω—Ç–Ω–æ—Å—Ç—ñ (0-10 –±–∞–ª—ñ–≤)
    if 'tracking_fe_in_tolerance_pct' in mpc_metrics:
        consistency_pct = mpc_metrics['tracking_fe_in_tolerance_pct']
        consistency = consistency_pct / 10  # 100% –≤ –¥–æ–ø—É—Å–∫—É = 10 –±–∞–ª—ñ–≤
        quality_factors.append(('–ö–æ–Ω—Å–∏—Å—Ç–µ–Ω—Ç–Ω—ñ—Å—Ç—å', consistency, 10))
    
    if quality_factors:
        total_score = sum(factor[1] for factor in quality_factors)
        max_possible = sum(factor[2] for factor in quality_factors)
        
        mpc_quality_score = (total_score / max_possible) * 100
        
        mpc_metrics['mpc_quality_score'] = mpc_quality_score
        
        # ‚úÖ –†–ï–ê–õ–Ü–°–¢–ò–ß–ù–ê –∫–ª–∞—Å–∏—Ñ—ñ–∫–∞—Ü—ñ—è —è–∫–æ—Å—Ç—ñ
        if mpc_quality_score >= 80:
            quality_class = "–ü—Ä–æ–º–∏—Å–ª–æ–≤–æ –≤—ñ–¥–º—ñ–Ω–Ω–æ"
        elif mpc_quality_score >= 65:
            quality_class = "–ü—Ä–æ–º–∏—Å–ª–æ–≤–æ –¥–æ–±—Ä–µ"  
        elif mpc_quality_score >= 50:
            quality_class = "–ü—Ä–æ–º–∏—Å–ª–æ–≤–æ –ø—Ä–∏–π–Ω—è—Ç–Ω–æ"
        elif mpc_quality_score >= 35:
            quality_class = "–ü–æ—Ç—Ä–µ–±—É—î –ø–æ–∫—Ä–∞—â–µ–Ω–Ω—è"
        else:
            quality_class = "–ù–µ–∑–∞–¥–æ–≤—ñ–ª—å–Ω–æ"
        
        mpc_metrics['mpc_quality_class'] = quality_class
    
    # 5. üí° –†–ï–ê–õ–Ü–°–¢–ò–ß–ù–Ü –†–ï–ö–û–ú–ï–ù–î–ê–¶–Ü–á (–ë–ï–ó –í–ò–í–û–î–£)
    recommendations = []
    
    # –û–Ω–æ–≤–ª–µ–Ω—ñ –ø–æ—Ä–æ–≥–∏ –¥–ª—è —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü—ñ–π
    if mpc_metrics.get('tracking_error_fe_mae', 0) > 0.8:  # –ë—É–ª–æ 0.05
        recommendations.append("–ü–æ–∫—Ä–∞—â–∏—Ç–∏ —Ç–æ—á–Ω—ñ—Å—Ç—å –≤—ñ–¥—Å–ª—ñ–¥–∫–æ–≤—É–≤–∞–Ω–Ω—è Fe (MAE > 0.8%)")
    
    if mpc_metrics.get('tracking_error_mass_mae', 0) > 2.0:  # –ë—É–ª–æ 0.5
        recommendations.append("–ü–æ–∫—Ä–∞—â–∏—Ç–∏ —Ç–æ—á–Ω—ñ—Å—Ç—å –≤—ñ–¥—Å–ª—ñ–¥–∫–æ–≤—É–≤–∞–Ω–Ω—è Mass (MAE > 2.0 —Ç/–≥–æ–¥)")
    
    if mpc_metrics.get('control_smoothness', 0) > 1.0:  # –ë—É–ª–æ 0.3
        recommendations.append("–ó–≥–ª–∞–¥–∏—Ç–∏ –∫–µ—Ä—É–≤–∞–Ω–Ω—è (smoothness > 1.0%)")
    
    if mpc_metrics.get('tracking_fe_in_tolerance_pct', 100) < 60:  # –ë—É–ª–æ 80
        recommendations.append("–ü–æ–∫—Ä–∞—â–∏—Ç–∏ –∫–æ–Ω—Å–∏—Å—Ç–µ–Ω—Ç–Ω—ñ—Å—Ç—å –∫–µ—Ä—É–≤–∞–Ω–Ω—è (< 60% –≤ –¥–æ–ø—É—Å–∫—É)")
    
    # –î–æ–¥–∞—î–º–æ –ø–æ–∑–∏—Ç–∏–≤–Ω—ñ —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü—ñ—ó
    if mpc_metrics.get('tracking_error_fe_mae', 0) <= 0.5:
        recommendations.append("‚úÖ –í—ñ–¥–º—ñ–Ω–Ω–∞ —Ç–æ—á–Ω—ñ—Å—Ç—å Fe - –ø—Ä–æ–¥–æ–≤–∂—É–π—Ç–µ!")
    
    if mpc_metrics.get('control_smoothness', 0) <= 0.5:
        recommendations.append("‚úÖ –°—Ç–∞–±—ñ–ª—å–Ω–µ –∫–µ—Ä—É–≤–∞–Ω–Ω—è - –¥–æ–±—Ä–µ –Ω–∞–ª–∞—à—Ç–æ–≤–∞–Ω–æ!")
    
    if not recommendations:
        recommendations.append("MPC –ø—Ä–∞—Ü—é—î –≤—ñ–¥–º—ñ–Ω–Ω–æ –≤ –ø—Ä–æ–º–∏—Å–ª–æ–≤–∏—Ö —É–º–æ–≤–∞—Ö!")
    
    mpc_metrics['recommendations'] = recommendations
    
    # –û–Ω–æ–≤–ª—é—î–º–æ –æ—Å–Ω–æ–≤–Ω—ñ –º–µ—Ç—Ä–∏–∫–∏
    basic_metrics.update(mpc_metrics)
    
    # ‚ùå –í–ò–î–ê–õ–Ø–Ñ–ú–û –ë–ï–ó–ì–õ–£–ó–î–Ü R¬≤ –ú–ï–¢–†–ò–ö–ò
    basic_metrics.pop('r2_fe', None)
    basic_metrics.pop('r2_mass', None)
    
    # ‚úÖ –î–û–î–ê–Ñ–ú–û –ü–†–ê–í–ò–õ–¨–ù–Ü –ú–ï–¢–†–ò–ö–ò
    basic_metrics['mpc_evaluation_method'] = 'realistic_industrial_criteria'
    basic_metrics['constant_outputs_detected'] = True
    basic_metrics['r2_not_applicable'] = 'MPC maintains constant outputs - using tracking metrics instead'
    
    return basic_metrics

# =============================================================================
# === –ê–õ–ò–ê–°–ò –î–õ–Ø –ó–í–û–†–û–¢–ù–û–á –°–£–ú–Ü–°–ù–û–°–¢–Ü ===
# =============================================================================

# –û—Å–Ω–æ–≤–Ω–∞ —Ñ—É–Ω–∫—Ü—ñ—è (—Ä–æ–∑—à–∏—Ä–µ–Ω–∞ –≤–µ—Ä—Å—ñ—è)
simulate_mpc = simulate_mpc_with_config_enhanced

# –û—Ä–∏–≥—ñ–Ω–∞–ª—å–Ω–∞ —Ñ—É–Ω–∫—Ü—ñ—è (–±–µ–∑ —Ä–æ–∑—à–∏—Ä–µ–Ω—å)
simulate_mpc_original = simulate_mpc_core_enhanced

# –ó–ê–ì–£–ë–õ–ï–ù–Ü –ú–ï–¢–û–î–ò –î–õ–Ø –î–û–î–ê–í–ê–ù–ù–Ø –í enhanced_sim.py

def quick_mpc_benchmark(
    hist_df: pd.DataFrame,
    config: str = 'oleksandr_original',
    models_to_test: List[str] = ['krr', 'svr', 'linear'],
    save_results: bool = True
) -> pd.DataFrame:
    """
    üöÄ –®–≤–∏–¥–∫–∏–π –±–µ–Ω—á–º–∞—Ä–∫ —Ä—ñ–∑–Ω–∏—Ö –º–æ–¥–µ–ª–µ–π MPC
    """
    
    print("üöÄ –®–í–ò–î–ö–ò–ô –ë–ï–ù–ß–ú–ê–†–ö MPC")
    print("="*40)
    
    results = []
    
    for model_type in models_to_test:
        print(f"\nüß™ –¢–µ—Å—Ç—É—î–º–æ –º–æ–¥–µ–ª—å: {model_type}")
        
        # –ö–æ–Ω—Ñ—ñ–≥—É—Ä–∞—Ü—ñ—è –¥–ª—è —à–≤–∏–¥–∫–æ–≥–æ —Ç–µ—Å—Ç—É
        config_override = {
            'model_type': model_type,
            'N_data': 3000,  # –ú–µ–Ω—à–µ –¥–∞–Ω–∏—Ö –¥–ª—è —à–≤–∏–¥–∫–æ—Å—Ç—ñ
            'control_pts': 500,
            'find_optimal_params': True,
            'benchmark_speed_analysis': True,
            'run_analysis': False,
            'silent_mode': True,  # –ë–µ–∑ –∑–∞–π–≤–æ–≥–æ –≤–∏–≤–æ–¥—É
            'verbose_reports': False
        }
        
        try:
            start_time = time.time()
            
            results_df, metrics = simulate_mpc_with_config_enhanced(
                hist_df,
                config=config,
                config_overrides=config_override
            )
            
            test_time = time.time() - start_time
            
            # –ó–±–∏—Ä–∞—î–º–æ –∫–ª—é—á–æ–≤—ñ –º–µ—Ç—Ä–∏–∫–∏
            result_row = {
                'Model': model_type,
                'Test_Time_Sec': test_time,
                'RMSE_Fe': metrics.get('test_rmse_conc_fe', 'N/A'),
                'RMSE_Mass': metrics.get('test_rmse_conc_mass', 'N/A'),
                'R2_Fe': metrics.get('r2_fe', 'N/A'),
                'R2_Mass': metrics.get('r2_mass', 'N/A'),
                'MPC_Solve_Time_Ms': metrics.get('mpc_solve_mean', 0) * 1000,
                'Quality_Score': metrics.get('quality_score', 'N/A'),
                'MPC_Quality_Score': metrics.get('mpc_quality_score', 'N/A'),
                'Cycle_Time_Ms': metrics.get('total_cycle_time', 0) * 1000,
                'Real_Time_Suitable': metrics.get('real_time_suitable', False),
                # ISE/IAE –º–µ—Ç—Ä–∏–∫–∏
                'ISE_Fe': metrics.get('performance_ise_fe_normalized', 'N/A'),
                'IAE_Fe': metrics.get('performance_iae_fe_normalized', 'N/A'),
                'Combined_ISE': metrics.get('performance_combined_ise', 'N/A')
            }
            
            results.append(result_row)
            
            print(f"   ‚úÖ –ó–∞–≤–µ—Ä—à–µ–Ω–æ –∑–∞ {test_time:.1f}—Å")
            if isinstance(result_row['RMSE_Fe'], (int, float)):
                print(f"   üìä RMSE Fe: {result_row['RMSE_Fe']:.4f}")
            if isinstance(result_row['MPC_Quality_Score'], (int, float)):
                print(f"   üéØ MPC –Ø–∫—ñ—Å—Ç—å: {result_row['MPC_Quality_Score']:.1f}")
            
        except Exception as e:
            print(f"   ‚ùå –ü–æ–º–∏–ª–∫–∞: {e}")
            results.append({
                'Model': model_type,
                'Error': str(e)
            })
    
    # –°—Ç–≤–æ—Ä—é—î–º–æ DataFrame
    results_df = pd.DataFrame(results)
    
    # –°–æ—Ä—Ç—É—î–º–æ –∑–∞ RMSE Fe (—è–∫—â–æ –¥–æ—Å—Ç—É–ø–Ω–µ)
    if 'RMSE_Fe' in results_df.columns:
        # –°–æ—Ä—Ç—É—î–º–æ —Ç—ñ–ª—å–∫–∏ —á–∏—Å–ª–æ–≤—ñ –∑–Ω–∞—á–µ–Ω–Ω—è
        numeric_mask = pd.to_numeric(results_df['RMSE_Fe'], errors='coerce').notna()
        if numeric_mask.any():
            results_df = pandas_safe_sort(results_df, 'RMSE_Fe')
    
    print(f"\nüìä –†–ï–ó–£–õ–¨–¢–ê–¢–ò –®–í–ò–î–ö–û–ì–û –ë–ï–ù–ß–ú–ê–†–ö–£:")
    display_cols = ['Model', 'RMSE_Fe', 'MPC_Quality_Score', 'ISE_Fe', 'Cycle_Time_Ms', 'Real_Time_Suitable']
    available_cols = [col for col in display_cols if col in results_df.columns]
    if available_cols:
        print(results_df[available_cols].to_string(index=False))
    
    # –ó–±–µ—Ä–µ–∂–µ–Ω–Ω—è —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ñ–≤
    if save_results:
        timestamp = pd.Timestamp.now().strftime("%Y%m%d_%H%M%S")
        filename = f"quick_benchmark_{timestamp}.csv"
        results_df.to_csv(filename, index=False)
        print(f"üíæ –†–µ–∑—É–ª—å—Ç–∞—Ç–∏ –∑–±–µ—Ä–µ–∂–µ–Ω–æ: {filename}")
    
    return results_df


def detailed_mpc_analysis(
    hist_df: pd.DataFrame,
    config: str = 'oleksandr_original',
    config_overrides: Optional[Dict] = None
) -> Dict[str, Any]:
    """
    üî¨ –î–µ—Ç–∞–ª—å–Ω–∏–π –∞–Ω–∞–ª—ñ–∑ MPC –∑ —É—Å—ñ–º–∞ –º–æ–∂–ª–∏–≤–∏–º–∏ –¥—ñ–∞–≥–Ω–æ—Å—Ç–∏–∫–∞–º–∏
    """
    
    print("üî¨ –î–ï–¢–ê–õ–¨–ù–ò–ô –ê–ù–ê–õ–Ü–ó MPC")
    print("="*50)
    
    # –ó–∞–ø—É—Å–∫–∞—î–º–æ –∑ —É—Å—ñ–º–∞ —É–≤—ñ–º–∫–Ω–µ–Ω–∏–º–∏ —Ñ—É–Ω–∫—Ü—ñ—è–º–∏
    results_df, metrics = simulate_mpc_with_config_enhanced(
        hist_df,
        config=config,
        config_overrides=config_overrides,
        enable_comprehensive_analysis=True,
        benchmark_control_quality=True,
        save_benchmark_results=True
    )
    
    # –°—Ç–≤–æ—Ä—é—î–º–æ –¥–µ—Ç–∞–ª—å–Ω–∏–π –∑–≤—ñ—Ç
    analysis_report = {
        'basic_metrics': {k: v for k, v in metrics.items() if k.startswith('test_')},
        'speed_metrics': {k: v for k, v in metrics.items() if 'time' in k.lower()},
        'quality_metrics': {k: v for k, v in metrics.items() if k.startswith('control_') or k.startswith('quality_')},
        'ise_iae_metrics': {k: v for k, v in metrics.items() if k.startswith('performance_')},
        'comprehensive_analysis': metrics.get('comprehensive_analysis', {}),
        'configuration': metrics.get('config_summary', {}),
        'recommendations': []
    }
    
    # –ì–µ–Ω–µ—Ä—É—î–º–æ —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü—ñ—ó
    rmse_fe = metrics.get('test_rmse_conc_fe', 0)
    if rmse_fe > 0.1:
        analysis_report['recommendations'].append(
            f"–í–∏—Å–æ–∫–∞ –ø–æ—Ö–∏–±–∫–∞ Fe (RMSE={rmse_fe:.4f}): —Ä–æ–∑–≥–ª—è–Ω—å—Ç–µ —ñ–Ω—à–∏–π —Ç–∏–ø –º–æ–¥–µ–ª—ñ –∞–±–æ –∑–±—ñ–ª—å—à—ñ—Ç—å –∫—ñ–ª—å–∫—ñ—Å—Ç—å –¥–∞–Ω–∏—Ö"
        )
    
    cycle_time = metrics.get('total_cycle_time', 0)
    if cycle_time > 5.0:
        analysis_report['recommendations'].append(
            f"–ü–æ–≤—ñ–ª—å–Ω–∏–π —Ü–∏–∫–ª ({cycle_time:.2f}—Å): –æ–ø—Ç–∏–º—ñ–∑—É–π—Ç–µ –ø–∞—Ä–∞–º–µ—Ç—Ä–∏ –º–æ–¥–µ–ª—ñ –∞–±–æ –∑–º–µ–Ω—à—ñ—Ç—å –≥–æ—Ä–∏–∑–æ–Ω—Ç MPC"
        )
    
    mpc_quality_score = metrics.get('mpc_quality_score', 100)
    if mpc_quality_score < 65:
        analysis_report['recommendations'].append(
            f"–ü–æ–≥–∞–Ω–∞ —è–∫—ñ—Å—Ç—å MPC ({mpc_quality_score:.1f}/100): –Ω–∞–ª–∞—à—Ç—É–π—Ç–µ –≤–∞–≥–∏ —Ü—ñ–ª—å–æ–≤–æ—ó —Ñ—É–Ω–∫—Ü—ñ—ó"
        )
    
    # ISE/IAE —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü—ñ—ó
    ise_fe = metrics.get('performance_ise_fe_normalized', 0)
    if ise_fe > 5.0:
        analysis_report['recommendations'].append(
            f"–í–∏—Å–æ–∫–∞ —ñ–Ω—Ç–µ–≥—Ä–∞–ª—å–Ω–∞ –ø–æ—Ö–∏–±–∫–∞ (ISE={ise_fe:.2f}): –ø–æ–∫—Ä–∞—â—ñ—Ç—å –Ω–∞–ª–∞—à—Ç—É–≤–∞–Ω–Ω—è –∫–æ–Ω—Ç—Ä–æ–ª–µ—Ä–∞"
        )
    
    print(f"\nüìã –î–ï–¢–ê–õ–¨–ù–ò–ô –ó–í–Ü–¢ –°–¢–í–û–†–ï–ù–û")
    print(f"   üìä –ë–∞–∑–æ–≤–∏—Ö –º–µ—Ç—Ä–∏–∫: {len(analysis_report['basic_metrics'])}")
    print(f"   ‚ö° –ú–µ—Ç—Ä–∏–∫ —à–≤–∏–¥–∫–æ—Å—Ç—ñ: {len(analysis_report['speed_metrics'])}")
    print(f"   üéØ –ú–µ—Ç—Ä–∏–∫ —è–∫–æ—Å—Ç—ñ: {len(analysis_report['quality_metrics'])}")
    print(f"   üìà ISE/IAE –º–µ—Ç—Ä–∏–∫: {len(analysis_report['ise_iae_metrics'])}")
    print(f"   üí° –†–µ–∫–æ–º–µ–Ω–¥–∞—Ü—ñ–π: {len(analysis_report['recommendations'])}")
    
    for rec in analysis_report['recommendations']:
        print(f"      ‚Ä¢ {rec}")
    
    return analysis_report


def compare_mpc_configurations(
    configurations: List[Dict],
    hist_df: pd.DataFrame,
    base_config: str = 'oleksandr_original',
    comparison_steps: int = 100,
    show_progress: bool = True
) -> pd.DataFrame:
    """
    üîÑ –ü–û–í–ù–ê –†–ï–ê–õ–Ü–ó–ê–¶–Ü–Ø –ø–æ—Ä—ñ–≤–Ω—è–Ω–Ω—è –∫–æ–Ω—Ñ—ñ–≥—É—Ä–∞—Ü—ñ–π MPC –∑ –¥—ñ–∞–≥–Ω–æ—Å—Ç–∏–∫–æ—é ISE/IAE
    
    üîß –í–ò–ü–†–ê–í–õ–ï–ù–û: –ü–µ—Ä–µ–Ω–µ—Å–µ–Ω–æ –ø–æ–≤–Ω—É —Ä–µ–∞–ª—ñ–∑–∞—Ü—ñ—é –≤ enhanced_sim.py + –¥–æ–¥–∞–Ω–æ –¥—ñ–∞–≥–Ω–æ—Å—Ç–∏–∫—É
    """
    
    print("üîÑ –ö–û–†–ï–ö–¢–ù–ï –ü–û–†–Ü–í–ù–Ø–ù–ù–Ø –ö–û–ù–§–Ü–ì–£–†–ê–¶–Ü–ô MPC")
    print("="*60)
    print("üéØ –ü—Ä–∏–Ω—Ü–∏–ø: –ü–æ–≤–Ω–∞ –ø–æ–≤–∞–≥–∞ –¥–æ –∫–æ–Ω—Ñ—ñ–≥—É—Ä–∞—Ü—ñ—ó –µ–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç–∞—Ç–æ—Ä–∞")
    print("üìä –†–∞–Ω–∂—É–≤–∞–Ω–Ω—è: 70% MPC —è–∫—ñ—Å—Ç—å + 30% —Ç–æ—á–Ω—ñ—Å—Ç—å –º–æ–¥–µ–ª—ñ")
    
    comparison_results = []
    detailed_reports = []
    
    for i, config in enumerate(configurations):
        config_name = config.get('name', f'Config_{i+1}')
        
        if show_progress:
            print(f"\nüß™ –¢–µ—Å—Ç—É—î–º–æ –∫–æ–Ω—Ñ—ñ–≥—É—Ä–∞—Ü—ñ—é {i+1}/{len(configurations)}: {config_name}")
        
        try:
            # üéØ –ü–ï–†–ï–î–ê–Ñ–ú–û –ö–û–ù–§–Ü–ì–£–†–ê–¶–Ü–Æ –ë–ï–ó –ó–ú–Ü–ù
            test_config = config.copy()
            test_config.pop('name', None)
            
            # üîá –ö–û–ù–¢–†–û–õ–¨ –í–ò–í–û–î–£
            output_control_params = ['silent_mode', 'verbose_reports']
            original_output_settings = {}
            
            for param in output_control_params:
                if param in test_config:
                    original_output_settings[param] = test_config[param]
                    if show_progress:
                        print(f"   üéØ –ï–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç–∞—Ç–æ—Ä –∑–∞–¥–∞–≤ {param}={test_config[param]}")
                else:
                    if param == 'silent_mode':
                        test_config[param] = True
                        original_output_settings[param] = None
                    elif param == 'verbose_reports':
                        test_config[param] = False
                        original_output_settings[param] = None
            
            # üìã –ü–û–ö–ê–ó–£–Ñ–ú–û –ö–û–ù–§–Ü–ì–£–†–ê–¶–Ü–Æ
            if show_progress:
                print(f"   üìã –ö–æ–Ω—Ñ—ñ–≥—É—Ä–∞—Ü—ñ—è –µ–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç–∞—Ç–æ—Ä–∞:")
                experimental_params = {k: v for k, v in test_config.items() 
                                     if k not in ['silent_mode', 'verbose_reports']}
                
                if experimental_params:
                    for key, value in experimental_params.items():
                        print(f"      üéØ {key}: {value}")
                else:
                    print(f"      üéØ –í–∏–∫–æ—Ä–∏—Å—Ç–æ–≤—É—é—Ç—å—Å—è –≤—Å—ñ –ø–∞—Ä–∞–º–µ—Ç—Ä–∏ –∑–∞ –∑–∞–º–æ–≤—á—É–≤–∞–Ω–Ω—è–º")
            
            # üöÄ –ó–ê–ü–£–°–ö–ê–Ñ–ú–û –°–ò–ú–£–õ–Ø–¶–Ü–Æ
            start_time = time.time()
            
            if base_config and base_config != 'default':
                try:
                    results_df, metrics = simulate_mpc_with_config_enhanced(
                        hist_df, 
                        config=base_config,
                        config_overrides=test_config
                    )
                except Exception as sim_error:
                    print(f"   ‚ö†Ô∏è Fallback –¥–æ simulate_mpc_core_enhanced: {sim_error}")
                    results_df, metrics = simulate_mpc_core_enhanced(hist_df, **test_config)
            else:
                results_df, metrics = simulate_mpc_core_enhanced(hist_df, **test_config)
            
            test_time = time.time() - start_time
            
            # üîç –î–û–î–ê–Ñ–ú–û –î–Ü–ê–ì–ù–û–°–¢–ò–ö–£ ISE/IAE –¢–£–¢!
            if show_progress:
                print(f"   üîç –î—ñ–∞–≥–Ω–æ—Å—Ç–∏–∫–∞ ISE/IAE...")
                try:
                    diagnostic_result = add_diagnostic_to_comparison(
                        config_name, 
                        results_df, 
                        metrics, 
                        {'fe': 54.5, 'mass': 57.0}
                    )
                except Exception as diag_error:
                    print(f"   ‚ö†Ô∏è –ü–æ–º–∏–ª–∫–∞ –¥—ñ–∞–≥–Ω–æ—Å—Ç–∏–∫–∏: {diag_error}")
                    diagnostic_result = {}
            
            # üìä –ó–ë–ò–†–ê–Ñ–ú–û –ú–ï–¢–†–ò–ö–ò –ó ISE/IAE
            comparison_row = {
                'Configuration': config_name,
                'Model': f"{config.get('model_type', 'default')}-{config.get('kernel', 'default')}",
                'Test_Time_Min': test_time / 60
            }
            
            # –î–æ–¥–∞—î–º–æ –ø–∞—Ä–∞–º–µ—Ç—Ä–∏ –µ–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç–∞—Ç–æ—Ä–∞
            experimental_params = ['N_data', 'Np', 'Nc', 'Œª_obj', 'w_fe', 'w_mass', 
                                 'find_optimal_params', 'model_type', 'kernel']
            
            for param in experimental_params:
                if param in config:
                    comparison_row[f'Config_{param}'] = config[param]
                else:
                    comparison_row[f'Config_{param}'] = 'default'
            
            # –î–æ–¥–∞—î–º–æ –±–∞–∑–æ–≤—ñ –º–µ—Ç—Ä–∏–∫–∏ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ñ–≤
            if isinstance(metrics, dict):
                result_metrics = {
                    'RMSE_Fe': metrics.get('test_rmse_conc_fe', np.nan),
                    'RMSE_Mass': metrics.get('test_rmse_conc_mass', np.nan),
                    'R2_Fe': metrics.get('r2_fe', np.nan),
                    'R2_Mass': metrics.get('r2_mass', np.nan),
                    'Quality_Score': metrics.get('quality_score', np.nan),
                    'MPC_Quality_Score': metrics.get('mpc_quality_score', np.nan),
                    'Total_Cycle_Time': metrics.get('total_cycle_time', np.nan),
                    'Real_Time_Suitable': metrics.get('real_time_suitable', False),
                    # üÜï –î–û–î–ê–Ñ–ú–û ISE/IAE –ú–ï–¢–†–ò–ö–ò
                    'ISE_Fe': metrics.get('performance_ise_fe_normalized', np.nan),
                    'IAE_Fe': metrics.get('performance_iae_fe_normalized', np.nan),
                    'ISE_Mass': metrics.get('performance_ise_mass_normalized', np.nan),
                    'IAE_Mass': metrics.get('performance_iae_mass_normalized', np.nan),
                    'ITSE_Fe': metrics.get('performance_itse_fe', np.nan),
                    'ITAE_Fe': metrics.get('performance_itae_fe', np.nan),
                    'Combined_ISE': metrics.get('performance_combined_ise', np.nan),
                    'Combined_IAE': metrics.get('performance_combined_iae', np.nan)
                }
                comparison_row.update(result_metrics)
                
                # üîß –ö–û–ú–ë–Ü–ù–û–í–ê–ù–ê –û–¶–Ü–ù–ö–ê
                rmse_fe = result_metrics['RMSE_Fe']
                mpc_quality = result_metrics['MPC_Quality_Score']
                
                if pd.notna(rmse_fe) and pd.notna(mpc_quality):
                    mpc_norm = mpc_quality / 100
                    rmse_norm = 1 / (1 + rmse_fe)
                    combined_score = 0.7 * mpc_norm + 0.3 * rmse_norm
                    comparison_row['Combined_Score'] = combined_score
                else:
                    comparison_row['Combined_Score'] = np.nan
                
                # –ó–±–µ—Ä—ñ–≥–∞—î–º–æ –¥–µ—Ç–∞–ª—å–Ω—ñ –¥–∞–Ω—ñ
                detailed_report = {
                    'config_name': config_name,
                    'original_config': config.copy(),
                    'base_config_used': base_config,
                    'results_df': results_df,
                    'full_metrics': metrics,
                    'summary_metrics': comparison_row,
                    'output_settings': original_output_settings
                }
                detailed_reports.append(detailed_report)
            
            comparison_results.append(comparison_row)
            
            # –ó–≤—ñ—Ç –ø—Ä–æ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∏ –∑ ISE/IAE
            if show_progress:
                rmse_fe = comparison_row.get('RMSE_Fe', float('inf'))
                quality = comparison_row.get('Quality_Score', 1)
                mpc_quality = comparison_row.get('MPC_Quality_Score', 0)
                combined = comparison_row.get('Combined_Score', 0)
                ise_fe = comparison_row.get('ISE_Fe', 0)
                iae_fe = comparison_row.get('IAE_Fe', 0)
                
                print(f"   ‚úÖ –†–µ–∑—É–ª—å—Ç–∞—Ç–∏:")
                print(f"      RMSE Fe: {rmse_fe:.4f}")
                print(f"      –Ø–∫—ñ—Å—Ç—å –∫–µ—Ä—É–≤–∞–Ω–Ω—è: {quality:.4f}")
                if not np.isnan(mpc_quality):
                    print(f"      MPC –æ—Ü—ñ–Ω–∫–∞: {mpc_quality:.1f}/100")
                if not np.isnan(combined):
                    print(f"      –ö–æ–º–±—ñ–Ω–æ–≤–∞–Ω–∞ –æ—Ü—ñ–Ω–∫–∞: {combined:.4f}")
                if not np.isnan(ise_fe):
                    print(f"      ISE Fe: {ise_fe:.2f}")
                if not np.isnan(iae_fe):
                    print(f"      IAE Fe: {iae_fe:.2f}")
                print(f"      –ß–∞—Å: {test_time/60:.1f}—Ö–≤")
            
        except Exception as e:
            print(f"   ‚ùå –ü–æ–º–∏–ª–∫–∞: {e}")
            import traceback
            traceback.print_exc()
            comparison_results.append({
                'Configuration': config_name,
                'Error': str(e),
                'Test_Time_Min': 0,
                'Combined_Score': np.nan
            })
    
    # –°—Ç–≤–æ—Ä—é—î–º–æ DataFrame
    comparison_df = pd.DataFrame(comparison_results)
    
    # üîß –°–û–†–¢–£–Ñ–ú–û –ó–ê –ö–û–ú–ë–Ü–ù–û–í–ê–ù–û–Æ –û–¶–Ü–ù–ö–û–Æ
    if not comparison_df.empty and 'Combined_Score' in comparison_df.columns:
        valid_mask = comparison_df['Combined_Score'].notna()
        if valid_mask.any():
            print(f"\nüîß –ó–∞—Å—Ç–æ—Å–æ–≤—É—î–º–æ –∫–æ–º–±—ñ–Ω–æ–≤–∞–Ω–µ —Å–æ—Ä—Ç—É–≤–∞–Ω–Ω—è –¥–ª—è {valid_mask.sum()} –∫–æ–Ω—Ñ—ñ–≥—É—Ä–∞—Ü—ñ–π...")
            
            valid_df = comparison_df[valid_mask].sort_values('Combined_Score', ascending=False)
            invalid_df = comparison_df[~valid_mask]
            comparison_df = pd.concat([valid_df, invalid_df], ignore_index=True)
            
            print(f"üèÜ –¢–æ–ø-3 –∑–∞ –∫–æ–º–±—ñ–Ω–æ–≤–∞–Ω–æ—é –æ—Ü—ñ–Ω–∫–æ—é:")
            for idx in range(min(3, len(valid_df))):
                row = valid_df.iloc[idx]
                print(f"   {idx+1}. {row['Configuration']}: {row['Combined_Score']:.4f} "
                      f"(MPC: {row.get('MPC_Quality_Score', 0):.1f}, RMSE: {row.get('RMSE_Fe', 0):.4f})")
        else:
            print(f"‚ö†Ô∏è –ù–µ –≤–¥–∞–ª–æ—Å—è –æ–±—á–∏—Å–ª–∏—Ç–∏ –∫–æ–º–±—ñ–Ω–æ–≤–∞–Ω—ñ –æ—Ü—ñ–Ω–∫–∏ - —Å–æ—Ä—Ç—É—î–º–æ –∑–∞ RMSE")
            if 'RMSE_Fe' in comparison_df.columns:
                valid_mask = comparison_df['RMSE_Fe'].notna()
                if valid_mask.any():
                    valid_df = comparison_df[valid_mask].sort_values('RMSE_Fe')
                    invalid_df = comparison_df[~valid_mask]
                    comparison_df = pd.concat([valid_df, invalid_df], ignore_index=True)
    
    # üìä –î–ï–¢–ê–õ–¨–ù–Ü –ó–í–Ü–¢–ò –ó ISE/IAE
    show_detailed_reports = any(
        report['output_settings'].get('verbose_reports', False) or 
        not report['output_settings'].get('silent_mode', True)
        for report in detailed_reports
    )
    
    if show_detailed_reports:
        print(f"\n" + "="*80)
        print(f"üìä –î–ï–¢–ê–õ–¨–ù–Ü –ó–í–Ü–¢–ò –î–õ–Ø –ö–û–ù–§–Ü–ì–£–†–ê–¶–Ü–ô –ó –£–í–Ü–ú–ö–ù–ï–ù–ò–ú –í–ò–í–û–î–û–ú")
        print("="*80)
        
        for i, report in enumerate(detailed_reports):
            if (report['output_settings'].get('verbose_reports', False) or 
                not report['output_settings'].get('silent_mode', True)):
                
                config_name = report['config_name']
                metrics = report['full_metrics']
                original_config = report['original_config']
                
                print(f"\n{'='*60}")
                print(f"üìã –ö–û–ù–§–Ü–ì–£–†–ê–¶–Ü–Ø: {config_name}")
                print(f"{'='*60}")
                
                # –ü–æ–∫–∞–∑—É—î–º–æ –æ—Ä–∏–≥—ñ–Ω–∞–ª—å–Ω—É –∫–æ–Ω—Ñ—ñ–≥—É—Ä–∞—Ü—ñ—é
                print(f"üéØ –ö–û–ù–§–Ü–ì–£–†–ê–¶–Ü–Ø –ï–ö–°–ü–ï–†–ò–ú–ï–ù–¢–ê–¢–û–†–ê:")
                experimental_params = {k: v for k, v in original_config.items() if k != 'name'}
                if experimental_params:
                    for key, value in experimental_params.items():
                        print(f"   ‚Ä¢ {key}: {value}")
                else:
                    print(f"   ‚Ä¢ –í–∏–∫–æ—Ä–∏—Å—Ç–æ–≤—É—é—Ç—å—Å—è –≤—Å—ñ –ø–∞—Ä–∞–º–µ—Ç—Ä–∏ –∑–∞ –∑–∞–º–æ–≤—á—É–≤–∞–Ω–Ω—è–º")
                
                # –§—ñ–Ω–∞–ª—å–Ω–∏–π –∑–≤—ñ—Ç –ø—Ä–æ –ø—Ä–æ–¥—É–∫—Ç–∏–≤–Ω—ñ—Å—Ç—å
                print(f"\nüîç –ó–í–Ü–¢ –ü–†–û –ü–†–û–î–£–ö–¢–ò–í–ù–Ü–°–¢–¨:")
                print("-" * 40)
                
                key_metrics = ['test_rmse_conc_fe', 'test_rmse_conc_mass', 'r2_fe', 'r2_mass']
                for metric in key_metrics:
                    if metric in metrics:
                        value = metrics[metric]
                        if hasattr(value, 'item'):
                            value = value.item()
                        print(f"   üìä {metric}: {value:.6f}")
                
                if 'total_cycle_time' in metrics:
                    print(f"   ‚ö° –ß–∞—Å —Ü–∏–∫–ª—É: {metrics['total_cycle_time']*1000:.1f}ms")
                
                if 'quality_score' in metrics:
                    print(f"   üéØ –û—Ü—ñ–Ω–∫–∞ —è–∫–æ—Å—Ç—ñ: {metrics['quality_score']:.4f}")
                
                # üÜï ISE/IAE –ú–ï–¢–†–ò–ö–ò –í –î–ï–¢–ê–õ–¨–ù–û–ú–£ –ó–í–Ü–¢–Ü
                print(f"\nüìà –Ü–ù–¢–ï–ì–†–ê–õ–¨–ù–Ü –ú–ï–¢–†–ò–ö–ò –Ø–ö–û–°–¢–Ü (ISE/IAE):")
                print("-" * 40)
                
                ise_iae_metrics = [
                    ('performance_ise_fe_normalized', 'ISE Fe (–Ω–æ—Ä–º–∞–ª—ñ–∑–æ–≤–∞–Ω–∏–π)'),
                    ('performance_iae_fe_normalized', 'IAE Fe (–Ω–æ—Ä–º–∞–ª—ñ–∑–æ–≤–∞–Ω–∏–π)'),
                    ('performance_ise_mass_normalized', 'ISE Mass (–Ω–æ—Ä–º–∞–ª—ñ–∑–æ–≤–∞–Ω–∏–π)'),
                    ('performance_iae_mass_normalized', 'IAE Mass (–Ω–æ—Ä–º–∞–ª—ñ–∑–æ–≤–∞–Ω–∏–π)'),
                    ('performance_combined_ise', '–ö–æ–º–±—ñ–Ω–æ–≤–∞–Ω–∏–π ISE'),
                    ('performance_combined_iae', '–ö–æ–º–±—ñ–Ω–æ–≤–∞–Ω–∏–π IAE')
                ]
                
                for key, description in ise_iae_metrics:
                    if key in metrics and not pd.isna(metrics[key]):
                        print(f"   üìä {description}: {metrics[key]:.4f}")
                    else:
                        print(f"   ‚ùå {description}: –ù–ï –û–ë–ß–ò–°–õ–ï–ù–û")
                
                # MPC –º–µ—Ç—Ä–∏–∫–∏
                print(f"\nüéØ –ú–ï–¢–†–ò–ö–ò –Ø–ö–û–°–¢–Ü MPC:")
                print("-" * 40)
                
                mpc_metrics = ['tracking_error_fe_mae', 'tracking_error_mass_mae', 
                             'control_smoothness', 'mpc_quality_score', 'mpc_quality_class']
                
                for key in mpc_metrics:
                    if key in metrics:
                        value = metrics[key]
                        if key == 'tracking_error_fe_mae':
                            print(f"   üìà Fe —Ç–æ—á–Ω—ñ—Å—Ç—å (MAE): {value:.3f}%")
                        elif key == 'tracking_error_mass_mae':
                            print(f"   üìà Mass —Ç–æ—á–Ω—ñ—Å—Ç—å (MAE): {value:.3f} —Ç/–≥–æ–¥")
                        elif key == 'control_smoothness':
                            print(f"   üéõÔ∏è –ü–ª–∞–≤–Ω—ñ—Å—Ç—å –∫–µ—Ä—É–≤–∞–Ω–Ω—è: {value:.3f}%")
                        elif key == 'mpc_quality_score':
                            print(f"   üèÜ –ó–∞–≥–∞–ª—å–Ω–∞ –æ—Ü—ñ–Ω–∫–∞ MPC: {value:.1f}/100")
                        elif key == 'mpc_quality_class':
                            print(f"   üìä –ö–ª–∞—Å–∏—Ñ—ñ–∫–∞—Ü—ñ—è: {value}")
                
                if 'recommendations' in metrics and metrics['recommendations']:
                    print(f"   üí° –†–µ–∫–æ–º–µ–Ω–¥–∞—Ü—ñ—ó:")
                    for j, rec in enumerate(metrics['recommendations'][:3], 1):
                        print(f"      {j}. {rec}")
    
    # üìä –ü–Ü–î–°–£–ú–ö–û–í–ê –¢–ê–ë–õ–ò–¶–Ø –ó ISE/IAE
    print(f"\n" + "="*80)
    print(f"üìä –ü–Ü–î–°–£–ú–ö–û–í–ê –¢–ê–ë–õ–ò–¶–Ø –ü–û–†–Ü–í–ù–Ø–ù–ù–Ø (–∑ ISE/IAE)")
    print("="*80)
    
    if not comparison_df.empty:
        # –í–∏–±–∏—Ä–∞—î–º–æ –∫–æ–ª–æ–Ω–∫–∏ –¥–ª—è –≤—ñ–¥–æ–±—Ä–∞–∂–µ–Ω–Ω—è –≤–∫–ª—é—á–∞—é—á–∏ ISE/IAE
        display_cols = ['Configuration', 'Model', 'RMSE_Fe', 'MPC_Quality_Score', 
                       'ISE_Fe', 'IAE_Fe', 'Combined_ISE', 'Combined_Score', 'Test_Time_Min']
        
        available_cols = [col for col in display_cols if col in comparison_df.columns]
        
        if available_cols:
            display_df = comparison_df[available_cols].round(4)
            print(display_df.to_string(index=False))
        
        # üîß –†–ï–ó–£–õ–¨–¢–ê–¢–ò –ó ISE/IAE –Ü–ù–§–û–†–ú–ê–¶–Ü–Ñ–Æ
        print(f"\nüèÜ –†–ï–ó–£–õ–¨–¢–ê–¢–ò (–∑–∞ –∫–æ–º–±—ñ–Ω–æ–≤–∞–Ω–æ—é –æ—Ü—ñ–Ω–∫–æ—é):")
        if not comparison_df.empty:
            best_config = comparison_df.iloc[0]
            print(f"   ü•á –ù–∞–π–∫—Ä–∞—â–∞ –∫–æ–Ω—Ñ—ñ–≥—É—Ä–∞—Ü—ñ—è: {best_config['Configuration']}")
            
            if 'Combined_Score' in best_config and pd.notna(best_config['Combined_Score']):
                print(f"   üéØ –ö–æ–º–±—ñ–Ω–æ–≤–∞–Ω–∞ –æ—Ü—ñ–Ω–∫–∞: {best_config['Combined_Score']:.4f}")
                print(f"   üìä –õ–æ–≥—ñ–∫–∞: 70% MPC —è–∫—ñ—Å—Ç—å + 30% —Ç–æ—á–Ω—ñ—Å—Ç—å –º–æ–¥–µ–ª—ñ")
            
            if 'RMSE_Fe' in best_config and pd.notna(best_config['RMSE_Fe']):
                print(f"   üìà RMSE Fe: {best_config['RMSE_Fe']:.4f}")
            
            if 'MPC_Quality_Score' in best_config and pd.notna(best_config['MPC_Quality_Score']):
                print(f"   üéØ MPC –Ø–∫—ñ—Å—Ç—å: {best_config['MPC_Quality_Score']:.1f}/100")
            
            # üÜï –î–û–î–ê–Ñ–ú–û ISE/IAE –î–û –ü–Ü–î–°–£–ú–ö–£
            if 'ISE_Fe' in best_config and pd.notna(best_config['ISE_Fe']):
                print(f"   üìä ISE Fe (–Ω–æ—Ä–º.): {best_config['ISE_Fe']:.4f}")
            else:
                print(f"   ‚ùå ISE Fe: –ù–ï –û–ë–ß–ò–°–õ–ï–ù–û")
            
            if 'IAE_Fe' in best_config and pd.notna(best_config['IAE_Fe']):
                print(f"   üìä IAE Fe (–Ω–æ—Ä–º.): {best_config['IAE_Fe']:.4f}")
            else:
                print(f"   ‚ùå IAE Fe: –ù–ï –û–ë–ß–ò–°–õ–ï–ù–û")
            
            if 'Combined_ISE' in best_config and pd.notna(best_config['Combined_ISE']):
                print(f"   üìä –ö–æ–º–±—ñ–Ω–æ–≤–∞–Ω–∏–π ISE: {best_config['Combined_ISE']:.4f}")
            else:
                print(f"   ‚ùå –ö–æ–º–±—ñ–Ω–æ–≤–∞–Ω–∏–π ISE: –ù–ï –û–ë–ß–ò–°–õ–ï–ù–û")
                
            # –Ü–Ω—Ç–µ—Ä–ø—Ä–µ—Ç–∞—Ü—ñ—è —Ä–µ–∑—É–ª—å—Ç–∞—Ç—É –∑ —É—Ä–∞—Ö—É–≤–∞–Ω–Ω—è–º ISE/IAE
            mpc_quality = best_config.get('MPC_Quality_Score', 0)
            if pd.notna(mpc_quality):
                if mpc_quality >= 65:
                    print(f"   ‚úÖ –í–∏—Å–æ–∫–∞ —è–∫—ñ—Å—Ç—å MPC - –≥–æ—Ç–æ–≤–æ –¥–ª—è –ø—Ä–æ–º–∏—Å–ª–æ–≤–æ–≥–æ –≤–∏–∫–æ—Ä–∏—Å—Ç–∞–Ω–Ω—è")
                elif mpc_quality >= 50:
                    print(f"   ‚ö†Ô∏è –°–µ—Ä–µ–¥–Ω—è —è–∫—ñ—Å—Ç—å MPC - —Ä–æ–∑–≥–ª—è–Ω—å—Ç–µ –¥–æ–¥–∞—Ç–∫–æ–≤–µ –Ω–∞–ª–∞—à—Ç—É–≤–∞–Ω–Ω—è")
                else:
                    print(f"   üîß –ù–∏–∑—å–∫–∞ —è–∫—ñ—Å—Ç—å MPC - –ø–æ—Ç—Ä—ñ–±–Ω–µ —Å–µ—Ä–π–æ–∑–Ω–µ –Ω–∞–ª–∞—à—Ç—É–≤–∞–Ω–Ω—è")
                
                # –î–æ–¥–∞—Ç–∫–æ–≤–∞ —ñ–Ω—Ç–µ—Ä–ø—Ä–µ—Ç–∞—Ü—ñ—è ISE/IAE
                ise_fe = best_config.get('ISE_Fe', np.nan)
                if pd.notna(ise_fe):
                    if ise_fe < 1.0:
                        print(f"   üìä –í—ñ–¥–º—ñ–Ω–Ω–∞ —ñ–Ω—Ç–µ–≥—Ä–∞–ª—å–Ω–∞ —è–∫—ñ—Å—Ç—å (ISE < 1.0)")
                    elif ise_fe < 5.0:
                        print(f"   üìä –•–æ—Ä–æ—à–∞ —ñ–Ω—Ç–µ–≥—Ä–∞–ª—å–Ω–∞ —è–∫—ñ—Å—Ç—å (ISE < 5.0)")
                    else:
                        print(f"   üìä –ü–æ—Ç—Ä–µ–±—É—î –ø–æ–∫—Ä–∞—â–µ–Ω–Ω—è —ñ–Ω—Ç–µ–≥—Ä–∞–ª—å–Ω–æ—ó —è–∫–æ—Å—Ç—ñ (ISE > 5.0)")
                else:
                    print(f"   ‚ö†Ô∏è –ù–µ–º–æ–∂–ª–∏–≤–æ –æ—Ü—ñ–Ω–∏—Ç–∏ —ñ–Ω—Ç–µ–≥—Ä–∞–ª—å–Ω—É —è–∫—ñ—Å—Ç—å - ISE –Ω–µ –æ–±—á–∏—Å–ª–µ–Ω–æ")
    
    print(f"\n‚úÖ –ü–æ—Ä—ñ–≤–Ω—è–Ω–Ω—è –∑–∞–≤–µ—Ä—à–µ–Ω–æ –∑ –¥—ñ–∞–≥–Ω–æ—Å—Ç–∏–∫–æ—é ISE/IAE!")
    print(f"üîç –Ø–∫—â–æ ISE/IAE –ø–æ–∫–∞–∑—É—é—Ç—å '–ù–ï –û–ë–ß–ò–°–õ–ï–ù–û', –ø–µ—Ä–µ–≤—ñ—Ä—Ç–µ –¥—ñ–∞–≥–Ω–æ—Å—Ç–∏–∫—É –≤–∏—â–µ")
    
    return comparison_df

def create_mpc_performance_report(results_df, metrics, reference_values=None):
    """üìã –°—Ç–≤–æ—Ä—é—î –¥–µ—Ç–∞–ª—å–Ω–∏–π –∑–≤—ñ—Ç –ø—Ä–æ –ø—Ä–æ–¥—É–∫—Ç–∏–≤–Ω—ñ—Å—Ç—å MPC –∑ ISE/IAE"""
    
    if reference_values is None:
        reference_values = {'fe': 53.5, 'mass': 57.0}
    
    report = f"""
üìã –ó–í–Ü–¢ –ü–†–û –ü–†–û–î–£–ö–¢–ò–í–ù–Ü–°–¢–¨ MPC
{"="*60}
üìÖ –ß–∞—Å –∞–Ω–∞–ª—ñ–∑—É: {pd.Timestamp.now().strftime("%Y-%m-%d %H:%M:%S")}
üìä –¢–æ—á–æ–∫ –¥–∞–Ω–∏—Ö: {len(results_df)}

üéØ –¢–û–ß–ù–Ü–°–¢–¨ –í–Ü–î–°–õ–Ü–î–ö–û–í–£–í–ê–ù–ù–Ø:
   Fe –∫–æ–Ω—Ü–µ–Ω—Ç—Ä–∞—Ç:
      –£—Å—Ç–∞–≤–∫–∞: {reference_values['fe']:.1f}%
      –î–æ—Å—è–≥–Ω—É—Ç–æ: {metrics.get('tracking_fe_achieved', 'N/A'):.3f}%
      –ü–æ–º–∏–ª–∫–∞: {metrics.get('tracking_error_fe_mean', 0):+.3f}%
      MAE: {metrics.get('tracking_error_fe_mae', 0):.3f}%
      –£ –¥–æ–ø—É—Å–∫—É: {metrics.get('tracking_fe_in_tolerance_pct', 0):.1f}%

   –ú–∞—Å–æ–≤–∏–π –ø–æ—Ç—ñ–∫:
      –£—Å—Ç–∞–≤–∫–∞: {reference_values['mass']:.1f} —Ç/–≥–æ–¥
      –î–æ—Å—è–≥–Ω—É—Ç–æ: {metrics.get('tracking_mass_achieved', 'N/A'):.2f} —Ç/–≥–æ–¥
      –ü–æ–º–∏–ª–∫–∞: {metrics.get('tracking_error_mass_mean', 0):+.2f} —Ç/–≥–æ–¥
      MAE: {metrics.get('tracking_error_mass_mae', 0):.2f} —Ç/–≥–æ–¥

üéõÔ∏è –°–¢–ê–ë–Ü–õ–¨–ù–Ü–°–¢–¨ –ö–ï–†–£–í–ê–ù–ù–Ø:
   –°–µ—Ä–µ–¥–Ω—î –∫–µ—Ä—É–≤–∞–Ω–Ω—è: {metrics.get('control_mean', 0):.2f}%
   –í–∞—Ä—ñ–∞–±–µ–ª—å–Ω—ñ—Å—Ç—å: {metrics.get('control_std', 0):.3f}%
   –ü–ª–∞–≤–Ω—ñ—Å—Ç—å: {metrics.get('control_smoothness', 0):.3f}%

üìà –Ü–ù–¢–ï–ì–†–ê–õ–¨–ù–Ü –ú–ï–¢–†–ò–ö–ò –Ø–ö–û–°–¢–Ü:
   ISE Fe (–Ω–æ—Ä–º.): {metrics.get('performance_ise_fe_normalized', 0):.4f}
   IAE Fe (–Ω–æ—Ä–º.): {metrics.get('performance_iae_fe_normalized', 0):.4f}
   ISE Mass (–Ω–æ—Ä–º.): {metrics.get('performance_ise_mass_normalized', 0):.4f}
   IAE Mass (–Ω–æ—Ä–º.): {metrics.get('performance_iae_mass_normalized', 0):.4f}
   –ö–æ–º–±—ñ–Ω–æ–≤–∞–Ω–∏–π ISE: {metrics.get('performance_combined_ise', 0):.4f}
   –ö–æ–º–±—ñ–Ω–æ–≤–∞–Ω–∏–π IAE: {metrics.get('performance_combined_iae', 0):.4f}

üèÜ –ó–ê–ì–ê–õ–¨–ù–ê –û–¶–Ü–ù–ö–ê: {metrics.get('mpc_quality_score', 0):.1f}/100
üìä –ö–ª–∞—Å–∏—Ñ—ñ–∫–∞—Ü—ñ—è: {metrics.get('mpc_quality_class', 'N/A')}

üí° –†–ï–ö–û–ú–ï–ù–î–ê–¶–Ü–á:
"""
    
    recommendations = metrics.get('recommendations', ['–ù–µ–º–∞—î'])
    for i, rec in enumerate(recommendations, 1):
        report += f"   {i}. {rec}\n"
    
    report += f"\n{'='*60}"
    
    return report


def load_historical_data() -> pd.DataFrame:
    """–ó–∞–≤–∞–Ω—Ç–∞–∂—É—î —ñ—Å—Ç–æ—Ä–∏—á–Ω—ñ –¥–∞–Ω—ñ –¥–ª—è —Å–∏–º—É–ª—è—Ü—ñ—ó"""
    
    # –°–ø—Ä–æ–±—É—î–º–æ –∑–∞–≤–∞–Ω—Ç–∞–∂–∏—Ç–∏ –∑ —Ä—ñ–∑–Ω–∏—Ö –º—ñ—Å—Ü—å
    possible_paths = [
        'processed.parquet',
        'data/processed.parquet', 
        '/content/KModel/src/processed.parquet',
        '../data/processed.parquet'
    ]
    
    for path in possible_paths:
        try:
            hist_df = pd.read_parquet(path)
            print(f"‚úÖ –î–∞–Ω—ñ –∑–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–æ –∑: {path}")
            print(f"   üìä –†–æ–∑–º—ñ—Ä: {hist_df.shape[0]} —Ä—è–¥–∫—ñ–≤, {hist_df.shape[1]} –∫–æ–ª–æ–Ω–æ–∫")
            return hist_df
        except FileNotFoundError:
            continue
        except Exception as e:
            print(f"‚ö†Ô∏è –ü–æ–º–∏–ª–∫–∞ –∑–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–Ω—è –∑ {path}: {e}")
            continue
    
    raise FileNotFoundError("‚ùå –ù–µ –≤–¥–∞–ª–æ—Å—è –∑–Ω–∞–π—Ç–∏ —Ñ–∞–π–ª processed.parquet")

# ---- debug_ise_iae
# –î–û–î–ê–ô–¢–ï –¶–Ü –§–£–ù–ö–¶–Ü–á –í –ö–Ü–ù–ï–¶–¨ enhanced_sim.py

def debug_ise_iae_calculation(results_df, metrics, reference_values=None):
    """
    üîç –î—ñ–∞–≥–Ω–æ—Å—Ç–∏—á–Ω–∏–π –º–µ—Ç–æ–¥ –¥–ª—è –≤–∏—è–≤–ª–µ–Ω–Ω—è –ø—Ä–æ–±–ª–µ–º –∑ ISE/IAE –æ–±—á–∏—Å–ª–µ–Ω–Ω—è–º
    """
    
    print("\nüîç –î–Ü–ê–ì–ù–û–°–¢–ò–ö–ê ISE/IAE –û–ë–ß–ò–°–õ–ï–ù–ù–Ø")
    print("="*50)
    
    if reference_values is None:
        reference_values = {'fe': 53.5, 'mass': 57.0}
    
    # 1. –ü–µ—Ä–µ–≤—ñ—Ä–∫–∞ DataFrame
    print(f"üìä –†–æ–∑–º—ñ—Ä results_df: {results_df.shape}")
    print(f"üìã –ö–æ–ª–æ–Ω–∫–∏: {list(results_df.columns)}")
    
    if not results_df.empty:
        print(f"üìà –ü–µ—Ä—à—ñ 3 —Ä—è–¥–∫–∏:")
        print(results_df.head(3))
    else:
        print("‚ùå results_df –ü–û–†–û–ñ–ù–Ü–ô!")
        return {'error': 'empty_dataframe'}
    
    # 2. –ü–µ—Ä–µ–≤—ñ—Ä–∫–∞ –Ω–∞—è–≤–Ω–æ—Å—Ç—ñ –ø–æ—Ç—Ä—ñ–±–Ω–∏—Ö –∫–æ–ª–æ–Ω–æ–∫
    required_columns = ['conc_fe', 'conc_mass']
    missing_columns = [col for col in required_columns if col not in results_df.columns]
    
    if missing_columns:
        print(f"‚ùå –í–Ü–î–°–£–¢–ù–Ü –ö–û–õ–û–ù–ö–ò: {missing_columns}")
        
        # –ü–æ—à—É–∫ —Å—Ö–æ–∂–∏—Ö –∫–æ–ª–æ–Ω–æ–∫
        available_cols = list(results_df.columns)
        similar_cols = {}
        
        for missing in missing_columns:
            candidates = []
            for available in available_cols:
                # –ü–æ—à—É–∫ –∑–∞ –∫–ª—é—á–æ–≤–∏–º–∏ —Å–ª–æ–≤–∞–º–∏
                if missing == 'conc_fe':
                    if 'fe' in available.lower() and ('conc' in available.lower() or 'percent' in available.lower()):
                        candidates.append(available)
                elif missing == 'conc_mass':
                    if 'mass' in available.lower() and ('conc' in available.lower() or 'flow' in available.lower()):
                        candidates.append(available)
            
            if candidates:
                similar_cols[missing] = candidates
        
        if similar_cols:
            print(f"üí° –°–•–û–ñ–Ü –ö–û–õ–û–ù–ö–ò:")
            for missing, candidates in similar_cols.items():
                print(f"   {missing} ‚Üí {candidates}")
    else:
        print(f"‚úÖ –í—Å—ñ –ø–æ—Ç—Ä—ñ–±–Ω—ñ –∫–æ–ª–æ–Ω–∫–∏ –ø—Ä–∏—Å—É—Ç–Ω—ñ")
    
    # 3. –¢–µ—Å—Ç–æ–≤–µ –æ–±—á–∏—Å–ª–µ–Ω–Ω—è ISE/IAE
    print(f"\nüß™ –¢–ï–°–¢–û–í–ï –û–ë–ß–ò–°–õ–ï–ù–ù–Ø ISE/IAE:")
    
    test_ise_iae = {}
    
    try:
        if 'conc_fe' in results_df.columns:
            fe_values = results_df['conc_fe'].dropna().values
            fe_setpoint = reference_values['fe']
            
            print(f"   üìä Fe –¥–∞–Ω—ñ:")
            print(f"      –ö—ñ–ª—å–∫—ñ—Å—Ç—å —Ç–æ—á–æ–∫: {len(fe_values)}")
            if len(fe_values) > 0:
                print(f"      –î—ñ–∞–ø–∞–∑–æ–Ω: {fe_values.min():.3f} - {fe_values.max():.3f}")
                print(f"      –°–µ—Ä–µ–¥–Ω—î: {fe_values.mean():.3f}")
                print(f"      –£—Å—Ç–∞–≤–∫–∞: {fe_setpoint}")
                
                # –û–±—á–∏—Å–ª—é—î–º–æ ISE/IAE
                fe_errors = fe_values - fe_setpoint
                ise_fe = np.sum(fe_errors**2)
                iae_fe = np.sum(np.abs(fe_errors))
                ise_fe_norm = ise_fe / len(fe_errors)
                iae_fe_norm = iae_fe / len(fe_errors)
                
                test_ise_iae = {
                    'performance_ise_fe': ise_fe,
                    'performance_iae_fe': iae_fe,
                    'performance_ise_fe_normalized': ise_fe_norm,
                    'performance_iae_fe_normalized': iae_fe_norm
                }
                
                print(f"      ‚úÖ ISE Fe: {ise_fe:.4f}")
                print(f"      ‚úÖ IAE Fe: {iae_fe:.4f}")
                print(f"      ‚úÖ ISE Fe (–Ω–æ—Ä–º.): {ise_fe_norm:.4f}")
                print(f"      ‚úÖ IAE Fe (–Ω–æ—Ä–º.): {iae_fe_norm:.4f}")
            else:
                print(f"      ‚ùå –ù–µ–º–∞—î –¥–∞–Ω–∏—Ö –ø—ñ—Å–ª—è dropna()")
            
        else:
            print(f"   ‚ùå –ö–æ–ª–æ–Ω–∫–∞ 'conc_fe' –Ω–µ –∑–Ω–∞–π–¥–µ–Ω–∞")
            
    except Exception as e:
        print(f"   ‚ùå –ü–æ–º–∏–ª–∫–∞ –æ–±—á–∏—Å–ª–µ–Ω–Ω—è: {e}")
        import traceback
        traceback.print_exc()
    
    # 4. –ü–µ—Ä–µ–≤—ñ—Ä–∫–∞ –Ω–∞—è–≤–Ω–æ—Å—Ç—ñ ISE/IAE –≤ metrics
    print(f"\nüìã –ü–ï–†–ï–í–Ü–†–ö–ê –ú–ï–¢–†–ò–ö:")
    ise_iae_keys = [k for k in metrics.keys() if 'ise' in k.lower() or 'iae' in k.lower() or 'performance' in k.lower()]
    
    if ise_iae_keys:
        print(f"   ‚úÖ –ó–Ω–∞–π–¥–µ–Ω—ñ ISE/IAE/performance –∫–ª—é—á—ñ: {ise_iae_keys}")
        for key in ise_iae_keys:
            value = metrics[key]
            if pd.isna(value):
                print(f"      {key}: NaN ‚ùå")
            else:
                print(f"      {key}: {value}")
    else:
        print(f"   ‚ùå ISE/IAE –∫–ª—é—á—ñ –ù–ï –∑–Ω–∞–π–¥–µ–Ω—ñ –≤ metrics")
        
        # –ü–æ–∫–∞–∑—É—î–º–æ –≤—Å—ñ –∫–ª—é—á—ñ –¥–ª—è –∞–Ω–∞–ª—ñ–∑—É
        all_keys = list(metrics.keys())
        print(f"   üìã –í—Å—ñ –¥–æ—Å—Ç—É–ø–Ω—ñ –∫–ª—é—á—ñ ({len(all_keys)}):")
        for i, key in enumerate(all_keys[:20]):  # –ü–µ—Ä—à—ñ 20
            print(f"      {i+1}. {key}")
        if len(all_keys) > 20:
            print(f"      ... —ñ —â–µ {len(all_keys)-20} –∫–ª—é—á—ñ–≤")
    
    # 5. –ü–µ—Ä–µ–≤—ñ—Ä–∫–∞ —á–∏ –≤–∏–∫–ª–∏–∫–∞—î—Ç—å—Å—è calculate_ise_iae_metrics
    print(f"\nüîß –ü–ï–†–ï–í–Ü–†–ö–ê –í–ò–ö–õ–ò–ö–£ calculate_ise_iae_metrics:")
    
    # –°–ø—Ä–æ–±—É—î–º–æ –≤–∏–∫–ª–∏–∫–∞—Ç–∏ —Ñ—É–Ω–∫—Ü—ñ—é –±–µ–∑–ø–æ—Å–µ—Ä–µ–¥–Ω—å–æ
    try:
        if hasattr(sys.modules[__name__], 'calculate_ise_iae_metrics'):
            print(f"   ‚úÖ –§—É–Ω–∫—Ü—ñ—è calculate_ise_iae_metrics —ñ—Å–Ω—É—î")
            
            # –¢–µ—Å—Ç–æ–≤–∏–π –≤–∏–∫–ª–∏–∫
            test_metrics = calculate_ise_iae_metrics(results_df, reference_values)
            print(f"   üß™ –¢–µ—Å—Ç–æ–≤–∏–π –≤–∏–∫–ª–∏–∫ –ø–æ–≤–µ—Ä–Ω—É–≤: {list(test_metrics.keys())}")
            
            for key, value in test_metrics.items():
                print(f"      {key}: {value}")
                
        else:
            print(f"   ‚ùå –§—É–Ω–∫—Ü—ñ—è calculate_ise_iae_metrics –ù–ï –Ü–°–ù–£–Ñ!")
            
    except Exception as e:
        print(f"   ‚ùå –ü–æ–º–∏–ª–∫–∞ –≤–∏–∫–ª–∏–∫—É calculate_ise_iae_metrics: {e}")
    
    # 6. –†–µ–∫–æ–º–µ–Ω–¥–∞—Ü—ñ—ó
    print(f"\nüí° –†–ï–ö–û–ú–ï–ù–î–ê–¶–Ü–á:")
    
    if missing_columns:
        print(f"   1. ‚ùå –ü–µ—Ä–µ–≤—ñ—Ä—Ç–µ –Ω–∞–∑–≤–∏ –∫–æ–ª–æ–Ω–æ–∫ —É results_df")
        print(f"   2. üîß –ú–æ–∂–ª–∏–≤–æ —Ç—Ä–µ–±–∞ –∑–º—ñ–Ω–∏—Ç–∏ 'conc_fe'/'conc_mass' –Ω–∞ —ñ–Ω—à—ñ –Ω–∞–∑–≤–∏")
        
        # –ö–æ–Ω–∫—Ä–µ—Ç–Ω—ñ —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü—ñ—ó –ø–æ –∑–∞–º—ñ–Ω—ñ
        if similar_cols:
            print(f"   3. üí° –°–ø—Ä–æ–±—É–π—Ç–µ –∑–∞–º—ñ–Ω–∏—Ç–∏:")
            for missing, candidates in similar_cols.items():
                for candidate in candidates:
                    print(f"      '{missing}' ‚Üí '{candidate}'")
    
    if not ise_iae_keys:
        print(f"   4. üîß ISE/IAE –º–µ—Ç—Ä–∏–∫–∏ –ù–ï –æ–±—á–∏—Å–ª—é—é—Ç—å—Å—è!")
        print(f"   5. üîß –ü–µ—Ä–µ–≤—ñ—Ä—Ç–µ —á–∏ –≤–∏–∫–ª–∏–∫–∞—î—Ç—å—Å—è calculate_ise_iae_metrics() –≤ compute_correct_mpc_metrics_silent()")
        
        if test_ise_iae:
            print(f"   6. ‚úÖ –¢–µ—Å—Ç–æ–≤–µ –æ–±—á–∏—Å–ª–µ–Ω–Ω—è –ü–†–ê–¶–Æ–Ñ - –ø—Ä–æ–±–ª–µ–º–∞ –≤ —ñ–Ω—Ç–µ–≥—Ä–∞—Ü—ñ—ó!")
            print(f"      –î–æ–¥–∞–π—Ç–µ —Ü—ñ –º–µ—Ç—Ä–∏–∫–∏ –≤—Ä—É—á–Ω—É: {list(test_ise_iae.keys())}")
    
    return {
        'has_required_columns': len(missing_columns) == 0,
        'missing_columns': missing_columns,
        'similar_columns': similar_cols if missing_columns else {},
        'has_ise_iae_metrics': len(ise_iae_keys) > 0,
        'ise_iae_keys': ise_iae_keys,
        'dataframe_size': results_df.shape,
        'available_columns': list(results_df.columns),
        'test_ise_iae_values': test_ise_iae
    }


def add_diagnostic_to_comparison(config_name, results_df, metrics, reference_values):
    """
    üîç –î–æ–¥–∞—î –¥—ñ–∞–≥–Ω–æ—Å—Ç–∏–∫—É ISE/IAE –≤ –ø—Ä–æ—Ü–µ—Å –ø–æ—Ä—ñ–≤–Ω—è–Ω–Ω—è –∫–æ–Ω—Ñ—ñ–≥—É—Ä–∞—Ü—ñ–π
    """
    
    print(f"\nüîç –î–Ü–ê–ì–ù–û–°–¢–ò–ö–ê ISE/IAE –î–õ–Ø –ö–û–ù–§–Ü–ì–£–†–ê–¶–Ü–á: {config_name}")
    print("-" * 60)
    
    # –ó–∞–ø—É—Å–∫–∞—î–º–æ –¥—ñ–∞–≥–Ω–æ—Å—Ç–∏–∫—É
    diagnostic_result = debug_ise_iae_calculation(results_df, metrics, reference_values)
    
    # –®–≤–∏–¥–∫–∏–π –≤–∏—Å–Ω–æ–≤–æ–∫
    if diagnostic_result.get('has_required_columns', False):
        print(f"‚úÖ {config_name}: –ö–æ–ª–æ–Ω–∫–∏ –≤ –ø–æ—Ä—è–¥–∫—É")
    else:
        missing = diagnostic_result.get('missing_columns', [])
        similar = diagnostic_result.get('similar_columns', {})
        print(f"‚ùå {config_name}: –í—ñ–¥—Å—É—Ç–Ω—ñ –∫–æ–ª–æ–Ω–∫–∏ {missing}")
        if similar:
            print(f"üí° {config_name}: –ú–æ–∂–ª–∏–≤—ñ –∑–∞–º—ñ–Ω–∏: {similar}")
    
    if diagnostic_result.get('has_ise_iae_metrics', False):
        print(f"‚úÖ {config_name}: ISE/IAE –º–µ—Ç—Ä–∏–∫–∏ –ø—Ä–∏—Å—É—Ç–Ω—ñ")
    else:
        print(f"‚ùå {config_name}: ISE/IAE –º–µ—Ç—Ä–∏–∫–∏ –í–Ü–î–°–£–¢–ù–Ü")
        
        # –Ø–∫—â–æ —Ç–µ—Å—Ç–æ–≤–µ –æ–±—á–∏—Å–ª–µ–Ω–Ω—è –ø—Ä–∞—Ü—é—î, –∞–ª–µ –º–µ—Ç—Ä–∏–∫–∏ –≤—ñ–¥—Å—É—Ç–Ω—ñ
        test_values = diagnostic_result.get('test_ise_iae_values', {})
        if test_values:
            print(f"üîß {config_name}: –¢–µ—Å—Ç–æ–≤–µ –æ–±—á–∏—Å–ª–µ–Ω–Ω—è –ø—Ä–∞—Ü—é—î - –ø—Ä–æ–±–ª–µ–º–∞ –≤ —ñ–Ω—Ç–µ–≥—Ä–∞—Ü—ñ—ó!")
            print(f"   –¢–µ—Å—Ç–æ–≤—ñ –∑–Ω–∞—á–µ–Ω–Ω—è: {test_values}")
    
    return diagnostic_result


# –Ü–ú–ü–û–†–¢ sys –î–õ–Ø –ü–ï–†–ï–í–Ü–†–ö–ò –ú–û–î–£–õ–Ü–í (–¥–æ–¥–∞–π—Ç–µ –Ω–∞ –ø–æ—á–∞—Ç–æ–∫ —Ñ–∞–π–ª—É —è–∫—â–æ –Ω–µ–º–∞—î)
import sys
# –î–æ–¥–∞—Ç–∫–æ–≤—ñ —ñ–º–ø–æ—Ä—Ç–∏, —è–∫—ñ –º–æ–∂—É—Ç—å –∑–Ω–∞–¥–æ–±–∏—Ç–∏—Å—è
import time
from typing import List, Optional, Dict, Any

print("‚úÖ –û—á–∏—â–µ–Ω–∏–π —Å–∏–º—É–ª—è—Ç–æ—Ä –±–µ–∑ –ø–ª—É—Ç–∞–Ω–æ–≥–æ –≤–∏–≤–æ–¥—É –≥–æ—Ç–æ–≤–∏–π!")
print("üîß –ö–ª—é—á–æ–≤—ñ –∑–º—ñ–Ω–∏:")
print("   ‚Ä¢ –í–∏–¥–∞–ª–µ–Ω–æ –ø–ª—É—Ç–∞–Ω–∏–π –ø–æ—á–∞—Ç–∫–æ–≤–∏–π –≤–∏–≤—ñ–¥")
print("   ‚Ä¢ compute_correct_mpc_metrics —Ç–µ–ø–µ—Ä –ø—Ä–∞—Ü—é—î –±–µ–∑ –≤–∏–≤–æ–¥—É")
print("   ‚Ä¢ –ó–±–µ—Ä–µ–∂–µ–Ω–æ –≤—Å—é —Ñ—É–Ω–∫—Ü—ñ–æ–Ω–∞–ª—å–Ω—ñ—Å—Ç—å")
print("   ‚Ä¢ –ß–∏—Å—Ç–∏–π flow: —Ç–µ—Å—Ç—É–≤–∞–Ω–Ω—è ‚Üí –¥–µ—Ç–∞–ª—å–Ω—ñ –∑–≤—ñ—Ç–∏ ‚Üí –ø—ñ–¥—Å—É–º–æ–∫")