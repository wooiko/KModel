import numpy as np  
import pandas as pd  
import time  
import json  
import os  
from datetime import datetime  

import traceback  

from typing import Callable, Dict, Any, Tuple
from sklearn.preprocessing import StandardScaler
from sklearn.metrics import mean_squared_error
from collections import deque

from data_gen import StatefulDataGenerator
from model import KernelModel
from objectives import MaxIronMassTrackingObjective
from mpc import MPCController
# from conf_manager import MPCConfigManager
from utils import (
    run_post_simulation_analysis_enhanced,  diagnose_mpc_behavior, diagnose_ekf_detailed
)
from ekf import ExtendedKalmanFilter
from anomaly_detector import SignalAnomalyDetector
from maf import MovingAverageFilter
from benchmark import benchmark_model_training, benchmark_mpc_solve_time
from conf_manager import config_manager
from typing import Optional, List


def run_model_comparison_experiment(  
    hist_df: pd.DataFrame,  
    base_config: str = 'oleksandr_original',  
    n_repeats: int = 5,  
    results_dir: str = 'model_comparison_experiment',  
    save_individual: bool = True  
) -> Dict[str, Dict]:  
    """  
    –ó–∞–ø—É—Å–∫ –µ–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç—É –ø–æ—Ä—ñ–≤–Ω—è–Ω–Ω—è –º–æ–¥–µ–ª–µ–π –∑ –ø–æ–≤—Ç–æ—Ä–µ–Ω–Ω—è–º–∏  
    
    Returns:  
        Dict –∑ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞–º–∏ –≤—Å—ñ—Ö –µ–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç—ñ–≤  
    """  
    
    # –ö–æ–Ω—Ñ—ñ–≥—É—Ä–∞—Ü—ñ—è –µ–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç—É  
    models_config = {  
        'KRR_RBF': {  
            'model_type': 'krr',  
            'kernel': 'rbf',  
            'find_optimal_params': True  
        },  
        'SVR_RBF': {  
            'model_type': 'svr',   
            'kernel': 'rbf',  
            'find_optimal_params': True  
        },  
        'GPR_RBF': {  
            'model_type': 'gpr',  
            'kernel': 'rbf',   
            'find_optimal_params': True  
        },  
        'LINEAR_RIDGE': {  
            'model_type': 'linear',  
            'linear_type': 'ridge',  
            'find_optimal_params': True  
        }  
    }  
    
    # –°—Ç–≤–æ—Ä—é—î–º–æ –¥–∏—Ä–µ–∫—Ç–æ—Ä—ñ—é  
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")  
    full_results_dir = f"{results_dir}_{timestamp}"  
    os.makedirs(full_results_dir, exist_ok=True)  
    
    print("üî¨ –ü–û–ß–ê–¢–û–ö –ï–ö–°–ü–ï–†–ò–ú–ï–ù–¢–£ –ü–û–†–Ü–í–ù–Ø–ù–ù–Ø –ú–û–î–ï–õ–ï–ô")  
    print("="*70)  
    print(f"üìä –ú–æ–¥–µ–ª–µ–π: {len(models_config)}")  
    print(f"üîÑ –ü–æ–≤—Ç–æ—Ä–µ–Ω—å: {n_repeats}")  
    print(f"üìÅ –î–∏—Ä–µ–∫—Ç–æ—Ä—ñ—è —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ñ–≤: {full_results_dir}")  
    print(f"‚ö° –ó–∞–≥–∞–ª–æ–º –∑–∞–ø—É—Å–∫—ñ–≤: {len(models_config) * n_repeats}")  
    print("="*70)  
    
    all_results = {}  
    experiment_summary = []  
    
    total_runs = len(models_config) * n_repeats  
    current_run = 0  
    
    for model_name, model_params in models_config.items():  
        print(f"\nüß™ –ú–û–î–ï–õ–¨: {model_name}")  
        print(f"   –ü–∞—Ä–∞–º–µ—Ç—Ä–∏: {model_params}")  
        
        model_results = {  
            'runs': {},  
            'summary_stats': {},  
            'model_config': model_params  
        }  
        
        run_metrics = []  
        
        for repeat in range(n_repeats):  
            current_run += 1  
            run_id = f"{model_name}_run_{repeat+1}"  
            
            print(f"\n   üéØ –ó–∞–ø—É—Å–∫ {repeat+1}/{n_repeats} ({current_run}/{total_runs})")  
            
            try:  
                # –ó–º—ñ–Ω—é—î–º–æ seed –¥–ª—è –∫–æ–∂–Ω–æ–≥–æ –ø–æ–≤—Ç–æ—Ä—É  
                run_start = time.time()  
                
                results_df, metrics = simulate_mpc(  
                    hist_df,  
                    config=base_config,  
                    config_overrides=model_params,  
                    seed=repeat * 42,  # –†—ñ–∑–Ω—ñ seeds –¥–ª—è –ø–æ–≤—Ç–æ—Ä—é–≤–∞–Ω–æ—Å—Ç—ñ  
                    run_analysis=False  
                )  
                
                run_time = time.time() - run_start  
                
                # –î–æ–¥–∞—î–º–æ –º–µ—Ç–∞—ñ–Ω—Ñ–æ—Ä–º–∞—Ü—ñ—é  
                results_df['experiment_model'] = model_name  
                results_df['experiment_run'] = repeat + 1  
                results_df['experiment_run_id'] = run_id  
                
                metrics['experiment_info'] = {  
                    'model_name': model_name,  
                    'run_number': repeat + 1,  
                    'run_id': run_id,  
                    'seed_used': repeat * 42,  
                    'run_time_seconds': run_time  
                }  
                
                # –ó–±–µ—Ä—ñ–≥–∞—î–º–æ —ñ–Ω–¥–∏–≤—ñ–¥—É–∞–ª—å–Ω—ñ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∏  
                if save_individual:  
                    results_df.to_parquet(f"{full_results_dir}/{run_id}_results.parquet")  
                    
                    with open(f"{full_results_dir}/{run_id}_metrics.json", 'w') as f:  
                        json_metrics = {}  
                        for key, value in metrics.items():  
                            try:  
                                json.dumps(value)  # –ü–µ—Ä–µ–≤—ñ—Ä—è—î–º–æ JSON serializable  
                                json_metrics[key] = value  
                            except:  
                                json_metrics[key] = str(value)  
                        json.dump(json_metrics, f, indent=2)  
                
                # –ó–±–∏—Ä–∞—î–º–æ –º–µ—Ç—Ä–∏–∫–∏ –¥–ª—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏  
                run_summary = {  
                    'run_id': run_id,  
                    'model': model_name,  
                    'run_number': repeat + 1,  
                    'run_time': run_time  
                }  
                
                # –î–æ–¥–∞—î–º–æ –∫–ª—é—á–æ–≤—ñ –º–µ—Ç—Ä–∏–∫–∏  
                key_metrics = ['rmse_fe', 'rmse_mass', 'mae_fe', 'mae_mass', 'r2_fe', 'r2_mass']  
                for metric in key_metrics:  
                    if metric in metrics:  
                        run_summary[metric] = metrics[metric]  
                
                run_metrics.append(run_summary)  
                model_results['runs'][run_id] = (results_df, metrics)  
                experiment_summary.append(run_summary)  
                
                print(f"      ‚úÖ –ó–∞–≤–µ—Ä—à–µ–Ω–æ –∑–∞ {run_time:.1f}—Å")  
                if 'rmse_fe' in metrics:  
                    print(f"      üìä RMSE: Fe={metrics['rmse_fe']:.4f}, Mass={metrics.get('rmse_mass', 'N/A'):.4f}")  
                
            except Exception as e:  
                print(f"      ‚ùå –ü–û–ú–ò–õ–ö–ê: {e}")  
                run_summary = {  
                    'run_id': run_id,  
                    'model': model_name,  
                    'run_number': repeat + 1,  
                    'error': str(e)  
                }  
                experiment_summary.append(run_summary)  
                continue  
        
        # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –ø–æ –º–æ–¥–µ–ª—ñ  
        if run_metrics:  
            metrics_df = pd.DataFrame(run_metrics)  
            
            model_stats = {}  
            for metric in ['rmse_fe', 'rmse_mass', 'r2_fe', 'r2_mass', 'run_time']:  
                if metric in metrics_df.columns:  
                    model_stats[f'{metric}_mean'] = metrics_df[metric].mean()  
                    model_stats[f'{metric}_std'] = metrics_df[metric].std()  
                    model_stats[f'{metric}_min'] = metrics_df[metric].min()  
                    model_stats[f'{metric}_max'] = metrics_df[metric].max()  
            
            model_results['summary_stats'] = model_stats  
            
            print(f"   üìà –°–¢–ê–¢–ò–°–¢–ò–ö–ê {model_name}:")  
            print(f"      RMSE Fe: {model_stats.get('rmse_fe_mean', 0):.4f} ¬± {model_stats.get('rmse_fe_std', 0):.4f}")  
            print(f"      RMSE Mass: {model_stats.get('rmse_mass_mean', 0):.4f} ¬± {model_stats.get('rmse_mass_std', 0):.4f}")  
            print(f"      R¬≤ Fe: {model_stats.get('r2_fe_mean', 0):.4f} ¬± {model_stats.get('r2_fe_std', 0):.4f}")  
            print(f"      –ß–∞—Å: {model_stats.get('run_time_mean', 0):.1f}—Å ¬± {model_stats.get('run_time_std', 0):.1f}—Å")  
        
        all_results[model_name] = model_results  
    
    # –ó–±–µ—Ä—ñ–≥–∞—î–º–æ –∑–∞–≥–∞–ª—å–Ω—É —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É  
    summary_df = pd.DataFrame(experiment_summary)  
    summary_df.to_csv(f"{full_results_dir}/experiment_summary.csv", index=False)  
    
    # –°—Ç–≤–æ—Ä—é—î–º–æ –ø–æ—Ä—ñ–≤–Ω—è–ª—å–Ω—É —Ç–∞–±–ª–∏—Ü—é  
    comparison_table = create_model_comparison_table(all_results)  
    comparison_table.to_csv(f"{full_results_dir}/model_comparison.csv", index=False)  
    
    print("\n" + "="*70)  
    print("üèÅ –ï–ö–°–ü–ï–†–ò–ú–ï–ù–¢ –ó–ê–í–ï–†–®–ï–ù–û")  
    print(f"üìÅ –†–µ–∑—É–ª—å—Ç–∞—Ç–∏ –∑–±–µ—Ä–µ–∂–µ–Ω–æ –≤: {full_results_dir}")  
    print("="*70)  
    
    return all_results, comparison_table  


def create_model_comparison_table(all_results: Dict) -> pd.DataFrame:  
    """–°—Ç–≤–æ—Ä—é—î —Ç–∞–±–ª–∏—Ü—é –ø–æ—Ä—ñ–≤–Ω—è–Ω–Ω—è –º–æ–¥–µ–ª–µ–π"""  
    
    comparison_data = []  
    
    for model_name, model_data in all_results.items():  
        if 'summary_stats' in model_data and model_data['summary_stats']:  
            stats = model_data['summary_stats']  
            
            row = {  
                'Model': model_name,  
                'RMSE_Fe_Mean': stats.get('rmse_fe_mean', np.nan),  
                'RMSE_Fe_Std': stats.get('rmse_fe_std', np.nan),  
                'RMSE_Mass_Mean': stats.get('rmse_mass_mean', np.nan),  
                'RMSE_Mass_Std': stats.get('rmse_mass_std', np.nan),  
                'R2_Fe_Mean': stats.get('r2_fe_mean', np.nan),  
                'R2_Fe_Std': stats.get('r2_fe_std', np.nan),  
                'R2_Mass_Mean': stats.get('r2_mass_mean', np.nan),  
                'R2_Mass_Std': stats.get('r2_mass_std', np.nan),  
                'Runtime_Mean': stats.get('run_time_mean', np.nan),  
                'Runtime_Std': stats.get('run_time_std', np.nan)  
            }  
            comparison_data.append(row)  
    
    comparison_df = pd.DataFrame(comparison_data)  
    
    # –°–æ—Ä—Ç—É—î–º–æ –ø–æ RMSE Fe (–Ω–∞–π–∫—Ä–∞—â–∏–π –∑–≤–µ—Ä—Ö—É)  
    if 'RMSE_Fe_Mean' in comparison_df.columns:  
        comparison_df = comparison_df.sort_values('RMSE_Fe_Mean')  
    
    return comparison_df  


def analyze_experiment_results(results_dir: str) -> None:  
    """–î–µ—Ç–∞–ª—å–Ω–∏–π –∞–Ω–∞–ª—ñ–∑ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ñ–≤ –µ–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç—É"""  
    
    print("üìä –ê–ù–ê–õ–Ü–ó –†–ï–ó–£–õ–¨–¢–ê–¢–Ü–í –ï–ö–°–ü–ï–†–ò–ú–ï–ù–¢–£")  
    print("="*70)  
    
    # –ó–∞–≤–∞–Ω—Ç–∞–∂—É—î–º–æ –ø–æ—Ä—ñ–≤–Ω—è–ª—å–Ω—É —Ç–∞–±–ª–∏—Ü—é  
    comparison_file = f"{results_dir}/model_comparison.csv"  
    if os.path.exists(comparison_file):  
        comparison_df = pd.read_csv(comparison_file)  
        
        print("üèÜ –†–ï–ô–¢–ò–ù–ì –ú–û–î–ï–õ–ï–ô (–ø–æ RMSE Fe):")  
        print(comparison_df[['Model', 'RMSE_Fe_Mean', 'RMSE_Fe_Std', 'R2_Fe_Mean']].round(4))  
        
        print("\nüìà –°–¢–ê–¢–ò–°–¢–ò–ß–ù–ê –ó–ù–ê–ß–£–©–Ü–°–¢–¨:")  
        # –ü—Ä–æ—Å—Ç–∏–π –∞–Ω–∞–ª—ñ–∑ —Å—Ç–∞—Ç–∏—Å—Ç–∏—á–Ω–æ—ó –∑–Ω–∞—á—É—â–æ—Å—Ç—ñ  
        best_model = comparison_df.iloc[0]  
        print(f"ü•á –ù–∞–π–∫—Ä–∞—â–∏–π: {best_model['Model']}")  
        print(f"   RMSE Fe: {best_model['RMSE_Fe_Mean']:.4f} ¬± {best_model['RMSE_Fe_Std']:.4f}")  
        print(f"   R¬≤ Fe: {best_model['R2_Fe_Mean']:.4f} ¬± {best_model['R2_Fe_Std']:.4f}")  
        
        if len(comparison_df) > 1:  
            second_model = comparison_df.iloc[1]  
            rmse_diff = second_model['RMSE_Fe_Mean'] - best_model['RMSE_Fe_Mean']  
            combined_std = np.sqrt(best_model['RMSE_Fe_Std']**2 + second_model['RMSE_Fe_Std']**2)  
            
            print(f"\nü•à –î—Ä—É–≥–∏–π: {second_model['Model']}")  
            print(f"   –†—ñ–∑–Ω–∏—Ü—è RMSE: +{rmse_diff:.4f}")  
            print(f"   –°—Ç–∞—Ç–∏—Å—Ç–∏—á–Ω–∞ –∑–Ω–∞—á—É—â—ñ—Å—Ç—å: {'–¢–∞–∫' if rmse_diff > 2*combined_std else '–°—É–º–Ω—ñ–≤–Ω–æ'}")  
    
    # –ó–∞–≤–∞–Ω—Ç–∞–∂—É—î–º–æ –¥–µ—Ç–∞–ª—å–Ω—É —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É  
    summary_file = f"{results_dir}/experiment_summary.csv"  
    if os.path.exists(summary_file):  
        summary_df = pd.read_csv(summary_file)  
        
        print(f"\nüìã –î–ï–¢–ê–õ–Ü –ï–ö–°–ü–ï–†–ò–ú–ï–ù–¢–£:")  
        print(f"   –ó–∞–≥–∞–ª–æ–º –∑–∞–ø—É—Å–∫—ñ–≤: {len(summary_df)}")  
        print(f"   –£—Å–ø—ñ—à–Ω–∏—Ö: {len(summary_df[~summary_df.get('error', pd.Series()).notna()])}")  
        
        # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –ø–æ –º–æ–¥–µ–ª—è—Ö  
        if 'model' in summary_df.columns:  
            model_stats = summary_df.groupby('model').agg({  
                'rmse_fe': ['count', 'mean', 'std'],  
                'run_time': ['mean', 'std']  
            }).round(4)  
            print(f"\nüìä –î–ï–¢–ê–õ–¨–ù–ê –°–¢–ê–¢–ò–°–¢–ò–ö–ê –ü–û –ú–û–î–ï–õ–Ø–•:")  
            print(model_stats)  


# üöÄ –ó–ê–ü–£–°–ö –ï–ö–°–ü–ï–†–ò–ú–ï–ù–¢–£  
def main_experiment():  
    """–ì–æ–ª–æ–≤–Ω–∞ —Ñ—É–Ω–∫—Ü—ñ—è –µ–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç—É"""  
    
    # –ó–∞–≤–∞–Ω—Ç–∞–∂—É—î–º–æ –¥–∞–Ω—ñ  
    try:  
        hist_df = pd.read_parquet('processed.parquet')  
        print(f"‚úÖ –î–∞–Ω—ñ –∑–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–æ: {hist_df.shape}")  
    except FileNotFoundError:  
        try:  
            hist_df = pd.read_parquet('/content/KModel/src/processed.parquet')  
            print(f"‚úÖ –î–∞–Ω—ñ –∑–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–æ –∑ /content/: {hist_df.shape}")  
        except Exception as e:  
            print(f"‚ùå –ü–æ–º–∏–ª–∫–∞ –∑–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–Ω—è –¥–∞–Ω–∏—Ö: {e}")  
            return  
    
    # Callback –¥–ª—è –ø—Ä–æ–≥—Ä–µ—Å—É (–ø–æ–∫–∞–∑—É—î–º–æ —Ç—ñ–ª—å–∫–∏ –∫–ª—é—á–æ–≤—ñ –º–æ–º–µ–Ω—Ç–∏)  
    def progress_callback(step, total, msg):  
        if step % 100 == 0 or step == total or '–∑–∞–≤–µ—Ä—à–µ–Ω' in msg.lower():  
            print(f"      [{step}/{total}] {msg}")  
    
    # –ó–∞–ø—É—Å–∫–∞—î–º–æ –µ–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç  
    print("üöÄ –ü–û–ß–ò–ù–ê–Ñ–ú–û –ï–ö–°–ü–ï–†–ò–ú–ï–ù–¢...")  
    start_time = time.time()  
    
    all_results, comparison_table = run_model_comparison_experiment(  
        hist_df,  
        base_config='oleksandr_original',  
        n_repeats=5,  
        results_dir='model_comparison_experiment'  
    )  
    
    total_time = time.time() - start_time  
    
    print(f"\n‚è±Ô∏è –ó–ê–ì–ê–õ–¨–ù–ò–ô –ß–ê–° –ï–ö–°–ü–ï–†–ò–ú–ï–ù–¢–£: {total_time/60:.1f} —Ö–≤")  
    print(f"üìä –†–ï–ó–£–õ–¨–¢–ê–¢–ò:")  
    print(comparison_table.round(4))  
    
    # –í–∏–∑–Ω–∞—á–∞—î–º–æ –¥–∏—Ä–µ–∫—Ç–æ—Ä—ñ—é —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ñ–≤  
    # –í–∏–∑–Ω–∞—á–∞—î–º–æ –¥–∏—Ä–µ–∫—Ç–æ—Ä—ñ—é —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ñ–≤  
    results_dirs = [d for d in os.listdir('.') if d.startswith('model_comparison_experiment_')]  
    if results_dirs:  
        latest_dir = max(results_dirs)  # –û—Å—Ç–∞–Ω–Ω—ñ–π –∑–∞ –∞–ª—Ñ–∞–≤—ñ—Ç–æ–º (–Ω–∞–π–Ω–æ–≤—ñ—à–∏–π timestamp)  
        print(f"\nüîç –î–µ—Ç–∞–ª—å–Ω–∏–π –∞–Ω–∞–ª—ñ–∑ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ñ–≤...")  
        analyze_experiment_results(latest_dir)  
        
        # –°—Ç–≤–æ—Ä—é—î–º–æ –≤—ñ–∑—É–∞–ª—ñ–∑–∞—Ü—ñ—é —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ñ–≤  
        create_experiment_visualizations(latest_dir)  
    
    return all_results, comparison_table  


def create_experiment_visualizations(results_dir: str) -> None:  
    """–°—Ç–≤–æ—Ä—é—î –≥—Ä–∞—Ñ—ñ–∫–∏ –¥–ª—è –∞–Ω–∞–ª—ñ–∑—É –µ–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç—É"""  
    
    try:  
        import matplotlib.pyplot as plt  
        import seaborn as sns  
        
        print("\nüìà –°–¢–í–û–†–ï–ù–ù–Ø –í–Ü–ó–£–ê–õ–Ü–ó–ê–¶–Ü–ô...")  
        
        # –ó–∞–≤–∞–Ω—Ç–∞–∂—É—î–º–æ –¥–∞–Ω—ñ  
        comparison_df = pd.read_csv(f"{results_dir}/model_comparison.csv")  
        summary_df = pd.read_csv(f"{results_dir}/experiment_summary.csv")  
        
        # –ù–∞–ª–∞—à—Ç—É–≤–∞–Ω–Ω—è —Å—Ç–∏–ª—é  
        plt.style.use('default')  
        sns.set_palette("husl")  
        
        # –°—Ç–≤–æ—Ä—é—î–º–æ —Ñ—ñ–≥—É—Ä—É –∑ –ø—ñ–¥–≥—Ä–∞—Ñ—ñ–∫–∞–º–∏  
        fig, axes = plt.subplots(2, 3, figsize=(18, 12))  
        fig.suptitle('üî¨ –†–µ–∑—É–ª—å—Ç–∞—Ç–∏ –µ–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç—É –ø–æ—Ä—ñ–≤–Ω—è–Ω–Ω—è –º–æ–¥–µ–ª–µ–π MPC', fontsize=16, fontweight='bold')  
        
        # 1. Bar plot RMSE Fe  
        ax1 = axes[0, 0]  
        bars1 = ax1.bar(comparison_df['Model'], comparison_df['RMSE_Fe_Mean'],   
                       yerr=comparison_df['RMSE_Fe_Std'], capsize=5, alpha=0.8)  
        ax1.set_title('üéØ RMSE Fe (–Ω–∏–∂—á–µ = –∫—Ä–∞—â–µ)', fontweight='bold')  
        ax1.set_ylabel('RMSE Fe')  
        ax1.tick_params(axis='x', rotation=45)  
        ax1.grid(True, alpha=0.3)  
        
        # –ü—ñ–¥—Å–≤—ñ—á—É—î–º–æ –Ω–∞–π–∫—Ä–∞—â–∏–π —Ä–µ–∑—É–ª—å—Ç–∞—Ç  
        min_idx = comparison_df['RMSE_Fe_Mean'].idxmin()  
        bars1[min_idx].set_color('gold')  
        bars1[min_idx].set_edgecolor('orange')  
        bars1[min_idx].set_linewidth(2)  
        
        # 2. Bar plot RMSE Mass  
        ax2 = axes[0, 1]  
        bars2 = ax2.bar(comparison_df['Model'], comparison_df['RMSE_Mass_Mean'],  
                       yerr=comparison_df['RMSE_Mass_Std'], capsize=5, alpha=0.8)  
        ax2.set_title('‚öñÔ∏è RMSE Mass (–Ω–∏–∂—á–µ = –∫—Ä–∞—â–µ)', fontweight='bold')  
        ax2.set_ylabel('RMSE Mass')  
        ax2.tick_params(axis='x', rotation=45)  
        ax2.grid(True, alpha=0.3)  
        
        # 3. R¬≤ Fe  
        ax3 = axes[0, 2]  
        bars3 = ax3.bar(comparison_df['Model'], comparison_df['R2_Fe_Mean'],  
                       yerr=comparison_df['R2_Fe_Std'], capsize=5, alpha=0.8)  
        ax3.set_title('üìà R¬≤ Fe (–≤–∏—â–µ = –∫—Ä–∞—â–µ)', fontweight='bold')  
        ax3.set_ylabel('R¬≤ Fe')  
        ax3.tick_params(axis='x', rotation=45)  
        ax3.grid(True, alpha=0.3)  
        ax3.set_ylim(0, 1)  
        
        # –ü—ñ–¥—Å–≤—ñ—á—É—î–º–æ –Ω–∞–π–∫—Ä–∞—â–∏–π R¬≤  
        max_r2_idx = comparison_df['R2_Fe_Mean'].idxmax()  
        bars3[max_r2_idx].set_color('gold')  
        bars3[max_r2_idx].set_edgecolor('orange')  
        bars3[max_r2_idx].set_linewidth(2)  
        
        # 4. Box plot RMSE –ø–æ –º–æ–¥–µ–ª—è—Ö (—è–∫—â–æ —î –¥–µ—Ç–∞–ª—å–Ω—ñ –¥–∞–Ω—ñ)  
        ax4 = axes[1, 0]  
        if 'rmse_fe' in summary_df.columns and 'model' in summary_df.columns:  
            summary_df.boxplot(column='rmse_fe', by='model', ax=ax4)  
            ax4.set_title('üì¶ –†–æ–∑–ø–æ–¥—ñ–ª RMSE Fe –ø–æ –º–æ–¥–µ–ª—è—Ö', fontweight='bold')  
            ax4.set_xlabel('–ú–æ–¥–µ–ª—å')  
            ax4.set_ylabel('RMSE Fe')  
        else:  
            ax4.text(0.5, 0.5, '–î–µ—Ç–∞–ª—å–Ω—ñ –¥–∞–Ω—ñ\n–Ω–µ–¥–æ—Å—Ç—É–ø–Ω—ñ', ha='center', va='center',   
                    transform=ax4.transAxes, fontsize=12)  
            ax4.set_title('üì¶ –†–æ–∑–ø–æ–¥—ñ–ª RMSE Fe')  
        
        # 5. –ß–∞—Å –≤–∏–∫–æ–Ω–∞–Ω–Ω—è  
        ax5 = axes[1, 1]  
        bars5 = ax5.bar(comparison_df['Model'], comparison_df['Runtime_Mean'],  
                       yerr=comparison_df['Runtime_Std'], capsize=5, alpha=0.8, color='lightcoral')  
        ax5.set_title('‚è±Ô∏è –ß–∞—Å –≤–∏–∫–æ–Ω–∞–Ω–Ω—è (—Å–µ–∫)', fontweight='bold')  
        ax5.set_ylabel('–ß–∞—Å (—Å–µ–∫)')  
        ax5.tick_params(axis='x', rotation=45)  
        ax5.grid(True, alpha=0.3)  
        
        # 6. Scatter RMSE vs R¬≤  
        ax6 = axes[1, 2]  
        scatter = ax6.scatter(comparison_df['RMSE_Fe_Mean'], comparison_df['R2_Fe_Mean'],  
                             s=100, alpha=0.7, c=range(len(comparison_df)), cmap='viridis')  
        ax6.set_xlabel('RMSE Fe')  
        ax6.set_ylabel('R¬≤ Fe')  
        ax6.set_title('üéØ RMSE vs R¬≤ (–ª—ñ–≤–æ-–≤–µ—Ä—Ö = –∫—Ä–∞—â–µ)', fontweight='bold')  
        ax6.grid(True, alpha=0.3)  
        
        # –î–æ–¥–∞—î–º–æ –ø—ñ–¥–ø–∏—Å–∏ —Ç–æ—á–æ–∫  
        for i, model in enumerate(comparison_df['Model']):  
            ax6.annotate(model,   
                        (comparison_df.iloc[i]['RMSE_Fe_Mean'], comparison_df.iloc[i]['R2_Fe_Mean']),  
                        xytext=(5, 5), textcoords='offset points', fontsize=8)  
        
        plt.tight_layout()  
        plt.savefig(f"{results_dir}/experiment_analysis.png", dpi=300, bbox_inches='tight')  
        plt.savefig(f"{results_dir}/experiment_analysis.pdf", bbox_inches='tight')  
        
        print(f"   ‚úÖ –ì—Ä–∞—Ñ—ñ–∫–∏ –∑–±–µ—Ä–µ–∂–µ–Ω–æ: {results_dir}/experiment_analysis.png")  
        
        # –î–æ–¥–∞—Ç–∫–æ–≤–∏–π –≥—Ä–∞—Ñ—ñ–∫: –¥–µ—Ç–∞–ª—å–Ω–∏–π –∞–Ω–∞–ª—ñ–∑ –∫–æ–∂–Ω–æ—ó –º–æ–¥–µ–ª—ñ  
        if 'rmse_fe' in summary_df.columns:  
            create_detailed_model_analysis(summary_df, results_dir)  
        
        plt.show()  
        
    except ImportError:  
        print("   ‚ö†Ô∏è matplotlib/seaborn –Ω–µ–¥–æ—Å—Ç—É–ø–Ω—ñ –¥–ª—è –≤—ñ–∑—É–∞–ª—ñ–∑–∞—Ü—ñ—ó")  
    except Exception as e:  
        print(f"   ‚ùå –ü–æ–º–∏–ª–∫–∞ —Å—Ç–≤–æ—Ä–µ–Ω–Ω—è –≥—Ä–∞—Ñ—ñ–∫—ñ–≤: {e}")  


def create_detailed_model_analysis(summary_df: pd.DataFrame, results_dir: str) -> None:  
    """–î–µ—Ç–∞–ª—å–Ω–∏–π –∞–Ω–∞–ª—ñ–∑ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ñ–≤ –ø–æ –º–æ–¥–µ–ª—è—Ö"""  
    
    try:  
        import matplotlib.pyplot as plt  
        import seaborn as sns  
        
        fig, axes = plt.subplots(2, 2, figsize=(15, 10))  
        fig.suptitle('üîç –î–µ—Ç–∞–ª—å–Ω–∏–π –∞–Ω–∞–ª—ñ–∑ —Å—Ç–∞–±—ñ–ª—å–Ω–æ—Å—Ç—ñ –º–æ–¥–µ–ª–µ–π', fontsize=14, fontweight='bold')  
        
        # 1. Violin plot RMSE Fe  
        ax1 = axes[0, 0]  
        if len(summary_df['model'].unique()) > 1:  
            sns.violinplot(data=summary_df, x='model', y='rmse_fe', ax=ax1)  
            ax1.set_title('üéª –†–æ–∑–ø–æ–¥—ñ–ª RMSE Fe')  
            ax1.tick_params(axis='x', rotation=45)  
        
        # 2. Violin plot R¬≤ Fe  
        ax2 = axes[0, 1]  
        if 'r2_fe' in summary_df.columns:  
            sns.violinplot(data=summary_df, x='model', y='r2_fe', ax=ax2)  
            ax2.set_title('üéª –†–æ–∑–ø–æ–¥—ñ–ª R¬≤ Fe')  
            ax2.tick_params(axis='x', rotation=45)  
        
        # 3. –ö–æ—Ä–µ–ª—è—Ü—ñ—è –º–µ—Ç—Ä–∏–∫  
        ax3 = axes[1, 0]  
        if 'r2_fe' in summary_df.columns:  
            ax3.scatter(summary_df['rmse_fe'], summary_df['r2_fe'], alpha=0.6)  
            ax3.set_xlabel('RMSE Fe')  
            ax3.set_ylabel('R¬≤ Fe')  
            ax3.set_title('üìä –ö–æ—Ä–µ–ª—è—Ü—ñ—è RMSE vs R¬≤')  
            ax3.grid(True, alpha=0.3)  
        
        # 4. –°—Ç–∞–±—ñ–ª—å–Ω—ñ—Å—Ç—å –ø–æ –∑–∞–ø—É—Å–∫–∞–º  
        ax4 = axes[1, 1]  
        if 'run_number' in summary_df.columns:  
            for model in summary_df['model'].unique():  
                model_data = summary_df[summary_df['model'] == model]  
                ax4.plot(model_data['run_number'], model_data['rmse_fe'],   
                        'o-', label=model, alpha=0.7)  
            ax4.set_xlabel('–ù–æ–º–µ—Ä –∑–∞–ø—É—Å–∫—É')  
            ax4.set_ylabel('RMSE Fe')  
            ax4.set_title('üìà –°—Ç–∞–±—ñ–ª—å–Ω—ñ—Å—Ç—å –ø–æ –∑–∞–ø—É—Å–∫–∞–º')  
            ax4.legend()  
            ax4.grid(True, alpha=0.3)  
        
        plt.tight_layout()  
        plt.savefig(f"{results_dir}/detailed_analysis.png", dpi=300, bbox_inches='tight')  
        print(f"   ‚úÖ –î–µ—Ç–∞–ª—å–Ω–∏–π –∞–Ω–∞–ª—ñ–∑ –∑–±–µ—Ä–µ–∂–µ–Ω–æ: {results_dir}/detailed_analysis.png")  
        
    except Exception as e:  
        print(f"   ‚ùå –ü–æ–º–∏–ª–∫–∞ –¥–µ—Ç–∞–ª—å–Ω–æ–≥–æ –∞–Ω–∞–ª—ñ–∑—É: {e}")  


def statistical_significance_test(results_dir: str) -> None:  
    """–°—Ç–∞—Ç–∏—Å—Ç–∏—á–Ω–∏–π —Ç–µ—Å—Ç –∑–Ω–∞—á—É—â–æ—Å—Ç—ñ —Ä—ñ–∑–Ω–∏—Ü—å –º—ñ–∂ –º–æ–¥–µ–ª—è–º–∏"""  
    
    try:  
        from scipy import stats  
        
        print("\nüßÆ –°–¢–ê–¢–ò–°–¢–ò–ß–ù–ò–ô –ê–ù–ê–õ–Ü–ó –ó–ù–ê–ß–£–©–û–°–¢–Ü")  
        print("="*50)  
        
        summary_df = pd.read_csv(f"{results_dir}/experiment_summary.csv")  
        
        if 'rmse_fe' not in summary_df.columns or 'model' not in summary_df.columns:  
            print("‚ùå –ù–µ–¥–æ—Å—Ç–∞—Ç–Ω—å–æ –¥–∞–Ω–∏—Ö –¥–ª—è —Å—Ç–∞—Ç–∏—Å—Ç–∏—á–Ω–æ–≥–æ —Ç–µ—Å—Ç—É")  
            return  
        
        models = summary_df['model'].unique()  
        if len(models) < 2:  
            print("‚ùå –ü–æ—Ç—Ä—ñ–±–Ω–æ –ø—Ä–∏–Ω–∞–π–º–Ω—ñ 2 –º–æ–¥–µ–ª—ñ –¥–ª—è –ø–æ—Ä—ñ–≤–Ω—è–Ω–Ω—è")  
            return  
        
        # –ü–∞—Ä–Ω—ñ t-—Ç–µ—Å—Ç–∏ –º—ñ–∂ –º–æ–¥–µ–ª—è–º–∏  
        print("üî¨ –ü–ê–†–ù–Ü T-–¢–ï–°–¢–ò (RMSE Fe):")  
        results_matrix = []  
        
        for i, model1 in enumerate(models):  
            row = []  
            for j, model2 in enumerate(models):  
                if i == j:  
                    row.append("-")  
                else:  
                    data1 = summary_df[summary_df['model'] == model1]['rmse_fe']  
                    data2 = summary_df[summary_df['model'] == model2]['rmse_fe']  
                    
                    if len(data1) >= 2 and len(data2) >= 2:  
                        t_stat, p_value = stats.ttest_ind(data1, data2)  
                        significance = "***" if p_value < 0.001 else "**" if p_value < 0.01 else "*" if p_value < 0.05 else "ns"  
                        row.append(f"{p_value:.4f} {significance}")  
                    else:  
                        row.append("N/A")  
            results_matrix.append(row)  
        
        # –°—Ç–≤–æ—Ä—é—î–º–æ —Ç–∞–±–ª–∏—Ü—é —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ñ–≤  
        results_df = pd.DataFrame(results_matrix, index=models, columns=models)  
        print(results_df)  
        
        print("\nüìä –ü–æ–∑–Ω–∞—á–µ–Ω–Ω—è: *** p<0.001, ** p<0.01, * p<0.05, ns p‚â•0.05")  
        
        # –ó–±–µ—Ä—ñ–≥–∞—î–º–æ —Å—Ç–∞—Ç–∏—Å—Ç–∏—á–Ω–∏–π –∞–Ω–∞–ª—ñ–∑  
        results_df.to_csv(f"{results_dir}/statistical_analysis.csv")  
        
    except ImportError:  
        print("‚ö†Ô∏è scipy –Ω–µ–¥–æ—Å—Ç—É–ø–Ω–∞ –¥–ª—è —Å—Ç–∞—Ç–∏—Å—Ç–∏—á–Ω–æ–≥–æ –∞–Ω–∞–ª—ñ–∑—É")  
    except Exception as e:  
        print(f"‚ùå –ü–æ–º–∏–ª–∫–∞ —Å—Ç–∞—Ç–∏—Å—Ç–∏—á–Ω–æ–≥–æ –∞–Ω–∞–ª—ñ–∑—É: {e}")  


# üéØ –ì–û–õ–û–í–ù–ê –§–£–ù–ö–¶–Ü–Ø –ó–ê–ü–£–°–ö–£  
if __name__ == '__main__':  
    print("üöÄ –ó–ê–ü–£–°–ö –ï–ö–°–ü–ï–†–ò–ú–ï–ù–¢–£ –ü–û–†–Ü–í–ù–Ø–ù–ù–Ø –ú–û–î–ï–õ–ï–ô MPC")  
    print("="*70)  
    
    # –ó–∞–ø—É—Å–∫–∞—î–º–æ –µ–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç  
    try:  
        all_results, comparison_table = main_experiment()  
        
        # –ó–Ω–∞—Ö–æ–¥–∏–º–æ –¥–∏—Ä–µ–∫—Ç–æ—Ä—ñ—é –∑ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞–º–∏  
        results_dirs = [d for d in os.listdir('.') if d.startswith('model_comparison_experiment_')]  
        if results_dirs:  
            latest_dir = max(results_dirs)  
            
            print(f"\nüìä –§–Ü–ù–ê–õ–¨–ù–Ü –†–ï–ó–£–õ–¨–¢–ê–¢–ò:")  
            print("="*70)  
            
            # –ü–æ–∫–∞–∑—É—î–º–æ –ø–æ—Ä—ñ–≤–Ω—è–ª—å–Ω—É —Ç–∞–±–ª–∏—Ü—é  
            print("üèÜ –†–ï–ô–¢–ò–ù–ì –ú–û–î–ï–õ–ï–ô:")  
            print(comparison_table[['Model', 'RMSE_Fe_Mean', 'RMSE_Fe_Std', 'R2_Fe_Mean', 'Runtime_Mean']].round(4))  
            
            # –°—Ç–∞—Ç–∏—Å—Ç–∏—á–Ω–∏–π –∞–Ω–∞–ª—ñ–∑  
            statistical_significance_test(latest_dir)  
            
            # –†–µ–∫–æ–º–µ–Ω–¥–∞—Ü—ñ—ó  
            print(f"\nüí° –†–ï–ö–û–ú–ï–ù–î–ê–¶–Ü–á:")  
            best_model = comparison_table.iloc[0]['Model']  
            best_rmse = comparison_table.iloc[0]['RMSE_Fe_Mean']  
            best_r2 = comparison_table.iloc[0]['R2_Fe_Mean']  
            
            print(f"ü•á –ù–∞–π–∫—Ä–∞—â–∏–π —Ä–µ–∑—É–ª—å—Ç–∞—Ç: {best_model}")  
            print(f"   RMSE Fe: {best_rmse:.4f}")  
            print(f"   R¬≤ Fe: {best_r2:.4f}")  
            
            if len(comparison_table) > 1:  
                second_best = comparison_table.iloc[1]  
                improvement = ((second_best['RMSE_Fe_Mean'] - best_rmse) / second_best['RMSE_Fe_Mean'] * 100)  
                print(f"   –ü–æ–∫—Ä–∞—â–µ–Ω–Ω—è –≤—ñ–¥–Ω–æ—Å–Ω–æ –¥—Ä—É–≥–æ–≥–æ –º—ñ—Å—Ü—è: {improvement:.2f}%")  
            
            print(f"\nüìÅ –í—Å—ñ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∏ –∑–±–µ—Ä–µ–∂–µ–Ω–æ –≤: {latest_dir}")  
            print(f"üìä –§–∞–π–ª–∏:")  
            print(f"   - model_comparison.csv (–ø–æ—Ä—ñ–≤–Ω—è–ª—å–Ω–∞ —Ç–∞–±–ª–∏—Ü—è)")  
            print(f"   - experiment_summary.csv (–¥–µ—Ç–∞–ª—å–Ω—ñ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∏)")  
            print(f"   - experiment_analysis.png (–≥—Ä–∞—Ñ—ñ–∫–∏)")  
            print(f"   - statistical_analysis.csv (—Å—Ç–∞—Ç–∏—Å—Ç–∏—á–Ω–∏–π –∞–Ω–∞–ª—ñ–∑)")  
            print(f"   - individual *_results.parquet (—Ä–µ–∑—É–ª—å—Ç–∞—Ç–∏ –∫–æ–∂–Ω–æ–≥–æ –∑–∞–ø—É—Å–∫—É)")  
            
    except Exception as e:  
        print(f"‚ùå –ö–†–ò–¢–ò–ß–ù–ê –ü–û–ú–ò–õ–ö–ê: {e}")
        import traceback
        traceback.print_exc()
        
    print("\nüéâ –ï–ö–°–ü–ï–†–ò–ú–ï–ù–¢ –ó–ê–í–ï–†–®–ï–ù–û!")
    print("="*70)


# üîß –î–û–î–ê–¢–ö–û–í–Ü –£–¢–ò–õ–Ü–¢–ò –î–õ–Ø –ê–ù–ê–õ–Ü–ó–£ –†–ï–ó–£–õ–¨–¢–ê–¢–Ü–í

def load_and_compare_experiments(experiment_dirs: List[str]) -> pd.DataFrame:
    """–ü–æ—Ä—ñ–≤–Ω—é—î —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∏ –∫—ñ–ª—å–∫–æ—Ö –µ–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç—ñ–≤"""
    
    print("üîç –ü–û–†–Ü–í–ù–Ø–ù–ù–Ø –ï–ö–°–ü–ï–†–ò–ú–ï–ù–¢–Ü–í")
    print("="*50)
    
    all_comparisons = []
    
    for exp_dir in experiment_dirs:
        try:
            comparison_file = f"{exp_dir}/model_comparison.csv"
            if os.path.exists(comparison_file):
                df = pd.read_csv(comparison_file)
                df['Experiment'] = exp_dir
                all_comparisons.append(df)
                print(f"‚úÖ –ó–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–æ: {exp_dir}")
            else:
                print(f"‚ùå –ù–µ –∑–Ω–∞–π–¥–µ–Ω–æ: {comparison_file}")
        except Exception as e:
            print(f"‚ùå –ü–æ–º–∏–ª–∫–∞ –∑–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–Ω—è {exp_dir}: {e}")
    
    if all_comparisons:
        combined_df = pd.concat(all_comparisons, ignore_index=True)
        
        # –°—Ç–≤–æ—Ä—é—î–º–æ –∑–≤–µ–¥–µ–Ω—É —Ç–∞–±–ª–∏—Ü—é
        pivot_table = combined_df.pivot_table(
            index='Model',
            columns='Experiment', 
            values='RMSE_Fe_Mean',
            aggfunc='mean'
        )
        
        print(f"\nüìä –ó–í–ï–î–ï–ù–ê –¢–ê–ë–õ–ò–¶–Ø RMSE Fe:")
        print(pivot_table.round(4))
        
        return combined_df
    else:
        print("‚ùå –ù–µ–º–∞—î –¥–∞–Ω–∏—Ö –¥–ª—è –ø–æ—Ä—ñ–≤–Ω—è–Ω–Ω—è")
        return pd.DataFrame()


def generate_experiment_report(results_dir: str, output_file: str = None) -> str:
    """–ì–µ–Ω–µ—Ä—É—î –¥–µ—Ç–∞–ª—å–Ω–∏–π –∑–≤—ñ—Ç –ø—Ä–æ –µ–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç"""
    
    if output_file is None:
        output_file = f"{results_dir}/experiment_report.md"
    
    try:
        comparison_df = pd.read_csv(f"{results_dir}/model_comparison.csv")
        summary_df = pd.read_csv(f"{results_dir}/experiment_summary.csv")
        
        report = f"""# üî¨ –ó–≤—ñ—Ç –ø—Ä–æ –µ–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç –ø–æ—Ä—ñ–≤–Ω—è–Ω–Ω—è –º–æ–¥–µ–ª–µ–π MPC

## üìä –ó–∞–≥–∞–ª—å–Ω–∞ —ñ–Ω—Ñ–æ—Ä–º–∞—Ü—ñ—è
- **–î–∞—Ç–∞ –µ–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç—É:** {datetime.now().strftime("%Y-%m-%d %H:%M:%S")}
- **–ö—ñ–ª—å–∫—ñ—Å—Ç—å –º–æ–¥–µ–ª–µ–π:** {len(comparison_df)}
- **–ü–æ–≤—Ç–æ—Ä–µ–Ω—å –Ω–∞ –º–æ–¥–µ–ª—å:** {summary_df['model'].value_counts().iloc[0] if len(summary_df) > 0 else 'N/A'}
- **–ó–∞–≥–∞–ª–æ–º –∑–∞–ø—É—Å–∫—ñ–≤:** {len(summary_df)}

## üèÜ –†–µ–∑—É–ª—å—Ç–∞—Ç–∏

### –†–µ–π—Ç–∏–Ω–≥ –º–æ–¥–µ–ª–µ–π (–ø–æ RMSE Fe):
"""
        
        for idx, row in comparison_df.iterrows():
            rank = idx + 1
            medal = "ü•á" if rank == 1 else "ü•à" if rank == 2 else "ü•â" if rank == 3 else f"{rank}."
            
            report += f"""
{medal} **{row['Model']}**
- RMSE Fe: {row['RMSE_Fe_Mean']:.4f} ¬± {row['RMSE_Fe_Std']:.4f}
- RMSE Mass: {row['RMSE_Mass_Mean']:.4f} ¬± {row['RMSE_Mass_Std']:.4f}
- R¬≤ Fe: {row['R2_Fe_Mean']:.4f} ¬± {row['R2_Fe_Std']:.4f}
- R¬≤ Mass: {row['R2_Mass_Mean']:.4f} ¬± {row['R2_Mass_Std']:.4f}
- –ß–∞—Å –≤–∏–∫–æ–Ω–∞–Ω–Ω—è: {row['Runtime_Mean']:.1f}—Å ¬± {row['Runtime_Std']:.1f}—Å
"""
        
        # –ê–Ω–∞–ª—ñ–∑ —Å—Ç–∞–±—ñ–ª—å–Ω–æ—Å—Ç—ñ
        report += f"""
## üìà –ê–Ω–∞–ª—ñ–∑ —Å—Ç–∞–±—ñ–ª—å–Ω–æ—Å—Ç—ñ

### –ö–æ–µ—Ñ—ñ—Ü—ñ—î–Ω—Ç–∏ –≤–∞—Ä—ñ–∞—Ü—ñ—ó (CV = std/mean):
"""
        
        for idx, row in comparison_df.iterrows():
            cv_rmse = (row['RMSE_Fe_Std'] / row['RMSE_Fe_Mean']) * 100
            cv_r2 = (row['R2_Fe_Std'] / row['R2_Fe_Mean']) * 100 if row['R2_Fe_Mean'] > 0 else float('inf')
            
            stability = "–î—É–∂–µ —Å—Ç–∞–±—ñ–ª—å–Ω–∞" if cv_rmse < 5 else "–°—Ç–∞–±—ñ–ª—å–Ω–∞" if cv_rmse < 10 else "–ù–µ—Å—Ç–∞–±—ñ–ª—å–Ω–∞"
            
            report += f"- **{row['Model']}**: CV_RMSE = {cv_rmse:.2f}% ({stability})\n"
        
        # –†–µ–∫–æ–º–µ–Ω–¥–∞—Ü—ñ—ó
        best_model = comparison_df.iloc[0]
        report += f"""
## üí° –†–µ–∫–æ–º–µ–Ω–¥–∞—Ü—ñ—ó

### üéØ –ù–∞–π–∫—Ä–∞—â–∏–π —Ä–µ–∑—É–ª—å—Ç–∞—Ç: {best_model['Model']}
- –ù–∞–π–Ω–∏–∂—á–∏–π RMSE Fe: {best_model['RMSE_Fe_Mean']:.4f}
- –í–∏—Å–æ–∫–∏–π R¬≤: {best_model['R2_Fe_Mean']:.4f}
- {'–®–≤–∏–¥–∫–∏–π' if best_model['Runtime_Mean'] < 60 else '–ü–æ–≤—ñ–ª—å–Ω–∏–π'} —á–∞—Å –≤–∏–∫–æ–Ω–∞–Ω–Ω—è: {best_model['Runtime_Mean']:.1f}—Å

### üìä –ü–æ—Ä—ñ–≤–Ω—è–Ω–Ω—è –∑ —ñ–Ω—à–∏–º–∏ –º–æ–¥–µ–ª—è–º–∏:
"""
        
        if len(comparison_df) > 1:
            for idx in range(1, min(4, len(comparison_df))):  # –¢–æ–ø-3 –ø—ñ—Å–ª—è –Ω–∞–π–∫—Ä–∞—â–æ—ó
                model = comparison_df.iloc[idx]
                improvement = ((model['RMSE_Fe_Mean'] - best_model['RMSE_Fe_Mean']) / model['RMSE_Fe_Mean'] * 100)
                report += f"- –ö—Ä–∞—â–µ –∑–∞ {model['Model']} –Ω–∞ {improvement:.2f}%\n"
        
        # –¢–µ—Ö–Ω—ñ—á–Ω—ñ –¥–µ—Ç–∞–ª—ñ
        report += f"""
## üîß –¢–µ—Ö–Ω—ñ—á–Ω—ñ –¥–µ—Ç–∞–ª—ñ

### –ö–æ–Ω—Ñ—ñ–≥—É—Ä–∞—Ü—ñ—è –µ–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç—É:
- –ë–∞–∑–æ–≤–∞ –∫–æ–Ω—Ñ—ñ–≥—É—Ä–∞—Ü—ñ—è: `oleksandr_original`
- Seeds –≤–∏–∫–æ—Ä–∏—Å—Ç–∞–Ω—ñ: 0, 42, 84, 126, 168 (–¥–ª—è –≤—ñ–¥—Ç–≤–æ—Ä—é–≤–∞–Ω–æ—Å—Ç—ñ)
- –ê–Ω–∞–ª—ñ–∑ –≤—ñ–¥–∫–ª—é—á–µ–Ω–∏–π –¥–ª—è —à–≤–∏–¥–∫–æ—Å—Ç—ñ

### –§–∞–π–ª–∏ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ñ–≤:
- `model_comparison.csv` - –ø–æ—Ä—ñ–≤–Ω—è–ª—å–Ω–∞ —Ç–∞–±–ª–∏—Ü—è
- `experiment_summary.csv` - –¥–µ—Ç–∞–ª—å–Ω—ñ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∏ –≤—Å—ñ—Ö –∑–∞–ø—É—Å–∫—ñ–≤
- `experiment_analysis.png` - –≤—ñ–∑—É–∞–ª—ñ–∑–∞—Ü—ñ—è —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ñ–≤
- `statistical_analysis.csv` - —Å—Ç–∞—Ç–∏—Å—Ç–∏—á–Ω–∏–π –∞–Ω–∞–ª—ñ–∑ –∑–Ω–∞—á—É—â–æ—Å—Ç—ñ
- `*_results.parquet` - —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∏ –æ–∫—Ä–µ–º–∏—Ö —Å–∏–º—É–ª—è—Ü—ñ–π
- `*_metrics.json` - –º–µ—Ç—Ä–∏–∫–∏ –æ–∫—Ä–µ–º–∏—Ö —Å–∏–º—É–ª—è—Ü—ñ–π

## üìù –í–∏—Å–Ω–æ–≤–∫–∏

1. **–ù–∞–π–∫—Ä–∞—â–∏–π –≤–∏–±—ñ—Ä:** {best_model['Model']} –ø–æ–∫–∞–∑—É—î –Ω–∞–π–∫—Ä–∞—â—ñ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∏ –ø–æ —Ç–æ—á–Ω–æ—Å—Ç—ñ
2. **–°—Ç–∞–±—ñ–ª—å–Ω—ñ—Å—Ç—å:** –í—Å—ñ –º–æ–¥–µ–ª—ñ –ø–æ–∫–∞–∑—É—é—Ç—å {'—Å—Ç–∞–±—ñ–ª—å–Ω—ñ' if comparison_df['RMSE_Fe_Std'].max() < 0.1 else '–≤–∞—Ä—ñ–∞—Ç–∏–≤–Ω—ñ'} —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∏
3. **–®–≤–∏–¥–∫–æ–¥—ñ—è:** {'GPR —Ç–∞ SVR' if any('GPR' in m or 'SVR' in m for m in comparison_df['Model']) else '–õ—ñ–Ω—ñ–π–Ω—ñ –º–æ–¥–µ–ª—ñ'} –ø–æ—Ç—Ä–µ–±—É—é—Ç—å –±—ñ–ª—å—à–µ —á–∞—Å—É –¥–ª—è –Ω–∞–≤—á–∞–Ω–Ω—è
4. **–†–µ–∫–æ–º–µ–Ω–¥–∞—Ü—ñ—è:** –í–∏–∫–æ—Ä–∏—Å—Ç–æ–≤—É–≤–∞—Ç–∏ {best_model['Model']} –¥–ª—è –ø—Ä–æ–¥–∞–∫—à–Ω —Å–∏—Å—Ç–µ–º–∏

---
*–ó–≤—ñ—Ç –∑–≥–µ–Ω–µ—Ä–æ–≤–∞–Ω–∏–π –∞–≤—Ç–æ–º–∞—Ç–∏—á–Ω–æ {datetime.now().strftime("%Y-%m-%d %H:%M:%S")}*
"""
        
        # –ó–±–µ—Ä—ñ–≥–∞—î–º–æ –∑–≤—ñ—Ç
        with open(output_file, 'w', encoding='utf-8') as f:
            f.write(report)
        
        print(f"üìÑ –ó–≤—ñ—Ç –∑–±–µ—Ä–µ–∂–µ–Ω–æ: {output_file}")
        return report
        
    except Exception as e:
        print(f"‚ùå –ü–æ–º–∏–ª–∫–∞ –≥–µ–Ω–µ—Ä–∞—Ü—ñ—ó –∑–≤—ñ—Ç—É: {e}")
        return ""


# üéØ –®–í–ò–î–ö–ò–ô –ó–ê–ü–£–°–ö (–î–õ–Ø –¢–ï–°–¢–£–í–ê–ù–ù–Ø)
def quick_test_experiment():
    """–®–≤–∏–¥–∫–∏–π —Ç–µ—Å—Ç –µ–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç—É –∑ –º–µ–Ω—à–æ—é –∫—ñ–ª—å–∫—ñ—Å—Ç—é –¥–∞–Ω–∏—Ö"""
    
    print("‚ö° –®–í–ò–î–ö–ò–ô –¢–ï–°–¢ –ï–ö–°–ü–ï–†–ò–ú–ï–ù–¢–£")
    
    try:
        hist_df = pd.read_parquet('processed.parquet')
    except:
        try:
            hist_df = pd.read_parquet('/content/KModel/src/processed.parquet')
        except Exception as e:
            print(f"‚ùå –ù–µ –º–æ–∂—É –∑–∞–≤–∞–Ω—Ç–∞–∂–∏—Ç–∏ –¥–∞–Ω—ñ: {e}")
            return
    
    # –¢–µ—Å—Ç—É—î–º–æ —Ç—ñ–ª—å–∫–∏ 2 –º–æ–¥–µ–ª—ñ –ø–æ 2 —Ä–∞–∑–∏ –∑ –º–µ–Ω—à–∏–º–∏ –¥–∞–Ω–∏–º–∏
    models_config = {
        'KRR_RBF_TEST': {
            'model_type': 'krr',
            'kernel': 'rbf',
            'N_data': 2000,
            'control_pts': 300,
            'find_optimal_params': False
        },
        'LINEAR_TEST': {
            'model_type': 'linear',
            'linear_type': 'ridge',
            'N_data': 2000,
            'control_pts': 300,
            'find_optimal_params': False
        }
    }
    
    results = {}
    for model_name, params in models_config.items():
        print(f"\nüß™ –¢–µ—Å—Ç—É—î–º–æ {model_name}...")
        
        try:
            results_df, metrics = simulate_mpc(
                hist_df,
                config='oleksandr_original',
                config_overrides=params,
                run_analysis=False
            )
            
            results[model_name] = {
                'rmse_fe': metrics.get('rmse_fe', 0),
                'rmse_mass': metrics.get('rmse_mass', 0),
                'r2_fe': metrics.get('r2_fe', 0)
            }
            
            print(f"   ‚úÖ RMSE Fe: {metrics.get('rmse_fe', 0):.4f}")
            
        except Exception as e:
            print(f"   ‚ùå –ü–æ–º–∏–ª–∫–∞: {e}")
    
    print(f"\nüìä –†–ï–ó–£–õ–¨–¢–ê–¢–ò –®–í–ò–î–ö–û–ì–û –¢–ï–°–¢–£:")
    for model, metrics in results.items():
        print(f"   {model}: RMSE_Fe={metrics['rmse_fe']:.4f}, R¬≤={metrics['r2_fe']:.4f}")
    
    return results


# üéØ –¢–û–ß–ö–ê –í–•–û–î–£
if __name__ == '__main__':
    import sys
    
    if len(sys.argv) > 1 and sys.argv[1] == 'quick':
        # –®–≤–∏–¥–∫–∏–π —Ç–µ—Å—Ç
        quick_test_experiment()
    else:
        # –ü–æ–≤–Ω–∏–π –µ–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç
        main_experiment()

print("‚úÖ –ö–æ–¥ –µ–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç—É –≥–æ—Ç–æ–≤–∏–π!")
print("\nüöÄ –î–õ–Ø –ó–ê–ü–£–°–ö–£:")
print("   python experiment.py          # –ü–æ–≤–Ω–∏–π –µ–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç (5 –º–æ–¥–µ–ª–µ–π √ó 5 –ø–æ–≤—Ç–æ—Ä—ñ–≤)")
print("   python experiment.py quick    # –®–≤–∏–¥–∫–∏–π —Ç–µ—Å—Ç (2 –º–æ–¥–µ–ª—ñ √ó 1 –ø–æ–≤—Ç–æ—Ä)")