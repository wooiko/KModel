# evaluation_simple.py - –ü—Ä–æ—Å—Ç–∏–π –º–æ–¥—É–ª—å –æ—Ü—ñ–Ω—é–≤–∞–Ω–Ω—è –µ—Ñ–µ–∫—Ç–∏–≤–Ω–æ—Å—Ç—ñ MPC-—Å–∏–º—É–ª—è—Ç–æ—Ä–∞

import numpy as np
import pandas as pd
from typing import Dict, List, Tuple, Optional
import matplotlib.pyplot as plt
from sklearn.metrics import mean_squared_error, r2_score
from dataclasses import dataclass

# =============================================================================
# === –°–¢–†–£–ö–¢–£–†–ò –î–ê–ù–ò–• ===
# =============================================================================

@dataclass
class EvaluationResults:
    """–ö–æ–Ω—Ç–µ–π–Ω–µ—Ä –¥–ª—è –≤—Å—ñ—Ö —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ñ–≤ –æ—Ü—ñ–Ω—é–≤–∞–Ω–Ω—è –∑ EKF —Ç–∞ Trust Region –º–µ—Ç—Ä–∏–∫–∞–º–∏"""
    # –ú–æ–¥–µ–ª—å (10 –º–µ—Ç—Ä–∏–∫ - MAE —ñ MAPE)
    model_rmse_fe: float
    model_rmse_mass: float
    model_r2_fe: float
    model_r2_mass: float
    model_bias_fe: float
    model_bias_mass: float
    model_mae_fe: float
    model_mae_mass: float
    model_mape_fe: float
    model_mape_mass: float
    
    # EKF –º–µ—Ç—Ä–∏–∫–∏ (8 –º–µ—Ç—Ä–∏–∫)
    ekf_rmse_fe: float               # ‚úÖ –ù–û–í–ò–ô: RMSE –¥–ª—è Fe —Å—Ç–∞–Ω—É
    ekf_rmse_mass: float             # ‚úÖ –ù–û–í–ò–ô: RMSE –¥–ª—è Mass —Å—Ç–∞–Ω—É  
    ekf_normalized_rmse_fe: float    # ‚úÖ –ù–û–í–ò–ô: –ù–æ—Ä–º–∞–ª—ñ–∑–æ–≤–∞–Ω–∏–π RMSE Fe
    ekf_normalized_rmse_mass: float  # ‚úÖ –ù–û–í–ò–ô: –ù–æ—Ä–º–∞–ª—ñ–∑–æ–≤–∞–Ω–∏–π RMSE Mass
    ekf_rmse_total: float            # ‚úÖ –ù–û–í–ò–ô: –ó–∞–≥–∞–ª—å–Ω–∏–π RMSE
    ekf_nees_mean: float             # ‚úÖ –ù–û–í–ò–ô: –°–µ—Ä–µ–¥–Ω—ñ–π NEES
    ekf_nis_mean: float              # ‚úÖ –ù–û–í–ò–ô: –°–µ—Ä–µ–¥–Ω—ñ–π NIS
    ekf_consistency: float           # ‚úÖ –ù–û–í–ò–ô: –ó–∞–≥–∞–ª—å–Ω–∞ –∫–æ–Ω—Å–∏—Å—Ç–µ–Ω—Ç–Ω—ñ—Å—Ç—å EKF (0-1)
    
    # Trust Region –º–µ—Ç—Ä–∏–∫–∏ (6 –º–µ—Ç—Ä–∏–∫) 
    trust_radius_mean: float         # ‚úÖ –ù–û–í–ò–ô: –°–µ—Ä–µ–¥–Ω—ñ–π —Ä–∞–¥—ñ—É—Å
    trust_radius_std: float          # ‚úÖ –ù–û–í–ò–ô: –°—Ç–∞–Ω–¥–∞—Ä—Ç–Ω–µ –≤—ñ–¥—Ö–∏–ª–µ–Ω–Ω—è —Ä–∞–¥—ñ—É—Å–∞
    trust_radius_min: float          # ‚úÖ –ù–û–í–ò–ô: –ú—ñ–Ω—ñ–º–∞–ª—å–Ω–∏–π —Ä–∞–¥—ñ—É—Å
    trust_radius_max: float          # ‚úÖ –ù–û–í–ò–ô: –ú–∞–∫—Å–∏–º–∞–ª—å–Ω–∏–π —Ä–∞–¥—ñ—É—Å
    trust_adaptivity_coeff: float    # ‚úÖ –ù–û–í–ò–ô: –ö–æ–µ—Ñ—ñ—Ü—ñ—î–Ω—Ç –∞–¥–∞–ø—Ç–∏–≤–Ω–æ—Å—Ç—ñ
    trust_stability_index: float     # ‚úÖ –ù–û–í–ò–ô: –Ü–Ω–¥–µ–∫—Å —Å—Ç–∞–±—ñ–ª—å–Ω–æ—Å—Ç—ñ Trust Region
    
    # –ß–∞—Å–æ–≤—ñ –º–µ—Ç—Ä–∏–∫–∏ (4 –º–µ—Ç—Ä–∏–∫–∏)
    initial_training_time: float
    avg_retraining_time: float
    avg_prediction_time: float
    total_retraining_count: float
    
    # –ö–µ—Ä—É–≤–∞–Ω–Ω—è (13 –º–µ—Ç—Ä–∏–∫ - MAE —ñ MAPE –¥–ª—è –≤—ñ–¥—Å—Ç–µ–∂–µ–Ω–Ω—è)
    tracking_error_fe: float
    tracking_error_mass: float
    control_smoothness: float
    setpoint_achievement_fe: float
    setpoint_achievement_mass: float
    ise_fe: float
    ise_mass: float
    iae_fe: float
    iae_mass: float
    tracking_mae_fe: float
    tracking_mae_mass: float
    tracking_mape_fe: float
    tracking_mape_mass: float
    
    # –ó–∞–≥–∞–ª—å–Ω–∞ –µ—Ñ–µ–∫—Ç–∏–≤–Ω—ñ—Å—Ç—å (2 –º–µ—Ç—Ä–∏–∫–∏)
    overall_score: float
    process_stability: float
    
    # –ê–≥—Ä–µ—Å–∏–≤–Ω—ñ—Å—Ç—å –∫–µ—Ä—É–≤–∞–Ω–Ω—è (11 –º–µ—Ç—Ä–∏–∫)
    control_aggressiveness: float
    control_variability: float
    control_energy: float
    control_stability_index: float
    control_utilization: float
    significant_changes_frequency: float
    significant_changes_count: float
    max_control_change: float
    directional_switches_per_step: float
    directional_switches_count: float
    steps_at_max_delta_u: float

    def to_dict(self) -> Dict:
        """–ö–æ–Ω–≤–µ—Ä—Ç—É—î –≤ —Å–ª–æ–≤–Ω–∏–∫ –¥–ª—è –∑—Ä—É—á–Ω–æ—Å—Ç—ñ"""
        return {
            # –ú–æ–¥–µ–ª—å
            'model_rmse_fe': self.model_rmse_fe,
            'model_rmse_mass': self.model_rmse_mass,
            'model_r2_fe': self.model_r2_fe,
            'model_r2_mass': self.model_r2_mass,
            'model_bias_fe': self.model_bias_fe,
            'model_bias_mass': self.model_bias_mass,
            'model_mae_fe': self.model_mae_fe,
            'model_mae_mass': self.model_mae_mass,
            'model_mape_fe': self.model_mape_fe,
            'model_mape_mass': self.model_mape_mass,
            
            # EKF –º–µ—Ç—Ä–∏–∫–∏
            'ekf_rmse_fe': self.ekf_rmse_fe,
            'ekf_rmse_mass': self.ekf_rmse_mass,
            'ekf_normalized_rmse_fe': self.ekf_normalized_rmse_fe,
            'ekf_normalized_rmse_mass': self.ekf_normalized_rmse_mass,
            'ekf_rmse_total': self.ekf_rmse_total,
            'ekf_nees_mean': self.ekf_nees_mean,
            'ekf_nis_mean': self.ekf_nis_mean,
            'ekf_consistency': self.ekf_consistency,
            
            # Trust Region –º–µ—Ç—Ä–∏–∫–∏
            'trust_radius_mean': self.trust_radius_mean,
            'trust_radius_std': self.trust_radius_std,
            'trust_radius_min': self.trust_radius_min,
            'trust_radius_max': self.trust_radius_max,
            'trust_adaptivity_coeff': self.trust_adaptivity_coeff,
            'trust_stability_index': self.trust_stability_index,
            
            # –ß–∞—Å–æ–≤—ñ –º–µ—Ç—Ä–∏–∫–∏
            'initial_training_time': self.initial_training_time,
            'avg_retraining_time': self.avg_retraining_time,
            'avg_prediction_time': self.avg_prediction_time,
            'total_retraining_count': self.total_retraining_count,
            
            # –ö–µ—Ä—É–≤–∞–Ω–Ω—è
            'tracking_error_fe': self.tracking_error_fe,
            'tracking_error_mass': self.tracking_error_mass,
            'control_smoothness': self.control_smoothness,
            'setpoint_achievement_fe': self.setpoint_achievement_fe,
            'setpoint_achievement_mass': self.setpoint_achievement_mass,
            'ise_fe': self.ise_fe,
            'ise_mass': self.ise_mass,
            'iae_fe': self.iae_fe,
            'iae_mass': self.iae_mass,
            'tracking_mae_fe': self.tracking_mae_fe,
            'tracking_mae_mass': self.tracking_mae_mass,
            'tracking_mape_fe': self.tracking_mape_fe,
            'tracking_mape_mass': self.tracking_mape_mass,
            
            # –ó–∞–≥–∞–ª—å–Ω–∞ –µ—Ñ–µ–∫—Ç–∏–≤–Ω—ñ—Å—Ç—å
            'overall_score': self.overall_score,
            'process_stability': self.process_stability,
            
            # –ê–≥—Ä–µ—Å–∏–≤–Ω—ñ—Å—Ç—å –∫–µ—Ä—É–≤–∞–Ω–Ω—è
            'control_aggressiveness': self.control_aggressiveness,
            'control_variability': self.control_variability,
            'control_energy': self.control_energy,
            'control_stability_index': self.control_stability_index,
            'control_utilization': self.control_utilization,
            'significant_changes_frequency': self.significant_changes_frequency,
            'significant_changes_count': self.significant_changes_count,
            'max_control_change': self.max_control_change,
            'directional_switches_per_step': self.directional_switches_per_step,
            'directional_switches_count': self.directional_switches_count,
            'steps_at_max_delta_u': self.steps_at_max_delta_u
        }
    
# =============================================================================
# === –§–£–ù–ö–¶–Ü–á –û–¶–Ü–ù–Æ–í–ê–ù–ù–Ø –ú–û–î–ï–õ–ï–ô ===
# =============================================================================

def evaluate_model_performance(results_df: pd.DataFrame, analysis_data: Dict) -> Dict[str, float]:
    """–û—Ü—ñ–Ω—é—î —è–∫—ñ—Å—Ç—å —Ä–æ–±–æ—Ç–∏ –º–æ–¥–µ–ª–µ–π –ø—Ä–æ–≥–Ω–æ–∑—É–≤–∞–Ω–Ω—è –∑ –¥–æ–¥–∞—Ç–∫–æ–≤–∏–º–∏ MAE —Ç–∞ MAPE –º–µ—Ç—Ä–∏–∫–∞–º–∏"""
    
    # –í–∏—Ç—è–≥—É—î–º–æ –¥–∞–Ω—ñ –¥–ª—è –ø–æ—Ä—ñ–≤–Ω—è–Ω–Ω—è
    y_true = analysis_data.get('y_true_seq', [])
    y_pred = analysis_data.get('y_pred_seq', [])
    
    if not y_true or not y_pred:
        # Fallback: –≤–∏–∫–æ—Ä–∏—Å—Ç–æ–≤—É—î–º–æ EKF —ñ–Ω–Ω–æ–≤–∞—Ü—ñ—ó —è–∫ –ø—Ä–æ–∫—Å—ñ –¥–ª—è –ø–æ–º–∏–ª–æ–∫ –º–æ–¥–µ–ª—ñ
        print("‚ö†Ô∏è –ü—Ä—è–º—ñ –¥–∞–Ω—ñ –º–æ–¥–µ–ª—ñ –Ω–µ–¥–æ—Å—Ç—É–ø–Ω—ñ, –≤–∏–∫–æ—Ä–∏—Å—Ç–æ–≤—É—î–º–æ EKF —ñ–Ω–Ω–æ–≤–∞—Ü—ñ—ó")
        innovations = analysis_data.get('innov', np.array([]))
        
        if len(innovations) > 0:
            # –í–∏–∫–æ—Ä–∏—Å—Ç–æ–≤—É—î–º–æ —ñ–Ω–Ω–æ–≤–∞—Ü—ñ—ó —è–∫ –æ—Ü—ñ–Ω–∫—É –ø–æ–º–∏–ª–∫–∏ –º–æ–¥–µ–ª—ñ
            rmse_fe = np.sqrt(np.mean(innovations[:, 0]**2))
            rmse_mass = np.sqrt(np.mean(innovations[:, 1]**2))
            
            # ‚úÖ –ù–û–í–ò–ô: MAE –∑ —ñ–Ω–Ω–æ–≤–∞—Ü—ñ–π
            mae_fe = np.mean(np.abs(innovations[:, 0]))
            mae_mass = np.mean(np.abs(innovations[:, 1]))
            
            # –û—Ü—ñ–Ω—é—î–º–æ R¬≤ —á–µ—Ä–µ–∑ –¥–∏—Å–ø–µ—Ä—Å—ñ—é —ñ–Ω–Ω–æ–≤–∞—Ü—ñ–π
            fe_values = results_df['conc_fe'].values
            mass_values = results_df['conc_mass'].values
            
            r2_fe = max(0, 1 - np.var(innovations[:len(fe_values), 0]) / np.var(fe_values))
            r2_mass = max(0, 1 - np.var(innovations[:len(mass_values), 1]) / np.var(mass_values))
            
            bias_fe = np.mean(innovations[:, 0])
            bias_mass = np.mean(innovations[:, 1])
            
            # ‚úÖ –ù–û–í–ò–ô: MAPE –¥–ª—è —ñ–Ω–Ω–æ–≤–∞—Ü—ñ–π (–≤–∏–∫–æ—Ä–∏—Å—Ç–æ–≤—É—î–º–æ —Ñ–∞–∫—Ç–∏—á–Ω—ñ –∑–Ω–∞—á–µ–Ω–Ω—è —è–∫ –±–∞–∑—É)
            # –û–±—á–∏—Å–ª—é—î–º–æ –≤—ñ–¥–Ω–æ—Å–Ω—É –ø–æ–º–∏–ª–∫—É –ø–æ –≤—ñ–¥–Ω–æ—à–µ–Ω–Ω—é –¥–æ —Ä–µ–∞–ª—å–Ω–∏—Ö –∑–Ω–∞—á–µ–Ω—å
            min_len = min(len(innovations), len(fe_values), len(mass_values))
            if min_len > 0:
                mape_fe = calculate_mape(fe_values[:min_len], 
                                       fe_values[:min_len] - innovations[:min_len, 0])
                mape_mass = calculate_mape(mass_values[:min_len], 
                                         mass_values[:min_len] - innovations[:min_len, 1])
            else:
                mape_fe = mape_mass = 0.0
        else:
            # –Ø–∫—â–æ –≤–∑–∞–≥–∞–ª—ñ –Ω–µ–º–∞ –¥–∞–Ω–∏—Ö
            rmse_fe = rmse_mass = mae_fe = mae_mass = mape_fe = mape_mass = 0.0
            r2_fe = r2_mass = 0.0
            bias_fe = bias_mass = 0.0
    else:
        # –û—Å–Ω–æ–≤–Ω–∏–π —à–ª—è—Ö: —î –¥–∞–Ω—ñ –ø–µ—Ä–µ–¥–±–∞—á–µ–Ω—å
        y_true = np.array(y_true)
        y_pred = np.array(y_pred)
        
        # –û–±—Ä—ñ–∑–∞—î–º–æ –¥–æ –æ–¥–Ω–∞–∫–æ–≤–æ—ó –¥–æ–≤–∂–∏–Ω–∏
        min_len = min(len(y_true), len(y_pred))
        y_true = y_true[:min_len]
        y_pred = y_pred[:min_len]
        
        # –†–æ–∑—Ä–∞—Ö—É–Ω–∫–∏ –¥–ª—è Fe (–∫–æ–ª–æ–Ω–∫–∞ 0)
        rmse_fe = np.sqrt(mean_squared_error(y_true[:, 0], y_pred[:, 0]))
        r2_fe = r2_score(y_true[:, 0], y_pred[:, 0])
        bias_fe = np.mean(y_pred[:, 0] - y_true[:, 0])
        mae_fe = calculate_mae(y_true[:, 0], y_pred[:, 0])              # ‚úÖ –ù–û–í–ò–ô
        mape_fe = calculate_mape(y_true[:, 0], y_pred[:, 0])            # ‚úÖ –ù–û–í–ò–ô
        
        # –†–æ–∑—Ä–∞—Ö—É–Ω–∫–∏ –¥–ª—è Mass (–∫–æ–ª–æ–Ω–∫–∞ 1)
        rmse_mass = np.sqrt(mean_squared_error(y_true[:, 1], y_pred[:, 1]))
        r2_mass = r2_score(y_true[:, 1], y_pred[:, 1])
        bias_mass = np.mean(y_pred[:, 1] - y_true[:, 1])
        mae_mass = calculate_mae(y_true[:, 1], y_pred[:, 1])            # ‚úÖ –ù–û–í–ò–ô
        mape_mass = calculate_mape(y_true[:, 1], y_pred[:, 1])          # ‚úÖ –ù–û–í–ò–ô
    
    return {
        # –Ü—Å–Ω—É—é—á—ñ –º–µ—Ç—Ä–∏–∫–∏
        'model_rmse_fe': rmse_fe,
        'model_rmse_mass': rmse_mass,
        'model_r2_fe': r2_fe,
        'model_r2_mass': r2_mass,
        'model_bias_fe': bias_fe,
        'model_bias_mass': bias_mass,
        
        # ‚úÖ –ù–û–í–Ü –ú–ï–¢–†–ò–ö–ò
        'model_mae_fe': mae_fe,
        'model_mae_mass': mae_mass,
        'model_mape_fe': mape_fe,
        'model_mape_mass': mape_mass
    }

# =============================================================================
# === –§–£–ù–ö–¶–Ü–á –û–¶–Ü–ù–Æ–í–ê–ù–ù–Ø –ö–ï–†–£–í–ê–ù–ù–Ø ===
# =============================================================================

def evaluate_control_performance(results_df: pd.DataFrame, params: Dict) -> Dict[str, float]:
    """–û—Ü—ñ–Ω—é—î —è–∫—ñ—Å—Ç—å —Ä–æ–±–æ—Ç–∏ —Å–∏—Å—Ç–µ–º–∏ –∫–µ—Ä—É–≤–∞–Ω–Ω—è –∑ –¥–æ–¥–∞—Ç–∫–æ–≤–∏–º–∏ MAE —Ç–∞ MAPE –º–µ—Ç—Ä–∏–∫–∞–º–∏"""
    
    # –£—Å—Ç–∞–≤–∫–∏
    ref_fe = params.get('ref_fe', 53.5)
    ref_mass = params.get('ref_mass', 57.0)
    
    # –ù–∞—Å—Ç—Ä–æ—é–≤–∞–Ω—ñ —Ç–æ–ª–µ—Ä–∞–Ω—Ç–Ω–æ—Å—Ç—ñ
    tolerance_fe_percent = params.get('tolerance_fe_percent', 2.0)    
    tolerance_mass_percent = params.get('tolerance_mass_percent', 2.0) 
    
    # –§–∞–∫—Ç–∏—á–Ω—ñ –∑–Ω–∞—á–µ–Ω–Ω—è
    fe_values = results_df['conc_fe'].values
    mass_values = results_df['conc_mass'].values
    control_values = results_df['solid_feed_percent'].values
    
    # –ü–æ–º–∏–ª–∫–∏ –≤—ñ–¥—Å—Ç–µ–∂–µ–Ω–Ω—è
    error_fe = fe_values - ref_fe
    error_mass = mass_values - ref_mass
    
    # ========== –Ü–°–ù–£–Æ–ß–Ü –ú–ï–¢–†–ò–ö–ò ==========
    
    # 1. –ü–æ–º–∏–ª–∫–∏ –≤—ñ–¥—Å—Ç–µ–∂–µ–Ω–Ω—è (RMSE –≤—ñ–¥ —É—Å—Ç–∞–≤–∫–∏)
    tracking_error_fe = np.sqrt(np.mean(error_fe**2))
    tracking_error_mass = np.sqrt(np.mean(error_mass**2))
    
    # 2. ISE (Integral of Squared Error)
    ise_fe = np.sum(error_fe**2)
    ise_mass = np.sum(error_mass**2)
    
    # 3. IAE (Integral of Absolute Error)
    iae_fe = np.sum(np.abs(error_fe))
    iae_mass = np.sum(np.abs(error_mass))
    
    # ========== –ù–û–í–Ü –ú–ï–¢–†–ò–ö–ò ==========
    
    # 4. ‚úÖ MAE –¥–ª—è –≤—ñ–¥—Å—Ç–µ–∂–µ–Ω–Ω—è —É—Å—Ç–∞–≤–æ–∫
    tracking_mae_fe = calculate_mae(np.full_like(fe_values, ref_fe), fe_values)
    tracking_mae_mass = calculate_mae(np.full_like(mass_values, ref_mass), mass_values)
    
    # 5. ‚úÖ MAPE –¥–ª—è –≤—ñ–¥—Å—Ç–µ–∂–µ–Ω–Ω—è —É—Å—Ç–∞–≤–æ–∫
    tracking_mape_fe = calculate_mape(np.full_like(fe_values, ref_fe), fe_values)
    tracking_mape_mass = calculate_mape(np.full_like(mass_values, ref_mass), mass_values)
    
    # ========== –†–ï–®–¢–ê –Ü–°–ù–£–Æ–ß–ò–• –ú–ï–¢–†–ò–ö ==========
    
    # 6. –ó–≥–ª–∞–¥–∂–µ–Ω—ñ—Å—Ç—å –∫–µ—Ä—É–≤–∞–Ω–Ω—è
    control_changes = np.diff(control_values)
    control_smoothness = 1 / (1 + np.std(control_changes))
    
    # 7. –î–æ—Å—è–≥–Ω–µ–Ω–Ω—è —É—Å—Ç–∞–≤–æ–∫ –∑ –Ω–∞—Å—Ç—Ä–æ—é–≤–∞–Ω–∏–º–∏ —Ç–æ–ª–µ—Ä–∞–Ω—Ç–Ω–æ—Å—Ç—è–º–∏
    tolerance_fe = (tolerance_fe_percent / 100.0) * abs(ref_fe)
    tolerance_mass = (tolerance_mass_percent / 100.0) * abs(ref_mass)
    
    setpoint_achievement_fe = calculate_setpoint_achievement(fe_values, ref_fe, tolerance_fe)
    setpoint_achievement_mass = calculate_setpoint_achievement(mass_values, ref_mass, tolerance_mass)
    
    delta_u_max = params.get('delta_u_max', 1.0)
    aggressiveness_metrics = calculate_control_aggressiveness_metrics(control_values, delta_u_max)
    
    return {
        # –Ü—Å–Ω—É—é—á—ñ –º–µ—Ç—Ä–∏–∫–∏
        'tracking_error_fe': tracking_error_fe,
        'tracking_error_mass': tracking_error_mass,
        'ise_fe': ise_fe,
        'ise_mass': ise_mass,
        'iae_fe': iae_fe,
        'iae_mass': iae_mass,
        'control_smoothness': control_smoothness,
        'setpoint_achievement_fe': setpoint_achievement_fe,
        'setpoint_achievement_mass': setpoint_achievement_mass,
        
        # ‚úÖ –ù–û–í–Ü –ú–ï–¢–†–ò–ö–ò
        'tracking_mae_fe': tracking_mae_fe,
        'tracking_mae_mass': tracking_mae_mass,
        'tracking_mape_fe': tracking_mape_fe,
        'tracking_mape_mass': tracking_mape_mass,
        
        # –ê–≥—Ä–µ—Å–∏–≤–Ω—ñ—Å—Ç—å –∫–µ—Ä—É–≤–∞–Ω–Ω—è (–±–µ–∑ –∑–º—ñ–Ω)
        **aggressiveness_metrics
    }

# evaluation_simple.py - –ù–æ–≤–∏–π –¥—ñ–∞–≥–Ω–æ—Å—Ç–∏—á–Ω–∏–π –º–µ—Ç–æ–¥

def diagnose_analysis_data(analysis_data: Dict) -> None:
    """
    –î—ñ–∞–≥–Ω–æ—Å—Ç—É—î —Å—Ç–∞–Ω analysis_data –¥–ª—è –≤–∏—è–≤–ª–µ–Ω–Ω—è –≤—ñ–¥—Å—É—Ç–Ω—ñ—Ö –∫–æ–º–ø–æ–Ω–µ–Ω—Ç—ñ–≤ –≤—ñ–∑—É–∞–ª—ñ–∑–∞—Ü—ñ—ó
    
    Args:
        analysis_data: –°–ª–æ–≤–Ω–∏–∫ –∑ –¥–∞–Ω–∏–º–∏ –∞–Ω–∞–ª—ñ–∑—É —Å–∏–º—É–ª—è—Ü—ñ—ó
    """
    print("\nüîç –î–Ü–ê–ì–ù–û–°–¢–ò–ö–ê ANALYSIS_DATA:")
    print("=" * 40)
    
    required_keys = [
        'y_true_seq', 'y_pred_seq', 'x_est_seq', 'innovation_seq',
        'trust_region_stats', 'timing_metrics', 'd_hat', 'u_seq'
    ]
    
    missing_keys = []
    empty_keys = []
    
    for key in required_keys:
        if key in analysis_data:
            data = analysis_data[key]
            if isinstance(data, (list, np.ndarray)):
                if len(data) == 0:
                    status = "‚ö†Ô∏è –ü–æ—Ä–æ–∂–Ω—ñ–π –º–∞—Å–∏–≤/—Å–ø–∏—Å–æ–∫"
                    empty_keys.append(key)
                else:
                    status = f"‚úÖ –î–æ—Å—Ç—É–ø–Ω–æ ({len(data)} –µ–ª–µ–º–µ–Ω—Ç—ñ–≤)"
                    
                    # –î–æ–¥–∞—Ç–∫–æ–≤–∞ –ø–µ—Ä–µ–≤—ñ—Ä–∫–∞ —Å—Ç—Ä—É–∫—Ç—É—Ä–∏ –¥–ª—è –∫—Ä–∏—Ç–∏—á–Ω–∏—Ö –∫–æ–º–ø–æ–Ω–µ–Ω—Ç—ñ–≤
                    if key == 'innovation_seq' and len(data) > 0:
                        try:
                            arr = np.array(data)
                            status += f" shape={arr.shape}"
                        except:
                            status += " (—Å—Ç—Ä—É–∫—Ç—É—Ä–∞ –ø–æ—à–∫–æ–¥–∂–µ–Ω–∞)"
                            
            elif isinstance(data, dict):
                if len(data) == 0:
                    status = "‚ö†Ô∏è –ü–æ—Ä–æ–∂–Ω—ñ–π —Å–ª–æ–≤–Ω–∏–∫"
                    empty_keys.append(key)
                else:
                    status = f"‚úÖ –°–ª–æ–≤–Ω–∏–∫ ({len(data)} –∫–ª—é—á—ñ–≤)"
            else:
                status = f"‚úÖ –¢–∏–ø: {type(data).__name__}"
        else:
            status = "‚ùå –í—ñ–¥—Å—É—Ç–Ω—ñ–π"
            missing_keys.append(key)
        
        print(f"   {key}: {status}")
    
    # –î–µ—Ç–∞–ª—å–Ω–∞ –¥—ñ–∞–≥–Ω–æ—Å—Ç–∏–∫–∞ –∫—Ä–∏—Ç–∏—á–Ω–∏—Ö –∫–æ–º–ø–æ–Ω–µ–Ω—Ç—ñ–≤
    print(f"\nüî¨ –î–ï–¢–ê–õ–¨–ù–ê –î–Ü–ê–ì–ù–û–°–¢–ò–ö–ê:")
    
    # Trust Region
    if 'trust_region_stats' in analysis_data and analysis_data['trust_region_stats']:
        stats = analysis_data['trust_region_stats']
        sample = stats[0] if len(stats) > 0 else None
        if sample:
            if isinstance(sample, dict):
                keys = list(sample.keys())
                print(f"   üìä Trust Region –∑—Ä–∞–∑–æ–∫: dict –∑ –∫–ª—é—á–∞–º–∏ {keys}")
            else:
                print(f"   üìä Trust Region –∑—Ä–∞–∑–æ–∫: {type(sample).__name__} = {sample}")
        else:
            print(f"   üìä Trust Region: —Å–ø–∏—Å–æ–∫ –ø–æ—Ä–æ–∂–Ω—ñ–π")
    
    # Innovation sequence
    if 'innovation_seq' in analysis_data and analysis_data['innovation_seq']:
        innov = analysis_data['innovation_seq']
        if len(innov) > 0:
            try:
                arr = np.array(innov)
                print(f"   üßÆ Innovation: {arr.shape}, dtype={arr.dtype}")
                if arr.ndim == 2:
                    print(f"        –ó—Ä–∞–∑–æ–∫: [{arr[0, 0]:.3f}, {arr[0, 1]:.3f}]")
                else:
                    print(f"        ‚ö†Ô∏è –ù–µ–æ—á—ñ–∫—É–≤–∞–Ω–∞ —Ä–æ–∑–º—ñ—Ä–Ω—ñ—Å—Ç—å: {arr.ndim}")
            except Exception as e:
                print(f"   üßÆ Innovation: –ø–æ–º–∏–ª–∫–∞ –∫–æ–Ω–≤–µ—Ä—Ç–∞—Ü—ñ—ó - {e}")
    
    # Disturbance estimates
    if 'd_hat' in analysis_data and len(analysis_data['d_hat']) > 0:
        d_hat = analysis_data['d_hat']
        if isinstance(d_hat, np.ndarray):
            print(f"   üéØ D_hat: {d_hat.shape}, range=[{d_hat.min():.3f}, {d_hat.max():.3f}]")
        else:
            print(f"   üéØ D_hat: —Ç–∏–ø {type(d_hat).__name__}, len={len(d_hat)}")
    
    # U sequence (MPC plans)
    if 'u_seq' in analysis_data and analysis_data['u_seq']:
        u_seq = analysis_data['u_seq']
        non_empty_plans = sum(1 for plan in u_seq if plan is not None and len(plan) > 0)
        print(f"   üéÆ U_seq: {len(u_seq)} –ø–ª–∞–Ω—ñ–≤, {non_empty_plans} –Ω–µ–ø–æ—Ä–æ–∂–Ω—ñ—Ö")
    
    # –ü—ñ–¥—Å—É–º–æ–∫
    print(f"\nüìã –ü–Ü–î–°–£–ú–û–ö:")
    if missing_keys:
        print(f"   ‚ùå –í—ñ–¥—Å—É—Ç–Ω—ñ –∫–ª—é—á—ñ: {', '.join(missing_keys)}")
    if empty_keys:
        print(f"   ‚ö†Ô∏è –ü–æ—Ä–æ–∂–Ω—ñ —Å—Ç—Ä—É–∫—Ç—É—Ä–∏: {', '.join(empty_keys)}")
    
    if not missing_keys and not empty_keys:
        print(f"   ‚úÖ –í—Å—ñ –¥–∞–Ω—ñ –¥–æ—Å—Ç—É–ø–Ω—ñ —Ç–∞ –∑–∞–ø–æ–≤–Ω–µ–Ω—ñ")
    
    # –†–µ–∫–æ–º–µ–Ω–¥–∞—Ü—ñ—ó
    print(f"\nüí° –†–ï–ö–û–ú–ï–ù–î–ê–¶–Ü–á:")
    if 'trust_region_stats' in missing_keys or 'trust_region_stats' in empty_keys:
        print(f"   üîß –î–æ–¥–∞–π—Ç–µ –∑–±—ñ—Ä Trust Region —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏ –≤ MPC —Ü–∏–∫–ª")
    if 'innovation_seq' in missing_keys or 'innovation_seq' in empty_keys:
        print(f"   üîß –ü–µ—Ä–µ–≤—ñ—Ä—Ç–µ –∑–±–µ—Ä–µ–∂–µ–Ω–Ω—è EKF —ñ–Ω–Ω–æ–≤–∞—Ü—ñ–π")
    if 'd_hat' in missing_keys or 'd_hat' in empty_keys:
        print(f"   üîß –ê–∫—Ç–∏–≤—É–π—Ç–µ –∑–±–µ—Ä–µ–∂–µ–Ω–Ω—è –æ—Ü—ñ–Ω–æ–∫ –∑–±—É—Ä–µ–Ω—å")
    if 'u_seq' in missing_keys or 'u_seq' in empty_keys:
        print(f"   üîß –î–æ–¥–∞–π—Ç–µ –∑–±–µ—Ä–µ–∂–µ–Ω–Ω—è MPC –ø–ª–∞–Ω—ñ–≤")
        
# =============================================================================
# === –§–£–ù–ö–¶–Ü–á –î–õ–Ø EKF –ú–ï–¢–†–ò–ö ===
# =============================================================================

def calculate_ekf_metrics(analysis_data: Dict) -> Dict[str, float]:
    """
    –†–æ–∑—Ä–∞—Ö–æ–≤—É—î –º–µ—Ç—Ä–∏–∫–∏ –µ—Ñ–µ–∫—Ç–∏–≤–Ω–æ—Å—Ç—ñ Extended Kalman Filter
    
    Args:
        analysis_data: –°–ª–æ–≤–Ω–∏–∫ –∑ –¥–∞–Ω–∏–º–∏ —Å–∏–º—É–ª—è—Ü—ñ—ó –≤–∫–ª—é—á–∞—é—á–∏ EKF –¥–∞–Ω—ñ
        
    Returns:
        –°–ª–æ–≤–Ω–∏–∫ –∑ EKF –º–µ—Ç—Ä–∏–∫–∞–º–∏
    """
    
    # –í–∏—Ç—è–≥—É—î–º–æ –¥–∞–Ω—ñ EKF
    y_true_seq = analysis_data.get('y_true_seq', [])
    y_pred_seq = analysis_data.get('y_pred_seq', [])
    x_est_seq = analysis_data.get('x_est_seq', [])
    innovation_seq = analysis_data.get('innovation_seq', [])
    
    # –ü–µ—Ä–µ–≤—ñ—Ä—è—î–º–æ –Ω–∞—è–≤–Ω—ñ—Å—Ç—å –¥–∞–Ω–∏—Ö
    if not y_true_seq or not y_pred_seq:
        print("‚ö†Ô∏è EKF –¥–∞–Ω—ñ –Ω–µ–¥–æ—Å—Ç—É–ø–Ω—ñ, –≤–∏–∫–æ—Ä–∏—Å—Ç–æ–≤—É—î–º–æ –Ω—É–ª—å–æ–≤—ñ –∑–Ω–∞—á–µ–Ω–Ω—è")
        return {
            'ekf_rmse_fe': 0.0,
            'ekf_rmse_mass': 0.0,
            'ekf_normalized_rmse_fe': 0.0,
            'ekf_normalized_rmse_mass': 0.0,
            'ekf_rmse_total': 0.0,
            'ekf_nees_mean': 0.0,
            'ekf_nis_mean': 0.0,
            'ekf_consistency': 0.0
        }
    
    # –ö–æ–Ω–≤–µ—Ä—Ç—É—î–º–æ —É numpy –º–∞—Å–∏–≤–∏
    y_true = np.array(y_true_seq)
    y_pred = np.array(y_pred_seq)
    
    # –û–±—Ä—ñ–∑—É—î–º–æ –¥–æ –æ–¥–Ω–∞–∫–æ–≤–æ—ó –¥–æ–≤–∂–∏–Ω–∏
    min_len = min(len(y_true), len(y_pred))
    y_true = y_true[:min_len]
    y_pred = y_pred[:min_len]
    
    # 1. RMSE –¥–ª—è –∫–æ–∂–Ω–æ–≥–æ —Å—Ç–∞–Ω—É (Fe —Ç–∞ Mass)
    ekf_rmse_fe = np.sqrt(np.mean((y_true[:, 0] - y_pred[:, 0])**2))
    ekf_rmse_mass = np.sqrt(np.mean((y_true[:, 1] - y_pred[:, 1])**2))
    
    # 2. –ù–æ—Ä–º–∞–ª—ñ–∑–æ–≤–∞–Ω–∏–π RMSE (–≤—ñ–¥–Ω–æ—Å–Ω–æ —Å–µ—Ä–µ–¥–Ω—å–æ–≥–æ –∑–Ω–∞—á–µ–Ω–Ω—è)
    ekf_normalized_rmse_fe = (ekf_rmse_fe / np.mean(np.abs(y_true[:, 0]))) * 100
    ekf_normalized_rmse_mass = (ekf_rmse_mass / np.mean(np.abs(y_true[:, 1]))) * 100
    
    # 3. –ó–∞–≥–∞–ª—å–Ω–∏–π RMSE
    ekf_rmse_total = np.sqrt(np.mean((y_true - y_pred)**2))
    
    # 4. NEES —Ç–∞ NIS (—Å–ø—Ä–æ—â–µ–Ω—ñ —Ä–æ–∑—Ä–∞—Ö—É–Ω–∫–∏)
    # –£ —Ä–µ–∞–ª—å–Ω—ñ–π —Ä–µ–∞–ª—ñ–∑–∞—Ü—ñ—ó –ø–æ—Ç—Ä—ñ–±–Ω—ñ –º–∞—Ç—Ä–∏—Ü—ñ –∫–æ–≤–∞—Ä—ñ–∞—Ü—ñ—ó P
    innovations = np.array(innovation_seq[:min_len]) if innovation_seq else np.zeros((min_len, 2))
    
    # –°–ø—Ä–æ—â–µ–Ω–∏–π NEES (Normalized Estimation Error Squared)
    if len(innovations) > 0:
        ekf_nees_mean = np.mean(np.sum(innovations**2, axis=1))
    else:
        ekf_nees_mean = 0.0
    
    # –°–ø—Ä–æ—â–µ–Ω–∏–π NIS (Normalized Innovation Squared) 
    if len(innovations) > 0:
        ekf_nis_mean = np.mean(np.sum(innovations**2, axis=1))
    else:
        ekf_nis_mean = 0.0
    
    # 5. –ó–∞–≥–∞–ª—å–Ω–∞ –∫–æ–Ω—Å–∏—Å—Ç–µ–Ω—Ç–Ω—ñ—Å—Ç—å EKF (–∫–æ–º–±—ñ–Ω–æ–≤–∞–Ω–∞ –º–µ—Ç—Ä–∏–∫–∞ 0-1)
    # –Ü–¥–µ–∞–ª—å–Ω—ñ –∑–Ω–∞—á–µ–Ω–Ω—è: NEES ‚âà 2, NIS ‚âà 2
    nees_consistency = max(0, 1 - abs(ekf_nees_mean - 2) / 2)
    nis_consistency = max(0, 1 - abs(ekf_nis_mean - 2) / 2)
    ekf_consistency = (nees_consistency + nis_consistency) / 2
    
    return {
        'ekf_rmse_fe': ekf_rmse_fe,
        'ekf_rmse_mass': ekf_rmse_mass,
        'ekf_normalized_rmse_fe': ekf_normalized_rmse_fe,
        'ekf_normalized_rmse_mass': ekf_normalized_rmse_mass,
        'ekf_rmse_total': ekf_rmse_total,
        'ekf_nees_mean': ekf_nees_mean,
        'ekf_nis_mean': ekf_nis_mean,
        'ekf_consistency': ekf_consistency
    }

# =============================================================================
# === –§–£–ù–ö–¶–Ü–á –î–õ–Ø TRUST REGION –ú–ï–¢–†–ò–ö ===
# =============================================================================

def calculate_trust_region_metrics(analysis_data: Dict) -> Dict[str, float]:
    """
    –†–æ–∑—Ä–∞—Ö–æ–≤—É—î –º–µ—Ç—Ä–∏–∫–∏ –µ—Ñ–µ–∫—Ç–∏–≤–Ω–æ—Å—Ç—ñ Trust Region –º–µ—Ö–∞–Ω—ñ–∑–º—É
    
    Args:
        analysis_data: –°–ª–æ–≤–Ω–∏–∫ –∑ –¥–∞–Ω–∏–º–∏ —Å–∏–º—É–ª—è—Ü—ñ—ó –≤–∫–ª—é—á–∞—é—á–∏ Trust Region —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É
        
    Returns:
        –°–ª–æ–≤–Ω–∏–∫ –∑ Trust Region –º–µ—Ç—Ä–∏–∫–∞–º–∏
    """
    
    # –í–∏—Ç—è–≥—É—î–º–æ –¥–∞–Ω—ñ Trust Region
    trust_region_stats = analysis_data.get('trust_region_stats', [])
    
    # –ü–µ—Ä–µ–≤—ñ—Ä—è—î–º–æ –Ω–∞—è–≤–Ω—ñ—Å—Ç—å –¥–∞–Ω–∏—Ö
    if not trust_region_stats:
        print("‚ö†Ô∏è Trust Region –¥–∞–Ω—ñ –Ω–µ–¥–æ—Å—Ç—É–ø–Ω—ñ, –≤–∏–∫–æ—Ä–∏—Å—Ç–æ–≤—É—î–º–æ –Ω—É–ª—å–æ–≤—ñ –∑–Ω–∞—á–µ–Ω–Ω—è")
        return {
            'trust_radius_mean': 0.0,
            'trust_radius_std': 0.0,
            'trust_radius_min': 0.0,
            'trust_radius_max': 0.0,
            'trust_adaptivity_coeff': 0.0,
            'trust_stability_index': 0.0
        }
    
    # –í–∏—Ç—è–≥—É—î–º–æ —Ä–∞–¥—ñ—É—Å–∏ –∑ –∫–æ–∂–Ω–æ–≥–æ –∫—Ä–æ–∫—É
    trust_radii = []
    radius_increases = 0
    radius_decreases = 0
    
    for stats in trust_region_stats:
        if isinstance(stats, dict) and 'current_radius' in stats:
            trust_radii.append(stats['current_radius'])
            
            # –ü—ñ–¥—Ä–∞—Ö—É–Ω–æ–∫ –∑–º—ñ–Ω —Ä–∞–¥—ñ—É—Å–∞ (—è–∫—â–æ –¥–æ—Å—Ç—É–ø–Ω–æ)
            if 'radius_increased' in stats and stats['radius_increased']:
                radius_increases += 1
            if 'radius_decreased' in stats and stats['radius_decreased']:
                radius_decreases += 1
        elif isinstance(stats, (int, float)):
            # –Ø–∫—â–æ stats —Ü–µ –ø—Ä–æ—Å—Ç–æ —á–∏—Å–ª–æ (—Ä–∞–¥—ñ—É—Å)
            trust_radii.append(float(stats))
    
    if not trust_radii:
        return {
            'trust_radius_mean': 0.0,
            'trust_radius_std': 0.0,
            'trust_radius_min': 0.0,
            'trust_radius_max': 0.0,
            'trust_adaptivity_coeff': 0.0,
            'trust_stability_index': 0.0
        }
    
    trust_radii = np.array(trust_radii)
    
    # 1. –ë–∞–∑–æ–≤–∞ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ —Ä–∞–¥—ñ—É—Å–∞
    trust_radius_mean = float(np.mean(trust_radii))
    trust_radius_std = float(np.std(trust_radii))
    trust_radius_min = float(np.min(trust_radii))
    trust_radius_max = float(np.max(trust_radii))
    
    # 2. –ö–æ–µ—Ñ—ñ—Ü—ñ—î–Ω—Ç –∞–¥–∞–ø—Ç–∏–≤–Ω–æ—Å—Ç—ñ (–Ω–∞—Å–∫—ñ–ª—å–∫–∏ –∞–∫—Ç–∏–≤–Ω–æ –∑–º—ñ–Ω—é—î—Ç—å—Å—è —Ä–∞–¥—ñ—É—Å)
    total_changes = radius_increases + radius_decreases
    if len(trust_radii) > 0:
        trust_adaptivity_coeff = total_changes / len(trust_radii)
    else:
        trust_adaptivity_coeff = 0.0
    
    # 3. –Ü–Ω–¥–µ–∫—Å —Å—Ç–∞–±—ñ–ª—å–Ω–æ—Å—Ç—ñ Trust Region (–æ–±–µ—Ä–Ω–µ–Ω–∏–π –¥–æ –∫–æ–µ—Ñ—ñ—Ü—ñ—î–Ω—Ç–∞ –≤–∞—Ä—ñ–∞—Ü—ñ—ó)
    if trust_radius_mean > 0:
        cv = trust_radius_std / trust_radius_mean
        trust_stability_index = 1 / (1 + cv)
    else:
        trust_stability_index = 0.0
    
    return {
        'trust_radius_mean': trust_radius_mean,
        'trust_radius_std': trust_radius_std,
        'trust_radius_min': trust_radius_min,
        'trust_radius_max': trust_radius_max,
        'trust_adaptivity_coeff': trust_adaptivity_coeff,
        'trust_stability_index': trust_stability_index
    }

def calculate_control_aggressiveness_metrics(control_values: np.ndarray, 
                                           delta_u_max: float) -> Dict[str, float]:
    """
    –†–æ–∑—Ä–∞—Ö–æ–≤—É—î –º–µ—Ç—Ä–∏–∫–∏ –∞–≥—Ä–µ—Å–∏–≤–Ω–æ—Å—Ç—ñ –∫–µ—Ä—É–≤–∞–Ω–Ω—è –Ω–∞ –æ—Å–Ω–æ–≤—ñ –≤–∞—à–æ–≥–æ –ø—Ä–∏–∫–ª–∞–¥—É
    """
    
    # –û–±—á–∏—Å–ª—é—î–º–æ –∑–º—ñ–Ω–∏ –∫–µ—Ä—É–≤–∞–Ω–Ω—è
    delta_u = np.diff(control_values)
    abs_delta_u = np.abs(delta_u)
    nonzero_delta_u = abs_delta_u[abs_delta_u > 1e-8]
    
    # 1. –û—Å–Ω–æ–≤–Ω—ñ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏
    mean_delta_u = np.mean(abs_delta_u) if len(abs_delta_u) > 0 else 0.0
    std_delta_u = np.std(delta_u) if len(delta_u) > 0 else 0.0
    max_abs_delta_u = np.max(abs_delta_u) if len(abs_delta_u) > 0 else 0.0
    mean_abs_nonzero_delta_u = np.mean(nonzero_delta_u) if len(nonzero_delta_u) > 0 else 0.0
    
    # 2. –ï–Ω–µ—Ä–≥—ñ—è –∫–µ—Ä—É–≤–∞–Ω–Ω—è
    energy_u = np.sum(delta_u**2)
    
    # 3. –ó–Ω–∞—á–Ω—ñ –∑–º—ñ–Ω–∏ (> 50% –≤—ñ–¥ max)
    significant_threshold = 0.5 * delta_u_max
    significant_magnitude_changes_count = np.sum(abs_delta_u > significant_threshold)
    significant_magnitude_changes_frequency = significant_magnitude_changes_count / len(delta_u) if len(delta_u) > 0 else 0.0
    
    # 4. –ó–º—ñ–Ω–∏ –Ω–∞–ø—Ä—è–º–∫—É
    directional_switch_count = 0
    for i in range(1, len(delta_u)):
        if np.sign(delta_u[i]) != np.sign(delta_u[i-1]) and abs(delta_u[i]) > 1e-8 and abs(delta_u[i-1]) > 1e-8:
            directional_switch_count += 1
    
    directional_switch_frequency = directional_switch_count / len(delta_u) if len(delta_u) > 0 else 0.0
    
    # 5. –í–∏–∫–æ—Ä–∏—Å—Ç–∞–Ω–Ω—è –º–∞–∫—Å–∏–º—É–º—É
    percentage_of_max_delta_u_used = (mean_delta_u / delta_u_max * 100) if delta_u_max > 0 else 0.0
    num_steps_at_delta_u_max = np.sum(abs_delta_u >= 0.95 * delta_u_max)
    
    return {
        'control_aggressiveness': mean_abs_nonzero_delta_u,  # –í–∏–∫–æ—Ä–∏—Å—Ç–æ–≤—É—î–º–æ nonzero —è–∫ —É –≤–∞—Å
        'control_variability': std_delta_u,
        'control_energy': energy_u,
        'control_stability_index': 1.0 - directional_switch_frequency,
        'control_utilization': percentage_of_max_delta_u_used,
        'significant_changes_frequency': significant_magnitude_changes_frequency,
        'significant_changes_count': float(significant_magnitude_changes_count),
        'max_control_change': max_abs_delta_u,
        'directional_switches_per_step': directional_switch_frequency,
        'directional_switches_count': float(directional_switch_count),
        'steps_at_max_delta_u': float(num_steps_at_delta_u_max)
    }

# =============================================================================
# === –ù–û–í–Ü –§–£–ù–ö–¶–Ü–á –î–õ–Ø –ß–ê–°–û–í–ò–• –ú–ï–¢–†–ò–ö ===
# =============================================================================

def extract_timing_metrics(analysis_data: Dict) -> Dict[str, float]:
    """
    –†–æ–∑—à–∏—Ä–µ–Ω–∞ —Ñ—É–Ω–∫—Ü—ñ—è –¥–ª—è –≤–∏—Ç—è–≥—É–≤–∞–Ω–Ω—è –≤—Å—ñ—Ö –º–µ—Ç—Ä–∏–∫ –≤–∫–ª—é—á–∞—é—á–∏ EKF —Ç–∞ Trust Region
    
    Args:
        analysis_data: –°–ª–æ–≤–Ω–∏–∫ –∑ –¥–∞–Ω–∏–º–∏ —Å–∏–º—É–ª—è—Ü—ñ—ó
        
    Returns:
        –°–ª–æ–≤–Ω–∏–∫ –∑ —É—Å—ñ–º–∞ –¥–æ–¥–∞—Ç–∫–æ–≤–∏–º–∏ –º–µ—Ç—Ä–∏–∫–∞–º–∏ (—á–∞—Å–æ–≤—ñ + EKF + Trust Region)
    """
    
    # ‚úÖ –í–ò–ü–†–ê–í–õ–ï–ù–ù–Ø: –ü—Ä–∏–±–∏—Ä–∞—î–º–æ —Ä–µ–∫—É—Ä—Å–∏–≤–Ω–∏–π –≤–∏–∫–ª–∏–∫!
    # –°–ø–æ—á–∞—Ç–∫—É –æ–±—á–∏—Å–ª—é—î–º–æ –±–∞–∑–æ–≤—ñ —á–∞—Å–æ–≤—ñ –º–µ—Ç—Ä–∏–∫–∏
    timing_data = analysis_data.get('timing_metrics', {})
    
    # –ü–æ—á–∞—Ç–∫–æ–≤–µ –Ω–∞–≤—á–∞–Ω–Ω—è
    initial_training_time = timing_data.get('initial_training_time', 0.0)
    
    # –ü–µ—Ä–µ–Ω–∞–≤—á–∞–Ω–Ω—è
    retraining_times = timing_data.get('retraining_times', [])
    avg_retraining_time = np.mean(retraining_times) if retraining_times else 0.0
    total_retraining_count = len(retraining_times)
    
    # –ü—Ä–æ–≥–Ω–æ–∑—É–≤–∞–Ω–Ω—è  
    prediction_times = timing_data.get('prediction_times', [])
    # –ö–æ–Ω–≤–µ—Ä—Ç—É—î–º–æ –≤ –º—ñ–ª—ñ—Å–µ–∫—É–Ω–¥–∏ –¥–ª—è –∫—Ä–∞—â–æ—ó —á–∏—Ç–∞–±–µ–ª—å–Ω–æ—Å—Ç—ñ
    avg_prediction_time = np.mean(prediction_times) * 1000 if prediction_times else 0.0
    
    # –ù–æ–≤—ñ EKF –º–µ—Ç—Ä–∏–∫–∏
    ekf_metrics = calculate_ekf_metrics(analysis_data)
    
    # –ù–æ–≤—ñ Trust Region –º–µ—Ç—Ä–∏–∫–∏
    trust_metrics = calculate_trust_region_metrics(analysis_data)
    
    # –û–±'—î–¥–Ω—É—î–º–æ –≤—Å—ñ –º–µ—Ç—Ä–∏–∫–∏
    all_metrics = {
        'initial_training_time': initial_training_time,
        'avg_retraining_time': avg_retraining_time,
        'avg_prediction_time': avg_prediction_time,
        'total_retraining_count': float(total_retraining_count)
    }
    all_metrics.update(ekf_metrics)
    all_metrics.update(trust_metrics)
    
    return all_metrics

def calculate_mae(y_true: np.ndarray, y_pred: np.ndarray) -> float:
    """–†–æ–∑—Ä–∞—Ö–æ–≤—É—î Mean Absolute Error"""
    return np.mean(np.abs(y_true - y_pred))

def calculate_mape(y_true: np.ndarray, y_pred: np.ndarray, epsilon: float = 1e-8) -> float:
    """
    –†–æ–∑—Ä–∞—Ö–æ–≤—É—î Mean Absolute Percentage Error
    
    Args:
        y_true: –°–ø—Ä–∞–≤–∂–Ω—ñ –∑–Ω–∞—á–µ–Ω–Ω—è
        y_pred: –ü–µ—Ä–µ–¥–±–∞—á–µ–Ω—ñ –∑–Ω–∞—á–µ–Ω–Ω—è
        epsilon: –ú–∞–ª–∞ –∫–æ–Ω—Å—Ç–∞–Ω—Ç–∞ –¥–ª—è —É–Ω–∏–∫–Ω–µ–Ω–Ω—è –¥—ñ–ª–µ–Ω–Ω—è –Ω–∞ –Ω—É–ª—å
        
    Returns:
        MAPE —É –≤—ñ–¥—Å–æ—Ç–∫–∞—Ö
    """
    # –£–Ω–∏–∫–∞—î–º–æ –¥—ñ–ª–µ–Ω–Ω—è –Ω–∞ –Ω—É–ª—å, –¥–æ–¥–∞—é—á–∏ epsilon
    denominator = np.maximum(np.abs(y_true), epsilon)
    mape = np.mean(np.abs((y_true - y_pred) / denominator)) * 100.0
    return mape

def calculate_setpoint_achievement(values: np.ndarray, setpoint: float, tolerance: float) -> float:
    """–†–æ–∑—Ä–∞—Ö–æ–≤—É—î –≤—ñ–¥—Å–æ—Ç–æ–∫ —á–∞—Å—É, –∫–æ–ª–∏ –∑–Ω–∞—á–µ–Ω–Ω—è –≤ –º–µ–∂–∞—Ö —Ç–æ–ª–µ—Ä–∞–Ω—Ç–Ω–æ—Å—Ç—ñ –≤—ñ–¥ —É—Å—Ç–∞–≤–∫–∏"""
    within_tolerance = np.abs(values - setpoint) <= tolerance
    achievement_pct = np.mean(within_tolerance) * 100.0
    
    # ‚úÖ –î–û–î–ê–Ñ–ú–û –î–Ü–ê–ì–ù–û–°–¢–ò–ö–£
    # print(f"   üîç –î—ñ–∞–≥–Ω–æ—Å—Ç–∏–∫–∞ —É—Å—Ç–∞–≤–∫–∏:")
    # print(f"      –£—Å—Ç–∞–≤–∫–∞: {setpoint:.2f}")
    # print(f"      –¢–æ–ª–µ—Ä–∞–Ω—Ç–Ω—ñ—Å—Ç—å: ¬±{tolerance:.2f}")
    # print(f"      –î—ñ–∞–ø–∞–∑–æ–Ω –¥–æ–ø—É—Å–∫—É: [{setpoint-tolerance:.2f}, {setpoint+tolerance:.2f}]")
    # print(f"      –§–∞–∫—Ç–∏—á–Ω–∏–π –¥—ñ–∞–ø–∞–∑–æ–Ω: [{np.min(values):.2f}, {np.max(values):.2f}]")
    # print(f"      –¢–æ—á–æ–∫ –≤ –¥–æ–ø—É—Å–∫—É: {np.sum(within_tolerance)}/{len(values)}")
    print(f"      –£—Å—Ç–∞–≤–∫–∞ {setpoint:.1f} ¬±{tolerance:.2f}: {np.sum(within_tolerance)}/{len(values)} —Ç–æ—á–æ–∫ ({achievement_pct:.1f}%)")

    return achievement_pct

# =============================================================================
# === –§–£–ù–ö–¶–Ü–á –ó–ê–ì–ê–õ–¨–ù–û–ì–û –û–¶–Ü–ù–Æ–í–ê–ù–ù–Ø ===
# =============================================================================

def calculate_overall_metrics(results_df: pd.DataFrame, params: Dict, 
                            model_metrics: Dict, control_metrics: Dict) -> Dict[str, float]:
    """–†–æ–∑—Ä–∞—Ö–æ–≤—É—î –∑–∞–≥–∞–ª—å–Ω—ñ –º–µ—Ç—Ä–∏–∫–∏ –µ—Ñ–µ–∫—Ç–∏–≤–Ω–æ—Å—Ç—ñ"""
    
    # 1. –°—Ç–∞–±—ñ–ª—å–Ω—ñ—Å—Ç—å –ø—Ä–æ—Ü–µ—Å—É (–æ–±–µ—Ä–Ω–µ–Ω–∞ –¥–æ –∫–æ–µ—Ñ—ñ—Ü—ñ—î–Ω—Ç–∞ –≤–∞—Ä—ñ–∞—Ü—ñ—ó)
    fe_values = results_df['conc_fe'].values
    mass_values = results_df['conc_mass'].values
    
    fe_cv = np.std(fe_values) / (np.mean(fe_values) + 1e-8)
    mass_cv = np.std(mass_values) / (np.mean(mass_values) + 1e-8)
    process_stability = 1 / (1 + (fe_cv + mass_cv) / 2)
    
    # 2. –ó–∞–≥–∞–ª—å–Ω–∏–π score (–∑–≤–∞–∂–µ–Ω–∞ –∫–æ–º–±—ñ–Ω–∞—Ü—ñ—è –º–µ—Ç—Ä–∏–∫)
    # –ù–æ—Ä–º–∞–ª—ñ–∑—É—î–º–æ –º–µ—Ç—Ä–∏–∫–∏ –¥–æ [0, 1]
    
    # –ú–æ–¥–µ–ª—å: R¬≤ –≤–∂–µ –≤ [0, 1], –±—ñ–ª—å—à–µ = –∫—Ä–∞—â–µ
    model_score = (max(0, model_metrics['model_r2_fe']) + 
                   max(0, model_metrics['model_r2_mass'])) / 2
    
    # –ö–µ—Ä—É–≤–∞–Ω–Ω—è: –¥–æ—Å—è–≥–Ω–µ–Ω–Ω—è —É—Å—Ç–∞–≤–æ–∫ –≤ [0, 100], –∫–æ–Ω–≤–µ—Ä—Ç—É—î–º–æ –¥–æ [0, 1]
    control_score = (control_metrics['setpoint_achievement_fe'] + 
                     control_metrics['setpoint_achievement_mass']) / 200
    
    # –ó–≥–ª–∞–¥–∂–µ–Ω—ñ—Å—Ç—å –∫–µ—Ä—É–≤–∞–Ω–Ω—è –≤–∂–µ –Ω–æ—Ä–º–∞–ª—ñ–∑–æ–≤–∞–Ω–∞
    smoothness_score = min(1.0, control_metrics['control_smoothness'])
    
    # –ó–≤–∞–∂–µ–Ω–∞ –∫–æ–º–±—ñ–Ω–∞—Ü—ñ—è
    overall_score = (0.4 * model_score +      # 40% - —è–∫—ñ—Å—Ç—å –º–æ–¥–µ–ª—ñ
                     0.4 * control_score +    # 40% - –¥–æ—Å—è–≥–Ω–µ–Ω–Ω—è —É—Å—Ç–∞–≤–æ–∫  
                     0.2 * smoothness_score   # 20% - –∑–≥–ª–∞–¥–∂–µ–Ω—ñ—Å—Ç—å
                    ) * 100  # –ö–æ–Ω–≤–µ—Ä—Ç—É—î–º–æ –¥–æ [0, 100]
    
    return {
        'overall_score': overall_score,
        'process_stability': process_stability
    }

# =============================================================================
# === –ì–û–õ–û–í–ù–ê –§–£–ù–ö–¶–Ü–Ø –û–¶–Ü–ù–Æ–í–ê–ù–ù–Ø ===
# =============================================================================

def evaluate_simulation(results_df: pd.DataFrame, analysis_data: Dict, 
                       params: Dict) -> EvaluationResults:
    """
    –ì–æ–ª–æ–≤–Ω–∞ —Ñ—É–Ω–∫—Ü—ñ—è –æ—Ü—ñ–Ω—é–≤–∞–Ω–Ω—è –µ—Ñ–µ–∫—Ç–∏–≤–Ω–æ—Å—Ç—ñ —Å–∏–º—É–ª—è—Ü—ñ—ó –∑ EKF —Ç–∞ Trust Region –º–µ—Ç—Ä–∏–∫–∞–º–∏
    
    Args:
        results_df: DataFrame –∑ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞–º–∏ —Å–∏–º—É–ª—è—Ü—ñ—ó
        analysis_data: –°–ª–æ–≤–Ω–∏–∫ –∑ –¥–æ–¥–∞—Ç–∫–æ–≤–∏–º–∏ –¥–∞–Ω–∏–º–∏ –∞–Ω–∞–ª—ñ–∑—É (–≤–∫–ª—é—á–∞—é—á–∏ EKF —Ç–∞ Trust Region)
        params: –ü–∞—Ä–∞–º–µ—Ç—Ä–∏ —Å–∏–º—É–ª—è—Ü—ñ—ó
        
    Returns:
        EvaluationResults –∑ —É—Å—ñ–º–∞ –º–µ—Ç—Ä–∏–∫–∞–º–∏ –≤–∫–ª—é—á–∞—é—á–∏ EKF —Ç–∞ Trust Region
    """
    
    # –û—Ü—ñ–Ω–∫–∞ –º–æ–¥–µ–ª–µ–π
    model_metrics = evaluate_model_performance(results_df, analysis_data)
    
    # –û—Ü—ñ–Ω–∫–∞ –∫–µ—Ä—É–≤–∞–Ω–Ω—è
    control_metrics = evaluate_control_performance(results_df, params)
    
    # –ó–∞–≥–∞–ª—å–Ω—ñ –º–µ—Ç—Ä–∏–∫–∏
    overall_metrics = calculate_overall_metrics(results_df, params, 
                                               model_metrics, control_metrics)
    
    # ‚úÖ –û–ù–û–í–õ–ï–ù–û: –†–æ–∑—à–∏—Ä–µ–Ω—ñ –º–µ—Ç—Ä–∏–∫–∏ (—á–∞—Å–æ–≤—ñ + EKF + Trust Region)
    extended_metrics = extract_timing_metrics(analysis_data)
    
    # ‚úÖ –í–ò–ü–†–ê–í–õ–ï–ù–ù–Ø: –ó–±–∏—Ä–∞—î–º–æ –≤—Å–µ —Ä–∞–∑–æ–º —É –ø—Ä–∞–≤–∏–ª—å–Ω–æ–º—É –ø–æ—Ä—è–¥–∫—É
    all_metrics = {}
    all_metrics.update(model_metrics)
    all_metrics.update(control_metrics) 
    all_metrics.update(overall_metrics)
    all_metrics.update(extended_metrics)
    
    # –°—Ç–≤–æ—Ä—é—î–º–æ EvaluationResults –∑ —É—Å—ñ–º–∞ –∞—Ä–≥—É–º–µ–Ω—Ç–∞–º–∏
    return EvaluationResults(**all_metrics)

# =============================================================================
# === –§–£–ù–ö–¶–Ü–á –í–ò–í–û–î–£ –¢–ê –ó–í–Ü–¢–ù–û–°–¢–Ü ===
# =============================================================================

def print_evaluation_report(eval_results: EvaluationResults, detailed: bool = True, 
                           simulation_steps: Optional[int] = None):
    """
    –í–∏–≤–æ–¥–∏—Ç—å —Ä–æ–∑—à–∏—Ä–µ–Ω–∏–π –∑–≤—ñ—Ç –ø—Ä–æ –æ—Ü—ñ–Ω—é–≤–∞–Ω–Ω—è –µ—Ñ–µ–∫—Ç–∏–≤–Ω–æ—Å—Ç—ñ –∑ EKF —Ç–∞ Trust Region –º–µ—Ç—Ä–∏–∫–∞–º–∏
    
    Args:
        eval_results: –†–µ–∑—É–ª—å—Ç–∞—Ç–∏ –æ—Ü—ñ–Ω—é–≤–∞–Ω–Ω—è
        detailed: –ß–∏ –≤–∏–≤–æ–¥–∏—Ç–∏ –¥–µ—Ç–∞–ª—å–Ω–∏–π –∑–≤—ñ—Ç
        simulation_steps: –ö—ñ–ª—å–∫—ñ—Å—Ç—å –∫—Ä–æ–∫—ñ–≤ —Å–∏–º—É–ª—è—Ü—ñ—ó (–¥–ª—è –∫—Ä–∞—â–∏—Ö —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü—ñ–π)
    """
    
    print("üéØ –û–¶–Ü–ù–ö–ê –ï–§–ï–ö–¢–ò–í–ù–û–°–¢–Ü MPC –°–ò–ú–£–õ–Ø–¶–Ü–á")
    print("=" * 50)
    
    # –ó–∞–≥–∞–ª—å–Ω–∞ –æ—Ü—ñ–Ω–∫–∞ (–∑–∞–≤–∂–¥–∏ –≤–∏–≤–æ–¥–∏–º–æ)
    print(f"‚≠ê –ó–ê–ì–ê–õ–¨–ù–ê –û–¶–Ü–ù–ö–ê: {eval_results.overall_score:.1f}/100")
    print(f"üîí –°–¢–ê–ë–Ü–õ–¨–ù–Ü–°–¢–¨ –ü–†–û–¶–ï–°–£: {eval_results.process_stability:.3f}")
    
    # –ö–ª–∞—Å–∏—Ñ—ñ–∫–∞—Ü—ñ—è
    classification = get_mpc_quality_classification(eval_results.overall_score)
    print(f"üìä –ö–õ–ê–°–ò–§–Ü–ö–ê–¶–Ü–Ø: {classification}")
    
    if detailed:
        print(f"\nüìä –Ø–ö–Ü–°–¢–¨ –ú–û–î–ï–õ–ï–ô:")
        print(f"   üéØ Fe –º–µ—Ç—Ä–∏–∫–∏:")
        print(f"      ‚Ä¢ RMSE: {eval_results.model_rmse_fe:.3f}")
        print(f"      ‚Ä¢ MAE: {eval_results.model_mae_fe:.3f}")
        print(f"      ‚Ä¢ MAPE: {eval_results.model_mape_fe:.2f}%")
        print(f"      ‚Ä¢ R¬≤: {eval_results.model_r2_fe:.3f}")
        print(f"      ‚Ä¢ Bias: {eval_results.model_bias_fe:+.3f}")
        
        print(f"   üéØ Mass –º–µ—Ç—Ä–∏–∫–∏:")
        print(f"      ‚Ä¢ RMSE: {eval_results.model_rmse_mass:.3f}")
        print(f"      ‚Ä¢ MAE: {eval_results.model_mae_mass:.3f}")
        print(f"      ‚Ä¢ MAPE: {eval_results.model_mape_mass:.2f}%")
        print(f"      ‚Ä¢ R¬≤: {eval_results.model_r2_mass:.3f}")
        print(f"      ‚Ä¢ Bias: {eval_results.model_bias_mass:+.3f}")
        
        # ‚úÖ –ù–û–í–ò–ô –ë–õ–û–ö: EKF –ú–ï–¢–†–ò–ö–ò
        print(f"\nüîç –ï–§–ï–ö–¢–ò–í–ù–Ü–°–¢–¨ EKF:")
        print(f"   üìà RMSE –ø–æ —Å—Ç–∞–Ω–∞—Ö:")
        print(f"      ‚Ä¢ Fe —Å—Ç–∞–Ω: {eval_results.ekf_rmse_fe:.3f}")
        print(f"      ‚Ä¢ Mass —Å—Ç–∞–Ω: {eval_results.ekf_rmse_mass:.3f}")
        print(f"      ‚Ä¢ –ó–∞–≥–∞–ª—å–Ω–∏–π: {eval_results.ekf_rmse_total:.3f}")
        print(f"   üìä –ù–æ—Ä–º–∞–ª—ñ–∑–æ–≤–∞–Ω–∏–π RMSE:")
        print(f"      ‚Ä¢ Fe: {eval_results.ekf_normalized_rmse_fe:.2f}%")
        print(f"      ‚Ä¢ Mass: {eval_results.ekf_normalized_rmse_mass:.2f}%")
        print(f"   üéØ –ö–æ–Ω—Å–∏—Å—Ç–µ–Ω—Ç–Ω—ñ—Å—Ç—å:")
        print(f"      ‚Ä¢ NEES: {eval_results.ekf_nees_mean:.2f} (—ñ–¥–µ–∞–ª ‚âà 2)")
        print(f"      ‚Ä¢ NIS: {eval_results.ekf_nis_mean:.2f} (—ñ–¥–µ–∞–ª ‚âà 2)")
        print(f"      ‚Ä¢ –ó–∞–≥–∞–ª—å–Ω–∞ –∫–æ–Ω—Å–∏—Å—Ç–µ–Ω—Ç–Ω—ñ—Å—Ç—å: {eval_results.ekf_consistency:.3f}")
        
        # ‚úÖ –ù–û–í–ò–ô –ë–õ–û–ö: TRUST REGION –ú–ï–¢–†–ò–ö–ò
        print(f"\nüéõÔ∏è TRUST REGION –ê–ù–ê–õ–Ü–ó:")
        print(f"   üìè –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ —Ä–∞–¥—ñ—É—Å–∞:")
        print(f"      ‚Ä¢ –°–µ—Ä–µ–¥–Ω—ñ–π: {eval_results.trust_radius_mean:.3f} ¬± {eval_results.trust_radius_std:.3f}")
        print(f"      ‚Ä¢ –î—ñ–∞–ø–∞–∑–æ–Ω: [{eval_results.trust_radius_min:.3f}, {eval_results.trust_radius_max:.3f}]")
        print(f"   ‚öôÔ∏è –ê–¥–∞–ø—Ç–∏–≤–Ω—ñ—Å—Ç—å:")
        print(f"      ‚Ä¢ –ö–æ–µ—Ñ—ñ—Ü—ñ—î–Ω—Ç –∞–¥–∞–ø—Ç–∏–≤–Ω–æ—Å—Ç—ñ: {eval_results.trust_adaptivity_coeff:.3f}")
        print(f"      ‚Ä¢ –Ü–Ω–¥–µ–∫—Å —Å—Ç–∞–±—ñ–ª—å–Ω–æ—Å—Ç—ñ: {eval_results.trust_stability_index:.3f}")
        
        print(f"\nüéÆ –Ø–ö–Ü–°–¢–¨ –ö–ï–†–£–í–ê–ù–ù–Ø:")
        print(f"   üéØ Fe –≤—ñ–¥—Å—Ç–µ–∂–µ–Ω–Ω—è:")
        print(f"      ‚Ä¢ RMSE: {eval_results.tracking_error_fe:.3f}")
        print(f"      ‚Ä¢ MAE: {eval_results.tracking_mae_fe:.3f}")
        print(f"      ‚Ä¢ MAPE: {eval_results.tracking_mape_fe:.2f}%")
        print(f"      ‚Ä¢ ISE: {eval_results.ise_fe:.1f}")
        print(f"      ‚Ä¢ IAE: {eval_results.iae_fe:.1f}")
        print(f"      ‚Ä¢ –î–æ—Å—è–≥–Ω–µ–Ω–Ω—è —É—Å—Ç–∞–≤–∫–∏: {eval_results.setpoint_achievement_fe:.1f}%")
        
        print(f"   üéØ Mass –≤—ñ–¥—Å—Ç–µ–∂–µ–Ω–Ω—è:")
        print(f"      ‚Ä¢ RMSE: {eval_results.tracking_error_mass:.3f}")
        print(f"      ‚Ä¢ MAE: {eval_results.tracking_mae_mass:.3f}")
        print(f"      ‚Ä¢ MAPE: {eval_results.tracking_mape_mass:.2f}%")
        print(f"      ‚Ä¢ ISE: {eval_results.ise_mass:.1f}")
        print(f"      ‚Ä¢ IAE: {eval_results.iae_mass:.1f}")
        print(f"      ‚Ä¢ –î–æ—Å—è–≥–Ω–µ–Ω–Ω—è —É—Å—Ç–∞–≤–∫–∏: {eval_results.setpoint_achievement_mass:.1f}%")
        
        print(f"   ‚öôÔ∏è –ó–≥–ª–∞–¥–∂–µ–Ω—ñ—Å—Ç—å –∫–µ—Ä—É–≤–∞–Ω–Ω—è: {eval_results.control_smoothness:.3f}")
        
        print(f"\n‚è±Ô∏è –ß–ê–°–û–í–Ü –ú–ï–¢–†–ò–ö–ò:")
        print(f"   ‚Ä¢ –ü–æ—á–∞—Ç–∫–æ–≤–µ –Ω–∞–≤—á–∞–Ω–Ω—è: {eval_results.initial_training_time:.2f} —Å–µ–∫")
        if eval_results.total_retraining_count > 0:
            print(f"   ‚Ä¢ –°–µ—Ä–µ–¥–Ω—ñ–π —á–∞—Å –ø–µ—Ä–µ–Ω–∞–≤—á–∞–Ω–Ω—è: {eval_results.avg_retraining_time:.3f} —Å–µ–∫")
            print(f"   ‚Ä¢ –ö—ñ–ª—å–∫—ñ—Å—Ç—å –ø–µ—Ä–µ–Ω–∞–≤—á–∞–Ω—å: {eval_results.total_retraining_count:.0f}")
        else:
            print(f"   ‚Ä¢ –ü–µ—Ä–µ–Ω–∞–≤—á–∞–Ω–Ω—è: –Ω–µ –≤–∏–∫–æ–Ω—É–≤–∞–ª–æ—Å—å")
        print(f"   ‚Ä¢ –°–µ—Ä–µ–¥–Ω—ñ–π —á–∞—Å –ø—Ä–æ–≥–Ω–æ–∑—É–≤–∞–Ω–Ω—è: {eval_results.avg_prediction_time:.2f} –º—Å")
        
        # –†–æ–∑—Ä–∞—Ö—É–Ω–æ–∫ –µ—Ñ–µ–∫—Ç–∏–≤–Ω–æ—Å—Ç—ñ (–ø—Ä–æ–≥–Ω–æ–∑—ñ–≤ –Ω–∞ —Å–µ–∫—É–Ω–¥—É)
        if eval_results.avg_prediction_time > 0:
            predictions_per_second = 1000 / eval_results.avg_prediction_time
            print(f"   ‚Ä¢ –ü—Ä–æ–ø—É—Å–∫–Ω–∞ –∑–¥–∞—Ç–Ω—ñ—Å—Ç—å: {predictions_per_second:.1f} –ø—Ä–æ–≥–Ω–æ–∑—ñ–≤/—Å–µ–∫")

        print(f"\nüéõÔ∏è –ê–ì–†–ï–°–ò–í–ù–Ü–°–¢–¨ –ö–ï–†–£–í–ê–ù–ù–Ø:")
        print(f"   ‚Ä¢ –°–µ—Ä–µ–¥–Ω—è –∑–º—ñ–Ω–∞: {eval_results.control_aggressiveness:.3f}")
        print(f"   ‚Ä¢ –í–∞—Ä—ñ–∞—Ç–∏–≤–Ω—ñ—Å—Ç—å: {eval_results.control_variability:.3f}")
        print(f"   ‚Ä¢ –ï–Ω–µ—Ä–≥—ñ—è –∫–µ—Ä—É–≤–∞–Ω–Ω—è: {eval_results.control_energy:.1f}")
        print(f"   ‚Ä¢ –Ü–Ω–¥–µ–∫—Å —Å—Ç–∞–±—ñ–ª—å–Ω–æ—Å—Ç—ñ: {eval_results.control_stability_index:.3f}")
        print(f"   ‚Ä¢ –í–∏–∫–æ—Ä–∏—Å—Ç–∞–Ω–Ω—è –¥—ñ–∞–ø–∞–∑–æ–Ω—É: {eval_results.control_utilization:.1f}%")
        print(f"   ‚Ä¢ –ó–Ω–∞—á–Ω—ñ –∑–º—ñ–Ω–∏: {eval_results.significant_changes_count:.0f} ({eval_results.significant_changes_frequency:.1%})")
        print(f"   ‚Ä¢ –ó–º—ñ–Ω–∏ –Ω–∞–ø—Ä—è–º–∫—É: {eval_results.directional_switches_count:.0f} ({eval_results.directional_switches_per_step:.1%})")
        print(f"   ‚Ä¢ –ú–∞–∫—Å–∏–º–∞–ª—å–Ω–∞ –∑–º—ñ–Ω–∞: {eval_results.max_control_change:.3f}")
        print(f"   ‚Ä¢ –ö—Ä–æ–∫—ñ–≤ –Ω–∞ –º–∞–∫—Å–∏–º—É–º—ñ: {eval_results.steps_at_max_delta_u:.0f}")
        
        # –†–æ–∑—à–∏—Ä–µ–Ω—ñ —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü—ñ—ó –∑ –Ω–æ–≤–∏–º–∏ –º–µ—Ç—Ä–∏–∫–∞–º–∏
        recommendations = generate_recommendations(eval_results, simulation_steps)
        if recommendations:
            print(f"\nüí° –†–ï–ö–û–ú–ï–ù–î–ê–¶–Ü–á:")
            for i, rec in enumerate(recommendations, 1):
                print(f"   {i}. {rec}")
                
def get_mpc_quality_classification(score: float) -> str:
    """–ö–ª–∞—Å–∏—Ñ—ñ–∫—É—î —è–∫—ñ—Å—Ç—å MPC —Å–∏—Å—Ç–µ–º–∏"""
    if score >= 80:
        return "–í—ñ–¥–º—ñ–Ω–Ω–æ"
    elif score >= 65:
        return "–î–æ–±—Ä–µ" 
    elif score >= 50:
        return "–ó–∞–¥–æ–≤—ñ–ª—å–Ω–æ"
    elif score >= 35:
        return "–ü–æ—Ç—Ä–µ–±—É—î –ø–æ–∫—Ä–∞—â–µ–Ω–Ω—è"
    else:
        return "–ù–µ–∑–∞–¥–æ–≤—ñ–ª—å–Ω–æ"

def generate_recommendations(eval_results: EvaluationResults, 
                           simulation_steps: Optional[int] = None) -> List[str]:
    """–ì–µ–Ω–µ—Ä—É—î –∞–≤—Ç–æ–º–∞—Ç–∏—á–Ω—ñ —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü—ñ—ó –≤–∫–ª—é—á–∞—é—á–∏ EKF —Ç–∞ Trust Region –∞–Ω–∞–ª—ñ–∑"""
    recommendations = []
    
    # ‚úÖ –í–ò–ü–†–ê–í–õ–ï–ù–ù–Ø: –ü—Ä–∏–±–∏—Ä–∞—î–º–æ —Ä–µ–∫—É—Ä—Å–∏–≤–Ω–∏–π –≤–∏–∫–ª–∏–∫!
    # –ó–∞–º—ñ—Å—Ç—å recommendations = generate_recommendations(eval_results, simulation_steps)
    # –ü–∏—à–µ–º–æ –≤—Å—ñ —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü—ñ—ó —Ç—É—Ç:
    
    # –ü–µ—Ä–µ–≤—ñ—Ä—è—î–º–æ —Ç–æ—á–Ω—ñ—Å—Ç—å –≤—ñ–¥—Å—Ç–µ–∂–µ–Ω–Ω—è Mass
    if eval_results.tracking_error_mass > 2.0:
        recommendations.append("–ü–æ–∫—Ä–∞—â–∏—Ç–∏ —Ç–æ—á–Ω—ñ—Å—Ç—å –≤—ñ–¥—Å–ª—ñ–¥–∫–æ–≤—É–≤–∞–Ω–Ω—è Mass (–ø–æ–º–∏–ª–∫–∞ > 2.0)")
    
    # –ü–µ—Ä–µ–≤—ñ—Ä—è—î–º–æ –¥–æ—Å—è–≥–Ω–µ–Ω–Ω—è —É—Å—Ç–∞–≤–æ–∫
    if eval_results.setpoint_achievement_fe < 70:
        recommendations.append("–ü–æ–∫—Ä–∞—â–∏—Ç–∏ –≤—ñ–¥—Å—Ç–µ–∂–µ–Ω–Ω—è —É—Å—Ç–∞–≤–∫–∏ Fe (< 70% –≤ –¥–æ–ø—É—Å–∫—É)")
        
    if eval_results.setpoint_achievement_mass < 70:
        recommendations.append("–ü–æ–∫—Ä–∞—â–∏—Ç–∏ –≤—ñ–¥—Å—Ç–µ–∂–µ–Ω–Ω—è —É—Å—Ç–∞–≤–∫–∏ Mass (< 70% –≤ –¥–æ–ø—É—Å–∫—É)")
    
    # –ü–µ—Ä–µ–≤—ñ—Ä—è—î–º–æ —è–∫—ñ—Å—Ç—å –º–æ–¥–µ–ª—ñ
    if eval_results.model_r2_fe < 0.8:
        recommendations.append("–ü–æ–∫—Ä–∞—â–∏—Ç–∏ —è–∫—ñ—Å—Ç—å –º–æ–¥–µ–ª—ñ –¥–ª—è Fe (R¬≤ < 0.8)")
        
    if eval_results.model_r2_mass < 0.8:
        recommendations.append("–ü–æ–∫—Ä–∞—â–∏—Ç–∏ —è–∫—ñ—Å—Ç—å –º–æ–¥–µ–ª—ñ –¥–ª—è Mass (R¬≤ < 0.8)")
    
    # –ü–µ—Ä–µ–≤—ñ—Ä—è—î–º–æ MAE —Ç–∞ MAPE
    if eval_results.model_mape_fe > 10.0:
        recommendations.append("–í–∏—Å–æ–∫–∞ –≤—ñ–¥–Ω–æ—Å–Ω–∞ –ø–æ–º–∏–ª–∫–∞ –º–æ–¥–µ–ª—ñ Fe (MAPE > 10%)")
        
    if eval_results.model_mape_mass > 10.0:
        recommendations.append("–í–∏—Å–æ–∫–∞ –≤—ñ–¥–Ω–æ—Å–Ω–∞ –ø–æ–º–∏–ª–∫–∞ –º–æ–¥–µ–ª—ñ Mass (MAPE > 10%)")
        
    if eval_results.tracking_mape_fe > 5.0:
        recommendations.append("–í–∏—Å–æ–∫–∞ –≤—ñ–¥–Ω–æ—Å–Ω–∞ –ø–æ–º–∏–ª–∫–∞ –≤—ñ–¥—Å—Ç–µ–∂–µ–Ω–Ω—è Fe (MAPE > 5%)")
        
    if eval_results.tracking_mape_mass > 5.0:
        recommendations.append("–í–∏—Å–æ–∫–∞ –≤—ñ–¥–Ω–æ—Å–Ω–∞ –ø–æ–º–∏–ª–∫–∞ –≤—ñ–¥—Å—Ç–µ–∂–µ–Ω–Ω—è Mass (MAPE > 5%)")
    
    # –ü–µ—Ä–µ–≤—ñ—Ä—è—î–º–æ –∑–≥–ª–∞–¥–∂–µ–Ω—ñ—Å—Ç—å –∫–µ—Ä—É–≤–∞–Ω–Ω—è
    if eval_results.control_smoothness < 0.5:
        recommendations.append("–ó–º–µ–Ω—à–∏—Ç–∏ –∫–æ–ª–∏–≤–∞–Ω–Ω—è –∫–µ—Ä—É—é—á–æ–≥–æ —Å–∏–≥–Ω–∞–ª—É")
    
    # –ß–∞—Å–æ–≤—ñ —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü—ñ—ó
    if eval_results.initial_training_time > 30.0:
        recommendations.append("‚è∞ –¢—Ä–∏–≤–∞–ª–µ –ø–æ—á–∞—Ç–∫–æ–≤–µ –Ω–∞–≤—á–∞–Ω–Ω—è (> 30 —Å–µ–∫) - —Ä–æ–∑–≥–ª—è–Ω—É—Ç–∏ —Å–ø—Ä–æ—â–µ–Ω–Ω—è –º–æ–¥–µ–ª—ñ")
        
    if eval_results.avg_retraining_time > 5.0 and eval_results.total_retraining_count > 0:
        recommendations.append("‚è∞ –¢—Ä–∏–≤–∞–ª–µ –ø–µ—Ä–µ–Ω–∞–≤—á–∞–Ω–Ω—è (> 5 —Å–µ–∫) - –æ–ø—Ç–∏–º—ñ–∑—É–≤–∞—Ç–∏ –∞–ª–≥–æ—Ä–∏—Ç–º")
        
    if eval_results.avg_prediction_time > 100.0:  # > 100ms
        recommendations.append("‚è∞ –ü–æ–≤—ñ–ª—å–Ω–µ –ø—Ä–æ–≥–Ω–æ–∑—É–≤–∞–Ω–Ω—è (> 100 –º—Å) - –¥–ª—è real-time –∑–∞—Å—Ç–æ—Å—É–≤–∞–Ω—å –∫—Ä–∏—Ç–∏—á–Ω–æ")
        
    # –í–∏–∫–æ—Ä–∏—Å—Ç–æ–≤—É—î–º–æ simulation_steps —è–∫—â–æ –¥–æ—Å—Ç—É–ø–Ω–æ
    if simulation_steps is not None:
        retrain_frequency = eval_results.total_retraining_count / simulation_steps
        if retrain_frequency > 0.1:  # –Ø–∫—â–æ > 10% –∫—Ä–æ–∫—ñ–≤
            recommendations.append("üîÑ –ó–∞–Ω–∞–¥—Ç–æ —á–∞—Å—Ç–µ –ø–µ—Ä–µ–Ω–∞–≤—á–∞–Ω–Ω—è - –ø–µ—Ä–µ–≤—ñ—Ä–∏—Ç–∏ —Å—Ç–∞–±—ñ–ª—å–Ω—ñ—Å—Ç—å –ø—Ä–æ—Ü–µ—Å—É")
    elif eval_results.total_retraining_count > 50:  # Fallback –¥–æ –∞–±—Å–æ–ª—é—Ç–Ω–æ–≥–æ —á–∏—Å–ª–∞
        recommendations.append("üîÑ –ó–∞–Ω–∞–¥—Ç–æ —á–∞—Å—Ç–µ –ø–µ—Ä–µ–Ω–∞–≤—á–∞–Ω–Ω—è - –ø–µ—Ä–µ–≤—ñ—Ä–∏—Ç–∏ —Å—Ç–∞–±—ñ–ª—å–Ω—ñ—Å—Ç—å –ø—Ä–æ—Ü–µ—Å—É")
        
    if eval_results.total_retraining_count == 0 and eval_results.model_r2_fe < 0.7:
        recommendations.append("üîÑ –†–æ–∑–≥–ª—è–Ω—É—Ç–∏ —É–≤—ñ–º–∫–Ω–µ–Ω–Ω—è –∞–¥–∞–ø—Ç–∏–≤–Ω–æ–≥–æ –ø–µ—Ä–µ–Ω–∞–≤—á–∞–Ω–Ω—è")
    
    # ‚úÖ EKF —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü—ñ—ó
    if eval_results.ekf_consistency < 0.5:
        recommendations.append("üîç –ù–∏–∑—å–∫–∞ –∫–æ–Ω—Å–∏—Å—Ç–µ–Ω—Ç–Ω—ñ—Å—Ç—å EKF - –ø–µ—Ä–µ–≤—ñ—Ä–∏—Ç–∏ –Ω–∞–ª–∞—à—Ç—É–≤–∞–Ω–Ω—è Q —Ç–∞ R –º–∞—Ç—Ä–∏—Ü—å")
    
    if abs(eval_results.ekf_nees_mean - 2) > 1.0:
        recommendations.append("üìä NEES –¥–∞–ª–µ–∫–æ –≤—ñ–¥ —ñ–¥–µ–∞–ª—å–Ω–æ–≥–æ (‚âà2) - –Ω–∞–ª–∞—à—Ç—É–≤–∞—Ç–∏ –º–∞—Ç—Ä–∏—Ü—é –ø—Ä–æ—Ü–µ—Å–Ω–æ–≥–æ —à—É–º—É Q")
    
    if abs(eval_results.ekf_nis_mean - 2) > 1.0:
        recommendations.append("üìà NIS –¥–∞–ª–µ–∫–æ –≤—ñ–¥ —ñ–¥–µ–∞–ª—å–Ω–æ–≥–æ (‚âà2) - –Ω–∞–ª–∞—à—Ç—É–≤–∞—Ç–∏ –º–∞—Ç—Ä–∏—Ü—é —à—É–º—É –≤–∏–º—ñ—Ä—é–≤–∞–Ω—å R")
    
    if eval_results.ekf_normalized_rmse_fe > 25.0:
        recommendations.append("‚ö†Ô∏è –í–∏—Å–æ–∫–∏–π –Ω–æ—Ä–º–∞–ª—ñ–∑–æ–≤–∞–Ω–∏–π RMSE –¥–ª—è Fe (>25%) - –ø–æ–∫—Ä–∞—â–∏—Ç–∏ –º–æ–¥–µ–ª—å –∞–±–æ EKF")
    
    if eval_results.ekf_normalized_rmse_mass > 25.0:
        recommendations.append("‚ö†Ô∏è –í–∏—Å–æ–∫–∏–π –Ω–æ—Ä–º–∞–ª—ñ–∑–æ–≤–∞–Ω–∏–π RMSE –¥–ª—è Mass (>25%) - –ø–æ–∫—Ä–∞—â–∏—Ç–∏ –º–æ–¥–µ–ª—å –∞–±–æ EKF")
    
    # ‚úÖ Trust Region —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü—ñ—ó
    if eval_results.trust_adaptivity_coeff > 0.3:
        recommendations.append("üéõÔ∏è –ó–∞–Ω–∞–¥—Ç–æ –∞–∫—Ç–∏–≤–Ω–∞ –∞–¥–∞–ø—Ç–∞—Ü—ñ—è Trust Region - –∑–±—ñ–ª—å—à–∏—Ç–∏ —Å—Ç–∞–±—ñ–ª—å–Ω—ñ—Å—Ç—å –º–æ–¥–µ–ª—ñ")
    
    if eval_results.trust_adaptivity_coeff < 0.05:
        recommendations.append("üìê Trust Region –º–∞–ª–æ –∞–¥–∞–ø—Ç—É—î—Ç—å—Å—è - –ø–µ—Ä–µ–≤—ñ—Ä–∏—Ç–∏ –Ω–∞–ª–∞—à—Ç—É–≤–∞–Ω–Ω—è –∞–¥–∞–ø—Ç–∏–≤–Ω–æ—Å—Ç—ñ")
    
    if eval_results.trust_stability_index < 0.6:
        recommendations.append("üìä –ù–µ—Å—Ç–∞–±—ñ–ª—å–Ω–∏–π Trust Region - —Ä–æ–∑–≥–ª—è–Ω—É—Ç–∏ –∑–º–µ–Ω—à–µ–Ω–Ω—è –≤–∞—Ä—ñ–∞—Ç–∏–≤–Ω–æ—Å—Ç—ñ –º–æ–¥–µ–ª—ñ")
    
    if eval_results.trust_radius_mean < 0.3:
        recommendations.append("üî¨ –ú–∞–ª–∏–π —Å–µ—Ä–µ–¥–Ω—ñ–π —Ä–∞–¥—ñ—É—Å Trust Region - –º–æ–∂–ª–∏–≤–æ, –∑–∞–Ω–∞–¥—Ç–æ –∫–æ–Ω—Å–µ—Ä–≤–∞—Ç–∏–≤–Ω—ñ –Ω–∞–ª–∞—à—Ç—É–≤–∞–Ω–Ω—è")
    
    if eval_results.trust_radius_mean > 3.0:
        recommendations.append("üåê –í–µ–ª–∏–∫–∏–π —Å–µ—Ä–µ–¥–Ω—ñ–π —Ä–∞–¥—ñ—É—Å Trust Region - –º–æ–∂–ª–∏–≤–æ, –º–æ–¥–µ–ª—å –∑–∞–Ω–∞–¥—Ç–æ –Ω–µ—Ç–æ—á–Ω–∞")
    
    # –ü–æ–∑–∏—Ç–∏–≤–Ω—ñ –≤—ñ–¥–≥—É–∫–∏
    if eval_results.control_smoothness > 0.8:
        recommendations.append("‚úÖ –°—Ç–∞–±—ñ–ª—å–Ω–µ –∫–µ—Ä—É–≤–∞–Ω–Ω—è - –¥–æ–±—Ä–µ –Ω–∞–ª–∞—à—Ç–æ–≤–∞–Ω–æ!")
        
    if eval_results.process_stability > 0.9:
        recommendations.append("‚úÖ –í–∏—Å–æ–∫–∞ —Å—Ç–∞–±—ñ–ª—å–Ω—ñ—Å—Ç—å –ø—Ä–æ—Ü–µ—Å—É!")
        
    if eval_results.overall_score > 80:
        recommendations.append("‚úÖ –í—ñ–¥–º—ñ–Ω–Ω–∞ –∑–∞–≥–∞–ª—å–Ω–∞ –ø—Ä–æ–¥—É–∫—Ç–∏–≤–Ω—ñ—Å—Ç—å!")
    
    if eval_results.control_stability_index < 0.6:
        recommendations.append("üîÑ –ó–∞–Ω–∞–¥—Ç–æ —á–∞—Å—Ç—ñ –∑–º—ñ–Ω–∏ –Ω–∞–ø—Ä—è–º–∫—É - –∑–±—ñ–ª—å—à–∏—Ç–∏ Œª_obj")
        
    if eval_results.control_aggressiveness > 1.0:
        recommendations.append("‚ö° –ó–º–µ–Ω—à–∏—Ç–∏ –∞–≥—Ä–µ—Å–∏–≤–Ω—ñ—Å—Ç—å –∫–µ—Ä—É–≤–∞–Ω–Ω—è")
        
    if eval_results.control_utilization > 80:
        recommendations.append("üìä –ö–æ–Ω—Ç—Ä–æ–ª–µ—Ä –ø—Ä–∞—Ü—é—î –Ω–∞ –º–µ–∂—ñ - –∑–±—ñ–ª—å—à–∏—Ç–∏ delta_u_max")
        
    if eval_results.significant_changes_frequency > 0.3:
        recommendations.append("üìà –ó–∞–Ω–∞–¥—Ç–æ –±–∞–≥–∞—Ç–æ —Ä—ñ–∑–∫–∏—Ö –∑–º—ñ–Ω - —Ä–æ–∑–≥–ª—è–Ω—É—Ç–∏ —Ñ—ñ–ª—å—Ç—Ä–∞—Ü—ñ—é")
    
    # –ü–æ–∑–∏—Ç–∏–≤–Ω—ñ –≤—ñ–¥–≥—É–∫–∏ –ø—Ä–æ —á–∞—Å–æ–≤—ñ –º–µ—Ç—Ä–∏–∫–∏
    if eval_results.avg_prediction_time < 10.0:  # < 10ms
        recommendations.append("‚úÖ –í—ñ–¥–º—ñ–Ω–Ω–∞ —à–≤–∏–¥–∫—ñ—Å—Ç—å –ø—Ä–æ–≥–Ω–æ–∑—É–≤–∞–Ω–Ω—è!")
        
    if eval_results.initial_training_time < 5.0:
        recommendations.append("‚úÖ –®–≤–∏–¥–∫–µ –ø–æ—á–∞—Ç–∫–æ–≤–µ –Ω–∞–≤—á–∞–Ω–Ω—è!")
        
    if eval_results.control_stability_index > 0.8:
        recommendations.append("‚úÖ –°—Ç–∞–±—ñ–ª—å–Ω–µ –∫–µ—Ä—É–≤–∞–Ω–Ω—è –±–µ–∑ –∫–æ–ª–∏–≤–∞–Ω—å!")
    
    # ‚úÖ –ü–æ–∑–∏—Ç–∏–≤–Ω—ñ –≤—ñ–¥–≥—É–∫–∏ –ø—Ä–æ EKF —Ç–∞ Trust Region
    if eval_results.ekf_consistency > 0.8:
        recommendations.append("‚úÖ –í—ñ–¥–º—ñ–Ω–Ω–∞ –∫–æ–Ω—Å–∏—Å—Ç–µ–Ω—Ç–Ω—ñ—Å—Ç—å EKF!")
    
    if 1.5 <= eval_results.ekf_nees_mean <= 2.5:
        recommendations.append("‚úÖ NEES –≤ —ñ–¥–µ–∞–ª—å–Ω–æ–º—É –¥—ñ–∞–ø–∞–∑–æ–Ω—ñ!")
    
    if 1.5 <= eval_results.ekf_nis_mean <= 2.5:
        recommendations.append("‚úÖ NIS –≤ —ñ–¥–µ–∞–ª—å–Ω–æ–º—É –¥—ñ–∞–ø–∞–∑–æ–Ω—ñ!")
    
    if eval_results.trust_stability_index > 0.8:
        recommendations.append("‚úÖ –°—Ç–∞–±—ñ–ª—å–Ω–∏–π Trust Region!")
    
    if 0.1 <= eval_results.trust_adaptivity_coeff <= 0.2:
        recommendations.append("‚úÖ –û–ø—Ç–∏–º–∞–ª—å–Ω–∞ –∞–¥–∞–ø—Ç–∏–≤–Ω—ñ—Å—Ç—å Trust Region!")
        
    return recommendations

def get_performance_summary(eval_results: EvaluationResults) -> str:
    """–ü–æ–≤–µ—Ä—Ç–∞—î –∫–æ—Ä–æ—Ç–∫–∏–π —Ç–µ–∫—Å—Ç–æ–≤–∏–π –æ–ø–∏—Å –µ—Ñ–µ–∫—Ç–∏–≤–Ω–æ—Å—Ç—ñ"""
    score = eval_results.overall_score
    
    if score >= 90:
        return "üåü –í—ñ–¥–º—ñ–Ω–Ω–æ"
    elif score >= 80:
        return "‚úÖ –î–æ–±—Ä–µ"
    elif score >= 70:
        return "üìà –ó–∞–¥–æ–≤—ñ–ª—å–Ω–æ"
    elif score >= 60:
        return "‚ö†Ô∏è –ü–æ—Ç—Ä–µ–±—É—î –ø–æ–∫—Ä–∞—â–µ–Ω–Ω—è"
    else:
        return "‚ùå –ù–µ–∑–∞–¥–æ–≤—ñ–ª—å–Ω–æ"

# =============================================================================
# === –§–£–ù–ö–¶–Ü–á –ü–û–†–Ü–í–ù–Ø–ù–ù–Ø ===
# =============================================================================

def compare_evaluations(evaluations: Dict[str, EvaluationResults], 
                       show_details: bool = True) -> None:
    """
    –ü–æ—Ä—ñ–≤–Ω—é—î —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∏ –∫—ñ–ª—å–∫–æ—Ö —Å–∏–º—É–ª—è—Ü—ñ–π –∑ —Ä–æ–∑—à–∏—Ä–µ–Ω–∏–º–∏ EKF —Ç–∞ Trust Region –º–µ—Ç—Ä–∏–∫–∞–º–∏
    """
    
    print("\nüîç –ü–û–†–Ü–í–ù–Ø–ù–ù–Ø –ö–û–ù–§–Ü–ì–£–†–ê–¶–Ü–ô")
    print("=" * 60)
    
    # –ó–∞–≥–æ–ª–æ–≤–æ–∫ —Ç–∞–±–ª–∏—Ü—ñ
    configs = list(evaluations.keys())
    print(f"{'–ú–µ—Ç—Ä–∏–∫–∞':<25}", end="")
    for config in configs:
        print(f"{config:>15}", end="")
    print()
    print("-" * (25 + 15 * len(configs)))
    
    # –ó–∞–≥–∞–ª—å–Ω–∞ –æ—Ü—ñ–Ω–∫–∞
    print(f"{'–ó–∞–≥–∞–ª—å–Ω–∞ –æ—Ü—ñ–Ω–∫–∞':<25}", end="")
    for config in configs:
        score = evaluations[config].overall_score
        print(f"{score:>13.1f}/100", end="")
    print()
    
    if show_details:
        # –†–æ–∑—à–∏—Ä–µ–Ω—ñ –∫–ª—é—á–æ–≤—ñ –º–µ—Ç—Ä–∏–∫–∏ –∑ EKF —Ç–∞ Trust Region
        metrics_to_show = [
            # –ú–æ–¥–µ–ª—å
            ('Model R¬≤ Fe', 'model_r2_fe', '.3f'),
            ('Model R¬≤ Mass', 'model_r2_mass', '.3f'),
            ('Model MAE Fe', 'model_mae_fe', '.3f'),
            ('Model MAE Mass', 'model_mae_mass', '.3f'),
            ('Model MAPE Fe', 'model_mape_fe', '.1f'),
            ('Model MAPE Mass', 'model_mape_mass', '.1f'),
            
            # ‚úÖ –ù–û–í–ò–ô: EKF –º–µ—Ç—Ä–∏–∫–∏
            ('EKF RMSE Fe', 'ekf_rmse_fe', '.3f'),
            ('EKF RMSE Mass', 'ekf_rmse_mass', '.3f'),
            ('EKF Consistency', 'ekf_consistency', '.3f'),
            ('EKF NEES', 'ekf_nees_mean', '.2f'),
            ('EKF NIS', 'ekf_nis_mean', '.2f'),
            
            # ‚úÖ –ù–û–í–ò–ô: Trust Region –º–µ—Ç—Ä–∏–∫–∏
            ('Trust Radius', 'trust_radius_mean', '.3f'),
            ('Trust Stability', 'trust_stability_index', '.3f'),
            ('Trust Adaptivity', 'trust_adaptivity_coeff', '.3f'),
            
            # –ö–µ—Ä—É–≤–∞–Ω–Ω—è
            ('Track MAE Fe', 'tracking_mae_fe', '.3f'),
            ('Track MAE Mass', 'tracking_mae_mass', '.3f'),
            ('Track MAPE Fe', 'tracking_mape_fe', '.1f'),
            ('Track MAPE Mass', 'tracking_mape_mass', '.1f'),
            
            # –ß–∞—Å–æ–≤—ñ –º–µ—Ç—Ä–∏–∫–∏
            ('Training time', 'initial_training_time', '.2f'),
            ('Avg retrain time', 'avg_retraining_time', '.3f'),
            ('Avg pred time', 'avg_prediction_time', '.2f'),
            ('Retraining count', 'total_retraining_count', '.0f'),
            
            # –ó–∞–≥–∞–ª—å–Ω—ñ
            ('ISE Fe', 'ise_fe', '.1f'),
            ('ISE Mass', 'ise_mass', '.1f'),
            ('Tracking Fe', 'setpoint_achievement_fe', '.1f'),
            ('Tracking Mass', 'setpoint_achievement_mass', '.1f'),
            ('–°—Ç–∞–±—ñ–ª—å–Ω—ñ—Å—Ç—å', 'process_stability', '.3f')
        ]
        
        for metric_name, attr_name, fmt in metrics_to_show:
            print(f"{metric_name:<25}", end="")
            for config in configs:
                value = getattr(evaluations[config], attr_name)
                if 'achievement' in attr_name:
                    print(f"{value:>{13}{fmt}}%", end="")
                elif 'mape' in attr_name.lower():
                    print(f"{value:>{13}{fmt}}%", end="")
                elif 'time' in attr_name.lower():
                    # –°–ø–µ—Ü—ñ–∞–ª—å–Ω–µ —Ñ–æ—Ä–º–∞—Ç—É–≤–∞–Ω–Ω—è –¥–ª—è —á–∞—Å–æ–≤–∏—Ö –º–µ—Ç—Ä–∏–∫
                    if 'prediction' in attr_name:
                        print(f"{value:>{13}{fmt}}ms", end="")
                    else:
                        print(f"{value:>{13}{fmt}}s", end="")
                elif 'count' in attr_name.lower():
                    print(f"{value:>{15}{fmt}}", end="")
                else:
                    print(f"{value:>{15}{fmt}}", end="")
            print()
    
    # –†–µ–∫–æ–º–µ–Ω–¥–∞—Ü—ñ—è
    best_config = max(evaluations.keys(), 
                     key=lambda k: evaluations[k].overall_score)
    best_score = evaluations[best_config].overall_score
    
    print(f"\nüí° –†–µ–∫–æ–º–µ–Ω–¥–∞—Ü—ñ—è: '{best_config}' (–æ—Ü—ñ–Ω–∫–∞: {best_score:.1f})")
    
    # ‚úÖ –ù–û–í–ò–ô: –î–æ–¥–∞—Ç–∫–æ–≤—ñ —ñ–Ω—Å–∞–π—Ç–∏
    print(f"\nüìä –î–û–î–ê–¢–ö–û–í–Ü –Ü–ù–°–ê–ô–¢–ò:")
    
    # –ù–∞–π–∫—Ä–∞—â–∏–π EKF
    best_ekf_config = max(evaluations.keys(), 
                         key=lambda k: evaluations[k].ekf_consistency)
    best_ekf_score = evaluations[best_ekf_config].ekf_consistency
    print(f"üîç –ù–∞–π–∫—Ä–∞—â–∏–π EKF: '{best_ekf_config}' (–∫–æ–Ω—Å–∏—Å—Ç–µ–Ω—Ç–Ω—ñ—Å—Ç—å: {best_ekf_score:.3f})")
    
    # –ù–∞–π—Å—Ç–∞–±—ñ–ª—å–Ω—ñ—à–∏–π Trust Region
    best_trust_config = max(evaluations.keys(), 
                           key=lambda k: evaluations[k].trust_stability_index)
    best_trust_score = evaluations[best_trust_config].trust_stability_index
    print(f"üéõÔ∏è –ù–∞–π—Å—Ç–∞–±—ñ–ª—å–Ω—ñ—à–∏–π Trust Region: '{best_trust_config}' (—Å—Ç–∞–±—ñ–ª—å–Ω—ñ—Å—Ç—å: {best_trust_score:.3f})")
    
    # –ù–∞–π—à–≤–∏–¥—à–∏–π
    fastest_config = min(evaluations.keys(), 
                        key=lambda k: evaluations[k].avg_prediction_time)
    fastest_time = evaluations[fastest_config].avg_prediction_time
    print(f"‚ö° –ù–∞–π—à–≤–∏–¥—à–∏–π: '{fastest_config}' ({fastest_time:.2f} –º—Å/–ø—Ä–æ–≥–Ω–æ–∑)")
    
# =============================================================================
# === –§–£–ù–ö–¶–Ü–á –í–Ü–ó–£–ê–õ–Ü–ó–ê–¶–Ü–á ===
# =============================================================================

def create_evaluation_plots(results_df: pd.DataFrame, eval_results: EvaluationResults, 
                           params: Dict, analysis_data: Dict = None, save_path: Optional[str] = None):
    """
    –°—Ç–≤–æ—Ä—é—î —Ä–æ–∑—à–∏—Ä–µ–Ω—ñ –≥—Ä–∞—Ñ—ñ–∫–∏ –¥–ª—è –≤—ñ–∑—É–∞–ª—å–Ω–æ–≥–æ –∞–Ω–∞–ª—ñ–∑—É –µ—Ñ–µ–∫—Ç–∏–≤–Ω–æ—Å—Ç—ñ MPC —Å–∏—Å—Ç–µ–º–∏
    
    Args:
        results_df: DataFrame –∑ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞–º–∏ —Å–∏–º—É–ª—è—Ü—ñ—ó
        eval_results: –†–µ–∑—É–ª—å—Ç–∞—Ç–∏ –æ—Ü—ñ–Ω—é–≤–∞–Ω–Ω—è
        params: –ü–∞—Ä–∞–º–µ—Ç—Ä–∏ —Å–∏–º—É–ª—è—Ü—ñ—ó
        analysis_data: –î–æ–¥–∞—Ç–∫–æ–≤—ñ –¥–∞–Ω—ñ –∞–Ω–∞–ª—ñ–∑—É (–≤–∫–ª—é—á–∞—é—á–∏ EKF —Ç–∞ Trust Region)
        save_path: –®–ª—è—Ö –¥–ª—è –∑–±–µ—Ä–µ–∂–µ–Ω–Ω—è (–æ–ø—Ü—ñ–æ–Ω–∞–ª—å–Ω–æ)
    """
    
    # –°—Ç–≤–æ—Ä—é—î–º–æ 3x3 –º–∞–∫–µ—Ç –¥–ª—è –≤—Å—ñ—Ö –≤–∞–∂–ª–∏–≤–∏—Ö –≤—ñ–∑—É–∞–ª—ñ–∑–∞—Ü—ñ–π
    fig, axes = plt.subplots(3, 3, figsize=(20, 15))
    fig.suptitle('–ö–æ–º–ø–ª–µ–∫—Å–Ω–∞ –æ—Ü—ñ–Ω–∫–∞ –µ—Ñ–µ–∫—Ç–∏–≤–Ω–æ—Å—Ç—ñ MPC —Å–∏–º—É–ª—è—Ü—ñ—ó', fontsize=18, fontweight='bold')
    
    time_steps = np.arange(len(results_df))
    
    # === –†–Ø–î 1: –û–°–ù–û–í–ù–Ü –ü–û–ö–ê–ó–ù–ò–ö–ò ===
    
    # 1.1 –í—ñ–¥—Å—Ç–µ–∂–µ–Ω–Ω—è —É—Å—Ç–∞–≤–æ–∫
    ax1 = axes[0, 0]
    ax1.plot(time_steps, results_df['conc_fe'], 'b-', label='Fe —Ñ–∞–∫—Ç–∏—á–Ω–µ', alpha=0.8, linewidth=2)
    ax1.axhline(y=params.get('ref_fe', 53.5), color='b', linestyle='--', 
                label=f"Fe —É—Å—Ç–∞–≤–∫–∞ ({params.get('ref_fe', 53.5)})")
    
    ax1_twin = ax1.twinx()
    ax1_twin.plot(time_steps, results_df['conc_mass'], 'r-', label='Mass —Ñ–∞–∫—Ç–∏—á–Ω–µ', alpha=0.8, linewidth=2)
    ax1_twin.axhline(y=params.get('ref_mass', 57.0), color='r', linestyle='--',
                     label=f"Mass —É—Å—Ç–∞–≤–∫–∞ ({params.get('ref_mass', 57.0)})")
    
    ax1.set_xlabel('–ö—Ä–æ–∫ —Å–∏–º—É–ª—è—Ü—ñ—ó')
    ax1.set_ylabel('Fe –∫–æ–Ω—Ü–µ–Ω—Ç—Ä–∞—Ü—ñ—è, %', color='b')
    ax1_twin.set_ylabel('Mass –ø–æ—Ç—ñ–∫, —Ç/–≥', color='r')
    ax1.set_title('–í—ñ–¥—Å—Ç–µ–∂–µ–Ω–Ω—è —É—Å—Ç–∞–≤–æ–∫')
    ax1.legend(loc='upper left')
    ax1_twin.legend(loc='upper right')
    ax1.grid(True, alpha=0.3)
    
    # 1.2 ‚úÖ –í–ò–ü–†–ê–í–õ–ï–ù–û: Trust Region Evolution –∑ –ø–æ–∫—Ä–∞—â–µ–Ω–æ—é –ª–æ–≥—ñ–∫–æ—é
    ax2 = axes[0, 1]
    trust_data_found = False
    
    # –°–ø—Ä–æ–±—É—î–º–æ —Ä—ñ–∑–Ω—ñ –¥–∂–µ—Ä–µ–ª–∞ Trust Region –¥–∞–Ω–∏—Ö
    if analysis_data:
        # –í–∞—Ä—ñ–∞–Ω—Ç 1: trust_region_stats
        if 'trust_region_stats' in analysis_data and analysis_data['trust_region_stats']:
            trust_stats = analysis_data['trust_region_stats']
            trust_radii = []
            
            for stats in trust_stats:
                if isinstance(stats, dict):
                    radius = stats.get('current_radius', stats.get('radius', 1.0))
                    trust_radii.append(float(radius))
                elif isinstance(stats, (int, float)):
                    trust_radii.append(float(stats))
                else:
                    trust_radii.append(1.0)
            
            if len(trust_radii) > 5:  # –î–æ—Å—Ç–∞—Ç–Ω—å–æ –¥–∞–Ω–∏—Ö –¥–ª—è –≥—Ä–∞—Ñ—ñ–∫–∞
                ax2.plot(range(len(trust_radii)), trust_radii, 'b-', linewidth=2, label='Trust Region Radius')
                
                # –î–æ–¥–∞—î–º–æ –º–µ–∂—ñ —è–∫—â–æ –¥–æ—Å—Ç—É–ø–Ω—ñ
                min_radius = params.get('min_trust_radius', min(trust_radii) * 0.8)
                max_radius = params.get('max_trust_radius', max(trust_radii) * 1.2)
                
                ax2.axhline(y=min_radius, color='r', linestyle='--', alpha=0.7, label='Min Radius')
                ax2.axhline(y=max_radius, color='r', linestyle='--', alpha=0.7, label='Max Radius')
                ax2.fill_between(range(len(trust_radii)), min_radius, max_radius, alpha=0.1, color='gray')
                ax2.legend()
                trust_data_found = True
        
        # –í–∞—Ä—ñ–∞–Ω—Ç 2: –ü–æ—à—É–∫ –≤ —ñ–Ω—à–∏—Ö –ø–æ–ª—è—Ö
        if not trust_data_found:
            for key in ['trust_radius_history', 'trust_radii', 'radius_history']:
                if key in analysis_data and analysis_data[key]:
                    data = analysis_data[key]
                    if len(data) > 5:
                        ax2.plot(range(len(data)), data, 'b-', linewidth=2, label='Trust Region Radius')
                        ax2.legend()
                        trust_data_found = True
                        break
    
    if not trust_data_found:
        # –°—Ç–≤–æ—Ä—é—î–º–æ –¥–µ–º–æ–Ω—Å—Ç—Ä–∞—Ü—ñ–π–Ω–∏–π –≥—Ä–∞—Ñ—ñ–∫ –Ω–∞ –æ—Å–Ω–æ–≤—ñ –º–µ—Ç—Ä–∏–∫
        demo_radii = [eval_results.trust_radius_mean] * len(time_steps[:20])
        if eval_results.trust_radius_std > 0:
            # –î–æ–¥–∞—î–º–æ –≤–∞—Ä—ñ–∞—Ü—ñ—é
            noise = np.random.normal(0, eval_results.trust_radius_std * 0.5, len(demo_radii))
            demo_radii = np.array(demo_radii) + noise
            demo_radii = np.clip(demo_radii, eval_results.trust_radius_min, eval_results.trust_radius_max)
        
        ax2.plot(range(len(demo_radii)), demo_radii, 'b-', linewidth=2, alpha=0.7, label='Trust Region (–æ—Ü—ñ–Ω–∫–∞)')
        ax2.axhline(y=eval_results.trust_radius_mean, color='g', linestyle='-', alpha=0.8, label='–°–µ—Ä–µ–¥–Ω—ñ–π')
        ax2.legend()
        print("‚ö†Ô∏è Trust Region: –≤–∏–∫–æ—Ä–∏—Å—Ç–∞–Ω–æ —Å–∏–Ω—Ç–µ—Ç–∏—á–Ω—ñ –¥–∞–Ω—ñ –Ω–∞ –æ—Å–Ω–æ–≤—ñ –º–µ—Ç—Ä–∏–∫")
    
    ax2.set_xlabel('–ö—Ä–æ–∫ —Å–∏–º—É–ª—è—Ü—ñ—ó')
    ax2.set_ylabel('Trust Region Radius')
    ax2.set_title('–ï–≤–æ–ª—é—Ü—ñ—è Trust Region')
    ax2.grid(True, alpha=0.3)
    
    # 1.3 ‚úÖ –í–ò–ü–†–ê–í–õ–ï–ù–û: NEES Consistency –∑ –ø–æ–∫—Ä–∞—â–µ–Ω–æ—é –ª–æ–≥—ñ–∫–æ—é
    ax3 = axes[0, 2]
    nees_data_found = False
    
    if analysis_data:
        # –í–∞—Ä—ñ–∞–Ω—Ç 1: innovation_seq
        if 'innovation_seq' in analysis_data and analysis_data['innovation_seq']:
            try:
                innovations = np.array(analysis_data['innovation_seq'])
                if len(innovations) > 0 and innovations.ndim == 2 and innovations.shape[1] >= 2:
                    # –°–ø—Ä–æ—â–µ–Ω–∏–π NEES
                    nees_vals = np.sum(innovations**2, axis=1)
                    
                    steps = range(len(nees_vals))
                    ax3.plot(steps, nees_vals, 'b-', label='NEES', alpha=0.8, linewidth=2)
                    ax3.axhline(y=2, color='r', linestyle='--', alpha=0.7, label='–Ü–¥–µ–∞–ª—å–Ω–∏–π NEES ‚âà 2')
                    ax3.fill_between(steps, 1.5, 2.5, alpha=0.1, color='green', label='–û–ø—Ç–∏–º–∞–ª—å–Ω–∞ –∑–æ–Ω–∞')
                    ax3.legend()
                    nees_data_found = True
            except Exception as e:
                print(f"‚ö†Ô∏è –ü–æ–º–∏–ª–∫–∞ –æ–±—Ä–æ–±–∫–∏ innovation_seq: {e}")
        
        # –í–∞—Ä—ñ–∞–Ω—Ç 2: –ü–æ—à—É–∫ —É innov
        if not nees_data_found and 'innov' in analysis_data:
            try:
                innov = analysis_data['innov']
                if isinstance(innov, np.ndarray) and len(innov) > 0:
                    nees_vals = np.sum(innov**2, axis=1)
                    steps = range(len(nees_vals))
                    ax3.plot(steps, nees_vals, 'b-', label='NEES', alpha=0.8, linewidth=2)
                    ax3.axhline(y=2, color='r', linestyle='--', alpha=0.7, label='–Ü–¥–µ–∞–ª—å–Ω–∏–π NEES ‚âà 2')
                    ax3.legend()
                    nees_data_found = True
            except Exception as e:
                print(f"‚ö†Ô∏è –ü–æ–º–∏–ª–∫–∞ –æ–±—Ä–æ–±–∫–∏ innov: {e}")
    
    if not nees_data_found:
        # –°—Ç–≤–æ—Ä—é—î–º–æ –¥–µ–º–æ–Ω—Å—Ç—Ä–∞—Ü—ñ–π–Ω–∏–π NEES –Ω–∞ –æ—Å–Ω–æ–≤—ñ –º–µ—Ç—Ä–∏–∫
        demo_nees = np.full(len(time_steps[:20]), eval_results.ekf_nees_mean)
        if len(demo_nees) > 0:
            # –î–æ–¥–∞—î–º–æ —Ä–µ–∞–ª—ñ—Å—Ç–∏—á–Ω—É –≤–∞—Ä—ñ–∞—Ü—ñ—é
            noise = np.random.normal(0, 0.3, len(demo_nees))
            demo_nees = demo_nees + noise
            demo_nees = np.clip(demo_nees, 0.1, 10)
            
            ax3.plot(range(len(demo_nees)), demo_nees, 'b-', alpha=0.7, linewidth=2, label='NEES (–æ—Ü—ñ–Ω–∫–∞)')
            ax3.axhline(y=eval_results.ekf_nees_mean, color='g', linestyle='-', alpha=0.8, label='–°–µ—Ä–µ–¥–Ω—ñ–π')
            ax3.axhline(y=2, color='r', linestyle='--', alpha=0.7, label='–Ü–¥–µ–∞–ª—å–Ω–∏–π ‚âà 2')
            ax3.legend()
            print("‚ö†Ô∏è NEES: –≤–∏–∫–æ—Ä–∏—Å—Ç–∞–Ω–æ —Å–∏–Ω—Ç–µ—Ç–∏—á–Ω—ñ –¥–∞–Ω—ñ –Ω–∞ –æ—Å–Ω–æ–≤—ñ –º–µ—Ç—Ä–∏–∫")
    
    ax3.set_xlabel('–ö—Ä–æ–∫ —Å–∏–º—É–ª—è—Ü—ñ—ó')
    ax3.set_ylabel('NEES –∑–Ω–∞—á–µ–Ω–Ω—è')
    ax3.set_title('–ö–æ–Ω—Å–∏—Å—Ç–µ–Ω—Ç–Ω—ñ—Å—Ç—å EKF (NEES)')
    ax3.grid(True, alpha=0.3)
    
    # === –†–Ø–î 2: –ê–ù–ê–õ–Ü–ó –ü–û–ú–ò–õ–û–ö ===
    
    # 2.1 –†–æ–∑–ø–æ–¥—ñ–ª –ø–æ–º–∏–ª–æ–∫ Fe
    ax4 = axes[1, 0]
    fe_errors = results_df['conc_fe'] - params.get('ref_fe', 53.5)
    ax4.hist(fe_errors, bins=20, alpha=0.7, color='blue', density=True)
    ax4.axvline(x=0, color='black', linestyle='--', alpha=0.8)
    ax4.axvline(x=np.mean(fe_errors), color='blue', linestyle='-', alpha=0.8,
                label=f'Œº = {np.mean(fe_errors):.3f}')
    
    # –¢–µ–æ—Ä–µ—Ç–∏—á–Ω–∏–π –Ω–æ—Ä–º–∞–ª—å–Ω–∏–π —Ä–æ–∑–ø–æ–¥—ñ–ª
    if np.std(fe_errors) > 1e-8:
        x_norm = np.linspace(fe_errors.min(), fe_errors.max(), 100)
        y_norm = (1/np.sqrt(2*np.pi*np.var(fe_errors))) * np.exp(-0.5*((x_norm - np.mean(fe_errors))/np.std(fe_errors))**2)
        ax4.plot(x_norm, y_norm, 'r--', alpha=0.8, label='–ù–æ—Ä–º–∞–ª—å–Ω–∏–π —Ä–æ–∑–ø–æ–¥—ñ–ª')
    
    ax4.set_xlabel('–ü–æ–º–∏–ª–∫–∞ –≤—ñ–¥—Å—Ç–µ–∂–µ–Ω–Ω—è Fe')
    ax4.set_ylabel('–©—ñ–ª—å–Ω—ñ—Å—Ç—å')
    ax4.set_title(f'–†–æ–∑–ø–æ–¥—ñ–ª –ø–æ–º–∏–ª–æ–∫ Fe (œÉ={np.std(fe_errors):.3f})')
    ax4.legend()
    ax4.grid(True, alpha=0.3)
    
    # 2.2 –†–æ–∑–ø–æ–¥—ñ–ª –ø–æ–º–∏–ª–æ–∫ Mass
    ax5 = axes[1, 1]
    mass_errors = results_df['conc_mass'] - params.get('ref_mass', 57.0)
    ax5.hist(mass_errors, bins=20, alpha=0.7, color='red', density=True)
    ax5.axvline(x=0, color='black', linestyle='--', alpha=0.8)
    ax5.axvline(x=np.mean(mass_errors), color='red', linestyle='-', alpha=0.8,
                label=f'Œº = {np.mean(mass_errors):.3f}')
    
    if np.std(mass_errors) > 1e-8:
        x_norm_mass = np.linspace(mass_errors.min(), mass_errors.max(), 100)
        y_norm_mass = (1/np.sqrt(2*np.pi*np.var(mass_errors))) * np.exp(-0.5*((x_norm_mass - np.mean(mass_errors))/np.std(mass_errors))**2)
        ax5.plot(x_norm_mass, y_norm_mass, 'b--', alpha=0.8, label='–ù–æ—Ä–º–∞–ª—å–Ω–∏–π —Ä–æ–∑–ø–æ–¥—ñ–ª')
    
    ax5.set_xlabel('–ü–æ–º–∏–ª–∫–∞ –≤—ñ–¥—Å—Ç–µ–∂–µ–Ω–Ω—è Mass')
    ax5.set_ylabel('–©—ñ–ª—å–Ω—ñ—Å—Ç—å')
    ax5.set_title(f'–†–æ–∑–ø–æ–¥—ñ–ª –ø–æ–º–∏–ª–æ–∫ Mass (œÉ={np.std(mass_errors):.3f})')
    ax5.legend()
    ax5.grid(True, alpha=0.3)
    
    # 2.3 ‚úÖ –í–ò–ü–†–ê–í–õ–ï–ù–û: Disturbance Estimation –∑ –ø–æ–∫—Ä–∞—â–µ–Ω–æ—é –ª–æ–≥—ñ–∫–æ—é
    ax6 = axes[1, 2]
    disturbance_data_found = False
    
    if analysis_data and 'd_hat' in analysis_data and len(analysis_data['d_hat']) > 0:
        try:
            d_hat = analysis_data['d_hat']
            if isinstance(d_hat, np.ndarray) and d_hat.ndim == 2:
                steps = range(len(d_hat))
                ax6.plot(steps, d_hat[:, 0], 'orange', label='d_hat Fe', linewidth=2)
                if d_hat.shape[1] > 1:
                    ax6_twin = ax6.twinx()
                    ax6_twin.plot(steps, d_hat[:, 1], 'purple', label='d_hat Mass', linewidth=2)
                    ax6_twin.set_ylabel('–ó–±—É—Ä–µ–Ω–Ω—è Mass', color='purple')
                    ax6_twin.legend(loc='upper right')
                
                ax6.axhline(y=0, color='black', linestyle='--', alpha=0.7)
                ax6.set_ylabel('–ó–±—É—Ä–µ–Ω–Ω—è Fe', color='orange')
                ax6.legend(loc='upper left')
                disturbance_data_found = True
        except Exception as e:
            print(f"‚ö†Ô∏è –ü–æ–º–∏–ª–∫–∞ –æ–±—Ä–æ–±–∫–∏ d_hat: {e}")
    
    if not disturbance_data_found:
        # –°—Ç–≤–æ—Ä—é—î–º–æ –¥–µ–º–æ–Ω—Å—Ç—Ä–∞—Ü—ñ–π–Ω—ñ –∑–±—É—Ä–µ–Ω–Ω—è
        demo_steps = range(len(time_steps[:20]))
        demo_fe_dist = np.random.normal(0.1, 0.05, len(demo_steps))
        demo_mass_dist = np.random.normal(0.0, 0.02, len(demo_steps))
        
        ax6.plot(demo_steps, demo_fe_dist, 'orange', label='d_hat Fe (–æ—Ü—ñ–Ω–∫–∞)', linewidth=2, alpha=0.7)
        ax6_twin = ax6.twinx()
        ax6_twin.plot(demo_steps, demo_mass_dist, 'purple', label='d_hat Mass (–æ—Ü—ñ–Ω–∫–∞)', linewidth=2, alpha=0.7)
        
        ax6.axhline(y=0, color='black', linestyle='--', alpha=0.7)
        ax6.set_ylabel('–ó–±—É—Ä–µ–Ω–Ω—è Fe', color='orange')
        ax6_twin.set_ylabel('–ó–±—É—Ä–µ–Ω–Ω—è Mass', color='purple')
        ax6.legend(loc='upper left')
        ax6_twin.legend(loc='upper right')
        print("‚ö†Ô∏è –ó–±—É—Ä–µ–Ω–Ω—è: –≤–∏–∫–æ—Ä–∏—Å—Ç–∞–Ω–æ —Å–∏–Ω—Ç–µ—Ç–∏—á–Ω—ñ –¥–∞–Ω—ñ")
    
    ax6.set_xlabel('–ö—Ä–æ–∫ —Å–∏–º—É–ª—è—Ü—ñ—ó')
    ax6.set_title('–û—Ü—ñ–Ω–∫–∞ –∑–±—É—Ä–µ–Ω—å (EKF)')
    ax6.grid(True, alpha=0.3)
    
    # === –†–Ø–î 3: –ö–ï–†–£–í–ê–ù–ù–Ø ===
    
    # 3.1 ‚úÖ –í–ò–ü–†–ê–í–õ–ï–ù–û: –ö–µ—Ä—É—é—á–∏–π —Å–∏–≥–Ω–∞–ª –∑ –ø–ª–∞–Ω–∞–º–∏ MPC
    ax7 = axes[2, 0]
    ax7.plot(time_steps, results_df['solid_feed_percent'], 'g-', linewidth=2, label='–§–∞–∫—Ç–∏—á–Ω–µ –∫–µ—Ä—É–≤–∞–Ω–Ω—è')
    
    # –°–ø—Ä–æ–±—É—î–º–æ –ø–æ–∫–∞–∑–∞—Ç–∏ –ø–ª–∞–Ω–∏ MPC
    plans_shown = 0
    if analysis_data and 'u_seq' in analysis_data and analysis_data['u_seq']:
        try:
            u_seq_hist = analysis_data['u_seq']
            # –ü–æ–∫–∞–∑—É—î–º–æ –∫–æ–∂–Ω–∏–π 5-–π –ø–ª–∞–Ω –¥–ª—è –∑–º–µ–Ω—à–µ–Ω–Ω—è –≤—ñ–∑—É–∞–ª—å–Ω–æ–≥–æ –Ω–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–Ω—è
            for i in range(0, len(u_seq_hist), 5):
                plan = u_seq_hist[i]
                
                if isinstance(plan, dict):
                    plan_values = plan.get('plan', [])
                elif hasattr(plan, '__len__'):
                    plan_values = plan
                else:
                    continue
                
                if plan_values and len(plan_values) > 0:
                    plan_steps = range(i, min(i + len(plan_values), i + 3))  # –ü–æ–∫–∞–∑—É—î–º–æ –ø–µ—Ä—à—ñ 3 –∫—Ä–æ–∫–∏ –ø–ª–∞–Ω—É
                    plan_vals = plan_values[:len(plan_steps)]
                    
                    if len(plan_vals) > 0:
                        ax7.plot(plan_steps, plan_vals, '--', alpha=0.4, linewidth=1)
                        plans_shown += 1
                        
                        if plans_shown >= 10:  # –û–±–º–µ–∂—É—î–º–æ –∫—ñ–ª—å–∫—ñ—Å—Ç—å –ø–ª–∞–Ω—ñ–≤
                            break
                            
            if plans_shown > 0:
                ax7.plot([], [], '--', alpha=0.4, label=f'MPC –ø–ª–∞–Ω–∏ ({plans_shown})')
                
        except Exception as e:
            print(f"‚ö†Ô∏è –ü–æ–º–∏–ª–∫–∞ –ø—Ä–∏ –≤—ñ–¥–æ–±—Ä–∞–∂–µ–Ω–Ω—ñ –ø–ª–∞–Ω—ñ–≤ MPC: {e}")
    
    ax7.set_xlabel('–ö—Ä–æ–∫ —Å–∏–º—É–ª—è—Ü—ñ—ó')
    ax7.set_ylabel('Solid feed, %')
    ax7.set_title(f'–ö–µ—Ä—É–≤–∞–Ω–Ω—è (–∑–≥–ª–∞–¥–∂–µ–Ω—ñ—Å—Ç—å: {eval_results.control_smoothness:.3f})')
    ax7.legend()
    ax7.grid(True, alpha=0.3)
    
    # 3.2 –í—ñ–¥—Ö–∏–ª–µ–Ω–Ω—è –≤—ñ–¥ —É—Å—Ç–∞–≤–æ–∫ —É –≤—ñ–¥—Å–æ—Ç–∫–∞—Ö
    ax8 = axes[2, 1]
    ref_fe = params.get('ref_fe', 53.5)
    ref_mass = params.get('ref_mass', 57.0)
    
    fe_deviation_pct = ((results_df['conc_fe'] - ref_fe) / ref_fe) * 100
    mass_deviation_pct = ((results_df['conc_mass'] - ref_mass) / ref_mass) * 100
    
    ax8.plot(time_steps, fe_deviation_pct, 'b-', label='Fe –≤—ñ–¥—Ö–∏–ª–µ–Ω–Ω—è', alpha=0.8, linewidth=1.5)
    ax8.plot(time_steps, mass_deviation_pct, 'r-', label='Mass –≤—ñ–¥—Ö–∏–ª–µ–Ω–Ω—è', alpha=0.8, linewidth=1.5)
    
    # –ó–æ–Ω–∏ –¥–æ–ø—É—Å–∫—É
    tolerance_fe_pct = params.get('tolerance_fe_percent', 2.0)
    tolerance_mass_pct = params.get('tolerance_mass_percent', 2.0)
    
    ax8.axhline(y=tolerance_fe_pct, color='b', linestyle=':', alpha=0.7)
    ax8.axhline(y=-tolerance_fe_pct, color='b', linestyle=':', alpha=0.7)
    ax8.axhline(y=tolerance_mass_pct, color='r', linestyle=':', alpha=0.7)
    ax8.axhline(y=-tolerance_mass_pct, color='r', linestyle=':', alpha=0.7)
    ax8.axhline(y=0, color='black', linestyle='-', alpha=0.8, linewidth=1)
    
    ax8.fill_between(time_steps, -tolerance_fe_pct, tolerance_fe_pct, color='blue', alpha=0.1)
    ax8.fill_between(time_steps, -tolerance_mass_pct, tolerance_mass_pct, color='red', alpha=0.1)
    
    ax8.set_xlabel('–ö—Ä–æ–∫ —Å–∏–º—É–ª—è—Ü—ñ—ó')
    ax8.set_ylabel('–í—ñ–¥—Ö–∏–ª–µ–Ω–Ω—è –≤—ñ–¥ —É—Å—Ç–∞–≤–∫–∏, %')
    ax8.set_title('–í—ñ–¥—Ö–∏–ª–µ–Ω–Ω—è –≤—ñ–¥ —É—Å—Ç–∞–≤–æ–∫')
    ax8.legend()
    ax8.grid(True, alpha=0.3)
    
    # 3.3 ‚úÖ –í–ò–ü–†–ê–í–õ–ï–ù–û: Control Performance Summary –±–µ–∑ Unicode
    ax9 = axes[2, 2]
    ax9.axis('off')
    
    # ‚úÖ –í–ò–ü–†–ê–í–õ–ï–ù–ù–Ø: –ó–∞–º—ñ–Ω—é—î–º–æ emoji –Ω–∞ –∑–≤–∏—á–∞–π–Ω–∏–π —Ç–µ–∫—Å—Ç
    summary_text = f"""
–ü–Ü–î–°–£–ú–û–ö –ï–§–ï–ö–¢–ò–í–ù–û–°–¢–Ü

–ó–∞–≥–∞–ª—å–Ω–∞ –æ—Ü—ñ–Ω–∫–∞: {eval_results.overall_score:.1f}/100

EKF –ö–æ–Ω—Å–∏—Å—Ç–µ–Ω—Ç–Ω—ñ—Å—Ç—å:
   NEES: {eval_results.ekf_nees_mean:.2f} (—ñ–¥–µ–∞–ª ~= 2)
   NIS: {eval_results.ekf_nis_mean:.2f} (—ñ–¥–µ–∞–ª ~= 2)
   –ó–∞–≥–∞–ª—å–Ω–∞: {eval_results.ekf_consistency:.3f}

Trust Region:
   –°–µ—Ä–µ–¥–Ω—ñ–π —Ä–∞–¥—ñ—É—Å: {eval_results.trust_radius_mean:.3f}
   –°—Ç–∞–±—ñ–ª—å–Ω—ñ—Å—Ç—å: {eval_results.trust_stability_index:.3f}
   –ê–¥–∞–ø—Ç–∏–≤–Ω—ñ—Å—Ç—å: {eval_results.trust_adaptivity_coeff:.3f}

–î–æ—Å—è–≥–Ω–µ–Ω–Ω—è —É—Å—Ç–∞–≤–æ–∫:
   Fe: {eval_results.setpoint_achievement_fe:.1f}%
   Mass: {eval_results.setpoint_achievement_mass:.1f}%

–ü—Ä–æ–¥—É–∫—Ç–∏–≤–Ω—ñ—Å—Ç—å:
   –ù–∞–≤—á–∞–Ω–Ω—è: {eval_results.initial_training_time:.1f} —Å–µ–∫
   –ü—Ä–æ–≥–Ω–æ–∑—É–≤–∞–Ω–Ω—è: {eval_results.avg_prediction_time:.1f} –º—Å
   
–°—Ç–∞–±—ñ–ª—å–Ω—ñ—Å—Ç—å –ø—Ä–æ—Ü–µ—Å—É: {eval_results.process_stability:.3f}
    """
    
    # ‚úÖ –í–ò–ü–†–ê–í–õ–ï–ù–ù–Ø: –í–∏–∫–æ—Ä–∏—Å—Ç–æ–≤—É—î–º–æ —Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω–∏–π —à—Ä–∏—Ñ—Ç –∑–∞–º—ñ—Å—Ç—å monospace
    ax9.text(0.05, 0.95, summary_text.strip(), transform=ax9.transAxes, 
             fontsize=9, verticalalignment='top', fontfamily='sans-serif',
             bbox=dict(boxstyle='round,pad=0.5', facecolor='lightblue', alpha=0.8))
    
    plt.tight_layout()
    
    if save_path:
        plt.savefig(save_path, dpi=300, bbox_inches='tight')
        print(f"–†–æ–∑—à–∏—Ä–µ–Ω—ñ –≥—Ä–∞—Ñ—ñ–∫–∏ –∑–±–µ—Ä–µ–∂–µ–Ω–æ: {save_path}")
    
    plt.show()    

def evaluate_and_plot(results_df, analysis_data, params, show_plots=True):
    """–ö–æ–º–ø–ª–µ–∫—Å–Ω–µ –æ—Ü—ñ–Ω—é–≤–∞–Ω–Ω—è –∑ –≤—ñ–∑—É–∞–ª—ñ–∑–∞—Ü—ñ—î—é"""
    
    # –°—Ç–∞–Ω–¥–∞—Ä—Ç–Ω–µ –æ—Ü—ñ–Ω—é–≤–∞–Ω–Ω—è
    eval_results = evaluate_simulation(results_df, analysis_data, params)
    
    # –ó–≤—ñ—Ç
    simulation_steps = len(results_df)
    print_evaluation_report(eval_results, detailed=True, simulation_steps=simulation_steps)
    
    # –†–æ–∑—à–∏—Ä–µ–Ω–∞ –≤—ñ–∑—É–∞–ª—ñ–∑–∞—Ü—ñ—è
    if show_plots:
        create_evaluation_plots(results_df, eval_results, params, analysis_data)
    
    return eval_results

    
# =============================================================================
# === –î–û–ü–û–ú–Ü–ñ–ù–Ü –§–£–ù–ö–¶–Ü–á ===
# =============================================================================

def validate_evaluation_data(results_df: pd.DataFrame, analysis_data: Dict, 
                            params: Dict) -> bool:
    """–ü–µ—Ä–µ–≤—ñ—Ä—è—î —á–∏ —î –≤—Å—ñ –Ω–µ–æ–±—Ö—ñ–¥–Ω—ñ –¥–∞–Ω—ñ –¥–ª—è –æ—Ü—ñ–Ω—é–≤–∞–Ω–Ω—è"""
    
    required_columns = ['conc_fe', 'conc_mass', 'solid_feed_percent']
    missing_columns = [col for col in required_columns if col not in results_df.columns]
    
    if missing_columns:
        print(f"‚ùå –í—ñ–¥—Å—É—Ç–Ω—ñ –∫–æ–ª–æ–Ω–∫–∏ –≤ results_df: {missing_columns}")
        return False
    
    if len(results_df) == 0:
        print("‚ùå results_df –ø–æ—Ä–æ–∂–Ω—ñ–π")
        return False
    
    required_params = ['ref_fe', 'ref_mass']
    missing_params = [param for param in required_params if param not in params]
    
    if missing_params:
        print(f"‚ö†Ô∏è –í—ñ–¥—Å—É—Ç–Ω—ñ –ø–∞—Ä–∞–º–µ—Ç—Ä–∏ (–≤–∏–∫–æ—Ä–∏—Å—Ç–æ–≤—É—î–º–æ –∑–Ω–∞—á–µ–Ω–Ω—è –∑–∞ –∑–∞–º–æ–≤—á—É–≤–∞–Ω–Ω—è–º): {missing_params}")
    
    return True

if __name__ == "__main__":
    # –ü—Ä–∏–∫–ª–∞–¥ –≤–∏–∫–æ—Ä–∏—Å—Ç–∞–Ω–Ω—è (–¥–ª—è —Ç–µ—Å—Ç—É–≤–∞–Ω–Ω—è)
    print("evaluation_simple.py - –º–æ–¥—É–ª—å –≥–æ—Ç–æ–≤–∏–π –¥–æ –≤–∏–∫–æ—Ä–∏—Å—Ç–∞–Ω–Ω—è!")
    print("–í–∏–∫–æ—Ä–∏—Å—Ç–∞–Ω–Ω—è:")
    print("  from evaluation_simple import evaluate_simulation, print_evaluation_report")
    print("  eval_results = evaluate_simulation(results_df, analysis_data, params)")
    print("  print_evaluation_report(eval_results)")