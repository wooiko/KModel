# enhanced_simulator_runner.py - –ü—Ä–∏–∫–ª–∞–¥–∏ –∑–∞–ø—É—Å–∫—É —Ä–æ–∑—à–∏—Ä–µ–Ω–æ–≥–æ —Å–∏–º—É–ª—è—Ç–æ—Ä–∞

import pandas as pd
import numpy as np
import time
import json
from pathlib import Path
from typing import Dict, Any, Optional, List
from enhanced_sim import compare_mpc_configurations

# –Ü–º–ø–æ—Ä—Ç—É—î–º–æ —Ä–æ–∑—à–∏—Ä–µ–Ω—ñ —Ñ—É–Ω–∫—Ü—ñ—ó
from enhanced_sim import (
    simulate_mpc,
    quick_mpc_benchmark, 
    detailed_mpc_analysis,
    simulate_mpc_with_config_enhanced,
    load_historical_data
)
from enhanced_benchmark import (
    pandas_safe_sort
)

# def pandas_safe_sort(df, column):
#     """–ë–µ–∑–ø–µ—á–Ω–µ —Å–æ—Ä—Ç—É–≤–∞–Ω–Ω—è –¥–ª—è –≤—Å—ñ—Ö –≤–µ—Ä—Å—ñ–π pandas"""
#     if df.empty or column not in df.columns:
#         return df
    
#     try:
#         return df.sort_values(column, na_position='last')
#     except (TypeError, ValueError):
#         try:
#             return df.sort_values(column, na_last=True)
#         except (TypeError, ValueError):
#             # –†—É—á–Ω–µ —Å–æ—Ä—Ç—É–≤–∞–Ω–Ω—è
#             valid_mask = df[column].notna()
#             if valid_mask.any():
#                 valid_df = df[valid_mask].sort_values(column)
#                 invalid_df = df[~valid_mask]
#                 return pd.concat([valid_df, invalid_df], ignore_index=True)
#             return df
        
def compare_mpc_configurations_improved(
    configurations: List[Dict],
    hist_df: pd.DataFrame,
    base_config: str = 'oleksandr_original',
    comparison_steps: int = 100
) -> pd.DataFrame:
    """üîÑ –ü–û–ö–†–ê–©–ï–ù–ï –ø–æ—Ä—ñ–≤–Ω—è–Ω–Ω—è –∫–æ–Ω—Ñ—ñ–≥—É—Ä–∞—Ü—ñ–π MPC –∑ –æ–ø—Ç–∏–º–∞–ª—å–Ω–∏–º–∏ —Ä–æ–∑–º—ñ—Ä–∞–º–∏ –¥–∞–Ω–∏—Ö"""
    
    print("üîÑ –ü–û–ö–†–ê–©–ï–ù–ï –ü–û–†–Ü–í–ù–Ø–ù–ù–Ø –ö–û–ù–§–Ü–ì–£–†–ê–¶–Ü–ô MPC")
    print("="*60)
    
    comparison_results = []
    
    for i, config in enumerate(configurations):
        config_name = config.get('name', f'Config_{i+1}')
        print(f"\nüß™ –¢–µ—Å—Ç—É—î–º–æ –∫–æ–Ω—Ñ—ñ–≥—É—Ä–∞—Ü—ñ—é: {config_name}")
        
        try:
            # –Ü–º–ø–æ—Ä—Ç—É—î–º–æ —Ñ—É–Ω–∫—Ü—ñ—é
            try:
                from enhanced_sim import simulate_mpc_core_enhanced as simulate_mpc_core
            except ImportError:
                from sim import simulate_mpc_core
            
            # –ì–æ—Ç—É—î–º–æ –∫–æ–Ω—Ñ—ñ–≥—É—Ä–∞—Ü—ñ—é
            test_config = config.copy()
            test_config.pop('name', None)  # –í–∏–¥–∞–ª—è—î–º–æ –ø—Ä–æ–±–ª–µ–º–Ω–∏–π –ø–∞—Ä–∞–º–µ—Ç—Ä
            
            # ‚úÖ –û–ü–¢–ò–ú–ê–õ–¨–ù–Ü –†–û–ó–ú–Ü–†–ò –î–ê–ù–ò–• –î–õ–Ø –ö–û–ñ–ù–û–á –ú–û–î–ï–õ–Ü
            model_type = test_config.get('model_type', 'linear')
            
            if model_type == 'krr':
                optimal_data = 8000  # KRR –ø–æ—Ç—Ä–µ–±—É—î –±–∞–≥–∞—Ç–æ –¥–∞–Ω–∏—Ö
            elif model_type == 'svr':
                optimal_data = 5000  # SVR –º–µ–Ω—à–µ
            else:
                optimal_data = 3000  # Linear –¥–æ—Å—Ç–∞—Ç–Ω—å–æ
            
            # –û–Ω–æ–≤–ª—é—î–º–æ –∫–æ–Ω—Ñ—ñ–≥—É—Ä–∞—Ü—ñ—é
            test_config.update({
                'N_data': optimal_data,  # ‚Üê –ö–õ–Æ–ß–û–í–ï –ü–û–ö–†–ê–©–ï–ù–ù–Ø!
                'control_pts': comparison_steps,
                'run_analysis': False,
                'find_optimal_params': True,  # ‚úÖ –û–±–æ–≤'—è–∑–∫–æ–≤–æ —É–≤—ñ–º–∫–Ω–µ–Ω–æ!
                'train_size': 0.7,
                'val_size': 0.15,
                'test_size': 0.15
            })
            
            print(f"   üîß –ú–æ–¥–µ–ª—å: {model_type}, –î–∞–Ω—ñ: {optimal_data}, –û–ø—Ç–∏–º—ñ–∑–∞—Ü—ñ—è: ‚úÖ")
            print(f"   ‚öôÔ∏è –ü–∞—Ä–∞–º–µ—Ç—Ä–∏: Np={config.get('Np', '?')}, Œª={config.get('Œª_obj', '?')}")
            
            # –ó–∞–ø—É—Å–∫–∞—î–º–æ —Å–∏–º—É–ª—è—Ü—ñ—é
            start_time = time.time()
            results_df, metrics = simulate_mpc_core(hist_df, **test_config)
            test_time = time.time() - start_time
            
            # –ó–±–∏—Ä–∞—î–º–æ –º–µ—Ç—Ä–∏–∫–∏
            comparison_row = {
                'Configuration': config_name,
                'Model': f"{config.get('model_type', 'unknown')}-{config.get('kernel', 'default')}",
                'Data_Size': optimal_data,
                'Np': config.get('Np', 'unknown'),
                'Nc': config.get('Nc', 'unknown'),
                'Lambda': config.get('Œª_obj', 'unknown'),
                'Test_Time_Min': test_time / 60
            }
            
            # –î–æ–¥–∞—î–º–æ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∏
            if isinstance(metrics, dict):
                comparison_row['RMSE_Fe'] = metrics.get('test_rmse_conc_fe', np.nan)
                comparison_row['RMSE_Mass'] = metrics.get('test_rmse_conc_mass', np.nan)
                comparison_row['R2_Fe'] = metrics.get('r2_fe', np.nan)
                comparison_row['R2_Mass'] = metrics.get('r2_mass', np.nan)
                comparison_row['Quality_Score'] = metrics.get('quality_score', np.nan)
                comparison_row['Real_Time_Suitable'] = metrics.get('real_time_suitable', False)
            
            comparison_results.append(comparison_row)
            
            # –ó–≤—ñ—Ç
            rmse_fe = comparison_row.get('RMSE_Fe', float('inf'))
            r2_fe = comparison_row.get('R2_Fe', 0)
            quality = comparison_row.get('Quality_Score', 1)
            
            print(f"   ‚úÖ –†–µ–∑—É–ª—å—Ç–∞—Ç–∏:")
            print(f"      RMSE Fe: {rmse_fe:.4f}")
            print(f"      R¬≤ Fe: {r2_fe:.4f}")
            print(f"      –Ø–∫—ñ—Å—Ç—å: {quality:.4f}")
            print(f"      –ß–∞—Å: {test_time/60:.1f}—Ö–≤")
            
        except Exception as e:
            print(f"   ‚ùå –ü–æ–º–∏–ª–∫–∞: {e}")
            comparison_results.append({
                'Configuration': config_name,
                'Error': str(e)
            })
    
    # –°—Ç–≤–æ—Ä—é—î–º–æ DataFrame
    comparison_df = pd.DataFrame(comparison_results)
    
    # –ë–µ–∑–ø–µ—á–Ω–µ —Å–æ—Ä—Ç—É–≤–∞–Ω–Ω—è (–≤–∏–∫–æ—Ä–∏—Å—Ç–æ–≤—É—î–º–æ —Ç—É —Å–∞–º—É —Ñ—É–Ω–∫—Ü—ñ—é —â–æ –≤ enhanced_benchmark.py)
    if not comparison_df.empty and 'RMSE_Fe' in comparison_df.columns:
        # –í—ñ–¥—Ñ—ñ–ª—å—Ç—Ä–æ–≤—É—î–º–æ NaN –ø–µ—Ä–µ–¥ —Å–æ—Ä—Ç—É–≤–∞–Ω–Ω—è–º
        valid_mask = comparison_df['RMSE_Fe'].notna()
        if valid_mask.any():
            valid_df = comparison_df[valid_mask].sort_values('RMSE_Fe')
            invalid_df = comparison_df[~valid_mask]
            comparison_df = pd.concat([valid_df, invalid_df], ignore_index=True)
    
    print(f"\nüìä –ü–Ü–î–°–£–ú–û–ö –ü–û–ö–†–ê–©–ï–ù–û–ì–û –ü–û–†–Ü–í–ù–Ø–ù–ù–Ø:")
    if not comparison_df.empty:
        display_cols = ['Configuration', 'Model', 'Data_Size', 'RMSE_Fe', 'R2_Fe', 'Quality_Score']
        available_cols = [col for col in display_cols if col in comparison_df.columns]
        if available_cols:
            print(comparison_df[available_cols].round(4))
    
    return comparison_df
        
# def load_historical_data() -> pd.DataFrame:
#     """–ó–∞–≤–∞–Ω—Ç–∞–∂—É—î —ñ—Å—Ç–æ—Ä–∏—á–Ω—ñ –¥–∞–Ω—ñ –¥–ª—è —Å–∏–º—É–ª—è—Ü—ñ—ó"""
    
#     # –°–ø—Ä–æ–±—É—î–º–æ –∑–∞–≤–∞–Ω—Ç–∞–∂–∏—Ç–∏ –∑ —Ä—ñ–∑–Ω–∏—Ö –º—ñ—Å—Ü—å
#     possible_paths = [
#         'processed.parquet',
#         'data/processed.parquet', 
#         '/content/KModel/src/processed.parquet',
#         '../data/processed.parquet'
#     ]
    
#     for path in possible_paths:
#         try:
#             hist_df = pd.read_parquet(path)
#             print(f"‚úÖ –î–∞–Ω—ñ –∑–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–æ –∑: {path}")
#             print(f"   üìä –†–æ–∑–º—ñ—Ä: {hist_df.shape[0]} —Ä—è–¥–∫—ñ–≤, {hist_df.shape[1]} –∫–æ–ª–æ–Ω–æ–∫")
#             return hist_df
#         except FileNotFoundError:
#             continue
#         except Exception as e:
#             print(f"‚ö†Ô∏è –ü–æ–º–∏–ª–∫–∞ –∑–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–Ω—è –∑ {path}: {e}")
#             continue
    
#     raise FileNotFoundError("‚ùå –ù–µ –≤–¥–∞–ª–æ—Å—è –∑–Ω–∞–π—Ç–∏ —Ñ–∞–π–ª processed.parquet")

def progress_callback(step: int, total: int, message: str):
    """Callback –¥–ª—è –≤—ñ–¥–æ–±—Ä–∞–∂–µ–Ω–Ω—è –ø—Ä–æ–≥—Ä–µ—Å—É"""
    if step % 50 == 0 or step == total or '–∑–∞–≤–µ—Ä—à–µ–Ω' in message.lower():
        progress_pct = (step / total * 100) if total > 0 else 0
        print(f"   üìà [{step:4d}/{total:4d}] {progress_pct:5.1f}% - {message}")

def example_1_quick_benchmark():
    """üöÄ –ü—Ä–∏–∫–ª–∞–¥ 1: –®–≤–∏–¥–∫–∏–π –±–µ–Ω—á–º–∞—Ä–∫ —Ä—ñ–∑–Ω–∏—Ö –º–æ–¥–µ–ª–µ–π"""
    
    print("\n" + "="*70)
    print("üöÄ –ü–†–ò–ö–õ–ê–î 1: –®–í–ò–î–ö–ò–ô –ë–ï–ù–ß–ú–ê–†–ö –ú–û–î–ï–õ–ï–ô MPC")
    print("="*70)
    
    try:
        hist_df = load_historical_data()
        
        # –ó–∞–ø—É—Å–∫–∞—î–º–æ —à–≤–∏–¥–∫–∏–π –±–µ–Ω—á–º–∞—Ä–∫
        models_to_test = ['krr', 'svr', 'linear']
        
        print(f"üß™ –¢–µ—Å—Ç—É—î–º–æ {len(models_to_test)} –º–æ–¥–µ–ª–µ–π...")
        start_time = time.time()
        
        results_df = quick_mpc_benchmark(
            hist_df=hist_df,
            config='oleksandr_original',
            models_to_test=models_to_test,
            save_results=True
        )
        
        total_time = time.time() - start_time
        
        print(f"\nüìä –†–ï–ó–£–õ–¨–¢–ê–¢–ò –®–í–ò–î–ö–û–ì–û –ë–ï–ù–ß–ú–ê–†–ö–£:")
        print(f"   ‚è±Ô∏è –ó–∞–≥–∞–ª—å–Ω–∏–π —á–∞—Å: {total_time:.1f} —Å–µ–∫—É–Ω–¥")
        print(f"   üèÜ –ù–∞–π–∫—Ä–∞—â–∞ –º–æ–¥–µ–ª—å: {results_df.iloc[0]['Model']}")
        
        # –ü–æ–∫–∞–∑—É—î–º–æ —Ç–æ–ø —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∏
        print(f"\nüèÖ –¢–û–ü-3 –ú–û–î–ï–õ–Ü:")
        top_3 = results_df.head(3)
        for idx, row in top_3.iterrows():
            rank = idx + 1
            medal = "ü•á" if rank == 1 else "ü•à" if rank == 2 else "ü•â"
            print(f"   {medal} {row['Model']}: RMSE_Fe={row['RMSE_Fe']:.4f}, "
                  f"–Ø–∫—ñ—Å—Ç—å={row['Quality_Score']:.3f}, "
                  f"–ß–∞—Å={row['Cycle_Time_Ms']:.1f}ms")
        
        return results_df
        
    except Exception as e:
        print(f"‚ùå –ü–æ–º–∏–ª–∫–∞ –≤ –ø—Ä–∏–∫–ª–∞–¥—ñ 1: {e}")
        return None

def example_2_detailed_analysis():
    """üî¨ –ü—Ä–∏–∫–ª–∞–¥ 2: –î–µ—Ç–∞–ª—å–Ω–∏–π –∞–Ω–∞–ª—ñ–∑ –∫–æ–Ω–∫—Ä–µ—Ç–Ω–æ—ó –∫–æ–Ω—Ñ—ñ–≥—É—Ä–∞—Ü—ñ—ó"""
    
    print("\n" + "="*70)
    print("üî¨ –ü–†–ò–ö–õ–ê–î 2: –î–ï–¢–ê–õ–¨–ù–ò–ô –ê–ù–ê–õ–Ü–ó MPC")
    print("="*70)
    
    try:
        hist_df = load_historical_data()
        
        # –ö–æ–Ω—Ñ—ñ–≥—É—Ä–∞—Ü—ñ—è –¥–ª—è –¥–µ—Ç–∞–ª—å–Ω–æ–≥–æ –∞–Ω–∞–ª—ñ–∑—É
        config_overrides = {
            'model_type': 'krr',
            'kernel': 'rbf',
            'Np': 8,
            'Nc': 6,
            'N_data': 3000,  # –ë—ñ–ª—å—à–µ –¥–∞–Ω–∏—Ö –¥–ª—è —Ç–æ—á–Ω–æ–≥–æ –∞–Ω–∞–ª—ñ–∑—É
            'control_pts': 500
        }
        
        print("üî¨ –ó–∞–ø—É—Å–∫–∞—î–º–æ –¥–µ—Ç–∞–ª—å–Ω–∏–π –∞–Ω–∞–ª—ñ–∑...")
        print(f"   üìã –ö–æ–Ω—Ñ—ñ–≥—É—Ä–∞—Ü—ñ—è: {config_overrides}")
        
        start_time = time.time()
        
        analysis_report = detailed_mpc_analysis(
            hist_df=hist_df,
            config='oleksandr_original',
            config_overrides=config_overrides
        )
        
        analysis_time = time.time() - start_time
        
        print(f"\nüìã –î–ï–¢–ê–õ–¨–ù–ò–ô –ó–í–Ü–¢:")
        print(f"   ‚è±Ô∏è –ß–∞—Å –∞–Ω–∞–ª—ñ–∑—É: {analysis_time:.1f} —Å–µ–∫—É–Ω–¥")
        
        # –û—Å–Ω–æ–≤–Ω—ñ –º–µ—Ç—Ä–∏–∫–∏
        basic_metrics = analysis_report['basic_metrics']
        print(f"\nüìä –û–°–ù–û–í–ù–Ü –ú–ï–¢–†–ò–ö–ò:")
        for key, value in basic_metrics.items():
            if isinstance(value, (int, float)):
                print(f"   ‚Ä¢ {key}: {value:.6f}")
        
        # –ú–µ—Ç—Ä–∏–∫–∏ —à–≤–∏–¥–∫–æ—Å—Ç—ñ  
        speed_metrics = analysis_report['speed_metrics']
        print(f"\n‚ö° –®–í–ò–î–ö–û–î–Ü–Ø:")
        for key, value in speed_metrics.items():
            if isinstance(value, (int, float)):
                if 'time' in key.lower():
                    unit = "ms" if value < 1 else "—Å"
                    display_value = value * 1000 if value < 1 else value
                    print(f"   ‚Ä¢ {key}: {display_value:.2f}{unit}")
        
        # –†–µ–∫–æ–º–µ–Ω–¥–∞—Ü—ñ—ó
        recommendations = analysis_report['recommendations']
        if recommendations:
            print(f"\nüí° –†–ï–ö–û–ú–ï–ù–î–ê–¶–Ü–á ({len(recommendations)}):")
            for i, rec in enumerate(recommendations, 1):
                print(f"   {i}. {rec}")
        else:
            print(f"\n‚úÖ –°–ò–°–¢–ï–ú–ê –ü–†–ê–¶–Æ–Ñ –û–ü–¢–ò–ú–ê–õ–¨–ù–û!")
        
        return analysis_report
        
    except Exception as e:
        print(f"‚ùå –ü–æ–º–∏–ª–∫–∞ –≤ –ø—Ä–∏–∫–ª–∞–¥—ñ 2: {e}")
        return None

def example_3_custom_simulation():
    """üéØ –ü—Ä–∏–∫–ª–∞–¥ 3: –ö–æ—Ä–∏—Å—Ç—É–≤–∞—Ü—å–∫–∞ —Å–∏–º—É–ª—è—Ü—ñ—è –∑ –±–µ–Ω—á–º–∞—Ä–∫–æ–º"""
    
    print("\n" + "="*70)
    print("üéØ –ü–†–ò–ö–õ–ê–î 3: –ö–û–†–ò–°–¢–£–í–ê–¶–¨–ö–ê –°–ò–ú–£–õ–Ø–¶–Ü–Ø –ó –ë–ï–ù–ß–ú–ê–†–ö–û–ú")
    print("="*70)
    
    try:
        hist_df = load_historical_data()
        
        # –ö–æ—Ä–∏—Å—Ç—É–≤–∞—Ü—å–∫–∞ –∫–æ–Ω—Ñ—ñ–≥—É—Ä–∞—Ü—ñ—è
        custom_config = {
            'model_type': 'gpr',  # Gaussian Process Regression
            'kernel': 'rbf',
            'Np': 10,  # –ë—ñ–ª—å—à–∏–π –≥–æ—Ä–∏–∑–æ–Ω—Ç –ø—Ä–æ–≥–Ω–æ–∑—É–≤–∞–Ω–Ω—è
            'Nc': 8,   # –ë—ñ–ª—å—à–∏–π –≥–æ—Ä–∏–∑–æ–Ω—Ç –∫–µ—Ä—É–≤–∞–Ω–Ω—è
            'w_fe': 10.0,  # –ë—ñ–ª—å—à–∞ –≤–∞–≥–∞ –¥–ª—è Fe
            'w_mass': 1.5,
            'Œª_obj': 0.05,  # –ú–µ–Ω—à–µ –∑–≥–ª–∞–¥–∂—É–≤–∞–Ω–Ω—è
            'ref_fe': 54.0,  # –í–∏—â–∞ —É—Å—Ç–∞–≤–∫–∞ Fe
            'ref_mass': 58.0,
            'N_data': 4000,
            'control_pts': 800,
            'find_optimal_params': True  # –û–ø—Ç–∏–º—ñ–∑–∞—Ü—ñ—è –≥—ñ–ø–µ—Ä–ø–∞—Ä–∞–º–µ—Ç—Ä—ñ–≤
        }
        
        print("üéØ –ó–∞–ø—É—Å–∫–∞—î–º–æ –∫–æ—Ä–∏—Å—Ç—É–≤–∞—Ü—å–∫—É —Å–∏–º—É–ª—è—Ü—ñ—é...")
        print(f"   üìã –û—Å–æ–±–ª–∏–≤–æ—Å—Ç—ñ:")
        print(f"      ‚Ä¢ –ú–æ–¥–µ–ª—å: {custom_config['model_type'].upper()}")
        print(f"      ‚Ä¢ –ì–æ—Ä–∏–∑–æ–Ω—Ç–∏: Np={custom_config['Np']}, Nc={custom_config['Nc']}")
        print(f"      ‚Ä¢ –£—Å—Ç–∞–≤–∫–∏: Fe={custom_config['ref_fe']}, Mass={custom_config['ref_mass']}")
        print(f"      ‚Ä¢ –û–ø—Ç–∏–º—ñ–∑–∞—Ü—ñ—è –≥—ñ–ø–µ—Ä–ø–∞—Ä–∞–º–µ—Ç—Ä—ñ–≤: ‚úÖ")
        
        start_time = time.time()
        
        results_df, metrics = simulate_mpc(
            hist_df,
            config='oleksandr_original',
            config_overrides=custom_config,
            # üÜï –£–≤—ñ–º–∫–Ω—É—Ç—ñ —Ä–æ–∑—à–∏—Ä–µ–Ω—ñ —Ñ—É–Ω–∫—Ü—ñ—ó –±–µ–Ω—á–º–∞—Ä–∫—É
            enable_comprehensive_analysis=True,
            benchmark_control_quality=True,
            save_benchmark_results=True,
            progress_callback=progress_callback
        )
        
        simulation_time = time.time() - start_time
        
        print(f"\nüéØ –†–ï–ó–£–õ–¨–¢–ê–¢–ò –ö–û–†–ò–°–¢–£–í–ê–¶–¨–ö–û–á –°–ò–ú–£–õ–Ø–¶–Ü–á:")
        print(f"   ‚è±Ô∏è –ß–∞—Å —Å–∏–º—É–ª—è—Ü—ñ—ó: {simulation_time/60:.1f} —Ö–≤–∏–ª–∏–Ω")
        print(f"   üìä –¢–æ—á–æ–∫ –¥–∞–Ω–∏—Ö: {len(results_df)}")
        
        # –ö–ª—é—á–æ–≤—ñ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∏
        key_results = {
            'RMSE Fe': metrics.get('test_rmse_conc_fe', 'N/A'),
            'RMSE Mass': metrics.get('test_rmse_conc_mass', 'N/A'), 
            'R¬≤ Fe': metrics.get('r2_fe', 'N/A'),
            'R¬≤ Mass': metrics.get('r2_mass', 'N/A'),
            '–Ø–∫—ñ—Å—Ç—å –∫–µ—Ä—É–≤–∞–Ω–Ω—è': metrics.get('quality_score', 'N/A'),
            '–ß–∞—Å —Ü–∏–∫–ª—É (ms)': metrics.get('total_cycle_time', 0) * 1000,
            'Real-time –ø—Ä–∏–¥–∞—Ç–Ω—ñ—Å—Ç—å': metrics.get('real_time_suitable', False)
        }
        
        print(f"\nüìà –ö–õ–Æ–ß–û–í–Ü –†–ï–ó–£–õ–¨–¢–ê–¢–ò:")
        for key, value in key_results.items():
            if isinstance(value, (int, float)):
                if 'R¬≤' in key:
                    print(f"   ‚Ä¢ {key}: {value:.4f}")
                elif 'RMSE' in key or '–Ø–∫—ñ—Å—Ç—å' in key:
                    print(f"   ‚Ä¢ {key}: {value:.6f}")
                elif 'ms' in key:
                    print(f"   ‚Ä¢ {key}: {value:.1f}")
                else:
                    print(f"   ‚Ä¢ {key}: {value}")
            else:
                print(f"   ‚Ä¢ {key}: {value}")
        
        # –ê–Ω–∞–ª—ñ–∑ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ñ–≤
        print(f"\nüîç –ê–ù–ê–õ–Ü–ó:")
        
        # –Ø–∫—ñ—Å—Ç—å –º–æ–¥–µ–ª—ñ
        rmse_fe = metrics.get('test_rmse_conc_fe', float('inf'))
        if rmse_fe < 0.05:
            print(f"   ‚úÖ –í—ñ–¥–º—ñ–Ω–Ω–∞ —Ç–æ—á–Ω—ñ—Å—Ç—å –º–æ–¥–µ–ª—ñ Fe (RMSE < 0.05)")
        elif rmse_fe < 0.1:
            print(f"   üëç –•–æ—Ä–æ—à–∞ —Ç–æ—á–Ω—ñ—Å—Ç—å –º–æ–¥–µ–ª—ñ Fe (RMSE < 0.1)")
        else:
            print(f"   ‚ö†Ô∏è –ü–æ—Ç—Ä–µ–±—É—î –ø–æ–∫—Ä–∞—â–µ–Ω–Ω—è —Ç–æ—á–Ω–æ—Å—Ç—ñ Fe (RMSE > 0.1)")
        
        # –®–≤–∏–¥–∫–æ–¥—ñ—è
        cycle_time = metrics.get('total_cycle_time', 0) * 1000
        if cycle_time < 1000:  # < 1 —Å–µ–∫—É–Ω–¥–∏
            print(f"   ‚ö° –í—ñ–¥–º—ñ–Ω–Ω–∞ —à–≤–∏–¥–∫–æ–¥—ñ—è ({cycle_time:.0f}ms)")
        elif cycle_time < 5000:  # < 5 —Å–µ–∫—É–Ω–¥
            print(f"   üëç –ü—Ä–∏–π–Ω—è—Ç–Ω–∞ —à–≤–∏–¥–∫–æ–¥—ñ—è –¥–ª—è real-time ({cycle_time:.0f}ms)")
        else:
            print(f"   üêå –ü–æ–≤—ñ–ª—å–Ω–∞ —à–≤–∏–¥–∫–æ–¥—ñ—è ({cycle_time:.0f}ms)")
        
        # –Ø–∫—ñ—Å—Ç—å –∫–µ—Ä—É–≤–∞–Ω–Ω—è
        quality_score = metrics.get('quality_score', 1.0)
        if quality_score < 0.3:
            print(f"   üéØ –í—ñ–¥–º—ñ–Ω–Ω–∞ —è–∫—ñ—Å—Ç—å –∫–µ—Ä—É–≤–∞–Ω–Ω—è")
        elif quality_score < 0.5:
            print(f"   üëç –•–æ—Ä–æ—à–∞ —è–∫—ñ—Å—Ç—å –∫–µ—Ä—É–≤–∞–Ω–Ω—è")
        else:
            print(f"   ‚ö†Ô∏è –ü–æ—Ç—Ä–µ–±—É—î –Ω–∞–ª–∞—à—Ç—É–≤–∞–Ω–Ω—è –ø–∞—Ä–∞–º–µ—Ç—Ä—ñ–≤ MPC")
        
        return results_df, metrics
        
    except Exception as e:
        print(f"‚ùå –ü–æ–º–∏–ª–∫–∞ –≤ –ø—Ä–∏–∫–ª–∞–¥—ñ 3: {e}")
        return None, None

def example_4_model_comparison_truly_correct():
    """üîÑ –ü—Ä–∏–∫–ª–∞–¥ 4: –ê–ë–°–û–õ–Æ–¢–ù–û –ü–†–ê–í–ò–õ–¨–ù–ï –ø–æ—Ä—ñ–≤–Ω—è–Ω–Ω—è –±–µ–∑ –≤—Ç—Ä—É—á–∞–Ω–Ω—è"""
    
    print("\n" + "="*70)
    print("üîÑ –ü–†–ò–ö–õ–ê–î 4: –ü–†–ê–í–ò–õ–¨–ù–ï –ü–û–†–Ü–í–ù–Ø–ù–ù–Ø –ë–ï–ó –í–¢–†–£–ß–ê–ù–ù–Ø")
    print("="*70)
    
    try:
        hist_df = load_historical_data()
        
        # üéØ –ï–ö–°–ü–ï–†–ò–ú–ï–ù–¢–ê–¢–û–† –ó–ê–î–ê–Ñ –ö–û–ù–§–Ü–ì–£–†–ê–¶–Ü–á
        configurations = [
            {
                'name': 'KRR_Conservative',
                'model_type': 'krr',
                'kernel': 'rbf', 
                'Np': 6,
                'Nc': 4,
                'Œª_obj': 0.2,
                'w_fe': 5.0,
                'w_mass': 1.0
                # –Ü–Ω—à—ñ –ø–∞—Ä–∞–º–µ—Ç—Ä–∏ - –∑–∞ –∑–∞–º–æ–≤—á—É–≤–∞–Ω–Ω—è–º –∑ simulate_mpc_core_enhanced
            },
            {
                'name': 'KRR_Aggressive', 
                'model_type': 'krr',
                'kernel': 'rbf',
                'Np': 8,
                'Nc': 6,
                'Œª_obj': 0.05,
                'w_fe': 10.0,
                'w_mass': 1.5,
                'N_data': 12000,  # –ï–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç–∞—Ç–æ—Ä —Ö–æ—á–µ –±—ñ–ª—å—à–µ –¥–∞–Ω–∏—Ö
                'find_optimal_params': False  # –ï–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç–∞—Ç–æ—Ä –ù–ï —Ö–æ—á–µ –æ–ø—Ç–∏–º—ñ–∑–∞—Ü—ñ—ó
            },
            {
                'name': 'SVR_Balanced',
                'model_type': 'svr',
                'kernel': 'rbf',
                'Np': 7,
                'Nc': 5,
                'Œª_obj': 0.1,
                'w_fe': 7.0,
                'w_mass': 1.2
            },
            {
                'name': 'Linear_Fast',
                'model_type': 'linear',
                'linear_type': 'ridge',
                'Np': 10,
                'Nc': 8,
                'Œª_obj': 0.15,
                'w_fe': 6.0,
                'w_mass': 1.0,
                'verbose_reports': True,  # –ï–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç–∞—Ç–æ—Ä —Ö–æ—á–µ –±–∞—á–∏—Ç–∏ –∑–≤—ñ—Ç –¥–ª—è —Ü—ñ—î—ó –∫–æ–Ω—Ñ—ñ–≥—É—Ä–∞—Ü—ñ—ó
                'silent_mode': False
            }
        ]
        
        print(f"üéØ –ü–æ—Ä—ñ–≤–Ω—é—î–º–æ {len(configurations)} –∫–æ–Ω—Ñ—ñ–≥—É—Ä–∞—Ü—ñ–π –ë–ï–ó –≤—Ç—Ä—É—á–∞–Ω–Ω—è...")
        
        start_time = time.time()
        
        # üîß –í–ò–ö–û–†–ò–°–¢–û–í–£–Ñ–ú–û –ü–†–ê–í–ò–õ–¨–ù–£ –§–£–ù–ö–¶–Ü–Æ
        comparison_df = compare_mpc_configurations_correct(
            configurations=configurations,
            hist_df=hist_df,
            base_config='oleksandr_original',
            comparison_steps=100,
            show_progress=True
        )
        
        comparison_time = time.time() - start_time
        
        print(f"\n‚è±Ô∏è –ó–∞–≥–∞–ª—å–Ω–∏–π —á–∞—Å –ø–æ—Ä—ñ–≤–Ω—è–Ω–Ω—è: {comparison_time/60:.1f} —Ö–≤–∏–ª–∏–Ω")
        print(f"‚úÖ –ñ–æ–¥–Ω–æ–≥–æ –≤—Ç—Ä—É—á–∞–Ω–Ω—è –≤ –∫–æ–Ω—Ñ—ñ–≥—É—Ä–∞—Ü—ñ—ó –µ–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç–∞—Ç–æ—Ä–∞!")
        
        return comparison_df
        
    except Exception as e:
        print(f"‚ùå –ü–æ–º–∏–ª–∫–∞ –≤ –ø—Ä–∏–∫–ª–∞–¥—ñ 4: {e}")
        return None

def compute_correct_mpc_metrics_silent(results_df, basic_metrics, reference_values=None):
    """
    üéØ –ú–û–î–ò–§–Ü–ö–û–í–ê–ù–ê –≤–µ—Ä—Å—ñ—è –∑ –æ–±—á–∏—Å–ª–µ–Ω–Ω—è–º —Ç–∞ –≤–∏–≤–æ–¥–æ–º ISE/IAE –º–µ—Ç—Ä–∏–∫
    
    üîß –ó–ú–Ü–ù–ê: –î–æ–¥–∞–Ω–æ –æ–±—á–∏—Å–ª–µ–Ω–Ω—è —Ç–∞ –∑–±–µ—Ä–µ–∂–µ–Ω–Ω—è ISE/IAE –¥–ª—è –∑–≤—ñ—Ç—É –ø–æ—Ä—ñ–≤–Ω—è–Ω–Ω—è
    """
    
    if reference_values is None:
        reference_values = {'fe': 53.5, 'mass': 57.0}
    
    mpc_metrics = {}
    
    # 1. üìä –ú–ï–¢–†–ò–ö–ò –¢–û–ß–ù–û–°–¢–Ü –í–Ü–î–°–õ–Ü–î–ö–û–í–£–í–ê–ù–ù–Ø
    if 'conc_fe' in results_df.columns:
        fe_values = results_df['conc_fe'].dropna().values
        fe_setpoint = reference_values['fe']
        
        fe_mean_error = np.mean(fe_values) - fe_setpoint
        fe_abs_error = np.mean(np.abs(fe_values - fe_setpoint))
        fe_max_error = np.max(np.abs(fe_values - fe_setpoint))
        fe_std_error = np.std(fe_values - fe_setpoint)
        
        fe_tolerance = 0.3
        fe_in_tolerance = np.mean(np.abs(fe_values - fe_setpoint) <= fe_tolerance) * 100
        
        mpc_metrics.update({
            'tracking_error_fe_mean': fe_mean_error,
            'tracking_error_fe_mae': fe_abs_error,
            'tracking_error_fe_max': fe_max_error,
            'tracking_error_fe_std': fe_std_error,
            'tracking_fe_in_tolerance_pct': fe_in_tolerance,
            'tracking_fe_setpoint': fe_setpoint,
            'tracking_fe_achieved': np.mean(fe_values)
        })
    
    if 'conc_mass' in results_df.columns:
        mass_values = results_df['conc_mass'].dropna().values
        mass_setpoint = reference_values['mass']
        
        mass_mean_error = np.mean(mass_values) - mass_setpoint
        mass_abs_error = np.mean(np.abs(mass_values - mass_setpoint))
        
        mass_tolerance = 2.0
        mass_in_tolerance = np.mean(np.abs(mass_values - mass_setpoint) <= mass_tolerance) * 100
        
        mpc_metrics.update({
            'tracking_error_mass_mean': mass_mean_error,
            'tracking_error_mass_mae': mass_abs_error,
            'tracking_mass_in_tolerance_pct': mass_in_tolerance,
            'tracking_mass_setpoint': mass_setpoint,
            'tracking_mass_achieved': np.mean(mass_values)
        })
    
    # 2. üìà –ú–ï–¢–†–ò–ö–ò –°–¢–ê–ë–Ü–õ–¨–ù–û–°–¢–Ü –ö–ï–†–£–í–ê–ù–ù–Ø
    if 'solid_feed_percent' in results_df.columns:
        control_actions = results_df['solid_feed_percent'].dropna().values
        
        control_std = np.std(control_actions)
        control_mean = np.mean(control_actions)
        
        if len(control_actions) > 1:
            control_changes = np.diff(control_actions)
            control_smoothness = np.std(control_changes)
        else:
            control_smoothness = 0
        
        mpc_metrics.update({
            'control_mean': control_mean,
            'control_std': control_std,
            'control_smoothness': control_smoothness
        })
    
    # 3. üÜï –Ü–ù–¢–ï–ì–†–ê–õ–¨–ù–Ü –ú–ï–¢–†–ò–ö–ò –Ø–ö–û–°–¢–Ü (ISE/IAE)
    mpc_metrics.update(calculate_ise_iae_metrics(results_df, reference_values))
    
    # 4. üìä –ó–ê–ì–ê–õ–¨–ù–ê –û–¶–Ü–ù–ö–ê MPC
    quality_factors = []
    
    if 'tracking_error_fe_mae' in mpc_metrics:
        mae_fe = mpc_metrics['tracking_error_fe_mae']
        fe_accuracy = max(0, 40 - mae_fe * 50)
        quality_factors.append(('Fe —Ç–æ—á–Ω—ñ—Å—Ç—å', fe_accuracy, 40))
    
    if 'tracking_error_mass_mae' in mpc_metrics:
        mae_mass = mpc_metrics['tracking_error_mass_mae']
        mass_accuracy = max(0, 30 - mae_mass * 15)
        quality_factors.append(('Mass —Ç–æ—á–Ω—ñ—Å—Ç—å', mass_accuracy, 30))
    
    if 'control_smoothness' in mpc_metrics:
        smoothness = mpc_metrics['control_smoothness']
        control_stability = max(0, 20 - smoothness * 20)
        quality_factors.append(('–°—Ç–∞–±—ñ–ª—å–Ω—ñ—Å—Ç—å', control_stability, 20))
    
    if 'tracking_fe_in_tolerance_pct' in mpc_metrics:
        consistency_pct = mpc_metrics['tracking_fe_in_tolerance_pct']
        consistency = consistency_pct / 10
        quality_factors.append(('–ö–æ–Ω—Å–∏—Å—Ç–µ–Ω—Ç–Ω—ñ—Å—Ç—å', consistency, 10))
    
    if quality_factors:
        total_score = sum(factor[1] for factor in quality_factors)
        max_possible = sum(factor[2] for factor in quality_factors)
        mpc_quality_score = (total_score / max_possible) * 100
        mpc_metrics['mpc_quality_score'] = mpc_quality_score
        
        # –ö–ª–∞—Å–∏—Ñ—ñ–∫–∞—Ü—ñ—è
        if mpc_quality_score >= 80:
            quality_class = "–ü—Ä–æ–º–∏—Å–ª–æ–≤–æ –≤—ñ–¥–º—ñ–Ω–Ω–æ"
        elif mpc_quality_score >= 65:
            quality_class = "–ü—Ä–æ–º–∏—Å–ª–æ–≤–æ –¥–æ–±—Ä–µ"  
        elif mpc_quality_score >= 50:
            quality_class = "–ü—Ä–æ–º–∏—Å–ª–æ–≤–æ –ø—Ä–∏–π–Ω—è—Ç–Ω–æ"
        else:
            quality_class = "–ü–æ—Ç—Ä–µ–±—É—î –ø–æ–∫—Ä–∞—â–µ–Ω–Ω—è"
        
        mpc_metrics['mpc_quality_class'] = quality_class
    
    # 5. üí° –†–ï–ö–û–ú–ï–ù–î–ê–¶–Ü–á
    recommendations = []
    
    if mpc_metrics.get('tracking_error_fe_mae', 0) <= 0.5:
        recommendations.append("‚úÖ –í—ñ–¥–º—ñ–Ω–Ω–∞ —Ç–æ—á–Ω—ñ—Å—Ç—å Fe - –ø—Ä–æ–¥–æ–≤–∂—É–π—Ç–µ!")
    
    if mpc_metrics.get('control_smoothness', 0) <= 0.5:
        recommendations.append("‚úÖ –°—Ç–∞–±—ñ–ª—å–Ω–µ –∫–µ—Ä—É–≤–∞–Ω–Ω—è - –¥–æ–±—Ä–µ –Ω–∞–ª–∞—à—Ç–æ–≤–∞–Ω–æ!")
    
    if not recommendations:
        recommendations.append("MPC –ø—Ä–∞—Ü—é—î –¥–æ–±—Ä–µ –≤ –ø—Ä–æ–º–∏—Å–ª–æ–≤–∏—Ö —É–º–æ–≤–∞—Ö!")
    
    mpc_metrics['recommendations'] = recommendations
    
    # –û–Ω–æ–≤–ª—é—î–º–æ –º–µ—Ç—Ä–∏–∫–∏
    basic_metrics.update(mpc_metrics)
    basic_metrics['mpc_evaluation_method'] = 'realistic_industrial_criteria'
    
    return basic_metrics


def calculate_ise_iae_metrics(results_df, reference_values):
    """
    üÜï –ù–û–í–ò–ô –ú–ï–¢–û–î: –û–±—á–∏—Å–ª—é—î ISE/IAE –º–µ—Ç—Ä–∏–∫–∏ –¥–ª—è –∑–≤—ñ—Ç—É –ø–æ—Ä—ñ–≤–Ω—è–Ω–Ω—è
    
    Args:
        results_df: DataFrame –∑ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞–º–∏ —Å–∏–º—É–ª—è—Ü—ñ—ó
        reference_values: –°–ª–æ–≤–Ω–∏–∫ –∑ —É—Å—Ç–∞–≤–∫–∞–º–∏ {'fe': 53.5, 'mass': 57.0}
        
    Returns:
        dict: –°–ª–æ–≤–Ω–∏–∫ –∑ ISE/IAE –º–µ—Ç—Ä–∏–∫–∞–º–∏
    """
    
    ise_iae_metrics = {}
    
    # ISE/IAE –¥–ª—è Fe –∫–æ–Ω—Ü–µ–Ω—Ç—Ä–∞—Ç—É
    if 'conc_fe' in results_df.columns:
        fe_values = results_df['conc_fe'].dropna().values
        fe_setpoint = reference_values['fe']
        
        # –û–±—á–∏—Å–ª—é—î–º–æ –ø–æ–º–∏–ª–∫–∏
        fe_errors = fe_values - fe_setpoint
        
        # ISE (Integral Square Error)
        ise_fe = np.sum(fe_errors**2)
        
        # IAE (Integral Absolute Error)  
        iae_fe = np.sum(np.abs(fe_errors))
        
        # ITSE (Integral Time Square Error)
        time_weights = np.arange(1, len(fe_errors) + 1)
        itse_fe = np.sum(time_weights * fe_errors**2)
        
        # ITAE (Integral Time Absolute Error)
        itae_fe = np.sum(time_weights * np.abs(fe_errors))
        
        ise_iae_metrics.update({
            'performance_ise_fe': ise_fe,
            'performance_iae_fe': iae_fe,
            'performance_itse_fe': itse_fe,
            'performance_itae_fe': itae_fe,
            # –ù–æ—Ä–º–∞–ª—ñ–∑–æ–≤–∞–Ω—ñ –º–µ—Ç—Ä–∏–∫–∏ (–Ω–∞ –æ–¥–∏–Ω–∏—Ü—é —á–∞—Å—É)
            'performance_ise_fe_normalized': ise_fe / len(fe_errors),
            'performance_iae_fe_normalized': iae_fe / len(fe_errors)
        })
    
    # ISE/IAE –¥–ª—è –º–∞—Å–æ–≤–æ–≥–æ –ø–æ—Ç–æ–∫—É
    if 'conc_mass' in results_df.columns:
        mass_values = results_df['conc_mass'].dropna().values
        mass_setpoint = reference_values['mass']
        
        # –û–±—á–∏—Å–ª—é—î–º–æ –ø–æ–º–∏–ª–∫–∏
        mass_errors = mass_values - mass_setpoint
        
        # ISE (Integral Square Error)
        ise_mass = np.sum(mass_errors**2)
        
        # IAE (Integral Absolute Error)
        iae_mass = np.sum(np.abs(mass_errors))
        
        # ITSE (Integral Time Square Error)
        time_weights = np.arange(1, len(mass_errors) + 1)
        itse_mass = np.sum(time_weights * mass_errors**2)
        
        # ITAE (Integral Time Absolute Error)
        itae_mass = np.sum(time_weights * np.abs(mass_errors))
        
        ise_iae_metrics.update({
            'performance_ise_mass': ise_mass,
            'performance_iae_mass': iae_mass,
            'performance_itse_mass': itse_mass,
            'performance_itae_mass': itae_mass,
            # –ù–æ—Ä–º–∞–ª—ñ–∑–æ–≤–∞–Ω—ñ –º–µ—Ç—Ä–∏–∫–∏ (–Ω–∞ –æ–¥–∏–Ω–∏—Ü—é —á–∞—Å—É)
            'performance_ise_mass_normalized': ise_mass / len(mass_errors),
            'performance_iae_mass_normalized': iae_mass / len(mass_errors)
        })
    
    # –ö–æ–º–±—ñ–Ω–æ–≤–∞–Ω—ñ –º–µ—Ç—Ä–∏–∫–∏
    if ('performance_ise_fe' in ise_iae_metrics and 
        'performance_ise_mass' in ise_iae_metrics):
        
        # –ó–≤–∞–∂–µ–Ω–∞ –∫–æ–º–±—ñ–Ω–æ–≤–∞–Ω–∞ ISE (60% Fe + 40% Mass)
        combined_ise = (0.6 * ise_iae_metrics['performance_ise_fe_normalized'] + 
                       0.4 * ise_iae_metrics['performance_ise_mass_normalized'])
        
        # –ó–≤–∞–∂–µ–Ω–∞ –∫–æ–º–±—ñ–Ω–æ–≤–∞–Ω–∞ IAE
        combined_iae = (0.6 * ise_iae_metrics['performance_iae_fe_normalized'] + 
                       0.4 * ise_iae_metrics['performance_iae_mass_normalized'])
        
        ise_iae_metrics.update({
            'performance_combined_ise': combined_ise,
            'performance_combined_iae': combined_iae
        })
    
    return ise_iae_metrics


def compare_mpc_configurations_correct(
    configurations: List[Dict],
    hist_df: pd.DataFrame,
    base_config: str = 'oleksandr_original',
    comparison_steps: int = 100,
    show_progress: bool = True
) -> pd.DataFrame:
    """
    üîÑ –ê–õ–ò–ê–° –¥–ª—è –∑–≤–æ—Ä–æ—Ç–Ω–æ—ó —Å—É–º—ñ—Å–Ω–æ—Å—Ç—ñ - —Ç–µ–ø–µ—Ä –≤–∏–∫–ª–∏–∫–∞—î —Ñ—É–Ω–∫—Ü—ñ—é –∑ enhanced_sim
    
    üîß –í–ò–ü–†–ê–í–õ–ï–ù–û: –¢–µ–ø–µ—Ä –≤–∏–∫–ª–∏–∫–∞—î –æ—Å–Ω–æ–≤–Ω—É —Ä–µ–∞–ª—ñ–∑–∞—Ü—ñ—é –∑ enhanced_sim.py
    """
    
   
    return compare_mpc_configurations(
        configurations=configurations,
        hist_df=hist_df,
        base_config=base_config,
        comparison_steps=comparison_steps,
        show_progress=show_progress
    )

import os
import json
import pandas as pd
from pathlib import Path
from datetime import datetime
from typing import Dict, Any, Optional

def save_experiment_summary(
    results: Dict[str, Any], 
    experiment_name: Optional[str] = None,
    base_results_dir: str = "experiment_results",
    save_detailed_data: bool = True,
    save_plots: bool = False,
    compress_results: bool = False
):
    """
    üíæ –ü–æ–∫—Ä–∞—â–µ–Ω–µ –∑–±–µ—Ä–µ–∂–µ–Ω–Ω—è —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ñ–≤ –µ–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç—É –≤ —Å—Ç—Ä—É–∫—Ç—É—Ä–æ–≤–∞–Ω—É –ø–∞–ø–∫—É
    üîß –í–ò–ü–†–ê–í–õ–ï–ù–û: –¥—É–±–ª—é–≤–∞–Ω–Ω—è timestamp, –ø–æ–º–∏–ª–∫–∏ —Ç–∏–ø—ñ–≤ –¥–∞–Ω–∏—Ö, –ª–æ–≥—ñ–∫–∞ —Ä–∞–Ω–∂—É–≤–∞–Ω–Ω—è
    """
    
    # 1. üìÅ –°–¢–í–û–†–ï–ù–ù–Ø –°–¢–†–£–ö–¢–£–†–ò –ü–ê–ü–û–ö (–í–ò–ü–†–ê–í–õ–ï–ù–û - –±–µ–∑ –¥—É–±–ª—é–≤–∞–Ω–Ω—è timestamp)
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    
    if experiment_name is None:
        experiment_name = f"experiment_{timestamp}"
        # –Ø–∫—â–æ –Ω–∞–∑–≤–∞ None, –ù–ï –¥–æ–¥–∞—î–º–æ timestamp –¥–≤—ñ—á—ñ
        safe_experiment_name = experiment_name
    else:
        # –û—á–∏—â—É—î–º–æ –Ω–∞–∑–≤—É –µ–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç—É –≤—ñ–¥ –Ω–µ–¥–æ–∑–≤–æ–ª–µ–Ω–∏—Ö —Å–∏–º–≤–æ–ª—ñ–≤
        safe_experiment_name = "".join(c for c in experiment_name if c.isalnum() or c in (' ', '-', '_')).rstrip()
        safe_experiment_name = safe_experiment_name.replace(' ', '_')
        # –î–æ–¥–∞—î–º–æ timestamp —Ç—ñ–ª—å–∫–∏ —è–∫—â–æ –Ω–∞–∑–≤–∞ –±—É–ª–∞ –∑–∞–¥–∞–Ω–∞ –∫–æ—Ä–∏—Å—Ç—É–≤–∞—á–µ–º
        safe_experiment_name = f"{safe_experiment_name}_{timestamp}"
    
    # –°—Ç–≤–æ—Ä—é—î–º–æ —ñ—î—Ä–∞—Ä—Ö—ñ—é –ø–∞–ø–æ–∫ –ë–ï–ó –¥–æ–¥–∞—Ç–∫–æ–≤–æ–≥–æ timestamp
    base_path = Path(base_results_dir)
    experiment_path = base_path / safe_experiment_name
    
    # –°—Ç–≤–æ—Ä—é—î–º–æ –ø—ñ–¥–ø–∞–ø–∫–∏
    subdirs = {
        'summary': experiment_path / "summary",
        'detailed': experiment_path / "detailed_data", 
        'configs': experiment_path / "configurations",
        'metrics': experiment_path / "metrics",
        'plots': experiment_path / "plots",
        'logs': experiment_path / "logs"
    }
    
    # –°—Ç–≤–æ—Ä—é—î–º–æ –≤—Å—ñ –ø–∞–ø–∫–∏
    for subdir_path in subdirs.values():
        subdir_path.mkdir(parents=True, exist_ok=True)
    
    print(f"üìÅ –°—Ç–≤–æ—Ä–µ–Ω–æ —Å—Ç—Ä—É–∫—Ç—É—Ä—É –µ–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç—É: {experiment_path}")
    
    # 2. üìã –ó–ë–ï–†–ï–ñ–ï–ù–ù–Ø –û–°–ù–û–í–ù–û–ì–û –†–ï–ó–Æ–ú–ï
    experiment_summary = {
        'experiment_info': {
            'name': experiment_name,
            'timestamp': datetime.now().isoformat(),
            'duration_minutes': _calculate_total_duration(results),
            'total_experiments': len(results),
            'successful_experiments': len([r for r in results.values() if r is not None]),
            'python_version': _get_python_version(),
            'system_info': _get_system_info()
        },
        'experiments_overview': _create_experiments_overview(results),
        'key_findings': _extract_key_findings(results),  # –í–∏–∫–æ—Ä–∏—Å—Ç–æ–≤—É—î–º–æ –≤–∏–ø—Ä–∞–≤–ª–µ–Ω—É –≤–µ—Ä—Å—ñ—é
        'file_structure': {
            'summary_files': [],
            'detailed_files': [],
            'config_files': [],
            'metric_files': []
        }
    }
    
    # –ó–±–µ—Ä—ñ–≥–∞—î–º–æ –æ—Å–Ω–æ–≤–Ω–µ —Ä–µ–∑—é–º–µ
    summary_file = subdirs['summary'] / "experiment_summary.json"
    with open(summary_file, 'w', encoding='utf-8') as f:
        json.dump(experiment_summary, f, indent=2, ensure_ascii=False, default=str)
    
    experiment_summary['file_structure']['summary_files'].append(str(summary_file.name))
    print(f"üìã –ó–±–µ—Ä–µ–∂–µ–Ω–æ –æ—Å–Ω–æ–≤–Ω–µ —Ä–µ–∑—é–º–µ: {summary_file}")
    
    # 3. üìä –ó–ë–ï–†–ï–ñ–ï–ù–ù–Ø –î–ï–¢–ê–õ–¨–ù–ò–• –†–ï–ó–£–õ–¨–¢–ê–¢–Ü–í (–í–ò–ü–†–ê–í–õ–ï–ù–û)
    if save_detailed_data:
        for exp_name, exp_result in results.items():
            if exp_result is not None:
                _save_detailed_experiment_data(  # –í–∏–∫–ª–∏–∫–∞—î–º–æ –≤–∏–ø—Ä–∞–≤–ª–µ–Ω—É –≤–µ—Ä—Å—ñ—é
                    exp_name, exp_result, subdirs, experiment_summary
                )
    
    # 4. ‚öôÔ∏è –ó–ë–ï–†–ï–ñ–ï–ù–ù–Ø –ö–û–ù–§–Ü–ì–£–†–ê–¶–Ü–ô
    _save_experiment_configurations(results, subdirs, experiment_summary)
    
    # 5. üìà –ó–ë–ï–†–ï–ñ–ï–ù–ù–Ø –ê–ì–†–ï–ì–û–í–ê–ù–ò–• –ú–ï–¢–†–ò–ö
    _save_aggregated_metrics(results, subdirs, experiment_summary)
    
    # 6. üìä –°–¢–í–û–†–ï–ù–ù–Ø –ó–í–ï–î–ï–ù–û–á –¢–ê–ë–õ–ò–¶–Ü –ü–û–†–Ü–í–ù–Ø–ù–ù–Ø (–í–ò–ü–†–ê–í–õ–ï–ù–û)
    comparison_table = _create_comparison_table(results)  # –í–∏–∫–æ—Ä–∏—Å—Ç–æ–≤—É—î–º–æ –≤–∏–ø—Ä–∞–≤–ª–µ–Ω—É –≤–µ—Ä—Å—ñ—é
    if comparison_table is not None:
        comparison_file = subdirs['summary'] / "comparison_table.csv"
        comparison_table.to_csv(comparison_file, index=False)
        experiment_summary['file_structure']['summary_files'].append(str(comparison_file.name))
        print(f"üìä –ó–±–µ—Ä–µ–∂–µ–Ω–æ —Ç–∞–±–ª–∏—Ü—é –ø–æ—Ä—ñ–≤–Ω—è–Ω–Ω—è: {comparison_file}")
    
    # 7. üìù –°–¢–í–û–†–ï–ù–ù–Ø –¢–ï–ö–°–¢–û–í–û–ì–û –ó–í–Ü–¢–£
    text_report = _create_text_report(experiment_summary, results)
    report_file = subdirs['summary'] / "experiment_report.txt"
    with open(report_file, 'w', encoding='utf-8') as f:
        f.write(text_report)
    experiment_summary['file_structure']['summary_files'].append(str(report_file.name))
    print(f"üìù –ó–±–µ—Ä–µ–∂–µ–Ω–æ —Ç–µ–∫—Å—Ç–æ–≤–∏–π –∑–≤—ñ—Ç: {report_file}")
    
    # 8. üóÉÔ∏è –û–ù–û–í–õ–ï–ù–ù–Ø –§–Ü–ù–ê–õ–¨–ù–û–ì–û –†–ï–ó–Æ–ú–ï
    with open(summary_file, 'w', encoding='utf-8') as f:
        json.dump(experiment_summary, f, indent=2, ensure_ascii=False, default=str)
    
    # 9. üì¶ –ê–†–•–Ü–í–£–í–ê–ù–ù–Ø (–æ–ø—Ü—ñ–æ–Ω–∞–ª—å–Ω–æ)
    if compress_results:
        archive_file = _compress_experiment_results(experiment_path)
        print(f"üì¶ –†–µ–∑—É–ª—å—Ç–∞—Ç–∏ –∞—Ä—Ö—ñ–≤–æ–≤–∞–Ω–æ: {archive_file}")
    
    # 10. üìä –ü–Ü–î–°–£–ú–û–ö –ó–ë–ï–†–ï–ñ–ï–ù–ù–Ø
    total_files = sum(len(files) for files in experiment_summary['file_structure'].values())
    
    print(f"\n‚úÖ –ï–ö–°–ü–ï–†–ò–ú–ï–ù–¢ –ó–ë–ï–†–ï–ñ–ï–ù–û –£–°–ü–Ü–®–ù–û!")
    print(f"üìÅ –ü–∞–ø–∫–∞: {experiment_path}")
    print(f"üìÑ –í—Å—å–æ–≥–æ —Ñ–∞–π–ª—ñ–≤: {total_files}")
    print(f"üíæ –†–æ–∑–º—ñ—Ä: {_calculate_directory_size(experiment_path):.1f} MB")
    
    # –ü–æ–∫–∞–∑—É—î–º–æ —Å—Ç—Ä—É–∫—Ç—É—Ä—É
    print(f"\nüìÅ –°–¢–†–£–ö–¢–£–†–ê –†–ï–ó–£–õ–¨–¢–ê–¢–Ü–í:")
    for subdir_name, subdir_path in subdirs.items():
        file_count = len(list(subdir_path.glob('*')))
        if file_count > 0:
            print(f"   üìÇ {subdir_name}/: {file_count} —Ñ–∞–π–ª—ñ–≤")
    
    return str(experiment_path)

def _save_detailed_experiment_data(
    exp_name: str, 
    exp_result: Any, 
    subdirs: Dict[str, Path], 
    experiment_summary: Dict
):
    """üîß –í–ò–ü–†–ê–í–õ–ï–ù–û: –ó–±–µ—Ä—ñ–≥–∞—î –¥–µ—Ç–∞–ª—å–Ω—ñ –¥–∞–Ω—ñ –∑ –æ–±—Ä–æ–±–∫–æ—é –ø–æ–º–∏–ª–æ–∫ —Ç–∏–ø—ñ–≤"""
    
    try:
        if isinstance(exp_result, tuple) and len(exp_result) == 2:
            # –†–µ–∑—É–ª—å—Ç–∞—Ç —Å–∏–º—É–ª—è—Ü—ñ—ó: (DataFrame, metrics)
            results_df, metrics = exp_result
            
            # –ó–±–µ—Ä—ñ–≥–∞—î–º–æ DataFrame
            if isinstance(results_df, pd.DataFrame) and not results_df.empty:
                data_file = subdirs['detailed'] / f"{exp_name}_results.parquet"
                results_df.to_parquet(data_file, index=False)
                experiment_summary['file_structure']['detailed_files'].append(str(data_file.name))
                
                # CSV –∑ –æ–±—Ä–æ–±–∫–æ—é –ø—Ä–æ–±–ª–µ–º–Ω–∏—Ö –∫–æ–ª–æ–Ω–æ–∫
                csv_file = subdirs['detailed'] / f"{exp_name}_results.csv"
                
                # üîß –í–ò–ü–†–ê–í–õ–ï–ù–ù–Ø: –û–±—Ä–æ–±–∫–∞ –∫–æ–ª–æ–Ω–æ–∫ –∑ mixed —Ç–∏–ø–∞–º–∏
                df_to_save = results_df.copy()
                for col in df_to_save.columns:
                    if df_to_save[col].dtype == 'object':
                        # –ö–æ–Ω–≤–µ—Ä—Ç—É—î–º–æ –ø—Ä–æ–±–ª–µ–º–Ω—ñ –∫–æ–ª–æ–Ω–∫–∏ –≤ string
                        df_to_save[col] = df_to_save[col].astype(str)
                
                df_to_save.to_csv(csv_file, index=False)
                experiment_summary['file_structure']['detailed_files'].append(str(csv_file.name))
            
            # –ó–±–µ—Ä—ñ–≥–∞—î–º–æ –º–µ—Ç—Ä–∏–∫–∏
            if isinstance(metrics, dict):
                metrics_file = subdirs['metrics'] / f"{exp_name}_metrics.json"
                
                # üîß –í–ò–ü–†–ê–í–õ–ï–ù–ù–Ø: –û—á–∏—â–µ–Ω–Ω—è –º–µ—Ç—Ä–∏–∫ –≤—ñ–¥ –ø—Ä–æ–±–ª–µ–º–Ω–∏—Ö —Ç–∏–ø—ñ–≤
                clean_metrics = _clean_metrics_for_json(metrics)
                
                with open(metrics_file, 'w', encoding='utf-8') as f:
                    json.dump(clean_metrics, f, indent=2, ensure_ascii=False, default=str)
                experiment_summary['file_structure']['metric_files'].append(str(metrics_file.name))
                
        elif isinstance(exp_result, pd.DataFrame):
            # DataFrame —Ä–µ–∑—É–ª—å—Ç–∞—Ç (–Ω–∞–ø—Ä–∏–∫–ª–∞–¥, –ø–æ—Ä—ñ–≤–Ω—è–Ω–Ω—è –∫–æ–Ω—Ñ—ñ–≥—É—Ä–∞—Ü—ñ–π)
            
            # üîß –í–ò–ü–†–ê–í–õ–ï–ù–ù–Ø: –û—á–∏—â–µ–Ω–Ω—è DataFrame –≤—ñ–¥ –ø—Ä–æ–±–ª–µ–º–Ω–∏—Ö —Ç–∏–ø—ñ–≤
            df_clean = _clean_dataframe_for_save(exp_result)
            
            data_file = subdirs['detailed'] / f"{exp_name}_comparison.parquet"
            df_clean.to_parquet(data_file, index=False)
            experiment_summary['file_structure']['detailed_files'].append(str(data_file.name))
            
            # CSV –≤–µ—Ä—Å—ñ—è
            csv_file = subdirs['detailed'] / f"{exp_name}_comparison.csv"
            df_clean.to_csv(csv_file, index=False)
            experiment_summary['file_structure']['detailed_files'].append(str(csv_file.name))
            
        elif isinstance(exp_result, dict):
            # –°–ª–æ–≤–Ω–∏–∫ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ñ–≤
            result_file = subdirs['detailed'] / f"{exp_name}_results.json"
            clean_result = _clean_metrics_for_json(exp_result)
            
            with open(result_file, 'w', encoding='utf-8') as f:
                json.dump(clean_result, f, indent=2, ensure_ascii=False, default=str)
            experiment_summary['file_structure']['detailed_files'].append(str(result_file.name))
            
    except Exception as e:
        print(f"   ‚ö†Ô∏è –ü–æ–º–∏–ª–∫–∞ –∑–±–µ—Ä–µ–∂–µ–Ω–Ω—è –¥–µ—Ç–∞–ª—å–Ω–∏—Ö –¥–∞–Ω–∏—Ö –¥–ª—è {exp_name}: {e}")
        # –ó–±–µ—Ä—ñ–≥–∞—î–º–æ —ñ–Ω—Ñ–æ—Ä–º–∞—Ü—ñ—é –ø—Ä–æ –ø–æ–º–∏–ª–∫—É –∑–∞–º—ñ—Å—Ç—å –ø–æ–≤–Ω–æ–≥–æ –ø–∞–¥—ñ–Ω–Ω—è
        error_file = subdirs['logs'] / f"{exp_name}_save_error.txt"
        error_file.parent.mkdir(parents=True, exist_ok=True)
        
        with open(error_file, 'w', encoding='utf-8') as f:
            f.write(f"–ü–æ–º–∏–ª–∫–∞ –∑–±–µ—Ä–µ–∂–µ–Ω–Ω—è {exp_name}:\n")
            f.write(f"–¢–∏–ø –ø–æ–º–∏–ª–∫–∏: {type(e).__name__}\n")
            f.write(f"–û–ø–∏—Å: {str(e)}\n")
            f.write(f"–¢–∏–ø —Ä–µ–∑—É–ª—å—Ç–∞—Ç—É: {type(exp_result)}\n")
            if isinstance(exp_result, pd.DataFrame):
                f.write(f"–ö–æ–ª–æ–Ω–∫–∏ DataFrame: {list(exp_result.columns)}\n")
                f.write(f"–¢–∏–ø–∏ –∫–æ–ª–æ–Ω–æ–∫: {exp_result.dtypes.to_dict()}\n")

def _save_experiment_configurations(results: Dict[str, Any], subdirs: Dict[str, Path], experiment_summary: Dict):
    """–ó–±–µ—Ä—ñ–≥–∞—î –∫–æ–Ω—Ñ—ñ–≥—É—Ä–∞—Ü—ñ—ó –µ–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç—ñ–≤"""
    
    configs = {}
    
    for exp_name, exp_result in results.items():
        try:
            config_info = None
            
            if isinstance(exp_result, tuple) and len(exp_result) == 2:
                _, metrics = exp_result
                if isinstance(metrics, dict) and 'config_info' in metrics:
                    config_info = metrics['config_info']
                elif isinstance(metrics, dict) and 'config_summary' in metrics:
                    config_info = metrics['config_summary']
            
            configs[exp_name] = config_info or "Configuration not available"
            
        except Exception as e:
            configs[exp_name] = f"Error extracting config: {e}"
    
    # –ó–±–µ—Ä—ñ–≥–∞—î–º–æ –≤—Å—ñ –∫–æ–Ω—Ñ—ñ–≥—É—Ä–∞—Ü—ñ—ó
    configs_file = subdirs['configs'] / "all_configurations.json"
    with open(configs_file, 'w', encoding='utf-8') as f:
        json.dump(configs, f, indent=2, ensure_ascii=False, default=str)
    
    experiment_summary['file_structure']['config_files'].append(str(configs_file.name))


def _save_aggregated_metrics(results: Dict[str, Any], subdirs: Dict[str, Path], experiment_summary: Dict):
    """–ó–±–µ—Ä—ñ–≥–∞—î –∞–≥—Ä–µ–≥–æ–≤–∞–Ω—ñ –º–µ—Ç—Ä–∏–∫–∏ –≤—Å—ñ—Ö –µ–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç—ñ–≤"""
    
    all_metrics = {}
    
    for exp_name, exp_result in results.items():
        try:
            if isinstance(exp_result, tuple) and len(exp_result) == 2:
                _, metrics = exp_result
                if isinstance(metrics, dict):
                    # –í–∏—Ç—è–≥—É—î–º–æ –∫–ª—é—á–æ–≤—ñ –º–µ—Ç—Ä–∏–∫–∏
                    key_metrics = {
                        'rmse_fe': metrics.get('test_rmse_conc_fe'),
                        'rmse_mass': metrics.get('test_rmse_conc_mass'),
                        'r2_fe': metrics.get('r2_fe'),
                        'r2_mass': metrics.get('r2_mass'),
                        'quality_score': metrics.get('quality_score'),
                        'mpc_quality_score': metrics.get('mpc_quality_score'),
                        'total_cycle_time': metrics.get('total_cycle_time'),
                        'real_time_suitable': metrics.get('real_time_suitable')
                    }
                    all_metrics[exp_name] = {k: v for k, v in key_metrics.items() if v is not None}
        except Exception as e:
            all_metrics[exp_name] = f"Error: {e}"
    
    # –ó–±–µ—Ä—ñ–≥–∞—î–º–æ –∞–≥—Ä–µ–≥–æ–≤–∞–Ω—ñ –º–µ—Ç—Ä–∏–∫–∏
    metrics_file = subdirs['metrics'] / "aggregated_metrics.json"
    with open(metrics_file, 'w', encoding='utf-8') as f:
        json.dump(all_metrics, f, indent=2, ensure_ascii=False, default=str)
    
    experiment_summary['file_structure']['metric_files'].append(str(metrics_file.name))


def _create_comparison_table(results: Dict[str, Any]) -> Optional[pd.DataFrame]:
    """üîß –í–ò–ü–†–ê–í–õ–ï–ù–û: –°—Ç–≤–æ—Ä—é—î –∑–≤–µ–¥–µ–Ω—É —Ç–∞–±–ª–∏—Ü—é –∑ –ø—Ä–∞–≤–∏–ª—å–Ω–æ—é –ª–æ–≥—ñ–∫–æ—é —Ä–∞–Ω–∂—É–≤–∞–Ω–Ω—è"""
    
    comparison_data = []
    
    for exp_name, exp_result in results.items():
        try:
            row = {'Experiment': exp_name}
            
            if isinstance(exp_result, tuple) and len(exp_result) == 2:
                _, metrics = exp_result
                if isinstance(metrics, dict):
                    row.update({
                        'RMSE_Fe': metrics.get('test_rmse_conc_fe'),
                        'RMSE_Mass': metrics.get('test_rmse_conc_mass'),
                        'R2_Fe': metrics.get('r2_fe'),
                        'R2_Mass': metrics.get('r2_mass'),
                        'Quality_Score': metrics.get('quality_score'),
                        'MPC_Quality': metrics.get('mpc_quality_score'),
                        'Cycle_Time_ms': metrics.get('total_cycle_time', 0) * 1000,
                        'Real_Time': metrics.get('real_time_suitable', False)
                    })
            elif isinstance(exp_result, pd.DataFrame):
                # üîß –í–ò–ü–†–ê–í–õ–ï–ù–ù–Ø: –ü—Ä–∞–≤–∏–ª—å–Ω–∞ –ª–æ–≥—ñ–∫–∞ –¥–ª—è –ø–æ—Ä—ñ–≤–Ω—è–ª—å–Ω–∏—Ö –µ–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç—ñ–≤
                if not exp_result.empty:
                    # –°–æ—Ä—Ç—É—î–º–æ –∑–∞ –∫–æ–º–±—ñ–Ω–æ–≤–∞–Ω–æ—é –º–µ—Ç—Ä–∏–∫–æ—é –∑–∞–º—ñ—Å—Ç—å —Ç—ñ–ª—å–∫–∏ RMSE
                    df_sorted = exp_result.copy()
                    
                    # –°—Ç–≤–æ—Ä—é—î–º–æ –∫–æ–º–±—ñ–Ω–æ–≤–∞–Ω—É –æ—Ü—ñ–Ω–∫—É: 70% MPC_Quality + 30% —Ç–æ—á–Ω—ñ—Å—Ç—å
                    if 'MPC_Quality_Score' in df_sorted.columns and 'RMSE_Fe' in df_sorted.columns:
                        # –ù–æ—Ä–º–∞–ª—ñ–∑—É—î–º–æ –º–µ—Ç—Ä–∏–∫–∏ (–≤–∏—â–µ MPC —è–∫—ñ—Å—Ç—å = –∫—Ä–∞—â–µ, –Ω–∏–∂—á–µ RMSE = –∫—Ä–∞—â–µ)
                        mpc_quality_norm = df_sorted['MPC_Quality_Score'].fillna(0) / 100
                        rmse_norm = 1 / (1 + df_sorted['RMSE_Fe'].fillna(1))  # –Ü–Ω–≤–µ—Ä—Ç—É—î–º–æ RMSE
                        
                        df_sorted['Combined_Score'] = 0.7 * mpc_quality_norm + 0.3 * rmse_norm
                        df_sorted = df_sorted.sort_values('Combined_Score', ascending=False)
                        
                        print(f"   üîß –°–æ—Ä—Ç—É–≤–∞–Ω–Ω—è –∑–∞ –∫–æ–º–±—ñ–Ω–æ–≤–∞–Ω–æ—é –æ—Ü—ñ–Ω–∫–æ—é (70% MPC —è–∫—ñ—Å—Ç—å + 30% —Ç–æ—á–Ω—ñ—Å—Ç—å)")
                    elif 'MPC_Quality_Score' in df_sorted.columns:
                        df_sorted = df_sorted.sort_values('MPC_Quality_Score', ascending=False)
                        print(f"   üîß –°–æ—Ä—Ç—É–≤–∞–Ω–Ω—è –∑–∞ MPC —è–∫—ñ—Å—Ç—é")
                    elif 'RMSE_Fe' in df_sorted.columns:
                        df_sorted = df_sorted.sort_values('RMSE_Fe', ascending=True)
                        print(f"   üîß –°–æ—Ä—Ç—É–≤–∞–Ω–Ω—è –∑–∞ RMSE Fe")
                    
                    best_row = df_sorted.iloc[0]
                    row.update({
                        'Best_Config': best_row.get('Configuration', 'Unknown'),
                        'RMSE_Fe': best_row.get('RMSE_Fe'),
                        'MPC_Quality': best_row.get('MPC_Quality_Score'),
                        'Combined_Score': best_row.get('Combined_Score', 'N/A'),
                        'Total_Configs_Tested': len(df_sorted),
                        'Ranking_Logic': '70% MPC Quality + 30% Model Accuracy'
                    })
            
            comparison_data.append(row)
            
        except Exception as e:
            comparison_data.append({
                'Experiment': exp_name,
                'Error': str(e)
            })
    
    if comparison_data:
        return pd.DataFrame(comparison_data)
    return None

def _create_experiments_overview(results: Dict[str, Any]) -> Dict:
    """–°—Ç–≤–æ—Ä—é—î –æ–≥–ª—è–¥ –µ–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç—ñ–≤"""
    
    overview = {
        'total_count': len(results),
        'successful_count': 0,
        'failed_count': 0,
        'experiment_types': {},
        'best_results': {}
    }
    
    for exp_name, exp_result in results.items():
        if exp_result is not None:
            overview['successful_count'] += 1
            
            # –í–∏–∑–Ω–∞—á–∞—î–º–æ —Ç–∏–ø –µ–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç—É
            if 'benchmark' in exp_name.lower():
                exp_type = 'benchmark'
            elif 'comparison' in exp_name.lower():
                exp_type = 'comparison'
            elif 'analysis' in exp_name.lower():
                exp_type = 'analysis'
            else:
                exp_type = 'simulation'
            
            overview['experiment_types'][exp_type] = overview['experiment_types'].get(exp_type, 0) + 1
        else:
            overview['failed_count'] += 1
    
    return overview


def _extract_key_findings(results: Dict[str, Any]) -> Dict:
    """üîß –í–ò–ü–†–ê–í–õ–ï–ù–û: –í–∏—Ç—è–≥—É—î –≤–∏—Å–Ω–æ–≤–∫–∏ –∑ –ø—Ä–∞–≤–∏–ª—å–Ω–æ—é –ª–æ–≥—ñ–∫–æ—é –æ—Ü—ñ–Ω–∫–∏"""
    
    findings = {
        'best_performers': {},
        'recommendations': [],
        'performance_summary': {},
        'ranking_logic': 'Combined score: 70% MPC Quality + 30% Model Accuracy'
    }
    
    # –ó–±–∏—Ä–∞—î–º–æ –≤—Å—ñ –º–µ—Ç—Ä–∏–∫–∏
    all_configs = []
    
    for exp_name, exp_result in results.items():
        try:
            if isinstance(exp_result, pd.DataFrame) and 'MPC_Quality_Score' in exp_result.columns:
                # –¶–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç –ø–æ—Ä—ñ–≤–Ω—è–Ω–Ω—è –∫–æ–Ω—Ñ—ñ–≥—É—Ä–∞—Ü—ñ–π
                for _, row in exp_result.iterrows():
                    config_data = {
                        'experiment': exp_name,
                        'configuration': row.get('Configuration', 'Unknown'),
                        'rmse_fe': row.get('RMSE_Fe'),
                        'mpc_quality': row.get('MPC_Quality_Score'),
                        'cycle_time': row.get('Total_Cycle_Time', 0) * 1000 if pd.notna(row.get('Total_Cycle_Time')) else None
                    }
                    
                    # –ö–æ–º–±—ñ–Ω–æ–≤–∞–Ω–∞ –æ—Ü—ñ–Ω–∫–∞
                    if pd.notna(config_data['mpc_quality']) and pd.notna(config_data['rmse_fe']):
                        mpc_norm = config_data['mpc_quality'] / 100
                        rmse_norm = 1 / (1 + config_data['rmse_fe'])
                        config_data['combined_score'] = 0.7 * mpc_norm + 0.3 * rmse_norm
                    
                    all_configs.append(config_data)
            
            elif isinstance(exp_result, tuple) and len(exp_result) == 2:
                _, metrics = exp_result
                if isinstance(metrics, dict):
                    config_data = {
                        'experiment': exp_name,
                        'configuration': exp_name,
                        'rmse_fe': metrics.get('test_rmse_conc_fe'),
                        'mpc_quality': metrics.get('mpc_quality_score'),
                        'quality_score': metrics.get('quality_score')
                    }
                    all_configs.append(config_data)
        except:
            continue
    
    # –ó–Ω–∞—Ö–æ–¥–∏–º–æ –Ω–∞–π–∫—Ä–∞—â—ñ –∫–æ–Ω—Ñ—ñ–≥—É—Ä–∞—Ü—ñ—ó
    if all_configs:
        # –ó–∞ –∫–æ–º–±—ñ–Ω–æ–≤–∞–Ω–æ—é –æ—Ü—ñ–Ω–∫–æ—é
        configs_with_combined = [c for c in all_configs if 'combined_score' in c and pd.notna(c['combined_score'])]
        if configs_with_combined:
            best_combined = max(configs_with_combined, key=lambda x: x['combined_score'])
            findings['best_performers']['best_overall'] = {
                'configuration': best_combined['configuration'],
                'experiment': best_combined['experiment'],
                'combined_score': best_combined['combined_score'],
                'mpc_quality': best_combined['mpc_quality'],
                'rmse_fe': best_combined['rmse_fe']
            }
        
        # –ó–∞ MPC —è–∫—ñ—Å—Ç—é
        configs_with_mpc = [c for c in all_configs if pd.notna(c.get('mpc_quality'))]
        if configs_with_mpc:
            best_mpc = max(configs_with_mpc, key=lambda x: x['mpc_quality'])
            findings['best_performers']['best_mpc_quality'] = {
                'configuration': best_mpc['configuration'],
                'experiment': best_mpc['experiment'],
                'mpc_quality': best_mpc['mpc_quality']
            }
        
        # –ó–∞ —Ç–æ—á–Ω—ñ—Å—Ç—é –º–æ–¥–µ–ª—ñ
        configs_with_rmse = [c for c in all_configs if pd.notna(c.get('rmse_fe'))]
        if configs_with_rmse:
            best_accuracy = min(configs_with_rmse, key=lambda x: x['rmse_fe'])
            findings['best_performers']['best_accuracy'] = {
                'configuration': best_accuracy['configuration'],
                'experiment': best_accuracy['experiment'],
                'rmse_fe': best_accuracy['rmse_fe']
            }
    
    # –ì–µ–Ω–µ—Ä—É—î–º–æ –ø—Ä–∞–≤–∏–ª—å–Ω—ñ —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü—ñ—ó
    if 'best_overall' in findings['best_performers']:
        best = findings['best_performers']['best_overall']
        findings['recommendations'].append(
            f"üèÜ –†–µ–∫–æ–º–µ–Ω–¥–æ–≤–∞–Ω–∞ –∫–æ–Ω—Ñ—ñ–≥—É—Ä–∞—Ü—ñ—è: {best['configuration']} "
            f"(–ö–æ–º–±—ñ–Ω–æ–≤–∞–Ω–∞ –æ—Ü—ñ–Ω–∫–∞: {best['combined_score']:.3f})"
        )
        
        if best['mpc_quality'] >= 65:
            findings['recommendations'].append("‚úÖ –í–∏—Å–æ–∫–∞ —è–∫—ñ—Å—Ç—å MPC - –≥–æ—Ç–æ–≤–æ –¥–ª—è –ø—Ä–æ–º–∏—Å–ª–æ–≤–æ–≥–æ –≤–∏–∫–æ—Ä–∏—Å—Ç–∞–Ω–Ω—è")
        elif best['mpc_quality'] >= 50:
            findings['recommendations'].append("‚ö†Ô∏è –°–µ—Ä–µ–¥–Ω—è —è–∫—ñ—Å—Ç—å MPC - —Ä–æ–∑–≥–ª—è–Ω—å—Ç–µ –¥–æ–¥–∞—Ç–∫–æ–≤–µ –Ω–∞–ª–∞—à—Ç—É–≤–∞–Ω–Ω—è")
        else:
            findings['recommendations'].append("üîß –ù–∏–∑—å–∫–∞ —è–∫—ñ—Å—Ç—å MPC - –ø–æ—Ç—Ä—ñ–±–Ω–µ —Å–µ—Ä–π–æ–∑–Ω–µ –Ω–∞–ª–∞—à—Ç—É–≤–∞–Ω–Ω—è")
    
    return findings

def _create_text_report(experiment_summary: Dict, results: Dict[str, Any]) -> str:
    """–°—Ç–≤–æ—Ä—é—î —Ç–µ–∫—Å—Ç–æ–≤–∏–π –∑–≤—ñ—Ç –µ–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç—É"""
    
    report = f"""
üî¨ –ó–í–Ü–¢ –ü–†–û –ï–ö–°–ü–ï–†–ò–ú–ï–ù–¢ MPC
{'='*60}

üìã –ó–ê–ì–ê–õ–¨–ù–ê –Ü–ù–§–û–†–ú–ê–¶–Ü–Ø:
   –ù–∞–∑–≤–∞ –µ–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç—É: {experiment_summary['experiment_info']['name']}
   –î–∞—Ç–∞/—á–∞—Å: {experiment_summary['experiment_info']['timestamp']}
   –¢—Ä–∏–≤–∞–ª—ñ—Å—Ç—å: {experiment_summary['experiment_info']['duration_minutes']:.1f} —Ö–≤–∏–ª–∏–Ω
   
üìä –û–ì–õ–Ø–î –ï–ö–°–ü–ï–†–ò–ú–ï–ù–¢–Ü–í:
   –í—Å—å–æ–≥–æ –µ–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç—ñ–≤: {experiment_summary['experiments_overview']['total_count']}
   –£—Å–ø—ñ—à–Ω–∏—Ö: {experiment_summary['experiments_overview']['successful_count']}
   –ù–µ–≤–¥–∞–ª–∏—Ö: {experiment_summary['experiments_overview']['failed_count']}

üéØ –ö–õ–Æ–ß–û–í–Ü –†–ï–ó–£–õ–¨–¢–ê–¢–ò:
"""
    
    # –î–æ–¥–∞—î–º–æ –∫—Ä–∞—â—ñ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∏
    if 'best_performers' in experiment_summary['key_findings']:
        best = experiment_summary['key_findings']['best_performers']
        
        if 'lowest_rmse_fe' in best:
            report += f"   üèÜ –ù–∞–π–∫—Ä–∞—â–∞ —Ç–æ—á–Ω—ñ—Å—Ç—å Fe: {best['lowest_rmse_fe']['experiment']} "
            report += f"(RMSE = {best['lowest_rmse_fe']['value']:.4f})\n"
        
        if 'best_quality' in best:
            report += f"   üéØ –ù–∞–π–∫—Ä–∞—â–∞ —è–∫—ñ—Å—Ç—å –∫–µ—Ä—É–≤–∞–Ω–Ω—è: {best['best_quality']['experiment']} "
            report += f"(Quality = {best['best_quality']['value']:.4f})\n"
    
    # –î–æ–¥–∞—î–º–æ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É
    if 'performance_summary' in experiment_summary['key_findings']:
        perf = experiment_summary['key_findings']['performance_summary']
        if 'rmse_fe' in perf:
            rmse_stats = perf['rmse_fe']
            report += f"\nüìà –°–¢–ê–¢–ò–°–¢–ò–ö–ê RMSE Fe:\n"
            report += f"   –°–µ—Ä–µ–¥–Ω—î: {rmse_stats['mean']:.4f}\n"
            report += f"   –°—Ç–¥. –≤—ñ–¥—Ö–∏–ª–µ–Ω–Ω—è: {rmse_stats['std']:.4f}\n"
            report += f"   –î—ñ–∞–ø–∞–∑–æ–Ω: {rmse_stats['min']:.4f} - {rmse_stats['max']:.4f}\n"
    
    # –î–æ–¥–∞—î–º–æ —Å—Ç—Ä—É–∫—Ç—É—Ä—É —Ñ–∞–π–ª—ñ–≤
    report += f"\nüìÅ –ó–ë–ï–†–ï–ñ–ï–ù–Ü –§–ê–ô–õ–ò:\n"
    for file_type, files in experiment_summary['file_structure'].items():
        if files:
            report += f"   üìÇ {file_type}: {len(files)} —Ñ–∞–π–ª—ñ–≤\n"
    
    report += f"\n{'='*60}\n"
    
    return report


# –î–æ–ø–æ–º—ñ–∂–Ω—ñ —Ñ—É–Ω–∫—Ü—ñ—ó
def _calculate_total_duration(results: Dict[str, Any]) -> float:
    """–û–±—á–∏—Å–ª—é—î –∑–∞–≥–∞–ª—å–Ω—É —Ç—Ä–∏–≤–∞–ª—ñ—Å—Ç—å –µ–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç—ñ–≤"""
    # Placeholder - –≤ —Ä–µ–∞–ª—å–Ω–æ—Å—Ç—ñ –º–æ–∂–Ω–∞ –¥–æ–¥–∞—Ç–∏ —Ç—Ä–µ–∫—ñ–Ω–≥ —á–∞—Å—É
    return len(results) * 2.5  # –ü—Ä–∏–±–ª–∏–∑–Ω–æ 2.5 —Ö–≤–∏–ª–∏–Ω–∏ –Ω–∞ –µ–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç

def _get_python_version() -> str:
    """–û—Ç—Ä–∏–º—É—î –≤–µ—Ä—Å—ñ—é Python"""
    import sys
    return f"{sys.version_info.major}.{sys.version_info.minor}.{sys.version_info.micro}"

def _get_system_info() -> Dict:
    """–û—Ç—Ä–∏–º—É—î —ñ–Ω—Ñ–æ—Ä–º–∞—Ü—ñ—é –ø—Ä–æ —Å–∏—Å—Ç–µ–º—É"""
    import platform
    return {
        'os': platform.system(),
        'os_version': platform.version(),
        'architecture': platform.architecture()[0],
        'processor': platform.processor()
    }

def _calculate_directory_size(directory: Path) -> float:
    """–û–±—á–∏—Å–ª—é—î —Ä–æ–∑–º—ñ—Ä –ø–∞–ø–∫–∏ –≤ MB"""
    total_size = 0
    for path in directory.rglob('*'):
        if path.is_file():
            total_size += path.stat().st_size
    return total_size / (1024 * 1024)  # –ö–æ–Ω–≤–µ—Ä—Ç—É—î–º–æ –≤ MB

def _clean_dataframe_for_save(df: pd.DataFrame) -> pd.DataFrame:
    """–û—á–∏—â—É—î DataFrame –≤—ñ–¥ –ø—Ä–æ–±–ª–µ–º–Ω–∏—Ö —Ç–∏–ø—ñ–≤ –¥–∞–Ω–∏—Ö"""
    
    df_clean = df.copy()
    
    for col in df_clean.columns:
        if df_clean[col].dtype == 'object':
            # –ü–µ—Ä–µ–≤—ñ—Ä—è—î–º–æ —á–∏ —î mixed —Ç–∏–ø–∏ –≤ –∫–æ–ª–æ–Ω—Ü—ñ
            unique_types = set(type(x).__name__ for x in df_clean[col].dropna())
            
            if len(unique_types) > 1:
                # Mixed —Ç–∏–ø–∏ - –∫–æ–Ω–≤–µ—Ä—Ç—É—î–º–æ –≤—Å–µ –≤ string
                df_clean[col] = df_clean[col].astype(str)
                print(f"   üîß –ö–æ–Ω–≤–µ—Ä—Ç–æ–≤–∞–Ω–æ –∫–æ–ª–æ–Ω–∫—É '{col}' –≤ string (–±—É–ª–æ mixed —Ç–∏–ø—ñ–≤: {unique_types})")
            else:
                # –û–¥–∏–Ω —Ç–∏–ø - –∑–∞–ª–∏—à–∞—î–º–æ —è–∫ —î, –∞–ª–µ –∫–æ–Ω–≤–µ—Ä—Ç—É—î–º–æ 'default' –≤ NaN –¥–ª—è —á–∏—Å–ª–æ–≤–∏—Ö –∫–æ–ª–æ–Ω–æ–∫
                if col.startswith('Config_') and any(x in col for x in ['N_data', 'Np', 'Nc']):
                    # –ß–∏—Å–ª–æ–≤–∞ –∫–æ–Ω—Ñ—ñ–≥—É—Ä–∞—Ü—ñ–π–Ω–∞ –∫–æ–ª–æ–Ω–∫–∞
                    df_clean[col] = pd.to_numeric(df_clean[col], errors='coerce')
                    print(f"   üîß –ö–æ–Ω–≤–µ—Ä—Ç–æ–≤–∞–Ω–æ –∫–æ–ª–æ–Ω–∫—É '{col}' –≤ —á–∏—Å–ª–æ–≤—É (NaN –¥–ª—è 'default')")
    
    return df_clean


def _clean_metrics_for_json(metrics: Dict) -> Dict:
    """–û—á–∏—â—É—î –º–µ—Ç—Ä–∏–∫–∏ –≤—ñ–¥ —Ç–∏–ø—ñ–≤, —è–∫—ñ –Ω–µ –º–æ–∂–Ω–∞ —Å–µ—Ä—ñ–∞–ª—ñ–∑—É–≤–∞—Ç–∏ –≤ JSON"""
    
    clean_metrics = {}
    
    for key, value in metrics.items():
        try:
            if isinstance(value, (np.integer, np.floating)):
                clean_metrics[key] = float(value)
            elif isinstance(value, np.ndarray):
                clean_metrics[key] = value.tolist()
            elif isinstance(value, dict):
                clean_metrics[key] = _clean_metrics_for_json(value)
            elif isinstance(value, list):
                clean_metrics[key] = [_clean_single_value_for_json(v) for v in value]
            elif pd.isna(value):
                clean_metrics[key] = None
            else:
                clean_metrics[key] = _clean_single_value_for_json(value)
        except Exception as e:
            # –Ø–∫—â–æ –Ω–µ –º–æ–∂–µ–º–æ –æ—á–∏—Å—Ç–∏—Ç–∏ –∑–Ω–∞—á–µ–Ω–Ω—è, –∑–±–µ—Ä—ñ–≥–∞—î–º–æ —è–∫ string
            clean_metrics[key] = str(value)
    
    return clean_metrics


def _clean_single_value_for_json(value):
    """–û—á–∏—â–∞—î –æ–¥–Ω–µ –∑–Ω–∞—á–µ–Ω–Ω—è –¥–ª—è JSON —Å–µ—Ä—ñ–∞–ª—ñ–∑–∞—Ü—ñ—ó"""
    
    if isinstance(value, (np.integer, np.floating)):
        return float(value)
    elif isinstance(value, np.ndarray):
        return value.tolist()
    elif pd.isna(value):
        return None
    elif isinstance(value, (int, float, str, bool, type(None))):
        return value
    else:
        return str(value)
    
def _compress_experiment_results(experiment_path: Path) -> str:
    """–ê—Ä—Ö—ñ–≤—É—î —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∏ –µ–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç—É"""
    import shutil
    
    archive_path = experiment_path.parent / f"{experiment_path.name}"
    archive_file = shutil.make_archive(str(archive_path), 'zip', str(experiment_path))
    return archive_file

print("‚úÖ –ü–æ–∫—Ä–∞—â–µ–Ω–∞ —Ñ—É–Ω–∫—Ü—ñ—è save_experiment_summary –≥–æ—Ç–æ–≤–∞!")
print("üìÅ –ù–æ–≤—ñ –º–æ–∂–ª–∏–≤–æ—Å—Ç—ñ:")
print("   ‚Ä¢ –°—Ç—Ä—É–∫—Ç—É—Ä–æ–≤–∞–Ω–∞ –ø–∞–ø–∫–∞ –¥–ª—è –∫–æ–∂–Ω–æ–≥–æ –µ–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç—É")
print("   ‚Ä¢ –ó–±–µ—Ä–µ–∂–µ–Ω–Ω—è –≤ —Ä—ñ–∑–Ω–∏—Ö —Ñ–æ—Ä–º–∞—Ç–∞—Ö (JSON, CSV, Parquet)")
print("   ‚Ä¢ –î–µ—Ç–∞–ª—å–Ω—ñ –∑–≤—ñ—Ç–∏ —Ç–∞ –ø–æ—Ä—ñ–≤–Ω—è–ª—å–Ω—ñ —Ç–∞–±–ª–∏—Ü—ñ")
print("   ‚Ä¢ –ê–≤—Ç–æ–º–∞—Ç–∏—á–Ω–µ –∞—Ä—Ö—ñ–≤—É–≤–∞–Ω–Ω—è —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ñ–≤")
print("   ‚Ä¢ –ú–µ—Ç–∞–¥–∞–Ω—ñ –ø—Ä–æ —Å–∏—Å—Ç–µ–º—É —Ç–∞ –∫–æ–Ω—Ñ—ñ–≥—É—Ä–∞—Ü—ñ—é")

def load_experiment_results(experiment_path: str) -> Dict[str, Any]:
    """
    üìÇ –ó–∞–≤–∞–Ω—Ç–∞–∂—É—î –∑–±–µ—Ä–µ–∂–µ–Ω—ñ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∏ –µ–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç—É
    
    Parameters:
    -----------
    experiment_path : str
        –®–ª—è—Ö –¥–æ –ø–∞–ø–∫–∏ –∑ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞–º–∏ –µ–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç—É
        
    Returns:
    --------
    Dict[str, Any]
        –°–ª–æ–≤–Ω–∏–∫ –∑ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞–º–∏ –µ–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç—É
    """
    
    experiment_path = Path(experiment_path)
    
    if not experiment_path.exists():
        raise FileNotFoundError(f"–ü–∞–ø–∫–∞ –µ–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç—É –Ω–µ –∑–Ω–∞–π–¥–µ–Ω–∞: {experiment_path}")
    
    # –ó–∞–≤–∞–Ω—Ç–∞–∂—É—î–º–æ –æ—Å–Ω–æ–≤–Ω–µ —Ä–µ–∑—é–º–µ
    summary_file = experiment_path / "summary" / "experiment_summary.json"
    if summary_file.exists():
        with open(summary_file, 'r', encoding='utf-8') as f:
            summary = json.load(f)
    else:
        summary = {}
    
    # –ó–∞–≤–∞–Ω—Ç–∞–∂—É—î–º–æ –¥–µ—Ç–∞–ª—å–Ω—ñ –¥–∞–Ω—ñ
    detailed_data = {}
    detailed_dir = experiment_path / "detailed_data"
    
    if detailed_dir.exists():
        for file_path in detailed_dir.glob("*.parquet"):
            exp_name = file_path.stem.replace('_results', '').replace('_comparison', '')
            try:
                detailed_data[exp_name] = pd.read_parquet(file_path)
            except Exception as e:
                print(f"‚ö†Ô∏è –ü–æ–º–∏–ª–∫–∞ –∑–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–Ω—è {file_path}: {e}")
    
    # –ó–∞–≤–∞–Ω—Ç–∞–∂—É—î–º–æ –º–µ—Ç—Ä–∏–∫–∏
    metrics_data = {}
    metrics_dir = experiment_path / "metrics"
    
    if metrics_dir.exists():
        for file_path in metrics_dir.glob("*.json"):
            exp_name = file_path.stem.replace('_metrics', '')
            try:
                with open(file_path, 'r', encoding='utf-8') as f:
                    metrics_data[exp_name] = json.load(f)
            except Exception as e:
                print(f"‚ö†Ô∏è –ü–æ–º–∏–ª–∫–∞ –∑–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–Ω—è {file_path}: {e}")
    
    return {
        'summary': summary,
        'detailed_data': detailed_data,
        'metrics': metrics_data,
        'experiment_path': str(experiment_path)
    }


def list_available_experiments(base_results_dir: str = "experiment_results") -> pd.DataFrame:
    """
    üìã –ü–æ–∫–∞–∑—É—î —Å–ø–∏—Å–æ–∫ –≤—Å—ñ—Ö –¥–æ—Å—Ç—É–ø–Ω–∏—Ö –µ–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç—ñ–≤
    
    Returns:
    --------
    pd.DataFrame
        –¢–∞–±–ª–∏—Ü—è –∑ —ñ–Ω—Ñ–æ—Ä–º–∞—Ü—ñ—î—é –ø—Ä–æ –µ–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç–∏
    """
    
    base_path = Path(base_results_dir)
    
    if not base_path.exists():
        print(f"üìÅ –ü–∞–ø–∫–∞ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ñ–≤ –Ω–µ –∑–Ω–∞–π–¥–µ–Ω–∞: {base_path}")
        return pd.DataFrame()
    
    experiments = []
    
    for exp_dir in base_path.iterdir():
        if exp_dir.is_dir():
            summary_file = exp_dir / "summary" / "experiment_summary.json"
            
            if summary_file.exists():
                try:
                    with open(summary_file, 'r', encoding='utf-8') as f:
                        summary = json.load(f)
                    
                    exp_info = summary.get('experiment_info', {})
                    overview = summary.get('experiments_overview', {})
                    
                    experiments.append({
                        'Experiment_Name': exp_info.get('name', exp_dir.name),
                        'Date': exp_info.get('timestamp', 'Unknown')[:19],  # –ë–µ–∑ –º—ñ–∫—Ä–æ—Å–µ–∫—É–Ω–¥
                        'Duration_Min': exp_info.get('duration_minutes', 0),
                        'Total_Tests': overview.get('total_count', 0),
                        'Successful': overview.get('successful_count', 0),
                        'Path': str(exp_dir),
                        'Size_MB': _calculate_directory_size(exp_dir)
                    })
                except Exception as e:
                    experiments.append({
                        'Experiment_Name': exp_dir.name,
                        'Date': 'Error',
                        'Duration_Min': 0,
                        'Total_Tests': 0,
                        'Successful': 0,
                        'Path': str(exp_dir),
                        'Size_MB': _calculate_directory_size(exp_dir),
                        'Error': str(e)
                    })
    
    if experiments:
        df = pd.DataFrame(experiments)
        # –°–æ—Ä—Ç—É—î–º–æ –∑–∞ –¥–∞—Ç–æ—é (–Ω–∞–π–Ω–æ–≤—ñ—à—ñ —Å–ø–æ—á–∞—Ç–∫—É)
        df = df.sort_values('Date', ascending=False)
        return df
    else:
        return pd.DataFrame()


def clean_old_experiments(base_results_dir: str = "experiment_results", keep_last_n: int = 10):
    """
    üßπ –í–∏–¥–∞–ª—è—î —Å—Ç–∞—Ä—ñ –µ–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç–∏, –∑–∞–ª–∏—à–∞—é—á–∏ —Ç—ñ–ª—å–∫–∏ –æ—Å—Ç–∞–Ω–Ω—ñ N
    
    Parameters:
    -----------
    base_results_dir : str
        –ü–∞–ø–∫–∞ –∑ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞–º–∏
    keep_last_n : int
        –ö—ñ–ª—å–∫—ñ—Å—Ç—å –æ—Å—Ç–∞–Ω–Ω—ñ—Ö –µ–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç—ñ–≤ –¥–ª—è –∑–±–µ—Ä–µ–∂–µ–Ω–Ω—è
    """
    
    experiments_df = list_available_experiments(base_results_dir)
    
    if len(experiments_df) <= keep_last_n:
        print(f"‚úÖ –ï–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç—ñ–≤ {len(experiments_df)} <= {keep_last_n}, –≤–∏–¥–∞–ª–µ–Ω–Ω—è –Ω–µ –ø–æ—Ç—Ä—ñ–±–Ω–µ")
        return
    
    # –í–∏–¥–∞–ª—è—î–º–æ —Å—Ç–∞—Ä—ñ –µ–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç–∏
    to_delete = experiments_df.iloc[keep_last_n:]
    total_size = to_delete['Size_MB'].sum()
    
    print(f"üßπ –í–∏–¥–∞–ª–µ–Ω–Ω—è {len(to_delete)} —Å—Ç–∞—Ä–∏—Ö –µ–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç—ñ–≤ (–∑–≤—ñ–ª—å–Ω–µ–Ω–Ω—è {total_size:.1f} MB)...")
    
    for _, row in to_delete.iterrows():
        try:
            exp_path = Path(row['Path'])
            if exp_path.exists():
                import shutil
                shutil.rmtree(exp_path)
                print(f"   üóëÔ∏è –í–∏–¥–∞–ª–µ–Ω–æ: {row['Experiment_Name']}")
        except Exception as e:
            print(f"   ‚ùå –ü–æ–º–∏–ª–∫–∞ –≤–∏–¥–∞–ª–µ–Ω–Ω—è {row['Experiment_Name']}: {e}")
    
    print(f"‚úÖ –û—á–∏—â–µ–Ω–Ω—è –∑–∞–≤–µ—Ä—à–µ–Ω–æ")


# enhanced_simulator_runner.py - –ü–û–í–ù–ò–ô –ö–û–î –≤—ñ–¥–∫–æ—Ä–∏–≥–æ–≤–∞–Ω–æ—ó —Ñ—É–Ω–∫—Ü—ñ—ó main

def main():
    """üöÄ –ì–æ–ª–æ–≤–Ω–∞ —Ñ—É–Ω–∫—Ü—ñ—è –∑–∞–ø—É—Å–∫—É –≤—Å—ñ—Ö –ø—Ä–∏–∫–ª–∞–¥—ñ–≤ –∑ –ø–æ–∫—Ä–∞—â–µ–Ω–∏–º –∑–±–µ—Ä–µ–∂–µ–Ω–Ω—è–º —Ç–∞ –ø—Ä–∞–≤–∏–ª—å–Ω–∏–º–∏ —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü—ñ—è–º–∏"""
    
    print("üî¨ –†–û–ó–®–ò–†–ï–ù–ò–ô –°–ò–ú–£–õ–Ø–¢–û–† MPC –ó –ë–ï–ù–ß–ú–ê–†–ö–û–ú")
    print("="*70)
    print("üéØ –î–æ—Å—Ç—É–ø–Ω—ñ –ø—Ä–∏–∫–ª–∞–¥–∏:")
    print("   1. üöÄ –®–≤–∏–¥–∫–∏–π –±–µ–Ω—á–º–∞—Ä–∫ –º–æ–¥–µ–ª–µ–π")
    print("   2. üî¨ –î–µ—Ç–∞–ª—å–Ω–∏–π –∞–Ω–∞–ª—ñ–∑ MPC")
    print("   3. üéØ –ö–æ—Ä–∏—Å—Ç—É–≤–∞—Ü—å–∫–∞ —Å–∏–º—É–ª—è—Ü—ñ—è")
    print("   4. üîÑ –ü–æ—Ä—ñ–≤–Ω—è–Ω–Ω—è –∫–æ–Ω—Ñ—ñ–≥—É—Ä–∞—Ü—ñ–π")
    print("   5. üèÉ –ó–∞–ø—É—Å—Ç–∏—Ç–∏ –≤—Å—ñ –ø—Ä–∏–∫–ª–∞–¥–∏")
    print("="*70)
    
    try:
        # –ó–∞–ø–∏—Ç—É—î–º–æ —É –∫–æ—Ä–∏—Å—Ç—É–≤–∞—á–∞ –≤–∏–±—ñ—Ä —Ç–∞ –Ω–∞–∑–≤—É –µ–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç—É
        choice = input("–û–±–µ—Ä—ñ—Ç—å –ø—Ä–∏–∫–ª–∞–¥ (1-5) –∞–±–æ Enter –¥–ª—è –≤—Å—ñ—Ö: ").strip()
        
        if not choice:
            choice = "5"  # –ó–∞–ø—É—Å–∫–∞—î–º–æ –≤—Å—ñ –∑–∞ –∑–∞–º–æ–≤—á—É–≤–∞–Ω–Ω—è–º
        
        # üÜï –ó–ê–ü–ò–¢–£–Ñ–ú–û –ù–ê–ó–í–£ –ï–ö–°–ü–ï–†–ò–ú–ï–ù–¢–£
        experiment_name = input("–í–≤–µ–¥—ñ—Ç—å –Ω–∞–∑–≤—É –µ–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç—É (–∞–±–æ Enter –¥–ª—è –∞–≤—Ç–æ–≥–µ–Ω–µ—Ä–∞—Ü—ñ—ó): ").strip()
        if not experiment_name:
            experiment_name = None  # –ë—É–¥–µ –∑–≥–µ–Ω–µ—Ä–æ–≤–∞–Ω–æ –∞–≤—Ç–æ–º–∞—Ç–∏—á–Ω–æ
        
        # üÜï –ù–ê–õ–ê–®–¢–£–í–ê–ù–ù–Ø –ó–ë–ï–†–ï–ñ–ï–ù–ù–Ø
        print("\nüìÅ –ù–∞–ª–∞—à—Ç—É–≤–∞–Ω–Ω—è –∑–±–µ—Ä–µ–∂–µ–Ω–Ω—è —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ñ–≤:")
        save_detailed = input("–ó–±–µ—Ä—ñ–≥–∞—Ç–∏ –¥–µ—Ç–∞–ª—å–Ω—ñ –¥–∞–Ω—ñ? (y/N): ").strip().lower() in ['y', 'yes', '—Ç–∞–∫', '—Ç']
        compress_results = input("–ê—Ä—Ö—ñ–≤—É–≤–∞—Ç–∏ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∏? (y/N): ").strip().lower() in ['y', 'yes', '—Ç–∞–∫', '—Ç']
        
        results = {}
        total_start_time = time.time()
        
        print(f"\nüöÄ –ü–û–ß–ê–¢–û–ö –ï–ö–°–ü–ï–†–ò–ú–ï–ù–¢–£: {experiment_name or '–ê–≤—Ç–æ–≥–µ–Ω–µ—Ä–æ–≤–∞–Ω–∏–π'}")
        print("="*70)
        
        # –ó–∞–ø—É—Å–∫–∞—î–º–æ –æ–±—Ä–∞–Ω—ñ –µ–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç–∏
        if choice in ["1", "5"]:
            print(f"\n{'üöÄ –ó–ê–ü–£–°–ö –ü–†–ò–ö–õ–ê–î–£ 1' if choice == '1' else 'üöÄ –ü–†–ò–ö–õ–ê–î 1/4'}")
            try:
                results['quick_benchmark'] = example_1_quick_benchmark()
                print("   ‚úÖ –ü—Ä–∏–∫–ª–∞–¥ 1 –∑–∞–≤–µ—Ä—à–µ–Ω–æ —É—Å–ø—ñ—à–Ω–æ")
            except Exception as e:
                print(f"   ‚ùå –ü–æ–º–∏–ª–∫–∞ –≤ –ø—Ä–∏–∫–ª–∞–¥—ñ 1: {e}")
                results['quick_benchmark'] = None
        
        if choice in ["2", "5"]:
            print(f"\n{'üî¨ –ó–ê–ü–£–°–ö –ü–†–ò–ö–õ–ê–î–£ 2' if choice == '2' else 'üî¨ –ü–†–ò–ö–õ–ê–î 2/4'}")
            try:
                results['detailed_analysis'] = example_2_detailed_analysis()
                print("   ‚úÖ –ü—Ä–∏–∫–ª–∞–¥ 2 –∑–∞–≤–µ—Ä—à–µ–Ω–æ —É—Å–ø—ñ—à–Ω–æ")
            except Exception as e:
                print(f"   ‚ùå –ü–æ–º–∏–ª–∫–∞ –≤ –ø—Ä–∏–∫–ª–∞–¥—ñ 2: {e}")
                results['detailed_analysis'] = None
        
        if choice in ["3", "5"]:
            print(f"\n{'üéØ –ó–ê–ü–£–°–ö –ü–†–ò–ö–õ–ê–î–£ 3' if choice == '3' else 'üéØ –ü–†–ò–ö–õ–ê–î 3/4'}")
            try:
                results['custom_simulation'] = example_3_custom_simulation()
                print("   ‚úÖ –ü—Ä–∏–∫–ª–∞–¥ 3 –∑–∞–≤–µ—Ä—à–µ–Ω–æ —É—Å–ø—ñ—à–Ω–æ")
            except Exception as e:
                print(f"   ‚ùå –ü–æ–º–∏–ª–∫–∞ –≤ –ø—Ä–∏–∫–ª–∞–¥—ñ 3: {e}")
                results['custom_simulation'] = None
        
        if choice in ["4", "5"]:
            print(f"\n{'üîÑ –ó–ê–ü–£–°–ö –ü–†–ò–ö–õ–ê–î–£ 4' if choice == '4' else 'üîÑ –ü–†–ò–ö–õ–ê–î 4/4'}")
            try:
                # üîß –í–ò–ö–û–†–ò–°–¢–û–í–£–Ñ–ú–û –í–ò–ü–†–ê–í–õ–ï–ù–£ –§–£–ù–ö–¶–Ü–Æ –ë–ï–ó –í–¢–†–£–ß–ê–ù–ù–Ø
                results['configuration_comparison'] = compare_mpc_configurations_correct(
                    configurations=[
                        {
                            'name': 'KRR_Conservative',
                            'N_data':1000, # added
                            'model_type': 'krr',
                            'kernel': 'rbf', 
                            'Np': 6,
                            'Nc': 4,
                            'Œª_obj': 0.2,
                            'w_fe': 5.0,
                            'w_mass': 1.0,
                            'find_optimal_params': False # added
                        },
                        {
                            'name': 'KRR_Aggressive', 
                            'N_data':1000, # added
                            'model_type': 'krr',
                            'kernel': 'rbf',
                            'Np': 8,
                            'Nc': 6,
                            'Œª_obj': 0.05,
                            'w_fe': 10.0,
                            'w_mass': 1.5,
                            # 'N_data': 12000 # removed
                            'find_optimal_params': False
                        }
                        # {
                        #     'name': 'SVR_Balanced',
                        #     'model_type': 'svr',
                        #     'kernel': 'rbf',
                        #     'Np': 7,
                        #     'Nc': 5,
                        #     'Œª_obj': 0.1,
                        #     'w_fe': 7.0,
                        #     'w_mass': 1.2
                        # },
                        # {
                        #     'name': 'Linear_Fast',
                        #     'model_type': 'linear',
                        #     'linear_type': 'ridge',
                        #     'Np': 10,
                        #     'Nc': 8,
                        #     'Œª_obj': 0.15,
                        #     'w_fe': 6.0,
                        #     'w_mass': 1.0,
                        #     'verbose_reports': True,
                        #     'silent_mode': False
                        # }
                    ],
                    hist_df=load_historical_data(),
                    base_config='oleksandr_original',
                    comparison_steps=100,
                    show_progress=True
                )
                print("   ‚úÖ –ü—Ä–∏–∫–ª–∞–¥ 4 –∑–∞–≤–µ—Ä—à–µ–Ω–æ —É—Å–ø—ñ—à–Ω–æ")
            except Exception as e:
                print(f"   ‚ùå –ü–æ–º–∏–ª–∫–∞ –≤ –ø—Ä–∏–∫–ª–∞–¥—ñ 4: {e}")
                results['configuration_comparison'] = None
        
        total_time = time.time() - total_start_time
        
        # –ü—ñ–¥—Å—É–º–æ–∫ –µ–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç—É
        print(f"\n" + "="*70)
        print(f"üéâ –ï–ö–°–ü–ï–†–ò–ú–ï–ù–¢ –ó–ê–í–ï–†–®–ï–ù–û")
        print(f"="*70)
        print(f"‚è±Ô∏è –ó–∞–≥–∞–ª—å–Ω–∏–π —á–∞—Å: {total_time/60:.1f} —Ö–≤–∏–ª–∏–Ω")
        print(f"üìä –ü—Ä–æ–≤–µ–¥–µ–Ω–æ –µ–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç—ñ–≤: {len([r for r in results.values() if r is not None])}")
        
        success_count = len([r for r in results.values() if r is not None])
        total_count = len(results)
        print(f"‚úÖ –£—Å–ø—ñ—à–Ω–∏—Ö: {success_count}/{total_count}")
        
        # üÜï –ó–ë–ï–†–ï–ñ–ï–ù–ù–Ø –†–ï–ó–£–õ–¨–¢–ê–¢–Ü–í –ó –ù–û–í–û–Æ –°–ò–°–¢–ï–ú–û–Æ
        if results:
            print(f"\nüíæ –ó–ë–ï–†–ï–ñ–ï–ù–ù–Ø –†–ï–ó–£–õ–¨–¢–ê–¢–Ü–í –ï–ö–°–ü–ï–†–ò–ú–ï–ù–¢–£...")
            
            try:
                experiment_path = save_experiment_summary(
                    results=results,
                    experiment_name=experiment_name,
                    base_results_dir="experiment_results",
                    save_detailed_data=save_detailed,
                    save_plots=False,  # –ü–æ–∫–∏ —â–æ –Ω–µ —Ä–µ–∞–ª—ñ–∑–æ–≤–∞–Ω–æ
                    compress_results=compress_results
                )
                
                print(f"üéØ –ï–ö–°–ü–ï–†–ò–ú–ï–ù–¢ –£–°–ü–Ü–®–ù–û –ó–ë–ï–†–ï–ñ–ï–ù–û!")
                print(f"üìÇ –õ–æ–∫–∞—Ü—ñ—è: {experiment_path}")
                
                # –ü–æ–∫–∞–∑—É—î–º–æ —â–æ –±—É–ª–æ –∑–±–µ—Ä–µ–∂–µ–Ω–æ
                if success_count > 0:
                    print(f"\nüìÅ –ó–ë–ï–†–ï–ñ–ï–ù–Ü –†–ï–ó–£–õ–¨–¢–ê–¢–ò:")
                    for exp_name, exp_result in results.items():
                        if exp_result is not None:
                            if isinstance(exp_result, pd.DataFrame):
                                print(f"   üìä {exp_name}: –¢–∞–±–ª–∏—Ü—è –ø–æ—Ä—ñ–≤–Ω—è–Ω–Ω—è ({exp_result.shape[0]} —Ä—è–¥–∫—ñ–≤)")
                            elif isinstance(exp_result, tuple):
                                print(f"   üìà {exp_name}: –†–µ–∑—É–ª—å—Ç–∞—Ç–∏ —Å–∏–º—É–ª—è—Ü—ñ—ó + –º–µ—Ç—Ä–∏–∫–∏")
                            elif isinstance(exp_result, dict):
                                print(f"   üìã {exp_name}: –î–µ—Ç–∞–ª—å–Ω–∏–π –∞–Ω–∞–ª—ñ–∑")
                            else:
                                print(f"   üìÑ {exp_name}: {type(exp_result).__name__}")
                
                # üîß –í–ò–ü–†–ê–í–õ–ï–ù–Ü –†–ï–ö–û–ú–ï–ù–î–ê–¶–Ü–á –Ω–∞ –æ—Å–Ω–æ–≤—ñ –∫–æ–º–±—ñ–Ω–æ–≤–∞–Ω–æ—ó –æ—Ü—ñ–Ω–∫–∏
                print(f"\nüí° –†–ï–ö–û–ú–ï–ù–î–ê–¶–Ü–á –î–õ–Ø –ü–û–î–ê–õ–¨–®–û–á –†–û–ë–û–¢–ò:")
                
                if 'configuration_comparison' in results and results['configuration_comparison'] is not None:
                    comparison_df = results['configuration_comparison']
                    if not comparison_df.empty and 'Configuration' in comparison_df.columns:
                        
                        # üîß –ü–†–ê–í–ò–õ–¨–ù–ê –õ–û–ì–Ü–ö–ê: –ó–Ω–∞—Ö–æ–¥–∏–º–æ –Ω–∞–π–∫—Ä–∞—â—É –∫–æ–Ω—Ñ—ñ–≥—É—Ä–∞—Ü—ñ—é –∑–∞ –∫–æ–º–±—ñ–Ω–æ–≤–∞–Ω–æ—é –æ—Ü—ñ–Ω–∫–æ—é
                        if 'Combined_Score' in comparison_df.columns:
                            valid_mask = comparison_df['Combined_Score'].notna()
                            if valid_mask.any():
                                # –°–æ—Ä—Ç—É—î–º–æ –∑–∞ –∫–æ–º–±—ñ–Ω–æ–≤–∞–Ω–æ—é –æ—Ü—ñ–Ω–∫–æ—é (–≤–∏—â–∞ = –∫—Ä–∞—â–∞)
                                sorted_df = comparison_df[valid_mask].sort_values('Combined_Score', ascending=False)
                                best_config = sorted_df.iloc[0]['Configuration']
                                best_score = sorted_df.iloc[0]['Combined_Score']
                                best_mpc_quality = sorted_df.iloc[0].get('MPC_Quality_Score', 0)
                                best_rmse = sorted_df.iloc[0].get('RMSE_Fe', 0)
                                
                                print(f"   üèÜ –í–∏–∫–æ—Ä–∏—Å—Ç–æ–≤—É–π—Ç–µ –∫–æ–Ω—Ñ—ñ–≥—É—Ä–∞—Ü—ñ—é '{best_config}' –¥–ª—è –ø—Ä–æ–¥–∞–∫—à–Ω")
                                print(f"   üìä –ö–æ–º–±—ñ–Ω–æ–≤–∞–Ω–∞ –æ—Ü—ñ–Ω–∫–∞: {best_score:.4f} (70% MPC —è–∫—ñ—Å—Ç—å + 30% —Ç–æ—á–Ω—ñ—Å—Ç—å)")
                                print(f"   üìà RMSE Fe: {best_rmse:.4f}, MPC —è–∫—ñ—Å—Ç—å: {best_mpc_quality:.1f}/100")
                                
                                # –Ü–Ω—Ç–µ—Ä–ø—Ä–µ—Ç–∞—Ü—ñ—è —è–∫–æ—Å—Ç—ñ
                                if best_mpc_quality >= 65:
                                    print(f"   ‚úÖ –í–∏—Å–æ–∫–∞ —è–∫—ñ—Å—Ç—å MPC - –≥–æ—Ç–æ–≤–æ –¥–ª—è –ø—Ä–æ–º–∏—Å–ª–æ–≤–æ–≥–æ –≤–∏–∫–æ—Ä–∏—Å—Ç–∞–Ω–Ω—è")
                                elif best_mpc_quality >= 50:
                                    print(f"   ‚ö†Ô∏è –°–µ—Ä–µ–¥–Ω—è —è–∫—ñ—Å—Ç—å MPC - —Ä–æ–∑–≥–ª—è–Ω—å—Ç–µ –¥–æ–¥–∞—Ç–∫–æ–≤–µ –Ω–∞–ª–∞—à—Ç—É–≤–∞–Ω–Ω—è")
                                else:
                                    print(f"   üîß –ù–∏–∑—å–∫–∞ —è–∫—ñ—Å—Ç—å MPC - –ø–æ—Ç—Ä—ñ–±–Ω–µ —Å–µ—Ä–π–æ–∑–Ω–µ –Ω–∞–ª–∞—à—Ç—É–≤–∞–Ω–Ω—è")
                                
                                # –ü–æ–∫–∞–∑—É—î–º–æ —Ç–æ–ø-3
                                print(f"\n   üìä –¢–æ–ø-3 –∫–æ–Ω—Ñ—ñ–≥—É—Ä–∞—Ü—ñ—ó –∑–∞ –∫–æ–º–±—ñ–Ω–æ–≤–∞–Ω–æ—é –æ—Ü—ñ–Ω–∫–æ—é:")
                                for idx in range(min(3, len(sorted_df))):
                                    row = sorted_df.iloc[idx]
                                    rank_emoji = "ü•á" if idx == 0 else "ü•à" if idx == 1 else "ü•â"
                                    print(f"      {rank_emoji} {row['Configuration']}: {row['Combined_Score']:.4f} "
                                          f"(MPC: {row.get('MPC_Quality_Score', 0):.1f}, RMSE: {row.get('RMSE_Fe', 0):.4f})")
                            else:
                                # Fallback –¥–æ –ø—Ä–æ—Å—Ç–æ–≥–æ RMSE
                                best_config = comparison_df.iloc[0]['Configuration']
                                print(f"   üèÜ –í–∏–∫–æ—Ä–∏—Å—Ç–æ–≤—É–π—Ç–µ –∫–æ–Ω—Ñ—ñ–≥—É—Ä–∞—Ü—ñ—é '{best_config}' –¥–ª—è –ø—Ä–æ–¥–∞–∫—à–Ω (–∑–∞ RMSE)")
                        else:
                            # –ù–µ–º–∞—î –∫–æ–º–±—ñ–Ω–æ–≤–∞–Ω–æ—ó –æ—Ü—ñ–Ω–∫–∏
                            best_config = comparison_df.iloc[0]['Configuration']
                            print(f"   üèÜ –í–∏–∫–æ—Ä–∏—Å—Ç–æ–≤—É–π—Ç–µ –∫–æ–Ω—Ñ—ñ–≥—É—Ä–∞—Ü—ñ—é '{best_config}' –¥–ª—è –ø—Ä–æ–¥–∞–∫—à–Ω")
                
                # –Ü–Ω—à—ñ —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü—ñ—ó
                if 'quick_benchmark' in results and results['quick_benchmark'] is not None:
                    benchmark_df = results['quick_benchmark']
                    if not benchmark_df.empty and 'Model' in benchmark_df.columns:
                        best_model = benchmark_df.iloc[0]['Model']
                        print(f"   üöÄ –ù–∞–π—à–≤–∏–¥—à–∞ –º–æ–¥–µ–ª—å: {best_model}")
                
                print(f"   üìä –†–µ–≥—É–ª—è—Ä–Ω–æ –∑–∞–ø—É—Å–∫–∞–π—Ç–µ –±–µ–Ω—á–º–∞—Ä–∫ –¥–ª—è –º–æ–Ω—ñ—Ç–æ—Ä–∏–Ω–≥—É –ø—Ä–æ–¥—É–∫—Ç–∏–≤–Ω–æ—Å—Ç—ñ")
                print(f"   üîß –ù–∞–ª–∞—à—Ç–æ–≤—É–π—Ç–µ –ø–∞—Ä–∞–º–µ—Ç—Ä–∏ MPC –Ω–∞ –æ—Å–Ω–æ–≤—ñ –∑–±–µ—Ä–µ–∂–µ–Ω–∏—Ö —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü—ñ–π")
                print(f"   üìà –í–∏–∫–æ—Ä–∏—Å—Ç–æ–≤—É–π—Ç–µ –∑–±–µ—Ä–µ–∂–µ–Ω—ñ –º–µ—Ç—Ä–∏–∫–∏ –¥–ª—è –ø–æ—Ä—ñ–≤–Ω—è–Ω–Ω—è –∑ –º–∞–π–±—É—Ç–Ω—ñ–º–∏ –µ–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç–∞–º–∏")
                
                # –Ü–Ω—Å—Ç—Ä—É–∫—Ü—ñ—ó —â–æ–¥–æ –¥–æ—Å—Ç—É–ø—É –¥–æ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ñ–≤
                print(f"\nüìñ –Ø–ö –í–ò–ö–û–†–ò–°–¢–û–í–£–í–ê–¢–ò –ó–ë–ï–†–ï–ñ–ï–ù–Ü –†–ï–ó–£–õ–¨–¢–ê–¢–ò:")
                print(f"   1. –û—Å–Ω–æ–≤–Ω–µ —Ä–µ–∑—é–º–µ: {experiment_path}/summary/experiment_summary.json")
                print(f"   2. –ü–æ—Ä—ñ–≤–Ω—è–ª—å–Ω–∞ —Ç–∞–±–ª–∏—Ü—è: {experiment_path}/summary/comparison_table.csv")
                print(f"   3. –î–µ—Ç–∞–ª—å–Ω—ñ –¥–∞–Ω—ñ: {experiment_path}/detailed_data/")
                print(f"   4. –ö–æ–Ω—Ñ—ñ–≥—É—Ä–∞—Ü—ñ—ó: {experiment_path}/configurations/")
                print(f"   5. –¢–µ–∫—Å—Ç–æ–≤–∏–π –∑–≤—ñ—Ç: {experiment_path}/summary/experiment_report.txt")
                
            except Exception as save_error:
                print(f"‚ùå –ü–æ–º–∏–ª–∫–∞ –∑–±–µ—Ä–µ–∂–µ–Ω–Ω—è —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ñ–≤: {save_error}")
                print(f"‚ö†Ô∏è –†–µ–∑—É–ª—å—Ç–∞—Ç–∏ –∑–∞–ª–∏—à–∞—é—Ç—å—Å—è –≤ –ø–∞–º'—è—Ç—ñ –¥–ª—è —Ü—ñ—î—ó —Å–µ—Å—ñ—ó")
                
                # Fallback: –∑–±–µ—Ä—ñ–≥–∞—î–º–æ –±–∞–∑–æ–≤–µ —Ä–µ–∑—é–º–µ
                try:
                    import json
                    fallback_summary = {
                        'timestamp': pd.Timestamp.now().isoformat(),
                        'experiments_conducted': len(results),
                        'successful_experiments': success_count,
                        'total_time_minutes': total_time / 60,
                        'results_summary': {k: str(type(v)) for k, v in results.items()},
                        'error': str(save_error)
                    }
                    
                    fallback_file = f"experiment_fallback_{pd.Timestamp.now().strftime('%Y%m%d_%H%M%S')}.json"
                    with open(fallback_file, 'w', encoding='utf-8') as f:
                        json.dump(fallback_summary, f, indent=2, default=str)
                    
                    print(f"üíæ –ë–∞–∑–æ–≤–µ —Ä–µ–∑—é–º–µ –∑–±–µ—Ä–µ–∂–µ–Ω–æ: {fallback_file}")
                    
                    # üîß FALLBACK —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü—ñ—ó
                    if 'configuration_comparison' in results and results['configuration_comparison'] is not None:
                        comparison_df = results['configuration_comparison']
                        if not comparison_df.empty:
                            best_config = comparison_df.iloc[0]['Configuration']
                            print(f"\nüí° –ë–ê–ó–û–í–ê –†–ï–ö–û–ú–ï–ù–î–ê–¶–Ü–Ø:")
                            print(f"   üèÜ –ù–∞–π–∫—Ä–∞—â–∞ –∫–æ–Ω—Ñ—ñ–≥—É—Ä–∞—Ü—ñ—è: {best_config}")
                            
                except Exception as fallback_error:
                    print(f"‚ùå –ù–µ –≤–¥–∞–ª–æ—Å—è –∑–±–µ—Ä–µ–≥—Ç–∏ –Ω–∞–≤—ñ—Ç—å –±–∞–∑–æ–≤–µ —Ä–µ–∑—é–º–µ: {fallback_error}")
        
        else:
            print(f"‚ö†Ô∏è –ù–µ–º–∞—î —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ñ–≤ –¥–ª—è –∑–±–µ—Ä–µ–∂–µ–Ω–Ω—è")
        
        # –§—ñ–Ω–∞–ª—å–Ω—ñ –ø–æ—Ä–∞–¥–∏
        print(f"\nüöÄ –ù–ê–°–¢–£–ü–ù–Ü –ö–†–û–ö–ò:")
        print(f"   ‚Ä¢ –ü—Ä–æ–∞–Ω–∞–ª—ñ–∑—É–π—Ç–µ –∑–±–µ—Ä–µ–∂–µ–Ω—ñ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∏")
        print(f"   ‚Ä¢ –í–∏–±–µ—Ä—ñ—Ç—å –æ–ø—Ç–∏–º–∞–ª—å–Ω—É –∫–æ–Ω—Ñ—ñ–≥—É—Ä–∞—Ü—ñ—é –¥–ª—è –≤–∞—à–æ–≥–æ –ø—Ä–æ—Ü–µ—Å—É")
        print(f"   ‚Ä¢ –ó–∞–ø—É—Å—Ç—ñ—Ç—å –¥–æ–¥–∞—Ç–∫–æ–≤—ñ –µ–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç–∏ –ø—Ä–∏ –Ω–µ–æ–±—Ö—ñ–¥–Ω–æ—Å—Ç—ñ")
        print(f"   ‚Ä¢ –í–∏–∫–æ—Ä–∏—Å—Ç–æ–≤—É–π—Ç–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∏ –¥–ª—è –Ω–∞–ª–∞—à—Ç—É–≤–∞–Ω–Ω—è –ø—Ä–æ–º–∏—Å–ª–æ–≤–æ—ó —Å–∏—Å—Ç–µ–º–∏")
        
    except KeyboardInterrupt:
        print(f"\n‚ö†Ô∏è –ï–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç –ø–µ—Ä–µ—Ä–≤–∞–Ω–æ –∫–æ—Ä–∏—Å—Ç—É–≤–∞—á–µ–º")
        
        # –°–ø—Ä–æ–±—É—î–º–æ –∑–±–µ—Ä–µ–≥—Ç–∏ —á–∞—Å—Ç–∫–æ–≤—ñ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∏
        if 'results' in locals() and results:
            try:
                print(f"üíæ –°–ø—Ä–æ–±–∞ –∑–±–µ—Ä–µ–∂–µ–Ω–Ω—è —á–∞—Å—Ç–∫–æ–≤–∏—Ö —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ñ–≤...")
                experiment_path = save_experiment_summary(
                    results=results,
                    experiment_name=f"{experiment_name or 'interrupted'}_partial",
                    base_results_dir="experiment_results",
                    save_detailed_data=False,  # –®–≤–∏–¥–∫–µ –∑–±–µ—Ä–µ–∂–µ–Ω–Ω—è
                    compress_results=False
                )
                print(f"‚úÖ –ß–∞—Å—Ç–∫–æ–≤—ñ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∏ –∑–±–µ—Ä–µ–∂–µ–Ω–æ: {experiment_path}")
                
                # üîß –ß–∞—Å—Ç–∫–æ–≤—ñ —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü—ñ—ó
                if 'configuration_comparison' in results and results['configuration_comparison'] is not None:
                    comparison_df = results['configuration_comparison']
                    if not comparison_df.empty and 'Combined_Score' in comparison_df.columns:
                        valid_mask = comparison_df['Combined_Score'].notna()
                        if valid_mask.any():
                            sorted_df = comparison_df[valid_mask].sort_values('Combined_Score', ascending=False)
                            best_config = sorted_df.iloc[0]['Configuration']
                            best_score = sorted_df.iloc[0]['Combined_Score']
                            print(f"\nüí° –ß–ê–°–¢–ö–û–í–ê –†–ï–ö–û–ú–ï–ù–î–ê–¶–Ü–Ø:")
                            print(f"   üèÜ –ù–∞–π–∫—Ä–∞—â–∞ –∫–æ–Ω—Ñ—ñ–≥—É—Ä–∞—Ü—ñ—è: {best_config} (–æ—Ü—ñ–Ω–∫–∞: {best_score:.4f})")
                
            except Exception as partial_save_error:
                print(f"‚ùå –ù–µ –≤–¥–∞–ª–æ—Å—è –∑–±–µ—Ä–µ–≥—Ç–∏ —á–∞—Å—Ç–∫–æ–≤—ñ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∏: {partial_save_error}")
    
    except Exception as e:
        print(f"\n‚ùå –ö—Ä–∏—Ç–∏—á–Ω–∞ –ø–æ–º–∏–ª–∫–∞: {e}")
        import traceback
        traceback.print_exc()
        
        # –°–ø—Ä–æ–±—É—î–º–æ –∑–±–µ—Ä–µ–≥—Ç–∏ —ñ–Ω—Ñ–æ—Ä–º–∞—Ü—ñ—é –ø—Ä–æ –ø–æ–º–∏–ª–∫—É
        try:
            import json
            error_info = {
                'timestamp': pd.Timestamp.now().isoformat(),
                'error_type': type(e).__name__,
                'error_message': str(e),
                'traceback': traceback.format_exc(),
                'experiment_name': experiment_name,
                'choice': choice if 'choice' in locals() else 'unknown'
            }
            
            error_file = f"experiment_error_{pd.Timestamp.now().strftime('%Y%m%d_%H%M%S')}.json"
            with open(error_file, 'w', encoding='utf-8') as f:
                json.dump(error_info, f, indent=2)
            
            print(f"üìù –Ü–Ω—Ñ–æ—Ä–º–∞—Ü—ñ—è –ø—Ä–æ –ø–æ–º–∏–ª–∫—É –∑–±–µ—Ä–µ–∂–µ–Ω–∞: {error_file}")
        except Exception as error_save_error:
            print(f"‚ùå –ù–µ –≤–¥–∞–ª–æ—Å—è –∑–±–µ—Ä–µ–≥—Ç–∏ —ñ–Ω—Ñ–æ—Ä–º–∞—Ü—ñ—é –ø—Ä–æ –ø–æ–º–∏–ª–∫—É: {error_save_error}")


if __name__ == '__main__':
    main()

print("‚úÖ –ü–û–í–ù–ò–ô –ö–û–î –í–Ü–î–ö–û–†–ò–ì–û–í–ê–ù–û–á –§–£–ù–ö–¶–Ü–á main –ì–û–¢–û–í–ò–ô!")
print("üîß –ö–ª—é—á–æ–≤—ñ –ø–æ–∫—Ä–∞—â–µ–Ω–Ω—è:")
print("   1. ‚úÖ –ü—Ä–∞–≤–∏–ª—å–Ω—ñ —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü—ñ—ó –∑–∞ –∫–æ–º–±—ñ–Ω–æ–≤–∞–Ω–æ—é –æ—Ü—ñ–Ω–∫–æ—é (70% MPC + 30% —Ç–æ—á–Ω—ñ—Å—Ç—å)")
print("   2. ‚úÖ –î–µ—Ç–∞–ª—å–Ω–µ –ø–æ—è—Å–Ω–µ–Ω–Ω—è –ª–æ–≥—ñ–∫–∏ –≤–∏–±–æ—Ä—É –Ω–∞–π–∫—Ä–∞—â–æ—ó –∫–æ–Ω—Ñ—ñ–≥—É—Ä–∞—Ü—ñ—ó")
print("   3. ‚úÖ –ü–æ–∫–∞–∑ —Ç–æ–ø-3 –∫–æ–Ω—Ñ—ñ–≥—É—Ä–∞—Ü—ñ–π –∑ –ø–æ—è—Å–Ω–µ–Ω–Ω—è–º")
print("   4. ‚úÖ –Ü–Ω—Ç–µ—Ä–ø—Ä–µ—Ç–∞—Ü—ñ—è —è–∫–æ—Å—Ç—ñ MPC (–≤–∏—Å–æ–∫–∞/—Å–µ—Ä–µ–¥–Ω—è/–Ω–∏–∑—å–∫–∞)")
print("   5. ‚úÖ –û–±—Ä–æ–±–∫–∞ –ø–æ–º–∏–ª–æ–∫ –∑ —á–∞—Å—Ç–∫–æ–≤–∏–º –∑–±–µ—Ä–µ–∂–µ–Ω–Ω—è–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ñ–≤")
print("   6. ‚úÖ Fallback –ª–æ–≥—ñ–∫–∞ –¥–ª—è –≤–∏–ø–∞–¥–∫—ñ–≤ –≤—ñ–¥—Å—É—Ç–Ω–æ—Å—Ç—ñ –∫–æ–º–±—ñ–Ω–æ–≤–∞–Ω–æ—ó –æ—Ü—ñ–Ω–∫–∏")
print("   7. ‚úÖ –Ü–Ω—Ñ–æ—Ä–º–∞—Ç–∏–≤–Ω—ñ —ñ–Ω—Å—Ç—Ä—É–∫—Ü—ñ—ó –∫–æ—Ä–∏—Å—Ç—É–≤–∞—á—É")