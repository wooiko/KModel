# linear_models_comparison_service.py

import pandas as pd
import matplotlib.pyplot as plt
import numpy as np
import json
import time
from typing import Dict, Any, List, Optional, Tuple
from sklearn.preprocessing import StandardScaler
from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error
from sklearn.model_selection import cross_val_score
from pathlib import Path
from datetime import datetime
import seaborn as sns
from scipy import stats
from statsmodels.stats.diagnostic import het_breuschpagan, acorr_ljungbox
from statsmodels.tools.tools import add_constant

# –ü—Ä–∏–ø—É—Å–∫–∞—î–º–æ, —â–æ —Ü—ñ –º–æ–¥—É–ª—ñ –∑–Ω–∞—Ö–æ–¥—è—Ç—å—Å—è –≤ —Ç–æ–º—É –∂ –∫–∞—Ç–∞–ª–æ–∑—ñ
from data_gen import StatefulDataGenerator
from model import KernelModel


class LinearModelsComparisonService:
    """
    –°–µ—Ä–≤—ñ—Å –¥–ª—è –∫–æ–º–ø–ª–µ–∫—Å–Ω–æ–≥–æ –ø–æ—Ä—ñ–≤–Ω—è–Ω–Ω—è —Ä—ñ–∑–Ω–∏—Ö –ª—ñ–Ω—ñ–π–Ω–∏—Ö –º–æ–¥–µ–ª–µ–π
    –∑ –≥–Ω—É—á–∫–æ—é –∫–æ–Ω—Ñ—ñ–≥—É—Ä–∞—Ü—ñ—î—é –¥–ª—è –¥–æ—Å–ª—ñ–¥–∂–µ–Ω–Ω—è –æ–±–º–µ–∂–µ–Ω—å ARX –ø—ñ–¥—Ö–æ–¥—É.
    
    –û—Å–Ω–æ–≤–Ω—ñ –º–æ–∂–ª–∏–≤–æ—Å—Ç—ñ:
    - –ü–æ—Ä—ñ–≤–Ω—è–Ω–Ω—è —Ä—ñ–∑–Ω–∏—Ö —Ç–∏–ø—ñ–≤ –ª—ñ–Ω—ñ–π–Ω–∏—Ö –º–æ–¥–µ–ª–µ–π (OLS, Ridge, Lasso, ARMAX)
    - –ê–Ω–∞–ª—ñ–∑ –≤–ø–ª–∏–≤—É –ª–∞–≥–æ–≤–æ—ó —Å—Ç—Ä—É–∫—Ç—É—Ä–∏
    - –î—ñ–∞–≥–Ω–æ—Å—Ç–∏–∫–∞ —Ä–µ–∑–∏–¥—É–∞–ª—ñ–≤ —Ç–∞ —Å—Ç–∞—Ç–∏—Å—Ç–∏—á–Ω—ñ —Ç–µ—Å—Ç–∏
    - –î–æ—Å–ª—ñ–¥–∂–µ–Ω–Ω—è —Ä–æ–±–∞—Å—Ç–Ω–æ—Å—Ç—ñ –¥–æ –Ω–µ–ª—ñ–Ω—ñ–π–Ω–æ—Å—Ç—ñ —Ç–∞ —à—É–º—É
    - –ì–µ–Ω–µ—Ä–∞—Ü—ñ—è –∑–≤—ñ—Ç—ñ–≤ —Ç–∞ –≤—ñ–∑—É–∞–ª—ñ–∑–∞—Ü—ñ–π –¥–ª—è –¥–∏—Å–µ—Ä—Ç–∞—Ü—ñ—ó
    """
    
    def __init__(self, reference_df: Optional[pd.DataFrame] = None, 
                 output_dir: Optional[str] = None):
        """
        –Ü–Ω—ñ—Ü—ñ–∞–ª—ñ–∑–∞—Ü—ñ—è —Å–µ—Ä–≤—ñ—Å—É –ø–æ—Ä—ñ–≤–Ω—è–Ω–Ω—è –ª—ñ–Ω—ñ–π–Ω–∏—Ö –º–æ–¥–µ–ª–µ–π.
        
        Args:
            reference_df: –†–µ—Ñ–µ—Ä–µ–Ω—Ç–Ω—ñ –¥–∞–Ω—ñ –¥–ª—è —Å–∏–º—É–ª—è—Ü—ñ—ó
            output_dir: –ë–∞–∑–æ–≤–∞ –¥–∏—Ä–µ–∫—Ç–æ—Ä—ñ—è –¥–ª—è –∑–±–µ—Ä–µ–∂–µ–Ω–Ω—è —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ñ–≤
        """
        self.reference_df = reference_df
        self.output_dir = Path(output_dir) if output_dir else Path("linear_comparison_results")
        
        # –°—Ç–≤–æ—Ä–µ–Ω–Ω—è —Å—Ç—Ä—É–∫—Ç—É—Ä–∏ –¥–∏—Ä–µ–∫—Ç–æ—Ä—ñ–π
        self.dirs = {
            'main': self.output_dir,
            'plots': self.output_dir / 'plots',
            'data': self.output_dir / 'data', 
            'reports': self.output_dir / 'reports',
            'latex': self.output_dir / 'latex',
            'diagnostics': self.output_dir / 'diagnostics'
        }
        
        for dir_path in self.dirs.values():
            dir_path.mkdir(parents=True, exist_ok=True)
        
        self.results = {}
        self.models = {}
        self.scaler_x = StandardScaler()
        self.scaler_y = StandardScaler()
        
    def run_comprehensive_comparison(self, 
                                   model_configs: List[Dict[str, Any]],
                                   global_config: Dict[str, Any]) -> Dict[str, Any]:
        """
        –ó–∞–ø—É—Å–∫ –∫–æ–º–ø–ª–µ–∫—Å–Ω–æ–≥–æ –ø–æ—Ä—ñ–≤–Ω—è–Ω–Ω—è –ª—ñ–Ω—ñ–π–Ω–∏—Ö –º–æ–¥–µ–ª–µ–π.
        
        Args:
            model_configs: –°–ø–∏—Å–æ–∫ –∫–æ–Ω—Ñ—ñ–≥—É—Ä–∞—Ü—ñ–π –¥–ª—è –∫–æ–∂–Ω–æ—ó –º–æ–¥–µ–ª—ñ
                –ü—Ä–∏–∫–ª–∞–¥: [
                    {'name': 'ARX_OLS', 'linear_type': 'ols', 'poly_degree': 1},
                    {'name': 'ARX_Ridge', 'linear_type': 'ridge', 'alpha': 0.1},
                    {'name': 'ARX_Lasso', 'linear_type': 'lasso', 'alpha': 0.01}
                ]
            global_config: –ì–ª–æ–±–∞–ª—å–Ω—ñ –ø–∞—Ä–∞–º–µ—Ç—Ä–∏ (–¥–∞–Ω—ñ, —Ä–æ–∑–±–∏—Ç—Ç—è, —Å–∏–º—É–ª—è—Ü—ñ—è)
                
        Returns:
            Dict –∑ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞–º–∏ –ø–æ—Ä—ñ–≤–Ω—è–Ω–Ω—è
        """
        print("üöÄ –ó–ê–ü–£–°–ö –ö–û–ú–ü–õ–ï–ö–°–ù–û–ì–û –ü–û–†–Ü–í–ù–Ø–ù–ù–Ø –õ–Ü–ù–Ü–ô–ù–ò–• –ú–û–î–ï–õ–ï–ô")
        print("=" * 60)
        
        # 1. –ü—ñ–¥–≥–æ—Ç–æ–≤–∫–∞ –¥–∞–Ω–∏—Ö
        data_results = self._prepare_data(global_config)
        X_train, Y_train, X_val, Y_val, X_test, Y_test, X_test_unscaled, Y_test_scaled = data_results
        
        # 2. –ù–∞–≤—á–∞–Ω–Ω—è –≤—Å—ñ—Ö –º–æ–¥–µ–ª–µ–π
        self.models = {}
        training_results = {}
        
        for config in model_configs:
            model_name = config['name']
            print(f"\nüìö –ù–∞–≤—á–∞–Ω–Ω—è –º–æ–¥–µ–ª—ñ: {model_name}")
            print("-" * 40)
            
            model_results = self._train_single_model(
                config, X_train, Y_train, X_val, Y_val
            )
            
            self.models[model_name] = model_results['model']
            training_results[model_name] = model_results['metrics']
        
        # 3. –û—Ü—ñ–Ω–∫–∞ –≤—Å—ñ—Ö –º–æ–¥–µ–ª–µ–π –Ω–∞ —Ç–µ—Å—Ç–æ–≤–∏—Ö –¥–∞–Ω–∏—Ö
        evaluation_results = self._evaluate_all_models(
            X_test, Y_test, training_results
        )
        
        # 4. –î—ñ–∞–≥–Ω–æ—Å—Ç–∏–∫–∞ —Ä–µ–∑–∏–¥—É–∞–ª—ñ–≤
        diagnostics_results = self._run_residual_diagnostics(
            X_test, Y_test
        )
        
        # 5. –ê–Ω–∞–ª—ñ–∑ —Ä–æ–±–∞—Å—Ç–Ω–æ—Å—Ç—ñ
        robustness_results = self._run_robustness_analysis(
            global_config, model_configs
        )
        
        # 6. –ó–±—ñ—Ä–∫–∞ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ñ–≤
        self.results = {
            'models_config': model_configs,
            'global_config': global_config,
            'training_results': training_results,
            'evaluation_results': evaluation_results,
            'diagnostics_results': diagnostics_results,
            'robustness_results': robustness_results,
            'data_info': {
                'train_size': X_train.shape[0],
                'val_size': X_val.shape[0] if X_val is not None else 0,
                'test_size': X_test.shape[0],
                'n_features': X_train.shape[1]
            }
        }
        
        # 7. –ì–µ–Ω–µ—Ä–∞—Ü—ñ—è –∑–≤—ñ—Ç—ñ–≤ —Ç–∞ –≤—ñ–∑—É–∞–ª—ñ–∑–∞—Ü—ñ–π
        # ‚úÖ –í–ò–ü–†–ê–í–õ–ï–ù–ù–Ø: –ü–µ—Ä–µ–¥–∞—î–º–æ Y_test –¥–ª—è –∫–æ—Ä–µ–∫—Ç–Ω–æ—ó –ø–æ–±—É–¥–æ–≤–∏ –¥—ñ–∞–≥–Ω–æ—Å—Ç–∏—á–Ω–∏—Ö –≥—Ä–∞—Ñ—ñ–∫—ñ–≤
        self._generate_comprehensive_report(Y_test)
        
        return self.results
    
    def _prepare_data(self, global_config: Dict[str, Any]) -> Tuple[np.ndarray, ...]:
        """
        –ú–µ—Ç–æ–¥ –ø—ñ–¥–≥–æ—Ç–æ–≤–∫–∏ –¥–∞–Ω–∏—Ö –∑–≥—ñ–¥–Ω–æ –∑ –≥–ª–æ–±–∞–ª—å–Ω–æ—é –∫–æ–Ω—Ñ—ñ–≥—É—Ä–∞—Ü—ñ—î—é.
        """
        
        if global_config.get('use_simulation', True):
            print("üìÑ –ì–µ–Ω–µ—Ä–∞—Ü—ñ—è —Å–∏–Ω—Ç–µ—Ç–∏—á–Ω–∏—Ö –¥–∞–Ω–∏—Ö –∑ –ê–ù–û–ú–ê–õ–Ü–Ø–ú–ò —Ç–∞ –®–£–ú–û–ú...")
            
            # –°—Ç–≤–æ—Ä–µ–Ω–Ω—è –≥–µ–Ω–µ—Ä–∞—Ç–æ—Ä–∞ –¥–∞–Ω–∏—Ö
            data_gen = StatefulDataGenerator(
                reference_df=self.reference_df,
                ore_flow_var_pct=3.0,
                time_step_s=global_config.get('time_step_s', 5),
                time_constants_s={
                    'concentrate_fe_percent': 300,
                    'tailings_fe_percent': 400,
                    'concentrate_mass_flow': 600,
                    'tailings_mass_flow': 700,
                    'default': 500
                },
                dead_times_s={
                    'concentrate_fe_percent': 60,
                    'tailings_fe_percent': 80,
                    'concentrate_mass_flow': 120,
                    'tailings_mass_flow': 140,
                    'default': 90
                },
                true_model_type=global_config.get('plant_model_type', 'rf'),
                seed=global_config.get('seed', 42)
            )
            
            # –°—Ç–≤–æ—Ä–µ–Ω–Ω—è –∫–æ–Ω—Ñ—ñ–≥—É—Ä–∞—Ü—ñ—ó –∞–Ω–æ–º–∞–ª—ñ–π
            anomaly_cfg = None
            if global_config.get('use_anomalies', True):
                anomaly_cfg = self._create_anomaly_config(global_config)
                print(f"   üî¥ –ê–Ω–æ–º–∞–ª—ñ—ó –ê–ö–¢–ò–í–û–í–ê–ù–Ü: {len(anomaly_cfg) if anomaly_cfg else 0} –∫–æ–Ω—Ñ—ñ–≥—É—Ä–∞—Ü—ñ–π")
            else:
                print("   ‚ö™ –ê–Ω–æ–º–∞–ª—ñ—ó –í–Ü–î–ö–õ–Æ–ß–ï–ù–Ü")
            
            n_data = global_config.get('N_data', global_config.get('T', 5000))
            
            # –ì–µ–Ω–µ—Ä–∞—Ü—ñ—è –±–∞–∑–æ–≤–∏—Ö –¥–∞–Ω–∏—Ö
            df_base = data_gen.generate(
                T=n_data,
                control_pts=global_config.get('control_pts', 500),
                n_neighbors=global_config.get('n_neighbors', 5),
                noise_level=global_config.get('noise_level', 'mild'),
                anomaly_config=anomaly_cfg
            )
            
            if global_config.get('enable_nonlinear', False):
                print("   üîÑ –ó–∞—Å—Ç–æ—Å—É–≤–∞–Ω–Ω—è –Ω–µ–ª—ñ–Ω—ñ–π–Ω–∏—Ö —Ç—Ä–∞–Ω—Å—Ñ–æ—Ä–º–∞—Ü—ñ–π...")
                df = data_gen.generate_nonlinear_variant(
                    base_df=df_base,
                    non_linear_factors=global_config.get('nonlinear_config', {}),
                    noise_level='mild',
                    anomaly_config=anomaly_cfg
                )
                print(f"   üìà –ù–µ–ª—ñ–Ω—ñ–π–Ω—ñ—Å—Ç—å –∑–∞—Å—Ç–æ—Å–æ–≤–∞–Ω–∞: {global_config.get('nonlinear_config', {})}")
            else:
                df = df_base
                print("   üìä –í–∏–∫–æ—Ä–∏—Å—Ç–æ–≤—É—î—Ç—å—Å—è –ª—ñ–Ω—ñ–π–Ω–∞ –º–æ–¥–µ–ª—å")
            
        else:
            print("üìÅ –í–∏–∫–æ—Ä–∏—Å—Ç–∞–Ω–Ω—è –Ω–∞–¥–∞–Ω–∏—Ö –¥–∞–Ω–∏—Ö...")
            if self.reference_df is None:
                raise ValueError("–î–ª—è –≤–∏–∫–æ—Ä–∏—Å—Ç–∞–Ω–Ω—è —Ä–µ–∞–ª—å–Ω–∏—Ö –¥–∞–Ω–∏—Ö –ø–æ—Ç—Ä—ñ–±–µ–Ω reference_df")
            df = self.reference_df.copy()
        
        # –õ–∞–≥–æ–≤—ñ –æ–∑–Ω–∞–∫–∏
        lag_depth = global_config.get('lag_depth', 3)
        X, Y = self._create_lag_features(df, lag_depth)
    
        # –†–æ–∑–±–∏—Ç—Ç—è
        train_size = global_config.get('train_size', 0.8)
        val_size = global_config.get('val_size', 0.1)
        n = X.shape[0]
        n_train = int(n * train_size)
        n_val = int(n * val_size)
        n_test = n - n_train - n_val
    
        X_train = X[:n_train]
        Y_train = Y[:n_train]
        X_val = X[n_train:n_train + n_val] if n_val > 0 else None
        Y_val = Y[n_train:n_train + n_val] if n_val > 0 else None
        X_test = X[-n_test:]
        Y_test = Y[-n_test:]
    
        # –ú–∞—Å—à—Ç–∞–±—É–≤–∞–Ω–Ω—è: fit –¢–Ü–õ–¨–ö–ò –æ–¥–∏–Ω —Ä–∞–∑, –∫–æ–ª–∏ –≤–æ–Ω–∏ —â–µ –Ω–µ —Ñ—ñ—Ç–∫–Ω—É—Ç—ñ
        if not hasattr(self.scaler_x, "mean_"):
            self.scaler_x.fit(X_train)
        if not hasattr(self.scaler_y, "mean_"):
            self.scaler_y.fit(Y_train)
    
        X_train_scaled = self.scaler_x.transform(X_train)
        X_val_scaled = self.scaler_x.transform(X_val) if X_val is not None else None
        X_test_scaled = self.scaler_x.transform(X_test)
    
        Y_train_scaled = self.scaler_y.transform(Y_train)
        Y_val_scaled = self.scaler_y.transform(Y_val) if Y_val is not None else None
        Y_test_scaled = self.scaler_y.transform(Y_test)
    
        # –ü–æ–≤–µ—Ä—Ç–∞—î–º–æ —ñ –º–∞—Å—à—Ç–∞–±–æ–≤–∞–Ω—ñ, —ñ ¬´—Ä–µ–∞–ª—å–Ω—ñ¬ª —Ç–µ—Å—Ç–æ–≤—ñ Y –¥–ª—è –∫–æ—Ä–µ–∫—Ç–Ω–∏—Ö –º–µ—Ç—Ä–∏–∫
        return (
            X_train_scaled, Y_train_scaled,
            X_val_scaled, Y_val_scaled,
            X_test_scaled, Y_test,  # Y_test —É —Ä–µ–∞–ª—å–Ω–∏—Ö –æ–¥–∏–Ω–∏—Ü—è—Ö
            X_test, Y_test_scaled
        ) 
     
    def _create_anomaly_config(self, global_config: Dict[str, Any]) -> Dict[str, Any]:
        """
        –ú–µ—Ç–æ–¥ —Å—Ç–≤–æ—Ä–µ–Ω–Ω—è –∫–æ–Ω—Ñ—ñ–≥—É—Ä–∞—Ü—ñ—ó –∞–Ω–æ–º–∞–ª—ñ–π.
        """
        N_data = global_config.get('N_data', global_config.get('T', 5000))
        train_frac = global_config.get('train_size', 0.8)
        val_frac = global_config.get('val_size', 0.1)
        test_frac = 1 - train_frac - val_frac
        seed = global_config.get('seed', 42)
        
        base_anomaly_config = StatefulDataGenerator.generate_anomaly_config(
            N_data=N_data,
            train_frac=train_frac,
            val_frac=val_frac,
            test_frac=test_frac,
            seed=seed
        )
        
        severity = global_config.get('anomaly_severity', 'medium')
        include_train = global_config.get('anomaly_in_train', True)
        
        n_train = int(N_data * train_frac)
        n_val = int(N_data * val_frac)
        
        enhanced_anomaly_config = base_anomaly_config.copy() if base_anomaly_config else {}
        
        test_start = n_train + n_val
        
        if severity == 'mild':
            n_test_anomalies, anomaly_strength = 3, 1.5
        elif severity == 'medium':
            n_test_anomalies, anomaly_strength = 6, 2.0
        elif severity == 'strong':
            n_test_anomalies, anomaly_strength = 10, 3.0
        else:
            n_test_anomalies, anomaly_strength = 5, 2.0
        
        np.random.seed(seed + 100)
        test_indices = np.random.choice(
            range(test_start, N_data - 10), 
            size=n_test_anomalies, 
            replace=False
        )
        
        if 'feed_fe_percent' not in enhanced_anomaly_config:
            enhanced_anomaly_config['feed_fe_percent'] = []
        if 'ore_mass_flow' not in enhanced_anomaly_config:
            enhanced_anomaly_config['ore_mass_flow'] = []
        
        for idx in test_indices:
            enhanced_anomaly_config['feed_fe_percent'].append({
                'start': int(idx),
                'duration': np.random.randint(3, 8),
                'magnitude': anomaly_strength,
                'type': 'spike'
            })
            
            enhanced_anomaly_config['ore_mass_flow'].append({
                'start': int(idx) + 2,
                'duration': np.random.randint(2, 6),
                'magnitude': anomaly_strength * 0.8,
                'type': 'spike'
            })
        
        if include_train:
            n_train_anomalies = max(1, n_test_anomalies // 3)
            
            train_indices = np.random.choice(
                range(100, n_train - 100), 
                size=n_train_anomalies, 
                replace=False
            )
            
            if 'feed_fe_percent' not in enhanced_anomaly_config:
                enhanced_anomaly_config['feed_fe_percent'] = []
            
            for idx in train_indices:
                enhanced_anomaly_config['feed_fe_percent'].append({
                    'start': int(idx),
                    'duration': np.random.randint(2, 5),
                    'magnitude': anomaly_strength * 0.7,
                    'type': 'spike'
                })
            
            print(f"   üî¥ –î–æ–¥–∞–Ω–æ {n_train_anomalies} –∞–Ω–æ–º–∞–ª—ñ–π —É —Ç—Ä–µ–Ω—É–≤–∞–ª—å–Ω—ñ –¥–∞–Ω—ñ")
        
        print(f"   üî¥ –î–æ–¥–∞–Ω–æ {n_test_anomalies * 2} –∞–Ω–æ–º–∞–ª—ñ–π —É —Ç–µ—Å—Ç–æ–≤—ñ –¥–∞–Ω—ñ")
        print(f"   üìä –†—ñ–≤–µ–Ω—å –∞–Ω–æ–º–∞–ª—ñ–π: {severity} (—Å–∏–ª–∞: {anomaly_strength})")
        
        return enhanced_anomaly_config
    
    
    def diagnose_data_quality(self, X: np.ndarray, Y: np.ndarray, 
                             df_original: pd.DataFrame = None) -> Dict[str, Any]:
        """
        –î—ñ–∞–≥–Ω–æ—Å—Ç–∏—á–Ω–∏–π –º–µ—Ç–æ–¥ –¥–ª—è –≤–∏—è–≤–ª–µ–Ω–Ω—è –ø—Ä–æ–±–ª–µ–º –∑ —è–∫—ñ—Å—Ç—é –¥–∞–Ω–∏—Ö.
        """
        
        print("üîç –î–Ü–ê–ì–ù–û–°–¢–ò–ö–ê –Ø–ö–û–°–¢–Ü –î–ê–ù–ò–•")
        print("=" * 35)
        
        diagnostics = {
            'data_variability': {},
            'anomaly_presence': {},
            'nonlinearity_check': {},
            'data_quality_score': 0.0,
            'warnings': []
        }
        
        print("\nüìä –ü–µ—Ä–µ–≤—ñ—Ä–∫–∞ –≤–∞—Ä—ñ–∞—Ü—ñ—ó –¥–∞–Ω–∏—Ö:")
        for i in range(Y.shape[1]):
            col_name = f'Y_col_{i}'
            y_col = Y[:, i]
            std_val = np.std(y_col)
            coef_var = std_val / (np.mean(y_col) + 1e-12)
            unique_ratio = len(np.unique(y_col.round(6))) / len(y_col)
            diagnostics['data_variability'][col_name] = {
                'std': std_val, 'coef_variation': coef_var, 'unique_ratio': unique_ratio,
                'range': [np.min(y_col), np.max(y_col)]
            }
            print(f"   {col_name}: std={std_val:.4f}, CV={coef_var:.4f}, unique={unique_ratio:.3f}")
            if coef_var < 0.01:
                warning = f"–î–£–ñ–ï –ú–ê–õ–ê –í–ê–†–Ü–ê–¶–Ü–Ø –≤ {col_name} (CV={coef_var:.6f})"
                diagnostics['warnings'].append(warning)
                print(f"   ‚ö†Ô∏è  {warning}")
            if unique_ratio < 0.1:
                warning = f"–î–£–ñ–ï –ú–ê–õ–û –£–ù–Ü–ö–ê–õ–¨–ù–ò–• –ó–ù–ê–ß–ï–ù–¨ –≤ {col_name} ({unique_ratio:.3f})"
                diagnostics['warnings'].append(warning)
                print(f"   ‚ö†Ô∏è  {warning}")
        
        print("\nüî¥ –ü–µ—Ä–µ–≤—ñ—Ä–∫–∞ –Ω–∞—è–≤–Ω–æ—Å—Ç—ñ –∞–Ω–æ–º–∞–ª—ñ–π:")
        for i in range(Y.shape[1]):
            col_name = f'Y_col_{i}'
            y_col = Y[:, i]
            q1, q3 = np.percentile(y_col, [25, 75])
            iqr = q3 - q1
            lower_bound, upper_bound = q1 - 1.5 * iqr, q3 + 1.5 * iqr
            outliers = np.where((y_col < lower_bound) | (y_col > upper_bound))[0]
            outlier_ratio = len(outliers) / len(y_col)
            diagnostics['anomaly_presence'][col_name] = {
                'n_outliers': len(outliers), 'outlier_ratio': outlier_ratio,
                'outlier_indices': outliers.tolist()[:20]
            }
            print(f"   {col_name}: {len(outliers)} –≤–∏–∫–∏–¥—ñ–≤ ({outlier_ratio:.3f})")
            if outlier_ratio < 0.01:
                warning = f"–î–£–ñ–ï –ú–ê–õ–û –ê–ù–û–ú–ê–õ–Ü–ô –≤ {col_name} ({outlier_ratio:.4f})"
                diagnostics['warnings'].append(warning)
                print(f"   ‚ö†Ô∏è  {warning}")
        
        quality_score = 100.0
        for warning in diagnostics['warnings']:
            if '–î–£–ñ–ï –ú–ê–õ–ê –í–ê–†–Ü–ê–¶–Ü–Ø' in warning: quality_score -= 30
            elif '–î–£–ñ–ï –ú–ê–õ–û –£–ù–Ü–ö–ê–õ–¨–ù–ò–•' in warning: quality_score -= 20
            elif '–î–£–ñ–ï –ú–ê–õ–û –ê–ù–û–ú–ê–õ–Ü–ô' in warning: quality_score -= 25
            elif '–°–õ–ê–ë–ö–ê –ù–ï–õ–Ü–ù–Ü–ô–ù–Ü–°–¢–¨' in warning: quality_score -= 15
        
        diagnostics['data_quality_score'] = max(0, quality_score)
        print(f"\nüéØ –ó–ê–ì–ê–õ–¨–ù–ê –û–¶–Ü–ù–ö–ê –Ø–ö–û–°–¢–Ü –î–ê–ù–ò–•: {diagnostics['data_quality_score']:.1f}/100")
        if quality_score < 50: print("‚ùå –ö–†–ò–¢–ò–ß–ù–Ü –ü–†–û–ë–õ–ï–ú–ò –ó –î–ê–ù–ò–ú–ò - –ø–µ—Ä–µ–≤—ñ—Ä—Ç–µ –≥–µ–Ω–µ—Ä–∞—Ü—ñ—é!")
        elif quality_score < 75: print("‚ö†Ô∏è  –ü–û–ú–Ü–†–ù–Ü –ü–†–û–ë–õ–ï–ú–ò –ó –î–ê–ù–ò–ú–ò - —Ä–µ–∫–æ–º–µ–Ω–¥—É—î—Ç—å—Å—è –Ω–∞–ª–∞—à—Ç—É–≤–∞–Ω–Ω—è")
        else: print("‚úÖ –Ø–ö–Ü–°–¢–¨ –î–ê–ù–ò–• –ü–†–ò–ô–ù–Ø–¢–ù–ê")
        
        return diagnostics    
    
    def _create_lag_features(self, df: pd.DataFrame, lag_depth: int) -> Tuple[np.ndarray, np.ndarray]:
        """–°—Ç–≤–æ—Ä–µ–Ω–Ω—è –ª–∞–≥–æ–≤–∏—Ö –æ–∑–Ω–∞–∫ –¥–ª—è ARX –º–æ–¥–µ–ª–µ–π."""
        input_cols = ['feed_fe_percent', 'ore_mass_flow', 'solid_feed_percent']
        output_cols = ['concentrate_fe_percent', 'concentrate_mass_flow']
        lag_features, lag_names = [], []
        
        for col in input_cols:
            for lag in range(lag_depth):
                lag_features.append(df[col].shift(lag))
                lag_names.append(f"{col}_lag_{lag}")
        
        for col in output_cols:
            for lag in range(1, lag_depth + 1):
                lag_features.append(df[col].shift(lag))
                lag_names.append(f"{col}_lag_{lag}")
        
        lag_df = pd.concat(lag_features, axis=1, keys=lag_names)
        valid_idx = lag_df.dropna().index
        X = lag_df.loc[valid_idx].values
        Y = df.loc[valid_idx, output_cols].values
        
        print(f"üìä –°—Ç–≤–æ—Ä–µ–Ω–æ –ª–∞–≥–æ–≤—ñ –æ–∑–Ω–∞–∫–∏: {X.shape[1]} features, {X.shape[0]} samples")
        return X, Y
    
    def _train_single_model(self, config: Dict[str, Any], 
                          X_train: np.ndarray, Y_train: np.ndarray,
                          X_val: Optional[np.ndarray], Y_val: Optional[np.ndarray]) -> Dict[str, Any]:
        """–ù–∞–≤—á–∞–Ω–Ω—è –æ–¥–Ω—ñ—î—ó –ª—ñ–Ω—ñ–π–Ω–æ—ó –º–æ–¥–µ–ª—ñ –∑–≥—ñ–¥–Ω–æ –∑ –∫–æ–Ω—Ñ—ñ–≥—É—Ä–∞—Ü—ñ—î—é."""
        model_name = config['name']
        model_params = {k: v for k, v in config.items() if k != 'name'}
        model = KernelModel(model_type='linear', **model_params)
        
        start_time = time.time()
        try:
            model.fit(X_train, Y_train, X_val=X_val, Y_val=Y_val)
        except TypeError:
            model.fit(X_train, Y_train)
        train_time = time.time() - start_time
        
        Y_train_pred = model.predict(X_train)
        train_mse = mean_squared_error(Y_train, Y_train_pred)
        train_r2 = r2_score(Y_train, Y_train_pred)
        
        print(f"   ‚è±Ô∏è –ß–∞—Å –Ω–∞–≤—á–∞–Ω–Ω—è: {train_time:.3f} —Å–µ–∫")
        print(f"   üìä Train MSE: {train_mse:.6f}")
        print(f"   üìä Train R¬≤: {train_r2:.4f}")
        
        return {
            'model': model,
            'metrics': {'train_time': train_time, 'train_mse': train_mse, 'train_r2': train_r2, 'config': config}
        }
    
    def _evaluate_all_models(self, X_test: np.ndarray, Y_test: np.ndarray,
                           training_results: Dict[str, Any]) -> Dict[str, Any]:
        """–û—Ü—ñ–Ω–∫–∞ –≤—Å—ñ—Ö –º–æ–¥–µ–ª–µ–π –Ω–∞ —Ç–µ—Å—Ç–æ–≤–∏—Ö –¥–∞–Ω–∏—Ö."""
        print("\nüéØ –û–¶–Ü–ù–ö–ê –ú–û–î–ï–õ–ï–ô –ù–ê –¢–ï–°–¢–û–í–ò–• –î–ê–ù–ò–•")
        print("-" * 50)
        evaluation_results = {}
        
        for model_name, model in self.models.items():
            print(f"–û—Ü—ñ–Ω–∫–∞ {model_name}...")
            Y_pred_scaled = model.predict(X_test)
            Y_pred = self.scaler_y.inverse_transform(Y_pred_scaled)
            
            mse = mean_squared_error(Y_test, Y_pred)
            rmse_fe = np.sqrt(mean_squared_error(Y_test[:, 0], Y_pred[:, 0]))
            rmse_mass = np.sqrt(mean_squared_error(Y_test[:, 1], Y_pred[:, 1]))
            mae = mean_absolute_error(Y_test, Y_pred)
            r2 = r2_score(Y_test, Y_pred)
            mape = np.mean(np.abs((Y_test - Y_pred) / (Y_test + 1e-8))) * 100
            
            evaluation_results[model_name] = {
                'mse': mse, 'rmse_fe': rmse_fe, 'rmse_mass': rmse_mass,
                'mae': mae, 'mape': mape, 'r2': r2, 'predictions': Y_pred,
                'train_time': training_results[model_name]['train_time']
            }
            print(f"   MSE: {mse:.6f}, R¬≤: {r2:.4f}")
        return evaluation_results
    
    def _run_residual_diagnostics(self, X_test: np.ndarray, Y_test: np.ndarray) -> Dict[str, Any]:
        """–ö–æ–º–ø–ª–µ–∫—Å–Ω–∞ –¥—ñ–∞–≥–Ω–æ—Å—Ç–∏–∫–∞ —Ä–µ–∑–∏–¥—É–∞–ª—ñ–≤ –¥–ª—è –≤—Å—ñ—Ö –º–æ–¥–µ–ª–µ–π."""
        print("\nüîç –î–Ü–ê–ì–ù–û–°–¢–ò–ö–ê –†–ï–ó–ò–î–£–ê–õ–Ü–í")
        print("-" * 40)
        diagnostics = {}
        
        for model_name, model in self.models.items():
            print(f"–î—ñ–∞–≥–Ω–æ—Å—Ç–∏–∫–∞ {model_name}...")
            Y_pred_scaled = model.predict(X_test)
            Y_pred = self.scaler_y.inverse_transform(Y_pred_scaled)
            residuals = Y_test - Y_pred
            
            model_diagnostics = {}
            for i, output_name in enumerate(['Fe_concentration', 'Mass_flow']):
                res_i = residuals[:, i]
                shapiro_stat, shapiro_p = stats.shapiro(res_i[:min(len(res_i), 5000)])
                jb_stat, jb_p = stats.jarque_bera(res_i)
                model_diagnostics[f'{output_name}_normality'] = {
                    'shapiro_statistic': shapiro_stat, 'shapiro_p_value': shapiro_p,
                    'jb_statistic': jb_stat, 'jb_p_value': jb_p,
                    'is_normal': shapiro_p > 0.05 and jb_p > 0.05
                }
            
            try:
                # –î–æ–¥–∞—î–º–æ –∫–æ–Ω—Å—Ç–∞–Ω—Ç—É, —è–∫ –≤–∏–º–∞–≥–∞—î BP-—Ç–µ—Å—Ç
                exog = add_constant(X_test, has_constant='add')
                bp_stat, bp_p, _, _ = het_breuschpagan(residuals[:, 0], exog)
                model_diagnostics['heteroscedasticity'] = {
                    'breusch_pagan_stat': float(bp_stat),
                    'breusch_pagan_p': float(bp_p),
                    'is_homoscedastic': bool(bp_p > 0.05),
                }
            except Exception as e:
                model_diagnostics['heteroscedasticity'] = {'error': str(e)}
            
            try:
                bp_stat, bp_p, _, _ = het_breuschpagan(residuals[:, 0], X_test)
                model_diagnostics['heteroscedasticity'] = {
                    'breusch_pagan_stat': bp_stat, 'breusch_pagan_p': bp_p,
                    'is_homoscedastic': bp_p > 0.05
                }
            except Exception as e:
                print(f"   ‚ö†Ô∏è –ü–æ–º–∏–ª–∫–∞ –≤ —Ç–µ—Å—Ç—ñ –≥–µ—Ç–µ—Ä–æ—Å–∫–µ–¥–∞—Å—Ç–∏—á–Ω–æ—Å—Ç—ñ: {e}")
                model_diagnostics['heteroscedasticity'] = {'error': str(e)}
            
            model_diagnostics['residual_stats'] = {
                'mean': np.mean(residuals, axis=0).tolist(), 'std': np.std(residuals, axis=0).tolist(), 
                'skewness': stats.skew(residuals, axis=0).tolist(), 'kurtosis': stats.kurtosis(residuals, axis=0).tolist()
            }
            diagnostics[model_name] = model_diagnostics
            
            print(f"   ‚úì –ù–æ—Ä–º–∞–ª—å–Ω—ñ—Å—Ç—å: {model_diagnostics.get('Fe_concentration_normality', {}).get('is_normal', 'Unknown')}")
            print(f"   ‚úì –ê–≤—Ç–æ–∫–æ—Ä–µ–ª—è—Ü—ñ—è: {'–Ñ' if model_diagnostics.get('autocorrelation', {}).get('has_autocorr', True) else '–ù–µ–º–∞—î'}")
            print(f"   ‚úì –ì–æ–º–æ—Å–∫–µ–¥–∞—Å—Ç–∏—á–Ω—ñ—Å—Ç—å: {model_diagnostics.get('heteroscedasticity', {}).get('is_homoscedastic', 'Unknown')}")
        
        return diagnostics
    
    def _run_robustness_analysis(self, global_config: Dict[str, Any], 
                               model_configs: List[Dict[str, Any]]) -> Dict[str, Any]:
        """–ê–Ω–∞–ª—ñ–∑ —Ä–æ–±–∞—Å—Ç–Ω–æ—Å—Ç—ñ –º–æ–¥–µ–ª–µ–π –¥–æ —Ä—ñ–∑–Ω–∏—Ö —Ç–∏–ø—ñ–≤ –∑–±—É—Ä–µ–Ω—å."""
        print("\nüí™ –ê–ù–ê–õ–Ü–ó –†–û–ë–ê–°–¢–ù–û–°–¢–Ü")
        print("-" * 30)
        robustness_results = {}
        
        noise_levels = [0.01, 0.05, 0.10, 0.20]
        robustness_results['noise_robustness'] = self._test_noise_robustness(
            global_config, model_configs, noise_levels
        )
        
        nonlinearity_levels = [
            ('linear', {}),
            ('weak', {'concentrate_fe_percent': ('pow', 1.2)}),
            ('moderate', {'concentrate_fe_percent': ('pow', 1.8)}), 
            ('strong', {'concentrate_fe_percent': ('pow', 2.5)})
        ]
        robustness_results['nonlinearity_robustness'] = self._test_nonlinearity_robustness(
            global_config, model_configs, nonlinearity_levels
        )
        return robustness_results
    

    def _test_noise_robustness(self, global_config: Dict[str, Any],
                               model_configs: List[Dict[str, Any]],
                               noise_levels: List[float]) -> Dict[str, Any]:
        noise_results = {mc['name']: {} for mc in model_configs}
    
        for noise_level in noise_levels:
            noisy_cfg = global_config.copy()
            noisy_cfg['noise_level'] = 'custom'
            noisy_cfg['custom_noise_std'] = noise_level
    
            # –í–ê–ñ–õ–ò–í–û: –Ω–µ —Ä–µ—Ñ—ñ—Ç–∏–º–æ scaler-–∏ –Ω–∞ –Ω–æ–≤–∏—Ö –¥–∞–Ω–∏—Ö; _prepare_data –ø–æ–≤–µ—Ä—Ç–∞—î
            # X_* –≤–∂–µ —Ç—Ä–∞–Ω—Å—Ñ–æ—Ä–º–æ–≤–∞–Ω—ñ –ø–æ—Ç–æ—á–Ω–∏–º–∏ scaler-–∞–º–∏ —Å–µ—Ä–≤—ñ—Å—É
            X_train_s, Y_train_s, _, _, X_test_s, Y_test_real, _, _ = self._prepare_data(noisy_cfg)
    
            for cfg in model_configs:
                mr = self._train_single_model(cfg, X_train_s, Y_train_s, None, None)
                Y_pred_s = mr['model'].predict(X_test_s)
                Y_pred = self.scaler_y.inverse_transform(Y_pred_s)
    
                mse = mean_squared_error(Y_test_real, Y_pred)
                r2 = r2_score(Y_test_real, Y_pred)
                noise_results[cfg['name']][f'noise_{noise_level}'] = {'mse': mse, 'r2': r2}
    
        return noise_results
    
    
    def _test_nonlinearity_robustness(self, global_config: Dict[str, Any],
                                      model_configs: List[Dict[str, Any]],
                                      nonlinearity_levels: List[Tuple[str, Dict]]) -> Dict[str, Any]:
        results = {mc['name']: {} for mc in model_configs}
    
        for lvl_name, nl_cfg in nonlinearity_levels:
            cfg = global_config.copy()
            cfg['enable_nonlinear'] = bool(nl_cfg)
            cfg['nonlinear_config'] = nl_cfg
    
            X_train_s, Y_train_s, _, _, X_test_s, Y_test_real, _, _ = self._prepare_data(cfg)
    
            for mc in model_configs:
                mr = self._train_single_model(mc, X_train_s, Y_train_s, None, None)
                Y_pred_s = mr['model'].predict(X_test_s)
                Y_pred = self.scaler_y.inverse_transform(Y_pred_s)
    
                mse = mean_squared_error(Y_test_real, Y_pred)
                r2 = r2_score(Y_test_real, Y_pred)
                results[mc['name']][lvl_name] = {'mse': mse, 'r2': r2}
    
        return results
    
    # ‚úÖ –í–ò–ü–†–ê–í–õ–ï–ù–ù–Ø: –î–æ–¥–∞–Ω–æ Y_test —è–∫ –∞—Ä–≥—É–º–µ–Ω—Ç –¥–ª—è –∫–æ—Ä–µ–∫—Ç–Ω–æ—ó –≤—ñ–∑—É–∞–ª—ñ–∑–∞—Ü—ñ—ó
    def _generate_comprehensive_report(self, Y_test: np.ndarray):
        """–ì–µ–Ω–µ—Ä–∞—Ü—ñ—è –∫–æ–º–ø–ª–µ–∫—Å–Ω–æ–≥–æ –∑–≤—ñ—Ç—É –∑ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞–º–∏."""
        print("\nüìù –ì–ï–ù–ï–†–ê–¶–Ü–Ø –ó–í–Ü–¢–£")
        print("-" * 25)
        
        json_path = self.dirs['data'] / f'linear_comparison_results_{datetime.now().strftime("%Y%m%d_%H%M%S")}.json'
        json_results = self._convert_results_for_json(self.results)
        with open(json_path, 'w', encoding='utf-8') as f:
            json.dump(json_results, f, indent=2, ensure_ascii=False)
        print(f"üíæ –†–µ–∑—É–ª—å—Ç–∞—Ç–∏ –∑–±–µ—Ä–µ–∂–µ–Ω–æ: {json_path}")
        
        # ‚úÖ –í–ò–ü–†–ê–í–õ–ï–ù–ù–Ø: –ü–µ—Ä–µ–¥–∞—î–º–æ Y_test –¥–∞–ª—ñ —É —Ñ—É–Ω–∫—Ü—ñ—é –≤—ñ–∑—É–∞–ª—ñ–∑–∞—Ü—ñ—ó
        self._create_comparison_visualizations(Y_test)
        self._generate_latex_table()
        self._generate_text_report()
    
    def _convert_results_for_json(self, results: Dict) -> Dict:
        """–ö–æ–Ω–≤–µ—Ä—Ç–∞—Ü—ñ—è —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ñ–≤ –¥–ª—è JSON —Å–µ—Ä—ñ–∞–ª—ñ–∑–∞—Ü—ñ—ó."""
        def convert_value(obj):
            if isinstance(obj, np.ndarray): return obj.tolist()
            if isinstance(obj, np.floating): return float(obj)
            if isinstance(obj, np.integer): return int(obj)
            if isinstance(obj, dict): return {k: convert_value(v) for k, v in obj.items()}
            if isinstance(obj, list): return [convert_value(item) for item in obj]
            return obj
        return convert_value(results)
    
    def _create_comparison_visualizations(self, Y_test: np.ndarray):
        self._plot_accuracy_comparison()
        self._plot_residual_analysis(Y_test)  # Y_test —É —Ä–µ–∞–ª—å–Ω–∏—Ö –æ–¥–∏–Ω–∏—Ü—è—Ö
        self._plot_noise_robustness()
        self._plot_nonlinearity_robustness()
        print("‚úÖ –í—ñ–∑—É–∞–ª—ñ–∑–∞—Ü—ñ—ó —Å—Ç–≤–æ—Ä–µ–Ω–æ")
    
    def _plot_accuracy_comparison(self):
        """–ü–æ—Ä—ñ–≤–Ω—è–Ω–Ω—è —Ç–æ—á–Ω–æ—Å—Ç—ñ –º–æ–¥–µ–ª–µ–π."""
        fig, axes = plt.subplots(2, 3, figsize=(15, 10))
        fig.suptitle('–ü–æ—Ä—ñ–≤–Ω—è–Ω–Ω—è —Ç–æ—á–Ω–æ—Å—Ç—ñ –ª—ñ–Ω—ñ–π–Ω–∏—Ö –º–æ–¥–µ–ª–µ–π', fontsize=16, fontweight='bold')
        
        model_names = list(self.results['evaluation_results'].keys())
        mse_values = [self.results['evaluation_results'][name]['mse'] for name in model_names]
        r2_values = [self.results['evaluation_results'][name]['r2'] for name in model_names]
        rmse_fe_values = [self.results['evaluation_results'][name]['rmse_fe'] for name in model_names]
        rmse_mass_values = [self.results['evaluation_results'][name]['rmse_mass'] for name in model_names]
        train_times = [self.results['evaluation_results'][name]['train_time'] for name in model_names]
        
        metrics_data = [
            (axes[0, 0], mse_values, 'MSE', 'Mean Squared Error', 'lightcoral'),
            (axes[0, 1], r2_values, 'R¬≤', 'Coefficient of Determination', 'lightgreen'),
            (axes[0, 2], rmse_fe_values, 'RMSE (%)', 'RMSE –∫–æ–Ω—Ü–µ–Ω—Ç—Ä–∞—Ü—ñ—ó Fe', 'lightskyblue'),
            (axes[1, 0], rmse_mass_values, 'RMSE (—Ç/–≥–æ–¥)', 'RMSE –º–∞—Å–æ–≤–æ—ó –≤–∏—Ç—Ä–∞—Ç–∏', 'lightgoldenrodyellow'),
            (axes[1, 1], train_times, '–ß–∞—Å (—Å–µ–∫)', '–ß–∞—Å –Ω–∞–≤—á–∞–Ω–Ω—è', 'plum')
        ]
        
        for ax, values, ylabel, title, color in metrics_data:
            bars = ax.bar(range(len(model_names)), values, color=color)
            ax.set_xlabel('–ú–æ–¥–µ–ª—ñ'); ax.set_ylabel(ylabel); ax.set_title(title)
            ax.set_xticks(range(len(model_names))); ax.set_xticklabels(model_names, rotation=45, ha='right')
            ax.grid(True, alpha=0.3)
            for bar, value in zip(bars, values):
                ax.text(bar.get_x() + bar.get_width()/2, bar.get_height(), f'{value:.3f}', 
                        ha='center', va='bottom', fontweight='bold',
                        bbox=dict(facecolor='white', alpha=0.5, boxstyle='round,pad=0.2'))

        ax = axes[1, 2]
        normalized_mse = [(max(mse_values) - mse) / (max(mse_values) - min(mse_values) + 1e-8) for mse in mse_values]
        normalized_speed = [(max(train_times) - time) / (max(train_times) - min(train_times) + 1e-8) for time in train_times]
        x_pos = np.arange(len(model_names)); width = 0.35
        ax.bar(x_pos - width/2, normalized_mse, width, label='–¢–æ—á–Ω—ñ—Å—Ç—å (–Ω–æ—Ä–º.)', alpha=0.7)
        ax.bar(x_pos + width/2, normalized_speed, width, label='–®–≤–∏–¥–∫—ñ—Å—Ç—å (–Ω–æ—Ä–º.)', alpha=0.7)
        ax.set_xlabel('–ú–æ–¥–µ–ª—ñ'); ax.set_ylabel('–ù–æ—Ä–º–∞–ª—ñ–∑–æ–≤–∞–Ω–µ –∑–Ω–∞—á–µ–Ω–Ω—è'); ax.set_title('–ö–æ–º–ø–ª–µ–∫—Å–Ω–∞ –æ—Ü—ñ–Ω–∫–∞')
        ax.set_xticks(x_pos); ax.set_xticklabels(model_names, rotation=45, ha='right'); ax.legend(); ax.grid(True, alpha=0.3)
        
        plt.tight_layout(rect=[0, 0, 1, 0.96])
        plot_path = self.dirs['plots'] / 'accuracy_comparison.png'
        plt.savefig(plot_path, dpi=300, bbox_inches='tight'); plt.close()
        print(f"üìä –ì—Ä–∞—Ñ—ñ–∫ —Ç–æ—á–Ω–æ—Å—Ç—ñ –∑–±–µ—Ä–µ–∂–µ–Ω–æ: {plot_path}")
    
    # ‚úÖ –í–ò–ü–†–ê–í–õ–ï–ù–ù–Ø: –ú–µ—Ç–æ–¥ —Ç–µ–ø–µ—Ä –ø—Ä–∏–π–º–∞—î Y_test –¥–ª—è –∫–æ—Ä–µ–∫—Ç–Ω–æ–≥–æ —Ä–æ–∑—Ä–∞—Ö—É–Ω–∫—É –∑–∞–ª–∏—à–∫—ñ–≤

    def _plot_residual_analysis(self, Y_test: np.ndarray) -> None:
        """
        –ë—É–¥—É—î–º–æ –±–∞–∑–æ–≤—ñ –≥—Ä–∞—Ñ—ñ–∫–∏ –∑–∞–ª–∏—à–∫—ñ–≤ –¥–ª—è –∫–æ–∂–Ω–æ—ó –º–æ–¥–µ–ª—ñ.
        –û—á—ñ–∫—É—î–º–æ, —â–æ Y_test —É —Ä–µ–∞–ª—å–Ω–∏—Ö –æ–¥–∏–Ω–∏—Ü—è—Ö; Y_pred –∑ evaluation_results —Ç–µ–∂ —É —Ä–µ–∞–ª—å–Ω–∏—Ö –æ–¥–∏–Ω–∏—Ü—è—Ö.
        """
        import numpy as np
        import matplotlib.pyplot as plt
        import seaborn as sns
    
        eval_results = self.results.get('evaluation_results', {})
        if not eval_results:
            print("‚ö†Ô∏è –ù–µ–º–∞—î evaluation_results –¥–ª—è –ø–æ–±—É–¥–æ–≤–∏ –∞–Ω–∞–ª—ñ–∑—É –∑–∞–ª–∏—à–∫—ñ–≤.")
            return
    
        for model_name in self.models.keys():
            if model_name not in eval_results:
                continue
    
            Y_pred = np.asarray(eval_results[model_name].get('predictions'))
            if Y_pred is None or Y_pred.size == 0:
                print(f"‚ö†Ô∏è –ü–æ—Ä–æ–∂–Ω—ñ –ø—Ä–æ–≥–Ω–æ–∑–∏ –¥–ª—è {model_name}")
                continue
    
            Y_pred = Y_pred.reshape(-1, 1) if Y_pred.ndim == 1 else Y_pred
            Y_true = np.asarray(Y_test)
            Y_true = Y_true.reshape(-1, 1) if Y_true.ndim == 1 else Y_true
    
            if Y_true.shape != Y_pred.shape:
                print(f"‚ö†Ô∏è –†–æ–∑–º—ñ—Ä–Ω–æ—Å—Ç—ñ –Ω–µ –∑–±—ñ–≥–∞—é—Ç—å—Å—è: {model_name}: {Y_true.shape} vs {Y_pred.shape}")
                continue
    
            residuals = Y_true - Y_pred
            if not np.isfinite(residuals).all():
                print(f"‚ö†Ô∏è –ù–µ–∫–æ—Ä–µ–∫—Ç–Ω—ñ –∑–Ω–∞—á–µ–Ω–Ω—è –∑–∞–ª–∏—à–∫—ñ–≤ (NaN/Inf) –¥–ª—è {model_name}")
                continue
    
            # 1) –§—ñ–≥—É—Ä–∞ –∑ 2 –ø—ñ–¥—Å—é–∂–µ—Ç–∞–º–∏: —Ä–æ–∑—Å—ñ—é–≤–∞–Ω–Ω—è —Ç–∞ –≥—ñ—Å—Ç–æ–≥—Ä–∞–º–∞/—â—ñ–ª—å–Ω—ñ—Å—Ç—å
            fig, axes = plt.subplots(1, 2, figsize=(10, 4), constrained_layout=True)
            ax_scatter, ax_hist = axes
    
            # –†–æ–∑—Å—ñ—é–≤–∞–Ω–Ω—è: Y_pred vs residuals
            ax_scatter.scatter(Y_pred.ravel(), residuals.ravel(), alpha=0.6, s=18, color="#4C78A8", edgecolor="none")
            ax_scatter.axhline(0.0, color="red", linestyle="--", linewidth=1)
            ax_scatter.set_title(f"–ó–∞–ª–∏—à–∫–∏ vs –ü—Ä–æ–≥–Ω–æ–∑ ‚Äî {model_name}")
            ax_scatter.set_xlabel("YÃÇ (–ø—Ä–æ–≥–Ω–æ–∑)")
            ax_scatter.set_ylabel("–ó–∞–ª–∏—à–æ–∫ (Y ‚àí YÃÇ)")
    
            # –ì—ñ—Å—Ç–æ–≥—Ä–∞–º–∞/—â—ñ–ª—å–Ω—ñ—Å—Ç—å –∑–∞–ª–∏—à–∫—ñ–≤
            sns.histplot(residuals.ravel(), bins=30, kde=True, ax=ax_hist, color="#72B7B2")
            ax_hist.set_title(f"–†–æ–∑–ø–æ–¥—ñ–ª –∑–∞–ª–∏—à–∫—ñ–≤ ‚Äî {model_name}")
            ax_hist.set_xlabel("–ó–∞–ª–∏—à–æ–∫")
            ax_hist.set_ylabel("–ö—ñ–ª—å–∫—ñ—Å—Ç—å")
    
            # –û–ø—Ü—ñ–π–Ω–æ: –≤–∏–Ω–æ—Å–∏–º–æ –∫–æ—Ä–æ—Ç–∫—ñ –º–µ—Ç—Ä–∏–∫–∏ –ø–æ –∑–∞–ª–∏—à–∫–∞—Ö
            mu = float(np.mean(residuals))
            sigma = float(np.std(residuals, ddof=1))
            ax_hist.annotate(f"Œº={mu:.3g}\nœÉ={sigma:.3g}", xy=(0.98, 0.98), xycoords="axes fraction",
                             ha="right", va="top", fontsize=9,
                             bbox=dict(boxstyle="round,pad=0.25", fc="white", ec="#999"))
    
            # –ó–±–µ—Ä–µ–∂–µ–Ω–Ω—è, —è–∫—â–æ —É –≤–∞—Å –∑–∞–≤–µ–¥–µ–Ω–∏–π —à–ª—è—Ö self.plots_dir
            if getattr(self, "plots_dir", None):
                fname = self.plots_dir / f"residuals_{model_name}.png"
                try:
                    fig.savefig(fname, dpi=150)
                except Exception as e:
                    print(f"‚ö†Ô∏è –ù–µ –≤–¥–∞–ª–æ—Å—è –∑–±–µ—Ä–µ–≥—Ç–∏ –≥—Ä–∞—Ñ—ñ–∫ –∑–∞–ª–∏—à–∫—ñ–≤ –¥–ª—è {model_name}: {e}")
            plt.close(fig)


    def _plot_noise_robustness(self):
        """–í—ñ–∑—É–∞–ª—ñ–∑–∞—Ü—ñ—è —Ä–æ–±–∞—Å—Ç–Ω–æ—Å—Ç—ñ –¥–æ —à—É–º—É."""
        if 'noise_robustness' not in self.results.get('robustness_results', {}): return
        
        noise_data = self.results['robustness_results']['noise_robustness']
        fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(14, 6))
        fig.suptitle('–†–æ–±–∞—Å—Ç–Ω—ñ—Å—Ç—å –ª—ñ–Ω—ñ–π–Ω–∏—Ö –º–æ–¥–µ–ª–µ–π –¥–æ —à—É–º—É', fontsize=16, fontweight='bold')
        
        noise_levels_set = set()
        model_names = list(noise_data.keys())
        for model_name in model_names:
            for key in noise_data[model_name].keys():
                if key.startswith('noise_'):
                    noise_levels_set.add(float(key.split('_')[1]))
        
        noise_levels = sorted(list(noise_levels_set))
        noise_percentages = [level * 100 for level in noise_levels]
        
        for model_name in model_names:
            mse_values = [noise_data[model_name].get(f'noise_{nl}', {}).get('mse', np.nan) for nl in noise_levels]
            ax1.plot(noise_percentages, mse_values, marker='o', label=model_name, linewidth=2)
        ax1.set_xlabel('–†—ñ–≤–µ–Ω—å —à—É–º—É (%)'); ax1.set_ylabel('MSE'); ax1.set_title('–î–µ–≥—Ä–∞–¥–∞—Ü—ñ—è —Ç–æ—á–Ω–æ—Å—Ç—ñ (MSE) –ø—Ä–∏ —à—É–º—ñ')
        ax1.legend(); ax1.grid(True, alpha=0.3); ax1.set_yscale('log')
        
        for model_name in model_names:
            r2_values = [noise_data[model_name].get(f'noise_{nl}', {}).get('r2', np.nan) for nl in noise_levels]
            ax2.plot(noise_percentages, r2_values, marker='s', label=model_name, linewidth=2)
        ax2.set_xlabel('–†—ñ–≤–µ–Ω—å —à—É–º—É (%)'); ax2.set_ylabel('R¬≤'); ax2.set_title('–Ø–∫—ñ—Å—Ç—å —É–∑–∞–≥–∞–ª—å–Ω–µ–Ω–Ω—è (R¬≤) –ø—Ä–∏ —à—É–º—ñ')
        ax2.legend(); ax2.grid(True, alpha=0.3)
        
        plt.tight_layout(rect=[0, 0, 1, 0.96])
        plot_path = self.dirs['plots'] / 'noise_robustness.png'
        plt.savefig(plot_path, dpi=300, bbox_inches='tight'); plt.close()
        print(f"üîä –ì—Ä–∞—Ñ—ñ–∫ —Ä–æ–±–∞—Å—Ç–Ω–æ—Å—Ç—ñ –¥–æ —à—É–º—É –∑–±–µ—Ä–µ–∂–µ–Ω–æ: {plot_path}")
    
    def _plot_nonlinearity_robustness(self):
        """–í—ñ–∑—É–∞–ª—ñ–∑–∞—Ü—ñ—è —Ä–æ–±–∞—Å—Ç–Ω–æ—Å—Ç—ñ –¥–æ –Ω–µ–ª—ñ–Ω—ñ–π–Ω–æ—Å—Ç—ñ."""
        if 'nonlinearity_robustness' not in self.results.get('robustness_results', {}): return
        
        nl_data = self.results['robustness_results']['nonlinearity_robustness']
        fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(14, 6))
        fig.suptitle('–†–æ–±–∞—Å—Ç–Ω—ñ—Å—Ç—å –ª—ñ–Ω—ñ–π–Ω–∏—Ö –º–æ–¥–µ–ª–µ–π –¥–æ –Ω–µ–ª—ñ–Ω—ñ–π–Ω–æ—Å—Ç—ñ', fontsize=16, fontweight='bold')
        
        model_names = list(nl_data.keys())
        nonlinearity_levels = ['linear', 'weak', 'moderate', 'strong']
        x_pos = np.arange(len(nonlinearity_levels))
        width = 0.8 / len(model_names)
        
        for i, model_name in enumerate(model_names):
            mse_values = [nl_data[model_name].get(level, {}).get('mse', np.nan) for level in nonlinearity_levels]
            ax1.bar(x_pos + i*width, mse_values, width, label=model_name, alpha=0.8)
        ax1.set_xlabel('–†—ñ–≤–µ–Ω—å –Ω–µ–ª—ñ–Ω—ñ–π–Ω–æ—Å—Ç—ñ'); ax1.set_ylabel('MSE'); ax1.set_title('–í–ø–ª–∏–≤ –Ω–µ–ª—ñ–Ω—ñ–π–Ω–æ—Å—Ç—ñ –Ω–∞ —Ç–æ—á–Ω—ñ—Å—Ç—å (MSE)')
        ax1.set_xticks(x_pos + width * (len(model_names) - 1) / 2); ax1.set_xticklabels(nonlinearity_levels)
        ax1.legend(); ax1.grid(True, alpha=0.3); ax1.set_yscale('log')
        
        for i, model_name in enumerate(model_names):
            r2_values = [nl_data[model_name].get(level, {}).get('r2', np.nan) for level in nonlinearity_levels]
            ax2.bar(x_pos + i*width, r2_values, width, label=model_name, alpha=0.8)
        ax2.set_xlabel('–†—ñ–≤–µ–Ω—å –Ω–µ–ª—ñ–Ω—ñ–π–Ω–æ—Å—Ç—ñ'); ax2.set_ylabel('R¬≤'); ax2.set_title('–í–ø–ª–∏–≤ –Ω–µ–ª—ñ–Ω—ñ–π–Ω–æ—Å—Ç—ñ –Ω–∞ —É–∑–∞–≥–∞–ª—å–Ω–µ–Ω–Ω—è (R¬≤)')
        ax2.set_xticks(x_pos + width * (len(model_names) - 1) / 2); ax2.set_xticklabels(nonlinearity_levels)
        ax2.legend(); ax2.grid(True, alpha=0.3)
        
        plt.tight_layout(rect=[0, 0, 1, 0.96])
        plot_path = self.dirs['plots'] / 'nonlinearity_robustness.png'
        plt.savefig(plot_path, dpi=300, bbox_inches='tight'); plt.close()
        print(f"üìà –ì—Ä–∞—Ñ—ñ–∫ —Ä–æ–±–∞—Å—Ç–Ω–æ—Å—Ç—ñ –¥–æ –Ω–µ–ª—ñ–Ω—ñ–π–Ω–æ—Å—Ç—ñ –∑–±–µ—Ä–µ–∂–µ–Ω–æ: {plot_path}")
    
    def _generate_latex_table(self):
        """–ì–µ–Ω–µ—Ä–∞—Ü—ñ—è LaTeX —Ç–∞–±–ª–∏—Ü—ñ –∑ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞–º–∏."""
        if not self.results: raise ValueError("–ù–µ–º–∞—î —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ñ–≤ –¥–ª—è –µ–∫—Å–ø–æ—Ä—Ç—É")
        
        eval_results = self.results['evaluation_results']
        latex_content = (
            "\\begin{table}[h]\n\\centering\n"
            "\\caption{–ü–æ—Ä—ñ–≤–Ω—è–Ω–Ω—è –ø—Ä–æ–¥—É–∫—Ç–∏–≤–Ω–æ—Å—Ç—ñ –ª—ñ–Ω—ñ–π–Ω–∏—Ö –º–æ–¥–µ–ª–µ–π –¥–ª—è –ø—Ä–æ—Ü–µ—Å—É –º–∞–≥–Ω—ñ—Ç–Ω–æ—ó —Å–µ–ø–∞—Ä–∞—Ü—ñ—ó}\n"
            "\\label{tab:linear_models_comparison}\n"
            "\\begin{tabular}{|l|c|c|c|c|c|}\n\\hline\n"
            "\\textbf{–ú–æ–¥–µ–ª—å} & \\textbf{MSE} & \\textbf{R¬≤} & \\textbf{RMSE Fe, \\%} & \\textbf{RMSE Mass, —Ç/–≥–æ–¥} & \\textbf{–ß–∞—Å –Ω–∞–≤—á–∞–Ω–Ω—è, —Å} \\\\\n\\hline\n"
        )
        for model_name, metrics in eval_results.items():
            latex_content += f"{model_name.replace('_', ' ')} & {metrics['mse']:.6f} & {metrics['r2']:.4f} & {metrics['rmse_fe']:.3f} & {metrics['rmse_mass']:.3f} & {metrics['train_time']:.3f} \\\\\n\\hline\n"
        latex_content += "\\end{tabular}\n\\end{table}"
        
        latex_path = self.dirs['latex'] / 'linear_models_comparison_table.tex'
        with open(latex_path, 'w', encoding='utf-8') as f: f.write(latex_content)
        print(f"üìÑ LaTeX —Ç–∞–±–ª–∏—Ü—é –∑–±–µ—Ä–µ–∂–µ–Ω–æ: {latex_path}")
        return latex_path
    
    def _generate_text_report(self):
        """–ì–µ–Ω–µ—Ä–∞—Ü—ñ—è —Ç–µ–∫—Å—Ç–æ–≤–æ–≥–æ –∑–≤—ñ—Ç—É –∑ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞–º–∏."""
        # ... (–ö–æ–¥ –≥–µ–Ω–µ—Ä–∞—Ü—ñ—ó —Ç–µ–∫—Å—Ç–æ–≤–æ–≥–æ –∑–≤—ñ—Ç—É –∑–∞–ª–∏—à–∞—î—Ç—å—Å—è –±–µ–∑ –∑–º—ñ–Ω) ...
        # –¶–µ–π –º–µ—Ç–æ–¥ –Ω–µ –º–∞–≤ –ø–æ–º–∏–ª–æ–∫, —Ç–æ–º—É –π–æ–≥–æ –º–æ–∂–Ω–∞ –∑–∞–ª–∏—à–∏—Ç–∏ —è–∫ —î.
        # –î–ª—è —Å—Ç–∏—Å–ª–æ—Å—Ç—ñ, –π–æ–≥–æ –∫–æ–¥ —Ç—É—Ç –ø—Ä–æ–ø—É—â–µ–Ω–æ.
        report_path = self.dirs['reports'] / f'linear_comparison_report_{datetime.now().strftime("%Y%m%d_%H%M%S")}.md'
        # ... –ª–æ–≥—ñ–∫–∞ –∑–∞–ø–∏—Å—É —É —Ñ–∞–π–ª ...
        print(f"üìã –¢–µ–∫—Å—Ç–æ–≤–∏–π –∑–≤—ñ—Ç –∑–±–µ—Ä–µ–∂–µ–Ω–æ: {report_path}") # Placeholder
        return report_path
    
    # ... (–†–µ—à—Ç–∞ –º–µ—Ç–æ–¥—ñ–≤, —Ç–∞–∫–∏—Ö —è–∫ analyze_arx_limitations_for_dissertation, –∑–∞–ª–∏—à–∞—é—Ç—å—Å—è –±–µ–∑ –∑–º—ñ–Ω) ...


def compare_linear_models_on_nonlinear_data_fixed(reference_df: Optional[pd.DataFrame] = None,
                                                output_dir: str = "nonlinear_data_comparison_fixed") -> Dict[str, Any]:
    """
    –í–ò–ü–†–ê–í–õ–ï–ù–ò–ô –ø–æ–∑–∞–∫–ª–∞—Å–æ–≤–∏–π –º–µ—Ç–æ–¥ –¥–ª—è –ø–æ—Ä—ñ–≤–Ω—è–Ω–Ω—è –±–∞–∑–æ–≤–∏—Ö –ª—ñ–Ω—ñ–π–Ω–∏—Ö –º–æ–¥–µ–ª–µ–π –Ω–∞ —Å–∏–ª—å–Ω–æ –Ω–µ–ª—ñ–Ω—ñ–π–Ω–∏—Ö –¥–∞–Ω–∏—Ö.
    """
    print("üî¨ –í–ò–ü–†–ê–í–õ–ï–ù–ï –ü–û–†–Ü–í–ù–Ø–ù–ù–Ø –õ–Ü–ù–Ü–ô–ù–ò–• –ú–û–î–ï–õ–ï–ô –ù–ê –ù–ï–õ–Ü–ù–Ü–ô–ù–ò–• –î–ê–ù–ò–•")
    print("=" * 70)
    print("üìã –î–æ—Å–ª—ñ–¥–∂–µ–Ω–Ω—è –∑ –ø—Ä–∞–≤–∏–ª—å–Ω–∏–º–∏ –∞–Ω–æ–º–∞–ª—ñ—è–º–∏ —Ç–∞ —à—É–º–æ–º\n")
    
    comparison_service = LinearModelsComparisonService(reference_df=reference_df, output_dir=output_dir)
    
    model_configs = [
        {'name': 'ARX_OLS', 'linear_type': 'ols'},
        {'name': 'ARX_Ridge', 'linear_type': 'ridge', 'alpha': 0.1},
        {'name': 'ARX_Lasso', 'linear_type': 'lasso', 'alpha': 0.01}
    ]
    
    global_config = {
        'N_data': 4000, 'lag_depth': 8, 'enable_nonlinear': True, 'use_simulation': True,   
        'use_anomalies': True, 'anomaly_severity': 'medium', 'anomaly_in_train': False, 
        'noise_level': 'medium',
        'nonlinear_config': {'concentrate_fe_percent': ('pow', 2.5), 'concentrate_mass_flow': ('pow', 1.8)},
        'train_size': 0.8, 'val_size': 0.1, 'test_size': 0.1, 'seed': 42
    }
    
    print("üîß –ö–û–ù–§–Ü–ì–£–†–ê–¶–Ü–Ø –î–õ–Ø –ü–†–ê–í–ò–õ–¨–ù–û–ì–û –¢–ï–°–¢–£–í–ê–ù–ù–Ø:")
    print(f"   üî¥ –ê–Ω–æ–º–∞–ª—ñ—ó: {global_config['use_anomalies']} ({global_config['anomaly_severity']})")
    print(f"   üîä –®—É–º: {global_config['noise_level']}")
    print(f"   üìà –ù–µ–ª—ñ–Ω—ñ–π–Ω—ñ—Å—Ç—å: Fe^{global_config['nonlinear_config']['concentrate_fe_percent'][1]}, Mass^{global_config['nonlinear_config']['concentrate_mass_flow'][1]}\n")
    
    print("üöÄ –ó–∞–ø—É—Å–∫ –∞–Ω–∞–ª—ñ–∑—É –∑ –í–ò–ü–†–ê–í–õ–ï–ù–ò–ú–ò –ø–∞—Ä–∞–º–µ—Ç—Ä–∞–º–∏...")
    try:
        results = comparison_service.run_comprehensive_comparison(model_configs, global_config)
        
        print("\nüîç –î–Ü–ê–ì–ù–û–°–¢–ò–ö–ê –Ø–ö–û–°–¢–Ü –ó–ì–ï–ù–ï–†–û–í–ê–ù–ò–• –î–ê–ù–ò–•:")
        data_results = comparison_service._prepare_data(global_config)
        _, Y_train, _, _, _, Y_test, _, _ = data_results
        X_full = np.vstack([data_results[0], data_results[4]]) # X_train_scaled, X_test_scaled
        Y_full = np.vstack([comparison_service.scaler_y.inverse_transform(Y_train), Y_test])
        
        data_diagnostics = comparison_service.diagnose_data_quality(X=X_full, Y=Y_full)
        
        print("\nüìä –ê–ù–ê–õ–Ü–ó –†–ï–ó–£–õ–¨–¢–ê–¢–Ü–í –ú–û–î–ï–õ–ï–ô:")
        realistic_results = {}
        for model_name_cfg in model_configs:
            model_key = model_name_cfg['name']
            if model_key in results['evaluation_results']:
                eval_data = results['evaluation_results'][model_key]
                
                rmse_fe = eval_data.get('rmse_fe', 0)
                rmse_mass = eval_data.get('rmse_mass', 0)
                # ‚úÖ –í–ò–ü–†–ê–í–õ–ï–ù–ù–Ø: –í–∏–∫–æ—Ä–∏—Å—Ç–æ–≤—É—î–º–æ –ø—Ä–∞–≤–∏–ª—å–Ω–∏–π –∫–ª—é—á 'r2' –∑–∞–º—ñ—Å—Ç—å 'r2_score'
                r2 = eval_data.get('r2', -1) 
                
                print(f"   {model_key}:")
                print(f"     RMSE Fe: {rmse_fe:.4f}")
                print(f"     RMSE Mass: {rmse_mass:.4f}") 
                print(f"     R¬≤ Score: {r2:.4f}")
                
                is_too_perfect = (rmse_fe < 0.01 and r2 > 0.99)
                is_reasonable = (0.5 < r2 < 0.9 and rmse_fe > 1.0)
                
                realistic_results[model_key] = {
                    'rmse_fe': rmse_fe, 'rmse_mass': rmse_mass, 'r2': r2,
                    'is_too_perfect': is_too_perfect, 'is_reasonable': is_reasonable
                }
                
                if is_too_perfect:
                    warning = f"–ü–Ü–î–û–ó–†–Ü–õ–û –Ü–î–ï–ê–õ–¨–ù–Ü —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∏ –¥–ª—è {model_key}"
                    print(f"     ‚ö†Ô∏è  {warning}")
                    data_diagnostics['warnings'].append(warning)
                elif is_reasonable:
                    print(f"     ‚úÖ –†–µ–∞–ª—ñ—Å—Ç–∏—á–Ω—ñ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∏ –¥–ª—è {model_key}")
        
        worst_rmse_fe = max([metrics['rmse_fe'] for metrics in realistic_results.values()])
        best_r2 = max([metrics['r2'] for metrics in realistic_results.values()])
        n_perfect_models = sum([1 for m in realistic_results.values() if m['is_too_perfect']])
        n_reasonable_models = sum([1 for m in realistic_results.values() if m['is_reasonable']])
        
        print(f"\nüéØ –ü–Ü–î–°–£–ú–ö–û–í–ê –û–¶–Ü–ù–ö–ê:")
        print(f"   üìä –ù–∞–π–≥—ñ—Ä—à–∞ RMSE Fe: {worst_rmse_fe:.4f}")
        print(f"   üìä –ù–∞–π–∫—Ä–∞—â–∏–π R¬≤: {best_r2:.4f}")
        print(f"   ‚úÖ –†–µ–∞–ª—ñ—Å—Ç–∏—á–Ω–∏—Ö –º–æ–¥–µ–ª–µ–π: {n_reasonable_models}/{len(model_configs)}")
        print(f"   ‚ö†Ô∏è  –ü—ñ–¥–æ–∑—Ä—ñ–ª–æ —ñ–¥–µ–∞–ª—å–Ω–∏—Ö: {n_perfect_models}/{len(model_configs)}")
        
        final_results = {'comprehensive_results': results, 'data_diagnostics': data_diagnostics, 'key_findings': {}}
        
    except Exception as e:
        print(f"‚ùå –ü–û–ú–ò–õ–ö–ê –ø—ñ–¥ —á–∞—Å –≤–∏–∫–æ–Ω–∞–Ω–Ω—è: {e}")
        import traceback
        traceback.print_exc()
        return {'error': str(e)}
    
    print(f"\n‚úÖ –ê–ù–ê–õ–Ü–ó –ó–ê–í–ï–†–®–ï–ù–û")
    print(f"üìÅ –†–µ–∑—É–ª—å—Ç–∞—Ç–∏ –∑–±–µ—Ä–µ–∂–µ–Ω–æ –≤: {output_dir}")
    print(f"üîç –Ø–∫—ñ—Å—Ç—å –¥–∞–Ω–∏—Ö: {data_diagnostics.get('data_quality_score', 'N/A'):.1f}/100")
    print(f"‚ö†Ô∏è  –ü–æ–ø–µ—Ä–µ–¥–∂–µ–Ω—å: {len(data_diagnostics.get('warnings', []))}")
    
    return final_results

if __name__ == "__main__":
    try:
        df = pd.read_parquet('processed.parquet')
        compare_linear_models_on_nonlinear_data_fixed(df, 'nonlinear_data_comparison_fixed')
    except FileNotFoundError:
        print("INFO: –§–∞–π–ª 'processed.parquet' –Ω–µ –∑–Ω–∞–π–¥–µ–Ω–æ. –ó–∞–ø—É—Å–∫ –±–µ–∑ —Ä–µ—Ñ–µ—Ä–µ–Ω—Ç–Ω–∏—Ö –¥–∞–Ω–∏—Ö.")
        compare_linear_models_on_nonlinear_data_fixed(None, 'nonlinear_data_comparison_fixed')