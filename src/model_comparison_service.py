# model_comparison_service.py

import pandas as pd
import matplotlib.pyplot as plt
import numpy as np
import json
import time
from typing import Dict, Any, Tuple, Optional
from sklearn.preprocessing import StandardScaler
from sklearn.metrics import mean_squared_error
from pathlib import Path
from datetime import datetime

from data_gen import StatefulDataGenerator
from model import KernelModel


class ModelComparisonService:
    """
    –°–ª—É–∂–±–æ–≤–∏–π –∫–ª–∞—Å –¥–ª—è –ø–æ—Ä—ñ–≤–Ω—è–Ω–Ω—è –ª—ñ–Ω—ñ–π–Ω–∏—Ö (ARX) —Ç–∞ —è–¥–µ—Ä–Ω–∏—Ö –º–æ–¥–µ–ª–µ–π —É —Ä–∞–º–∫–∞—Ö –¥–∏—Å–µ—Ä—Ç–∞—Ü—ñ–π–Ω–æ–≥–æ –¥–æ—Å–ª—ñ–¥–∂–µ–Ω–Ω—è.
    
    –û—Å–Ω–æ–≤–Ω—ñ –º–æ–∂–ª–∏–≤–æ—Å—Ç—ñ:
    - –°—Ç–≤–æ—Ä–µ–Ω–Ω—è —Å–∏–º—É–ª—è—Ü—ñ–π–Ω–∏—Ö –¥–∞–Ω–∏—Ö –∑ –∫–µ—Ä–æ–≤–∞–Ω–∏–º–∏ –∞–Ω–æ–º–∞–ª—ñ—è–º–∏
    - –ù–∞–≤—á–∞–Ω–Ω—è —Ç–∞ –ø–æ—Ä—ñ–≤–Ω—è–Ω–Ω—è –ª—ñ–Ω—ñ–π–Ω–∏—Ö —ñ —è–¥–µ—Ä–Ω–∏—Ö –º–æ–¥–µ–ª–µ–π
    - –ê–Ω–∞–ª—ñ–∑ –Ω–µ–ª—ñ–Ω—ñ–π–Ω–æ—Å—Ç—ñ –ø—Ä–æ—Ü–µ—Å—É
    - –ì–µ–Ω–µ—Ä–∞—Ü—ñ—è –∫–æ–º–ø–ª–µ–∫—Å–Ω–∏—Ö –≤—ñ–∑—É–∞–ª—ñ–∑–∞—Ü—ñ–π
    - –ó–±–µ—Ä–µ–∂–µ–Ω–Ω—è —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ñ–≤ —É JSON —Ñ–æ—Ä–º–∞—Ç—ñ
    """
    
    def __init__(self, reference_df: Optional[pd.DataFrame] = None, 
                 output_dir: Optional[str] = None):
        """
        –Ü–Ω—ñ—Ü—ñ–∞–ª—ñ–∑–∞—Ü—ñ—è —Å–µ—Ä–≤—ñ—Å—É –ø–æ—Ä—ñ–≤–Ω—è–Ω–Ω—è –º–æ–¥–µ–ª–µ–π.
        
        Args:
            reference_df: –†–µ—Ñ–µ—Ä–µ–Ω—Ç–Ω—ñ –¥–∞–Ω—ñ –¥–ª—è —Å–∏–º—É–ª—è—Ü—ñ—ó
            output_dir: –ë–∞–∑–æ–≤–∞ –¥–∏—Ä–µ–∫—Ç–æ—Ä—ñ—è –¥–ª—è –∑–±–µ—Ä–µ–∂–µ–Ω–Ω—è —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ñ–≤. 
                       –Ø–∫—â–æ None, —Å—Ç–≤–æ—Ä—é—î—Ç—å—Å—è 'results/YYYY-MM-DD_HH-MM-SS'
        """
        self.reference_df = self._load_reference_data(reference_df)
        self.results = {}
        self.figures = {}
        self._setup_output_directories(output_dir)
        
    def _load_reference_data(self, reference_df: Optional[pd.DataFrame]) -> pd.DataFrame:
        """–ó–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–Ω—è —Ä–µ—Ñ–µ—Ä–µ–Ω—Ç–Ω–∏—Ö –¥–∞–Ω–∏—Ö"""
        if reference_df is None:
            try:
                reference_df = pd.read_parquet('processed.parquet')
                print(f"‚úÖ –ó–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–æ {len(reference_df)} –∑–∞–ø–∏—Å—ñ–≤ –∑ processed.parquet")
            except FileNotFoundError:
                print("‚ùå –§–∞–π–ª 'processed.parquet' –Ω–µ –∑–Ω–∞–π–¥–µ–Ω–æ")
                raise
        return reference_df
    
    def _setup_output_directories(self, output_dir: Optional[str]) -> None:
        """–°—Ç–≤–æ—Ä–µ–Ω–Ω—è —Å—Ç—Ä—É–∫—Ç—É—Ä–∏ –¥–∏—Ä–µ–∫—Ç–æ—Ä—ñ–π –¥–ª—è –∑–±–µ—Ä–µ–∂–µ–Ω–Ω—è —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ñ–≤"""
        if output_dir is None:
            timestamp = datetime.now().strftime("%Y-%m-%d_%H-%M-%S")
            output_dir = f"evaluation_results/models/{timestamp}"
        
        self.output_dir = Path(output_dir)
        
        # –°—Ç–≤–æ—Ä–µ–Ω–Ω—è –ø—ñ–¥–ø–∞–ø–æ–∫
        self.dirs = {
            'data': self.output_dir / 'data',
            'visualizations': self.output_dir / 'visualizations', 
            'reports': self.output_dir / 'reports',
            'latex': self.output_dir / 'latex',
            'comparisons': self.output_dir / 'comparisons'
        }
        
        # –°—Ç–≤–æ—Ä–µ–Ω–Ω—è –≤—Å—ñ—Ö –¥–∏—Ä–µ–∫—Ç–æ—Ä—ñ–π
        for dir_path in self.dirs.values():
            dir_path.mkdir(parents=True, exist_ok=True)
            
        print(f"üìÅ –†–µ–∑—É–ª—å—Ç–∞—Ç–∏ –∑–±–µ—Ä—ñ–≥–∞—Ç–∏–º—É—Ç—å—Å—è —É: {self.output_dir.absolute()}")
        
    def create_anomaly_config(self, N_data: int, train_frac: float = 0.7, 
                             val_frac: float = 0.15, test_frac: float = 0.15,
                             seed: int = 42, severity: str = "mild", 
                             include_train: bool = False) -> dict:
        """
        –ì–µ–Ω–µ—Ä—É—î reproducible anomaly_config –¥–ª—è DataGenerator.generate_anomalies().
        
        Args:
            N_data: –ó–∞–≥–∞–ª—å–Ω–∞ –∫—ñ–ª—å–∫—ñ—Å—Ç—å —Ç–æ—á–æ–∫ –¥–∞–Ω–∏—Ö
            train_frac: –ß–∞—Å—Ç–∫–∞ —Ç—Ä–µ–Ω—É–≤–∞–ª—å–Ω–∏—Ö –¥–∞–Ω–∏—Ö
            val_frac: –ß–∞—Å—Ç–∫–∞ –≤–∞–ª—ñ–¥–∞—Ü—ñ–π–Ω–∏—Ö –¥–∞–Ω–∏—Ö  
            test_frac: –ß–∞—Å—Ç–∫–∞ —Ç–µ—Å—Ç–æ–≤–∏—Ö –¥–∞–Ω–∏—Ö
            seed: –ù–∞—Å—ñ–Ω–Ω—è –¥–ª—è –≤—ñ–¥—Ç–≤–æ—Ä—é–≤–∞–Ω–æ—Å—Ç—ñ
            severity: –†—ñ–≤–µ–Ω—å —Å–µ—Ä–π–æ–∑–Ω–æ—Å—Ç—ñ –∞–Ω–æ–º–∞–ª—ñ–π ('mild' | 'medium' | 'strong')
            include_train: –ß–∏ –≤–∫–ª—é—á–∞—Ç–∏ –∞–Ω–æ–º–∞–ª—ñ—ó –≤ —Ç—Ä–µ–Ω—É–≤–∞–ª—å–Ω—ñ –¥–∞–Ω—ñ
            
        Returns:
            dict: –ö–æ–Ω—Ñ—ñ–≥—É—Ä–∞—Ü—ñ—è –∞–Ω–æ–º–∞–ª—ñ–π –¥–ª—è –≥–µ–Ω–µ—Ä–∞—Ç–æ—Ä–∞ –¥–∞–Ω–∏—Ö
        """
        total = train_frac + val_frac + test_frac
        train_frac, val_frac, test_frac = train_frac/total, val_frac/total, test_frac/total

        train_end = int(train_frac * N_data)
        val_end   = train_end + int(val_frac * N_data)
        segments = {"train": (0, train_end), "val": (train_end, val_end), "test": (val_end, N_data)}

        base_durations = {"spike": 1, "drift": 25, "drop": 20, "freeze": 15}
        sev_map = {"mild": (0.08, 0.15), "medium": (0.12, 0.22), "strong": (0.18, 0.30)}
        mag_lo, mag_hi = sev_map.get(severity, sev_map["mild"])

        rng = np.random.default_rng(seed)

        def seg_bounds(name):
            s, e = segments[name]
            return s, max(s, e-1), max(0, e-s)

        def pick_start(seg_name, dur):
            s, e_minus1, length = seg_bounds(seg_name)
            if length <= 0:
                return None
            dur = min(dur, length)
            hi = max(s, e_minus1 - (dur-1))
            return int(rng.integers(low=s, high=hi+1)), dur

        params = [
            "ore_mass_flow", "feed_fe_percent", "solid_feed_percent",
            "concentrate_fe_percent", "tailings_fe_percent",
            "concentrate_mass_flow", "tailings_mass_flow"
        ]
        cfg = {p: [] for p in params}

        def add_anom(param, seg, typ, mag=None, force_positive=False):
            dur = base_durations[typ]
            sd = pick_start(seg, dur)
            if sd is None:
                return
            start, dur = sd
            if typ == "freeze":
                cfg[param].append({"start": start, "duration": dur, "type": typ})
            else:
                m = float(abs(mag) if mag is not None else rng.uniform(mag_lo, mag_hi))
                if typ != "drop" and not force_positive and rng.random() < 0.5:
                    m = -m
                if typ == "drop":
                    m = abs(m)
                cfg[param].append({"start": start, "duration": dur, "magnitude": m, "type": typ})

        # –ü–ª–∞–Ω –∞–Ω–æ–º–∞–ª—ñ–π
        if include_train: 
            add_anom("ore_mass_flow", "train", "drift")
            add_anom("solid_feed_percent", "train", "freeze")
            
        add_anom("ore_mass_flow", "val",  "drift")
        add_anom("ore_mass_flow", "test", "spike")
        add_anom("solid_feed_percent", "val", "freeze")
        add_anom("feed_fe_percent", "test", "spike")
        add_anom("concentrate_mass_flow", "val", "drop", force_positive=True)
        add_anom("tailings_mass_flow", "test", "drift")
        add_anom("concentrate_fe_percent", "val", "spike")
        add_anom("tailings_fe_percent", "test", "freeze")

        return cfg
    
    def create_simulation_data(self, params: dict) -> Tuple[StatefulDataGenerator, pd.DataFrame]:
        """
        –°—Ç–≤–æ—Ä–µ–Ω–Ω—è —Å–∏–º—É–ª—è—Ü—ñ–π–Ω–∏—Ö –¥–∞–Ω–∏—Ö —á–µ—Ä–µ–∑ StatefulDataGenerator.
        
        Args:
            params: –ü–∞—Ä–∞–º–µ—Ç—Ä–∏ —Å–∏–º—É–ª—è—Ü—ñ—ó
            
        Returns:
            Tuple[StatefulDataGenerator, pd.DataFrame]: –ì–µ–Ω–µ—Ä–∞—Ç–æ—Ä —Ç–∞ —Å–∏–º—É–ª—è—Ü—ñ–π–Ω—ñ –¥–∞–Ω—ñ
        """
        true_gen = StatefulDataGenerator(
            self.reference_df,
            ore_flow_var_pct=3.0,
            time_step_s=params['time_step_s'],
            time_constants_s=params['time_constants_s'],
            dead_times_s=params['dead_times_s'],
            true_model_type=params['plant_model_type'],
            seed=params['seed']
        )

        # –ê–Ω–æ–º–∞–ª—ñ—ó
        anomaly_cfg = None
        if params.get('use_anomalies', True):
            anomaly_cfg = self.create_anomaly_config(
                N_data=params['N_data'],
                train_frac=params.get('train_size', 0.8),
                val_frac=params.get('val_size', 0.1),
                test_frac=params.get('test_size', 0.1),
                seed=params['seed'],
                severity=params.get('anomaly_severity', 'mild'),
                include_train=params.get('anomaly_in_train', False),
            )

        # –ë–∞–∑–æ–≤—ñ –¥–∞–Ω—ñ
        df_true_orig = true_gen.generate(
            T=params['N_data'],
            control_pts=params['control_pts'],
            n_neighbors=params['n_neighbors'],
            noise_level=params.get('noise_level', 'none'),
            anomaly_config=anomaly_cfg
        )

        # –ù–µ–ª—ñ–Ω—ñ–π–Ω–∏–π –≤–∞—Ä—ñ–∞–Ω—Ç
        if params.get('enable_nonlinear', False):
            df_true = true_gen.generate_nonlinear_variant(
                base_df=df_true_orig,
                non_linear_factors=params['nonlinear_config'],
                noise_level='none',
                anomaly_config=anomaly_cfg
            )
        else:
            df_true = df_true_orig

        return true_gen, df_true
    
    def create_lagged_matrices(self, df: pd.DataFrame, lag: int = 2) -> Tuple[np.ndarray, np.ndarray]:
        """
        –°—Ç–≤–æ—Ä–µ–Ω–Ω—è –ª–∞–≥–æ–≤–∏—Ö –º–∞—Ç—Ä–∏—Ü—å –¥–ª—è –ø–æ—Ä—ñ–≤–Ω—è–Ω–Ω—è –º–æ–¥–µ–ª–µ–π.
        
        Args:
            df: DataFrame –∑ –¥–∞–Ω–∏–º–∏
            lag: –ö—ñ–ª—å–∫—ñ—Å—Ç—å –ª–∞–≥—ñ–≤
            
        Returns:
            Tuple[np.ndarray, np.ndarray]: –ú–∞—Ç—Ä–∏—Ü—ñ X (–≤—Ö–æ–¥–∏) —Ç–∞ Y (–≤–∏—Ö–æ–¥–∏)
        """
        input_vars = ['feed_fe_percent', 'ore_mass_flow', 'solid_feed_percent']
        output_vars = ['concentrate_fe', 'concentrate_mass']
        
        # –ü–µ—Ä–µ–≤—ñ—Ä–∫–∞ –∞–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤–Ω–∏—Ö –Ω–∞–∑–≤
        if 'concentrate_fe' not in df.columns and 'concentrate_fe_percent' in df.columns:
            output_vars = ['concentrate_fe_percent', 'concentrate_mass_flow']
        
        # –ü–µ—Ä–µ–≤—ñ—Ä–∫–∞ –Ω–∞—è–≤–Ω–æ—Å—Ç—ñ –∫–æ–ª–æ–Ω–æ–∫
        missing_vars = [var for var in input_vars + output_vars if var not in df.columns]
        if missing_vars:
            print(f"‚ö†Ô∏è –í—ñ–¥—Å—É—Ç–Ω—ñ –∫–æ–ª–æ–Ω–∫–∏: {missing_vars}")
            print(f"üìã –î–æ—Å—Ç—É–ø–Ω—ñ –∫–æ–ª–æ–Ω–∫–∏: {list(df.columns)}")
            return StatefulDataGenerator.create_lagged_dataset(df, lags=lag)
        
        n = len(df)
        X, Y = [], []
        
        for i in range(lag, n):
            row = []
            for var in input_vars:
                for j in range(lag + 1):
                    row.append(df[var].iloc[i - j])
            X.append(row)
            Y.append([df[var].iloc[i] for var in output_vars])
        
        return np.array(X), np.array(Y)
    
    def analyze_nonlinearity(self, df_sim: pd.DataFrame, true_gen: StatefulDataGenerator) -> dict:
        """
        –ê–Ω–∞–ª—ñ–∑ –Ω–µ–ª—ñ–Ω—ñ–π–Ω–æ—Å—Ç—ñ —Å–∏–º—É–ª—è—Ü—ñ–π–Ω–∏—Ö –¥–∞–Ω–∏—Ö.
        
        Args:
            df_sim: –°–∏–º—É–ª—è—Ü—ñ–π–Ω—ñ –¥–∞–Ω—ñ
            true_gen: –ì–µ–Ω–µ—Ä–∞—Ç–æ—Ä –¥–∞–Ω–∏—Ö
            
        Returns:
            dict: –ú–µ—Ç—Ä–∏–∫–∏ –Ω–µ–ª—ñ–Ω—ñ–π–Ω–æ—Å—Ç—ñ
        """
        metrics = {}
        
        # –û—Ü—ñ–Ω–∫–∞ S-–ø–æ–¥—ñ–±–Ω–æ—Å—Ç—ñ —á–µ—Ä–µ–∑ –≤–∞—Ä—ñ–∞—Ü—ñ—ó –≥—Ä–∞–¥—ñ—î–Ω—Ç—ñ–≤
        if 'concentrate_fe' in df_sim.columns:
            fe_values = df_sim['concentrate_fe'].values
            fe_gradients = np.diff(fe_values)
            metrics['fe_gradient_variance'] = np.var(fe_gradients)
            metrics['fe_gradient_skewness'] = pd.Series(fe_gradients).skew()
        
        # –ù–µ–ª—ñ–Ω—ñ–π–Ω—ñ –≤–∑–∞—î–º–æ–¥—ñ—ó —á–µ—Ä–µ–∑ –∫–æ—Ä–µ–ª—è—Ü—ñ–π–Ω–∏–π –∞–Ω–∞–ª—ñ–∑
        numeric_cols = df_sim.select_dtypes(include=[np.number]).columns
        if len(numeric_cols) >= 3:
            pearson_corr = df_sim[numeric_cols].corr(method='pearson')
            spearman_corr = df_sim[numeric_cols].corr(method='spearman')
            nonlinearity_indicator = abs(spearman_corr - pearson_corr).mean().mean()
            metrics['correlation_nonlinearity'] = nonlinearity_indicator
        
        # –ï–Ω—Ç—Ä–æ–ø—ñ–π–Ω–∞ –æ—Ü—ñ–Ω–∫–∞ —Å–∫–ª–∞–¥–Ω–æ—Å—Ç—ñ
        if 'solid_feed_percent' in df_sim.columns:
            control_changes = np.abs(np.diff(df_sim['solid_feed_percent']))
            control_entropy = -np.sum((control_changes + 1e-10) * np.log(control_changes + 1e-10))
            metrics['control_complexity'] = control_entropy
        
        # –•–∞—Ä–∞–∫—Ç–µ—Ä–∏—Å—Ç–∏–∫–∏ —Ä–æ–∑–ø–æ–¥—ñ–ª—É
        if 'concentrate_mass' in df_sim.columns:
            mass_values = df_sim['concentrate_mass'].values
            metrics['mass_distribution_kurtosis'] = pd.Series(mass_values).kurtosis()
            metrics['mass_distribution_skewness'] = pd.Series(mass_values).skew()
        
        return metrics
    
    def train_models(self, X_train_scaled: np.ndarray, Y_train_scaled: np.ndarray,
                    X_val_scaled: Optional[np.ndarray] = None, 
                    Y_val_scaled: Optional[np.ndarray] = None,
                    **kwargs) -> Tuple[KernelModel, KernelModel, dict]:
        """
        –ù–∞–≤—á–∞–Ω–Ω—è –ª—ñ–Ω—ñ–π–Ω–æ—ó —Ç–∞ —è–¥–µ—Ä–Ω–æ—ó –º–æ–¥–µ–ª–µ–π.
        
        Args:
            X_train_scaled: –ú–∞—Å—à—Ç–∞–±–æ–≤–∞–Ω—ñ —Ç—Ä–µ–Ω—É–≤–∞–ª—å–Ω—ñ –≤—Ö–æ–¥–∏
            Y_train_scaled: –ú–∞—Å—à—Ç–∞–±–æ–≤–∞–Ω—ñ —Ç—Ä–µ–Ω—É–≤–∞–ª—å–Ω—ñ –≤–∏—Ö–æ–¥–∏
            X_val_scaled: –ú–∞—Å—à—Ç–∞–±–æ–≤–∞–Ω—ñ –≤–∞–ª—ñ–¥–∞—Ü—ñ–π–Ω—ñ –≤—Ö–æ–¥–∏ (–æ–ø—Ü—ñ–π–Ω–æ)
            Y_val_scaled: –ú–∞—Å—à—Ç–∞–±–æ–≤–∞–Ω—ñ –≤–∞–ª—ñ–¥–∞—Ü—ñ–π–Ω—ñ –≤–∏—Ö–æ–¥–∏ (–æ–ø—Ü—ñ–π–Ω–æ)
            **kwargs: –î–æ–¥–∞—Ç–∫–æ–≤—ñ –ø–∞—Ä–∞–º–µ—Ç—Ä–∏ –Ω–∞–≤—á–∞–Ω–Ω—è
            
        Returns:
            Tuple: (–ª—ñ–Ω—ñ–π–Ω–∞_–º–æ–¥–µ–ª—å, —è–¥–µ—Ä–Ω–∞_–º–æ–¥–µ–ª—å, –º–µ—Ç—Ä–∏–∫–∏_–Ω–∞–≤—á–∞–Ω–Ω—è)
        """
        training_metrics = {}
        
        # –õ—ñ–Ω—ñ–π–Ω–∞ –º–æ–¥–µ–ª—å (ARX)
        print("\nüî¥ –ù–ê–í–ß–ê–ù–ù–Ø –õ–Ü–ù–Ü–ô–ù–û–á –ú–û–î–ï–õ–Ü (ARX)")
        print("-" * 40)
        linear_model = KernelModel(
            model_type='linear', 
            linear_type='ols', 
            poly_degree=1, 
            include_bias=True
        )
        
        start_time = time.time()
        try:
            if X_val_scaled is not None and Y_val_scaled is not None:
                linear_model.fit(X_train_scaled, Y_train_scaled, 
                               X_val=X_val_scaled, Y_val=Y_val_scaled)
            else:
                linear_model.fit(X_train_scaled, Y_train_scaled)
        except TypeError:
            linear_model.fit(X_train_scaled, Y_train_scaled)
        linear_train_time = time.time() - start_time
        
        print(f"   ‚è±Ô∏è –ß–∞—Å –Ω–∞–≤—á–∞–Ω–Ω—è: {linear_train_time:.3f} —Å–µ–∫")
        
        # –Ø–¥–µ—Ä–Ω–∞ –º–æ–¥–µ–ª—å (KRR)  
        print("\nüü¢ –ù–ê–í–ß–ê–ù–ù–Ø –Ø–î–ï–†–ù–û–á –ú–û–î–ï–õ–Ü (KRR)")
        print("-" * 40)
        kernel_model = KernelModel(
            model_type='krr',
            kernel='rbf',
            find_optimal_params=kwargs.get('find_optimal_params', True),
            n_iter_random_search=kwargs.get('n_iter_search', 20)
        )
        
        start_time = time.time()
        try:
            if X_val_scaled is not None and Y_val_scaled is not None:
                kernel_model.fit(X_train_scaled, Y_train_scaled,
                               X_val=X_val_scaled, Y_val=Y_val_scaled)
            else:
                kernel_model.fit(X_train_scaled, Y_train_scaled)
        except TypeError:
            kernel_model.fit(X_train_scaled, Y_train_scaled)
        kernel_train_time = time.time() - start_time
        
        print(f"   ‚è±Ô∏è –ß–∞—Å –Ω–∞–≤—á–∞–Ω–Ω—è: {kernel_train_time:.3f} —Å–µ–∫")
        
        training_metrics = {
            'linear_train_time': linear_train_time,
            'kernel_train_time': kernel_train_time
        }
        
        return linear_model, kernel_model, training_metrics
    
    def evaluate_models(self, linear_model: KernelModel, kernel_model: KernelModel,
                       X_test_scaled: np.ndarray, Y_test: np.ndarray, 
                       y_scaler: StandardScaler) -> dict:
        """
        –û—Ü—ñ–Ω–∫–∞ –ø—Ä–æ–¥—É–∫—Ç–∏–≤–Ω–æ—Å—Ç—ñ –º–æ–¥–µ–ª–µ–π.
        
        Args:
            linear_model: –ù–∞–≤—á–µ–Ω–∞ –ª—ñ–Ω—ñ–π–Ω–∞ –º–æ–¥–µ–ª—å
            kernel_model: –ù–∞–≤—á–µ–Ω–∞ —è–¥–µ—Ä–Ω–∞ –º–æ–¥–µ–ª—å
            X_test_scaled: –ú–∞—Å—à—Ç–∞–±–æ–≤–∞–Ω—ñ —Ç–µ—Å—Ç–æ–≤—ñ –≤—Ö–æ–¥–∏
            Y_test: –ù–µ–º–∞—Å—à—Ç–∞–±–æ–≤–∞–Ω—ñ —Ç–µ—Å—Ç–æ–≤—ñ –≤–∏—Ö–æ–¥–∏
            y_scaler: –°–∫–µ–π–ª–µ—Ä –¥–ª—è –≤–∏—Ö–æ–¥—ñ–≤
            
        Returns:
            dict: –ú–µ—Ç—Ä–∏–∫–∏ –æ—Ü—ñ–Ω–∫–∏
        """
        # –ü—Ä–æ–≥–Ω–æ–∑—É–≤–∞–Ω–Ω—è
        Y_pred_linear_scaled = linear_model.predict(X_test_scaled)
        Y_pred_linear = y_scaler.inverse_transform(Y_pred_linear_scaled)
        
        Y_pred_kernel_scaled = kernel_model.predict(X_test_scaled)
        Y_pred_kernel = y_scaler.inverse_transform(Y_pred_kernel_scaled)
        
        # –ú–µ—Ç—Ä–∏–∫–∏
        linear_mse = mean_squared_error(Y_test, Y_pred_linear)
        linear_rmse_fe = np.sqrt(mean_squared_error(Y_test[:, 0], Y_pred_linear[:, 0]))
        linear_rmse_mass = np.sqrt(mean_squared_error(Y_test[:, 1], Y_pred_linear[:, 1]))
        
        kernel_mse = mean_squared_error(Y_test, Y_pred_kernel)
        kernel_rmse_fe = np.sqrt(mean_squared_error(Y_test[:, 0], Y_pred_kernel[:, 0]))
        kernel_rmse_mass = np.sqrt(mean_squared_error(Y_test[:, 1], Y_pred_kernel[:, 1]))
        
        # –ü–æ–∫—Ä–∞—â–µ–Ω–Ω—è
        improvement_mse = ((linear_mse - kernel_mse) / (linear_mse + 1e-12)) * 100
        improvement_fe = ((linear_rmse_fe - kernel_rmse_fe) / (linear_rmse_fe + 1e-12)) * 100
        improvement_mass = ((linear_rmse_mass - kernel_rmse_mass) / (linear_rmse_mass + 1e-12)) * 100
        
        print(f"   üìä –õ—ñ–Ω—ñ–π–Ω–∞ MSE: {linear_mse:.6f}")
        print(f"   üìä –õ—ñ–Ω—ñ–π–Ω–∞ RMSE Fe: {linear_rmse_fe:.3f}")
        print(f"   üìä –õ—ñ–Ω—ñ–π–Ω–∞ RMSE Mass: {linear_rmse_mass:.3f}")
        print(f"   üìä –Ø–¥–µ—Ä–Ω–∞ MSE: {kernel_mse:.6f}")
        print(f"   üìä –Ø–¥–µ—Ä–Ω–∞ RMSE Fe: {kernel_rmse_fe:.3f}")
        print(f"   üìä –Ø–¥–µ—Ä–Ω–∞ RMSE Mass: {kernel_rmse_mass:.3f}")
        
        return {
            'Y_pred_linear': Y_pred_linear,
            'Y_pred_kernel': Y_pred_kernel,
            'linear_mse': linear_mse,
            'linear_rmse_fe': linear_rmse_fe,
            'linear_rmse_mass': linear_rmse_mass,
            'kernel_mse': kernel_mse,
            'kernel_rmse_fe': kernel_rmse_fe,
            'kernel_rmse_mass': kernel_rmse_mass,
            'improvement_mse': improvement_mse,
            'improvement_fe': improvement_fe,
            'improvement_mass': improvement_mass
        }

    def run_comparison(self, **kwargs) -> dict:
        """
        –í–∏–∫–æ–Ω–∞–Ω–Ω—è –ø–æ–≤–Ω–æ–≥–æ –ø–æ—Ä—ñ–≤–Ω—è–Ω–Ω—è –ª—ñ–Ω—ñ–π–Ω–∏—Ö —Ç–∞ —è–¥–µ—Ä–Ω–∏—Ö –º–æ–¥–µ–ª–µ–π.
        
        Args:
            **kwargs: –ü–∞—Ä–∞–º–µ—Ç—Ä–∏ —Å–∏–º—É–ª—è—Ü—ñ—ó —Ç–∞ –Ω–∞–≤—á–∞–Ω–Ω—è
            
        Returns:
            dict: –ü–æ–≤–Ω—ñ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∏ –ø–æ—Ä—ñ–≤–Ω—è–Ω–Ω—è
        """
        print("üéì –ü–û–†–Ü–í–ù–Ø–ù–ù–Ø –ú–û–î–ï–õ–ï–ô –î–õ–Ø –î–ò–°–ï–†–¢–ê–¶–Ü–á")
        print("=" * 60)
        print("–†–æ–∑–¥—ñ–ª 2.1.1: –õ–æ–≥—ñ—á–Ω–∏–π –ø–µ—Ä–µ—Ö—ñ–¥ –¥–æ —è–¥–µ—Ä–Ω–∏—Ö –º–æ–¥–µ–ª–µ–π")
        print("=" * 60)

        # –ü–∞—Ä–∞–º–µ—Ç—Ä–∏ —Å–∏–º—É–ª—è—Ü—ñ—ó
        simulation_params = {
            'N_data': kwargs.get('N_data', 7000),
            'control_pts': 700,
            'lag': kwargs.get('lag', 2),
            'train_size': kwargs.get('train_size', 0.8),
            'val_size': kwargs.get('val_size', 0.1),
            'test_size': kwargs.get('test_size', 0.1),
            'time_step_s': 5,
            'time_constants_s': {
                'concentrate_fe_percent': 8.0,
                'tailings_fe_percent': 10.0,
                'concentrate_mass_flow': 5.0,
                'tailings_mass_flow': 7.0
            },
            'dead_times_s': {
                'concentrate_fe_percent': 20.0,
                'tailings_fe_percent': 25.0,
                'concentrate_mass_flow': 20.0,
                'tailings_mass_flow': 25.0
            },
            'plant_model_type': 'rf',
            'seed': kwargs.get('seed', 42),
            'n_neighbors': 5,
            'noise_level': kwargs.get('noise_level', 'none'),
            'enable_nonlinear': True,
            'nonlinear_config': {
                'concentrate_fe_percent': ('pow', 2.0),
                'concentrate_mass_flow': ('pow', 1.5)
            },
            'use_anomalies': kwargs.get('use_anomalies', True),
            'anomaly_severity': kwargs.get('anomaly_severity', 'mild'),
            'anomaly_in_train': kwargs.get('anomaly_in_train', False),
        }

        # –°—Ç–≤–æ—Ä–µ–Ω–Ω—è —Å–∏–º—É–ª—è—Ü—ñ–π–Ω–∏—Ö –¥–∞–Ω–∏—Ö
        print(f"üìà –°—Ç–≤–æ—Ä–µ–Ω–Ω—è —Å–∏–º—É–ª—è—Ü—ñ–π–Ω–∏—Ö –¥–∞–Ω–∏—Ö (N={simulation_params['N_data']}, L={simulation_params['lag']})...")
        true_gen, df_sim = self.create_simulation_data(simulation_params)

        # –õ–∞–≥–æ–≤–∞–Ω—ñ –º–∞—Ç—Ä–∏—Ü—ñ
        X, Y = self.create_lagged_matrices(df_sim, simulation_params['lag'])
        print(f"   –†–æ–∑–º—ñ—Ä–Ω—ñ—Å—Ç—å X: {X.shape}, Y: {Y.shape}")

        # –°–ø–ª—ñ—Ç –Ω–∞ train/val/test
        n = X.shape[0]
        n_train = int(simulation_params['train_size'] * n)
        n_val = int(simulation_params['val_size'] * n)

        X_train, Y_train = X[:n_train], Y[:n_train]
        X_val, Y_val = X[n_train:n_train + n_val], Y[n_train:n_train + n_val]
        X_test, Y_test = X[n_train + n_val:], Y[n_train + n_val:]

        # –ù–æ—Ä–º–∞–ª—ñ–∑–∞—Ü—ñ—è
        x_scaler = StandardScaler()
        y_scaler = StandardScaler()

        X_train_scaled = x_scaler.fit_transform(X_train)
        Y_train_scaled = y_scaler.fit_transform(Y_train)
        X_val_scaled = x_scaler.transform(X_val)
        Y_val_scaled = y_scaler.transform(Y_val)
        X_test_scaled = x_scaler.transform(X_test)

        print(f"   –¢—Ä–µ–Ω—É–≤–∞–ª—å–Ω–∏–π –Ω–∞–±—ñ—Ä: {X_train_scaled.shape[0]} –∑—Ä–∞–∑–∫—ñ–≤")
        print(f"   –í–∞–ª—ñ–¥–∞—Ü—ñ–π–Ω–∏–π –Ω–∞–±—ñ—Ä: {X_val_scaled.shape[0]} –∑—Ä–∞–∑–∫—ñ–≤")
        print(f"   –¢–µ—Å—Ç–æ–≤–∏–π –Ω–∞–±—ñ—Ä: {X_test_scaled.shape[0]} –∑—Ä–∞–∑–∫—ñ–≤")

        # –ù–∞–≤—á–∞–Ω–Ω—è –º–æ–¥–µ–ª–µ–π
        linear_model, kernel_model, training_metrics = self.train_models(
            X_train_scaled, Y_train_scaled, X_val_scaled, Y_val_scaled, **kwargs
        )

        # –û—Ü—ñ–Ω–∫–∞ –º–æ–¥–µ–ª–µ–π
        evaluation_metrics = self.evaluate_models(
            linear_model, kernel_model, X_test_scaled, Y_test, y_scaler
        )

        # –ê–Ω–∞–ª—ñ–∑ –Ω–µ–ª—ñ–Ω—ñ–π–Ω–æ—Å—Ç—ñ
        print("\nüîç –ê–ù–ê–õ–Ü–ó –ù–ï–õ–Ü–ù–Ü–ô–ù–û–°–¢–Ü –ü–†–û–¶–ï–°–£")
        print("-" * 40)
        nonlinearity_metrics = self.analyze_nonlinearity(df_sim, true_gen)
        for metric_name, value in nonlinearity_metrics.items():
            print(f"   üìà {metric_name}: {value:.3f}")

        # –ó–±–µ—Ä–µ–∂–µ–Ω–Ω—è –¥–∞–Ω–∏—Ö –¥–ª—è –≤—ñ–∑—É–∞–ª—ñ–∑–∞—Ü—ñ—ó
        self._last_simulation_data = (
            Y_test, 
            evaluation_metrics['Y_pred_linear'], 
            evaluation_metrics['Y_pred_kernel'],
            evaluation_metrics, 
            nonlinearity_metrics, 
            df_sim
        )

        # –ü—ñ–¥—Å—É–º–∫–æ–≤—ñ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∏
        improvement_mse = evaluation_metrics['improvement_mse']
        target_achieved = improvement_mse >= 15
        
        print("\nüìä –ü–û–†–Ü–í–ù–Ø–ù–ù–Ø –¢–ê –ê–ù–ê–õ–Ü–ó –ù–ï–õ–Ü–ù–Ü–ô–ù–û–°–¢–Ü")
        print("-" * 50)
        print("üéØ –ö–õ–Æ–ß–û–í–Ü –†–ï–ó–£–õ–¨–¢–ê–¢–ò –î–õ–Ø –î–ò–°–ï–†–¢–ê–¶–Ü–á:")
        print(f"   üí° –ü–æ–∫—Ä–∞—â–µ–Ω–Ω—è MSE: {improvement_mse:.1f}%")
        print(f"   üí° –ü–æ–∫—Ä–∞—â–µ–Ω–Ω—è RMSE Fe: {evaluation_metrics['improvement_fe']:.1f}%")
        print(f"   üí° –ü–æ–∫—Ä–∞—â–µ–Ω–Ω—è RMSE Mass: {evaluation_metrics['improvement_mass']:.1f}%")
        print(f"   {'‚úÖ' if target_achieved else '‚ùå'} –¶—ñ–ª—å–æ–≤–∏–π –¥—ñ–∞–ø–∞–∑–æ–Ω "
              f"{'–î–û–°–Ø–ì–ù–£–¢–û' if target_achieved else '–ù–ï –¥–æ—Å—è–≥–Ω—É—Ç–æ'}")

        # –ó–±–µ—Ä–µ–∂–µ–Ω–Ω—è —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ñ–≤
        results = {
            'timestamp': pd.Timestamp.now().isoformat(),
            'simulation_params': simulation_params,
            'data_info': {
                'samples_total': len(df_sim),
                'samples_train': X_train_scaled.shape[0],
                'samples_val': X_val_scaled.shape[0],
                'samples_test': X_test_scaled.shape[0],
                'lag_used': simulation_params['lag'],
                'features': X_train_scaled.shape[1]
            },
            'linear_model': {
                'type': 'Linear (ARX)',
                'mse': evaluation_metrics['linear_mse'],
                'rmse_fe': evaluation_metrics['linear_rmse_fe'],
                'rmse_mass': evaluation_metrics['linear_rmse_mass'],
                'train_time': training_metrics['linear_train_time']
            },
            'kernel_model': {
                'type': 'Kernel Ridge Regression (RBF)',
                'mse': evaluation_metrics['kernel_mse'],
                'rmse_fe': evaluation_metrics['kernel_rmse_fe'],
                'rmse_mass': evaluation_metrics['kernel_rmse_mass'],
                'train_time': training_metrics['kernel_train_time']
            },
            'performance_comparison': {
                'mse_improvement_percent': improvement_mse,
                'rmse_fe_improvement_percent': evaluation_metrics['improvement_fe'],
                'rmse_mass_improvement_percent': evaluation_metrics['improvement_mass'],
                'target_achieved': target_achieved,
                'target_range': (15, 20)
            },
            'nonlinearity_analysis': nonlinearity_metrics
        }

        self.results = results
        return results
       
    def save_results(self, filename: Optional[str] = None) -> str:
        """
        –ó–±–µ—Ä–µ–∂–µ–Ω–Ω—è —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ñ–≤ —É JSON —Ñ–∞–π–ª.
        
        Args:
            filename: –Ü–º'—è —Ñ–∞–π–ª—É. –Ø–∫—â–æ None, –≥–µ–Ω–µ—Ä—É—î—Ç—å—Å—è –∞–≤—Ç–æ–º–∞—Ç–∏—á–Ω–æ
            
        Returns:
            str: –®–ª—è—Ö –¥–æ –∑–±–µ—Ä–µ–∂–µ–Ω–æ–≥–æ —Ñ–∞–π–ª—É
        """
        if not self.results:
            raise ValueError("–ù–µ–º–∞—î —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ñ–≤ –¥–ª—è –∑–±–µ—Ä–µ–∂–µ–Ω–Ω—è. –°–ø–æ—á–∞—Ç–∫—É –≤–∏–∫–æ–Ω–∞–π—Ç–µ run_comparison()")
        
        if filename is None:
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            filename = f'comparison_results_{timestamp}.json'
        
        filepath = self.dirs['data'] / filename
        
        with open(filepath, 'w', encoding='utf-8') as f:
            json.dump(self.results, f, indent=2, default=str, ensure_ascii=False)
            
        print(f"üìÅ –†–µ–∑—É–ª—å—Ç–∞—Ç–∏ –∑–±–µ—Ä–µ–∂–µ–Ω–æ —É {filepath}")
        return str(filepath)

    def create_comparison_visualizations(self, Y_test: np.ndarray, Y_pred_linear: np.ndarray, 
                                       Y_pred_kernel: np.ndarray, evaluation_metrics: dict,
                                       nonlinearity_metrics: dict, df_sim: pd.DataFrame) -> dict:
        """
        –°—Ç–≤–æ—Ä–µ–Ω–Ω—è –∫–æ–º–ø–ª–µ–∫—Å–Ω–∏—Ö –≤—ñ–∑—É–∞–ª—ñ–∑–∞—Ü—ñ–π –¥–ª—è –ø–æ—Ä—ñ–≤–Ω—è–Ω–Ω—è –º–æ–¥–µ–ª–µ–π.
        
        Args:
            Y_test: –†–µ–∞–ª—å–Ω—ñ —Ç–µ—Å—Ç–æ–≤—ñ –∑–Ω–∞—á–µ–Ω–Ω—è
            Y_pred_linear: –ü—Ä–æ–≥–Ω–æ–∑–∏ –ª—ñ–Ω—ñ–π–Ω–æ—ó –º–æ–¥–µ–ª—ñ
            Y_pred_kernel: –ü—Ä–æ–≥–Ω–æ–∑–∏ —è–¥–µ—Ä–Ω–æ—ó –º–æ–¥–µ–ª—ñ
            evaluation_metrics: –ú–µ—Ç—Ä–∏–∫–∏ –æ—Ü—ñ–Ω–∫–∏ –º–æ–¥–µ–ª–µ–π
            nonlinearity_metrics: –ú–µ—Ç—Ä–∏–∫–∏ –Ω–µ–ª—ñ–Ω—ñ–π–Ω–æ—Å—Ç—ñ
            df_sim: –ü–æ–≤–Ω—ñ —Å–∏–º—É–ª—è—Ü—ñ–π–Ω—ñ –¥–∞–Ω—ñ
            
        Returns:
            dict: –°–ª–æ–≤–Ω–∏–∫ —Å—Ç–≤–æ—Ä–µ–Ω–∏—Ö —Ñ—ñ–≥—É—Ä
        """
        import matplotlib.pyplot as plt
        
        # –ù–∞–ª–∞—à—Ç—É–≤–∞–Ω–Ω—è —Å—Ç–∏–ª—é
        plt.style.use('default')
        plt.rcParams['figure.figsize'] = (16, 12)
        plt.rcParams['font.size'] = 10
        
        figures = {}
        
        # –û–°–ù–û–í–ù–ê –§–Ü–ì–£–†–ê: –ü–û–†–Ü–í–ù–Ø–ù–ù–Ø –ú–û–î–ï–õ–ï–ô
        fig1, axes = plt.subplots(2, 3, figsize=(18, 12))
        fig1.suptitle('–ü–æ—Ä—ñ–≤–Ω—è–Ω–Ω—è –ª—ñ–Ω—ñ–π–Ω–æ—ó —Ç–∞ —è–¥–µ—Ä–Ω–æ—ó –º–æ–¥–µ–ª–µ–π –¥–ª—è –¥–∏—Å–µ—Ä—Ç–∞—Ü—ñ—ó', fontsize=16, fontweight='bold')
        
        # 1.1 Scatter plot –¥–ª—è Fe –∫–æ–Ω—Ü–µ–Ω—Ç—Ä–∞—Ü—ñ—ó
        ax = axes[0, 0]
        ax.scatter(Y_test[:, 0], Y_pred_linear[:, 0], alpha=0.6, s=20, color='red', label='–õ—ñ–Ω—ñ–π–Ω–∞ –º–æ–¥–µ–ª—å')
        ax.scatter(Y_test[:, 0], Y_pred_kernel[:, 0], alpha=0.6, s=20, color='green', label='–Ø–¥–µ—Ä–Ω–∞ –º–æ–¥–µ–ª—å')
        
        # –Ü–¥–µ–∞–ª—å–Ω–∞ –ª—ñ–Ω—ñ—è
        min_val, max_val = Y_test[:, 0].min(), Y_test[:, 0].max()
        ax.plot([min_val, max_val], [min_val, max_val], 'k--', alpha=0.8, linewidth=2, label='–Ü–¥–µ–∞–ª—å–Ω–∞ –ª—ñ–Ω—ñ—è')
        
        ax.set_xlabel('–†–µ–∞–ª—å–Ω–∞ –∫–æ–Ω—Ü–µ–Ω—Ç—Ä–∞—Ü—ñ—è Fe (%)')
        ax.set_ylabel('–ü—Ä–æ–≥–Ω–æ–∑–æ–≤–∞–Ω–∞ –∫–æ–Ω—Ü–µ–Ω—Ç—Ä–∞—Ü—ñ—è Fe (%)')
        ax.set_title('–ü—Ä–æ–≥–Ω–æ–∑—É–≤–∞–Ω–Ω—è –∫–æ–Ω—Ü–µ–Ω—Ç—Ä–∞—Ü—ñ—ó Fe')
        ax.legend()
        ax.grid(True, alpha=0.3)
        
        # –î–æ–¥–∞–≤–∞–Ω–Ω—è R¬≤ –Ω–∞ –≥—Ä–∞—Ñ—ñ–∫
        r2_linear = 1 - np.sum((Y_test[:, 0] - Y_pred_linear[:, 0])**2) / np.sum((Y_test[:, 0] - np.mean(Y_test[:, 0]))**2)
        r2_kernel = 1 - np.sum((Y_test[:, 0] - Y_pred_kernel[:, 0])**2) / np.sum((Y_test[:, 0] - np.mean(Y_test[:, 0]))**2)
        ax.text(0.05, 0.95, f'R¬≤ –ª—ñ–Ω—ñ–π–Ω–∞: {r2_linear:.3f}\nR¬≤ —è–¥–µ—Ä–Ω–∞: {r2_kernel:.3f}', 
                transform=ax.transAxes, verticalalignment='top', 
                bbox=dict(boxstyle='round', facecolor='white', alpha=0.8))
        
        # 1.2 Scatter plot –¥–ª—è –º–∞—Å–æ–≤–æ–≥–æ –ø–æ—Ç–æ–∫—É
        ax = axes[0, 1]
        ax.scatter(Y_test[:, 1], Y_pred_linear[:, 1], alpha=0.6, s=20, color='red', label='–õ—ñ–Ω—ñ–π–Ω–∞ –º–æ–¥–µ–ª—å')
        ax.scatter(Y_test[:, 1], Y_pred_kernel[:, 1], alpha=0.6, s=20, color='green', label='–Ø–¥–µ—Ä–Ω–∞ –º–æ–¥–µ–ª—å')
        
        min_val, max_val = Y_test[:, 1].min(), Y_test[:, 1].max()
        ax.plot([min_val, max_val], [min_val, max_val], 'k--', alpha=0.8, linewidth=2, label='–Ü–¥–µ–∞–ª—å–Ω–∞ –ª—ñ–Ω—ñ—è')
        
        ax.set_xlabel('–†–µ–∞–ª—å–Ω–∏–π –º–∞—Å–æ–≤–∏–π –ø–æ—Ç—ñ–∫ (—Ç/–≥–æ–¥)')
        ax.set_ylabel('–ü—Ä–æ–≥–Ω–æ–∑–æ–≤–∞–Ω–∏–π –º–∞—Å–æ–≤–∏–π –ø–æ—Ç—ñ–∫ (—Ç/–≥–æ–¥)')
        ax.set_title('–ü—Ä–æ–≥–Ω–æ–∑—É–≤–∞–Ω–Ω—è –º–∞—Å–æ–≤–æ–≥–æ –ø–æ—Ç–æ–∫—É')
        ax.legend()
        ax.grid(True, alpha=0.3)
        
        # 1.3 –ü–æ—Ä—ñ–≤–Ω—è–Ω–Ω—è MSE
        ax = axes[0, 2]
        models = ['–õ—ñ–Ω—ñ–π–Ω–∞\n(ARX)', '–Ø–¥–µ—Ä–Ω–∞\n(KRR)']
        mse_values = [evaluation_metrics['linear_mse'], evaluation_metrics['kernel_mse']]
        colors = ['red', 'green']
        
        bars = ax.bar(models, mse_values, color=colors, alpha=0.7, width=0.6)
        ax.set_ylabel('MSE')
        ax.set_title(f'–ü–æ—Ä—ñ–≤–Ω—è–Ω–Ω—è MSE\n(–ø–æ–∫—Ä–∞—â–µ–Ω–Ω—è: {evaluation_metrics["improvement_mse"]:.1f}%)')
        ax.grid(True, alpha=0.3, axis='y')
        
        # –î–æ–¥–∞–≤–∞–Ω–Ω—è –∑–Ω–∞—á–µ–Ω—å –Ω–∞ —Å—Ç–æ–≤–ø—Ü—ñ
        for bar, value in zip(bars, mse_values):
            ax.text(bar.get_x() + bar.get_width()/2, bar.get_height() + max(mse_values)*0.02,
                    f'{value:.4f}', ha='center', va='bottom', fontweight='bold')
        
        # –î–æ–¥–∞–≤–∞–Ω–Ω—è —Å—Ç—Ä—ñ–ª–∫–∏ –ø–æ–∫—Ä–∞—â–µ–Ω–Ω—è
        improvement = evaluation_metrics['improvement_mse']
        if improvement > 0:
            ax.annotate('', xy=(1, evaluation_metrics['kernel_mse']), xytext=(0, evaluation_metrics['linear_mse']),
                       arrowprops=dict(arrowstyle='<->', color='blue', lw=2))
            ax.text(0.5, (evaluation_metrics['linear_mse'] + evaluation_metrics['kernel_mse'])/2, 
                   f'-{improvement:.1f}%', ha='center', va='center', color='blue', fontweight='bold',
                   bbox=dict(boxstyle='round', facecolor='yellow', alpha=0.7))
        
        # 1.4 –ß–∞—Å–æ–≤–∏–π —Ä—è–¥ –ø–æ–º–∏–ª–æ–∫ –¥–ª—è Fe
        ax = axes[1, 0]
        time_steps = range(len(Y_test))
        error_linear_fe = Y_test[:, 0] - Y_pred_linear[:, 0]
        error_kernel_fe = Y_test[:, 0] - Y_pred_kernel[:, 0]
        
        ax.plot(time_steps, error_linear_fe, color='red', alpha=0.7, linewidth=1, label='–ü–æ–º–∏–ª–∫–∞ –ª—ñ–Ω—ñ–π–Ω–æ—ó')
        ax.plot(time_steps, error_kernel_fe, color='green', alpha=0.7, linewidth=1, label='–ü–æ–º–∏–ª–∫–∞ —è–¥–µ—Ä–Ω–æ—ó')
        ax.axhline(y=0, color='black', linestyle='--', alpha=0.5)
        
        ax.set_xlabel('–ö—Ä–æ–∫ —Ç–µ—Å—Ç—É–≤–∞–Ω–Ω—è')
        ax.set_ylabel('–ü–æ–º–∏–ª–∫–∞ –ø—Ä–æ–≥–Ω–æ–∑—É Fe (%)')
        ax.set_title('–î–∏–Ω–∞–º—ñ–∫–∞ –ø–æ–º–∏–ª–æ–∫ –ø—Ä–æ–≥–Ω–æ–∑—É–≤–∞–Ω–Ω—è Fe')
        ax.legend()
        ax.grid(True, alpha=0.3)
        
        # 1.5 –†–æ–∑–ø–æ–¥—ñ–ª –ø–æ–º–∏–ª–æ–∫
        ax = axes[1, 1]
        ax.hist(error_linear_fe, bins=30, alpha=0.6, color='red', label='–õ—ñ–Ω—ñ–π–Ω–∞ –º–æ–¥–µ–ª—å', density=True)
        ax.hist(error_kernel_fe, bins=30, alpha=0.6, color='green', label='–Ø–¥–µ—Ä–Ω–∞ –º–æ–¥–µ–ª—å', density=True)
        
        ax.set_xlabel('–ü–æ–º–∏–ª–∫–∞ –ø—Ä–æ–≥–Ω–æ–∑—É Fe (%)')
        ax.set_ylabel('–©—ñ–ª—å–Ω—ñ—Å—Ç—å —Ä–æ–∑–ø–æ–¥—ñ–ª—É')
        ax.set_title('–†–æ–∑–ø–æ–¥—ñ–ª –ø–æ–º–∏–ª–æ–∫ –ø—Ä–æ–≥–Ω–æ–∑—É–≤–∞–Ω–Ω—è')
        ax.legend()
        ax.grid(True, alpha=0.3)
        
        # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏ –ø–æ–º–∏–ª–æ–∫
        ax.text(0.02, 0.98, 
               f'–õ—ñ–Ω—ñ–π–Ω–∞:\n–°–¢–î: {np.std(error_linear_fe):.3f}\n–°–µ—Ä.: {np.mean(error_linear_fe):.3f}\n\n'
               f'–Ø–¥–µ—Ä–Ω–∞:\n–°–¢–î: {np.std(error_kernel_fe):.3f}\n–°–µ—Ä.: {np.mean(error_kernel_fe):.3f}',
               transform=ax.transAxes, verticalalignment='top',
               bbox=dict(boxstyle='round', facecolor='white', alpha=0.8))
        
        # 1.6 –ú–µ—Ç—Ä–∏–∫–∏ –Ω–µ–ª—ñ–Ω—ñ–π–Ω–æ—Å—Ç—ñ
        ax = axes[1, 2]
        if nonlinearity_metrics:
            metric_names = list(nonlinearity_metrics.keys())
            metric_values = list(nonlinearity_metrics.values())
            
            # –°–∫–æ—Ä–æ—á–µ–Ω–Ω—è –Ω–∞–∑–≤ –¥–ª—è –∫—Ä–∞—â–æ–≥–æ –≤—ñ–¥–æ–±—Ä–∞–∂–µ–Ω–Ω—è
            short_names = []
            for name in metric_names:
                if 'gradient' in name:
                    short_names.append('–ì—Ä–∞–¥—ñ—î–Ω—Ç\n–≤–∞—Ä—ñ–∞—Ü—ñ—ó')
                elif 'correlation' in name:
                    short_names.append('–ö–æ—Ä–µ–ª—è—Ü—ñ–π–Ω–∞\n–Ω–µ–ª—ñ–Ω—ñ–π–Ω—ñ—Å—Ç—å')
                elif 'complexity' in name:
                    short_names.append('–°–∫–ª–∞–¥–Ω—ñ—Å—Ç—å\n–∫–µ—Ä—É–≤–∞–Ω–Ω—è')
                elif 'kurtosis' in name:
                    short_names.append('–ö—É—Ä—Ç–æ–∑–∏—Å\n—Ä–æ–∑–ø–æ–¥—ñ–ª—É')
                elif 'skewness' in name:
                    short_names.append('–ê—Å–∏–º–µ—Ç—Ä—ñ—è\n—Ä–æ–∑–ø–æ–¥—ñ–ª—É')
                else:
                    short_names.append(name[:10] + '...' if len(name) > 10 else name)
            
            bars = ax.bar(range(len(metric_values)), metric_values, color='orange', alpha=0.7)
            ax.set_xticks(range(len(short_names)))
            ax.set_xticklabels(short_names, rotation=45, ha='right', fontsize=8)
            ax.set_ylabel('–ó–Ω–∞—á–µ–Ω–Ω—è –º–µ—Ç—Ä–∏–∫–∏')
            ax.set_title('–•–∞—Ä–∞–∫—Ç–µ—Ä–∏—Å—Ç–∏–∫–∏ –Ω–µ–ª—ñ–Ω—ñ–π–Ω–æ—Å—Ç—ñ –ø—Ä–æ—Ü–µ—Å—É')
            ax.grid(True, alpha=0.3, axis='y')
            
            # –î–æ–¥–∞–≤–∞–Ω–Ω—è –∑–Ω–∞—á–µ–Ω—å –Ω–∞ —Å—Ç–æ–≤–ø—Ü—ñ
            for i, (bar, value) in enumerate(zip(bars, metric_values)):
                ax.text(bar.get_x() + bar.get_width()/2, bar.get_height() + max(metric_values)*0.02,
                       f'{value:.2f}', ha='center', va='bottom', fontsize=8)
        else:
            ax.text(0.5, 0.5, '–ú–µ—Ç—Ä–∏–∫–∏ –Ω–µ–ª—ñ–Ω—ñ–π–Ω–æ—Å—Ç—ñ\n–Ω–µ –¥–æ—Å—Ç—É–ø–Ω—ñ', 
                   ha='center', va='center', transform=ax.transAxes)
            ax.set_title('–•–∞—Ä–∞–∫—Ç–µ—Ä–∏—Å—Ç–∏–∫–∏ –Ω–µ–ª—ñ–Ω—ñ–π–Ω–æ—Å—Ç—ñ –ø—Ä–æ—Ü–µ—Å—É')
    
        main_plot_path = self.dirs['visualizations'] / 'model_comparison_main.png'
        plt.tight_layout()
        plt.savefig(main_plot_path, dpi=300, bbox_inches='tight')
        figures['main_comparison'] = fig1
        
        # –î–û–î–ê–¢–ö–û–í–ê –§–Ü–ì–£–†–ê: –î–ï–¢–ê–õ–¨–ù–ò–ô –ê–ù–ê–õ–Ü–ó
        fig2, axes = plt.subplots(2, 2, figsize=(14, 10))
        fig2.suptitle('–î–µ—Ç–∞–ª—å–Ω–∏–π –∞–Ω–∞–ª—ñ–∑ –ø—Ä–æ–¥—É–∫—Ç–∏–≤–Ω–æ—Å—Ç—ñ –º–æ–¥–µ–ª–µ–π', fontsize=14, fontweight='bold')
        
        # 2.1 Box plot –ø–æ–º–∏–ª–æ–∫
        ax = axes[0, 0]
        error_data = [error_linear_fe, error_kernel_fe]
        bp = ax.boxplot(error_data, labels=['–õ—ñ–Ω—ñ–π–Ω–∞', '–Ø–¥–µ—Ä–Ω–∞'], patch_artist=True)
        bp['boxes'][0].set_facecolor('red')
        bp['boxes'][1].set_facecolor('green')
        bp['boxes'][0].set_alpha(0.6)
        bp['boxes'][1].set_alpha(0.6)
        
        ax.set_ylabel('–ü–æ–º–∏–ª–∫–∞ –ø—Ä–æ–≥–Ω–æ–∑—É Fe (%)')
        ax.set_title('–†–æ–∑–ø–æ–¥—ñ–ª –ø–æ–º–∏–ª–æ–∫ (–∫–≤–∞—Ä—Ç–∏–ª—ñ)')
        ax.grid(True, alpha=0.3)
        
        # 2.2 –ö—É–º—É–ª—è—Ç–∏–≤–Ω–∏–π —Ä–æ–∑–ø–æ–¥—ñ–ª –ø–æ–º–∏–ª–æ–∫
        ax = axes[0, 1]
        sorted_linear = np.sort(np.abs(error_linear_fe))
        sorted_kernel = np.sort(np.abs(error_kernel_fe))
        
        y_linear = np.arange(1, len(sorted_linear) + 1) / len(sorted_linear)
        y_kernel = np.arange(1, len(sorted_kernel) + 1) / len(sorted_kernel)
        
        ax.plot(sorted_linear, y_linear, color='red', linewidth=2, label='–õ—ñ–Ω—ñ–π–Ω–∞ –º–æ–¥–µ–ª—å')
        ax.plot(sorted_kernel, y_kernel, color='green', linewidth=2, label='–Ø–¥–µ—Ä–Ω–∞ –º–æ–¥–µ–ª—å')
        
        ax.set_xlabel('–ê–±—Å–æ–ª—é—Ç–Ω–∞ –ø–æ–º–∏–ª–∫–∞ Fe (%)')
        ax.set_ylabel('–ö—É–º—É–ª—è—Ç–∏–≤–Ω–∞ –π–º–æ–≤—ñ—Ä–Ω—ñ—Å—Ç—å')
        ax.set_title('–ö—É–º—É–ª—è—Ç–∏–≤–Ω–∏–π —Ä–æ–∑–ø–æ–¥—ñ–ª –ø–æ–º–∏–ª–æ–∫')
        ax.legend()
        ax.grid(True, alpha=0.3)
        
        # 2.3 –ö–æ—Ä–µ–ª—è—Ü—ñ—è –∑–∞–ª–∏—à–∫—ñ–≤
        ax = axes[1, 0]
        ax.scatter(error_linear_fe, error_kernel_fe, alpha=0.6, s=20, color='purple')
        
        # –õ—ñ–Ω—ñ—è –∫–æ—Ä–µ–ª—è—Ü—ñ—ó
        correlation = np.corrcoef(error_linear_fe, error_kernel_fe)[0, 1]
        ax.plot([error_linear_fe.min(), error_linear_fe.max()], 
               [error_kernel_fe.min(), error_kernel_fe.max()], 'r--', alpha=0.8)
        
        ax.set_xlabel('–ü–æ–º–∏–ª–∫–∞ –ª—ñ–Ω—ñ–π–Ω–æ—ó –º–æ–¥–µ–ª—ñ (%)')
        ax.set_ylabel('–ü–æ–º–∏–ª–∫–∞ —è–¥–µ—Ä–Ω–æ—ó –º–æ–¥–µ–ª—ñ (%)')
        ax.set_title(f'–ö–æ—Ä–µ–ª—è—Ü—ñ—è –ø–æ–º–∏–ª–æ–∫ (r = {correlation:.3f})')
        ax.grid(True, alpha=0.3)
        
        # 2.4 –ü–æ–∫—Ä–∞—â–µ–Ω–Ω—è –∑–∞ –∫–≤–∞—Ä—Ç–∏–ª—è–º–∏
        ax = axes[1, 1]
        quartiles = [25, 50, 75, 90, 95]
        linear_percentiles = np.percentile(np.abs(error_linear_fe), quartiles)
        kernel_percentiles = np.percentile(np.abs(error_kernel_fe), quartiles)
        improvements = ((linear_percentiles - kernel_percentiles) / linear_percentiles) * 100
        
        bars = ax.bar(range(len(quartiles)), improvements, color='blue', alpha=0.7)
        ax.set_xticks(range(len(quartiles)))
        ax.set_xticklabels([f'{q}%' for q in quartiles])
        ax.set_ylabel('–ü–æ–∫—Ä–∞—â–µ–Ω–Ω—è (%)')
        ax.set_xlabel('–ö–≤–∞—Ä—Ç–∏–ª—å –ø–æ–º–∏–ª–æ–∫')
        ax.set_title('–ü–æ–∫—Ä–∞—â–µ–Ω–Ω—è –∑–∞ –∫–≤–∞—Ä—Ç–∏–ª—è–º–∏ –ø–æ–º–∏–ª–æ–∫')
        ax.grid(True, alpha=0.3, axis='y')
        
        # –î–æ–¥–∞–≤–∞–Ω–Ω—è –∑–Ω–∞—á–µ–Ω—å –Ω–∞ —Å—Ç–æ–≤–ø—Ü—ñ
        for bar, value in zip(bars, improvements):
            color = 'green' if value > 0 else 'red'
            ax.text(bar.get_x() + bar.get_width()/2, bar.get_height() + max(improvements)*0.02,
                   f'{value:.1f}%', ha='center', va='bottom', color=color, fontweight='bold')
        
        detailed_plot_path = self.dirs['visualizations'] / 'model_comparison_detailed.png'
        plt.tight_layout()
        plt.savefig(detailed_plot_path, dpi=300, bbox_inches='tight')
        figures['detailed_analysis'] = fig2
        
        print("üìä –°—Ç–≤–æ—Ä–µ–Ω–æ –∫–æ–º–ø–ª–µ–∫—Å–Ω—ñ –≤—ñ–∑—É–∞–ª—ñ–∑–∞—Ü—ñ—ó:")
        print("   üìà dissertation_model_comparison.png - –æ—Å–Ω–æ–≤–Ω–µ –ø–æ—Ä—ñ–≤–Ω—è–Ω–Ω—è")
        print("   üìä dissertation_detailed_analysis.png - –¥–µ—Ç–∞–ª—å–Ω–∏–π –∞–Ω–∞–ª—ñ–∑")
        
        self.figures = figures
        return figures

    def create_dissertation_summary_visualization(self, Y_test: np.ndarray, Y_pred_linear: np.ndarray, 
                                                 Y_pred_kernel: np.ndarray, evaluation_metrics: dict) -> str:
        """
        –°—Ç–≤–æ—Ä–µ–Ω–Ω—è –∫–æ–º–ø–∞–∫—Ç–Ω–æ—ó –≤—ñ–∑—É–∞–ª—ñ–∑–∞—Ü—ñ—ó –¥–ª—è –¥–∏—Å–µ—Ä—Ç–∞—Ü—ñ—ó.
        –î–≤–∞ –≥—Ä–∞—Ñ—ñ–∫–∏: scatter plot –ø–æ—Ä—ñ–≤–Ω—è–Ω–Ω—è —Ç–∞ bar chart –ø–æ–∫—Ä–∞—â–µ–Ω–Ω—è.
        
        Args:
            Y_test: –†–µ–∞–ª—å–Ω—ñ —Ç–µ—Å—Ç–æ–≤—ñ –∑–Ω–∞—á–µ–Ω–Ω—è
            Y_pred_linear: –ü—Ä–æ–≥–Ω–æ–∑–∏ –ª—ñ–Ω—ñ–π–Ω–æ—ó –º–æ–¥–µ–ª—ñ
            Y_pred_kernel: –ü—Ä–æ–≥–Ω–æ–∑–∏ —è–¥–µ—Ä–Ω–æ—ó –º–æ–¥–µ–ª—ñ
            evaluation_metrics: –ú–µ—Ç—Ä–∏–∫–∏ –æ—Ü—ñ–Ω–∫–∏ –º–æ–¥–µ–ª–µ–π
            
        Returns:
            str: –®–ª—è—Ö –¥–æ –∑–±–µ—Ä–µ–∂–µ–Ω–æ–≥–æ —Ñ–∞–π–ª—É
        """
        import matplotlib.pyplot as plt
        
        # –ù–∞–ª–∞—à—Ç—É–≤–∞–Ω–Ω—è –¥–ª—è –¥–∏—Å–µ—Ä—Ç–∞—Ü—ñ—ó
        plt.style.use('default')
        fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 5))
        fig.suptitle('–ü–æ—Ä—ñ–≤–Ω—è–Ω–Ω—è –ª—ñ–Ω—ñ–π–Ω–æ—ó —Ç–∞ —è–¥–µ—Ä–Ω–æ—ó –º–æ–¥–µ–ª–µ–π', fontsize=14, fontweight='bold')
        
        # –ì–†–ê–§–Ü–ö 1: Scatter plot –¥–ª—è –∫–æ–Ω—Ü–µ–Ω—Ç—Ä–∞—Ü—ñ—ó Fe (–Ω–∞–π–≤–∞–∂–ª–∏–≤—ñ—à–∏–π –ø–æ–∫–∞–∑–Ω–∏–∫)
        ax1.scatter(Y_test[:, 0], Y_pred_linear[:, 0], alpha=0.7, s=30, 
                   color='red', label='–õ—ñ–Ω—ñ–π–Ω–∞ –º–æ–¥–µ–ª—å', marker='o')
        ax1.scatter(Y_test[:, 0], Y_pred_kernel[:, 0], alpha=0.7, s=30, 
                   color='green', label='–Ø–¥–µ—Ä–Ω–∞ –º–æ–¥–µ–ª—å', marker='s')
        
        # –Ü–¥–µ–∞–ª—å–Ω–∞ –ª—ñ–Ω—ñ—è
        min_val, max_val = Y_test[:, 0].min(), Y_test[:, 0].max()
        ax1.plot([min_val, max_val], [min_val, max_val], 'k--', 
                 alpha=0.8, linewidth=2, label='–Ü–¥–µ–∞–ª—å–Ω–∞ –ª—ñ–Ω—ñ—è')
        
        ax1.set_xlabel('–†–µ–∞–ª—å–Ω–∞ –∫–æ–Ω—Ü–µ–Ω—Ç—Ä–∞—Ü—ñ—è Fe (%)')
        ax1.set_ylabel('–ü—Ä–æ–≥–Ω–æ–∑–æ–≤–∞–Ω–∞ –∫–æ–Ω—Ü–µ–Ω—Ç—Ä–∞—Ü—ñ—è Fe (%)')
        ax1.set_title('–¢–æ—á–Ω—ñ—Å—Ç—å –ø—Ä–æ–≥–Ω–æ–∑—É–≤–∞–Ω–Ω—è')
        ax1.legend(loc='upper left')
        ax1.grid(True, alpha=0.3)
        
        # –î–æ–¥–∞–≤–∞–Ω–Ω—è R¬≤ –≤ –Ω–∏–∂–Ω—ñ–π –ø—Ä–∞–≤–∏–π –∫—É—Ç
        r2_linear = 1 - np.sum((Y_test[:, 0] - Y_pred_linear[:, 0])**2) / np.sum((Y_test[:, 0] - np.mean(Y_test[:, 0]))**2)
        r2_kernel = 1 - np.sum((Y_test[:, 0] - Y_pred_kernel[:, 0])**2) / np.sum((Y_test[:, 0] - np.mean(Y_test[:, 0]))**2)
        
        ax1.text(0.98, 0.02, f'R¬≤ –ª—ñ–Ω—ñ–π–Ω–∞: {r2_linear:.3f}\nR¬≤ —è–¥–µ—Ä–Ω–∞: {r2_kernel:.3f}', 
                 transform=ax1.transAxes, ha='right', va='bottom',
                 bbox=dict(boxstyle='round,pad=0.3', facecolor='white', alpha=0.8))
        
        # –ì–†–ê–§–Ü–ö 2: Bar chart –ø–æ–∫—Ä–∞—â–µ–Ω–Ω—è –º–µ—Ç—Ä–∏–∫
        metrics = ['MSE', 'RMSE Fe', 'RMSE Mass']
        improvements = [
            evaluation_metrics['improvement_mse'],
            evaluation_metrics['improvement_fe'], 
            evaluation_metrics['improvement_mass']
        ]
        
        colors = ['#2E86AB', '#A23B72', '#F18F01']  # –ü—Ä–æ—Ñ–µ—Å—ñ–π–Ω–∞ –ø–∞–ª—ñ—Ç—Ä–∞
        bars = ax2.bar(metrics, improvements, color=colors, alpha=0.8, width=0.6)
        
        ax2.set_ylabel('–ü–æ–∫—Ä–∞—â–µ–Ω–Ω—è (%)')
        ax2.set_title('–ü–µ—Ä–µ–≤–∞–≥–∏ —è–¥–µ—Ä–Ω–æ—ó –º–æ–¥–µ–ª—ñ')
        ax2.grid(True, alpha=0.3, axis='y')
        ax2.set_ylim(0, max(improvements) * 1.2)
        
        # –î–æ–¥–∞–≤–∞–Ω–Ω—è –∑–Ω–∞—á–µ–Ω—å –Ω–∞ —Å—Ç–æ–≤–ø—Ü—ñ
        for bar, value in zip(bars, improvements):
            height = bar.get_height()
            ax2.text(bar.get_x() + bar.get_width()/2, height + max(improvements)*0.02,
                    f'{value:.1f}%', ha='center', va='bottom', fontweight='bold', fontsize=11)
        
        # –õ—ñ–Ω—ñ—è —Ü—ñ–ª—å–æ–≤–æ–≥–æ —Ä—ñ–≤–Ω—è –ø–æ–∫—Ä–∞—â–µ–Ω–Ω—è (15%)
        ax2.axhline(y=15, color='red', linestyle='--', alpha=0.7, linewidth=2)
        ax2.text(len(metrics)-1, 15.5, '–¶—ñ–ª—å–æ–≤–∏–π —Ä—ñ–≤–µ–Ω—å (15%)', 
                 ha='right', va='bottom', color='red', fontsize=10)
        
        plt.tight_layout()
        
        # –ó–±–µ—Ä–µ–∂–µ–Ω–Ω—è
        summary_plot_path = self.dirs['visualizations'] / 'dissertation_summary.png'
        plt.savefig(summary_plot_path, dpi=300, bbox_inches='tight')
        plt.close()
        
        print(f"–ö–æ–º–ø–∞–∫—Ç–Ω—É –≤—ñ–∑—É–∞–ª—ñ–∑–∞—Ü—ñ—é –∑–±–µ—Ä–µ–∂–µ–Ω–æ —É {summary_plot_path}")
        return str(summary_plot_path)
    
    def create_performance_table_visualization(self, evaluation_metrics: dict) -> str:
        """
        –°—Ç–≤–æ—Ä–µ–Ω–Ω—è —Ç–∞–±–ª–∏—á–Ω–æ—ó –≤—ñ–∑—É–∞–ª—ñ–∑–∞—Ü—ñ—ó –º–µ—Ç—Ä–∏–∫ —É –≤–∏–≥–ª—è–¥—ñ –≥—Ä–∞—Ñ—ñ–∫—É.
        –ê–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤–∞ –¥–ª—è –ø—Ä–µ–∑–µ–Ω—Ç–∞—Ü—ñ–π.
        """
        import matplotlib.pyplot as plt
        
        fig, ax = plt.subplots(figsize=(10, 6))
        
        # –î–∞–Ω—ñ –¥–ª—è —Ç–∞–±–ª–∏—Ü—ñ
        metrics_data = [
            ['–ú–µ—Ç—Ä–∏–∫–∞', '–õ—ñ–Ω—ñ–π–Ω–∞ –º–æ–¥–µ–ª—å', '–Ø–¥–µ—Ä–Ω–∞ –º–æ–¥–µ–ª—å', '–ü–æ–∫—Ä–∞—â–µ–Ω–Ω—è'],
            ['MSE', f"{evaluation_metrics['linear_mse']:.4f}", 
             f"{evaluation_metrics['kernel_mse']:.4f}", 
             f"{evaluation_metrics['improvement_mse']:.1f}%"],
            ['RMSE Fe (%)', f"{evaluation_metrics['linear_rmse_fe']:.3f}", 
             f"{evaluation_metrics['kernel_rmse_fe']:.3f}", 
             f"{evaluation_metrics['improvement_fe']:.1f}%"],
            ['RMSE Mass (—Ç/–≥–æ–¥)', f"{evaluation_metrics['linear_rmse_mass']:.3f}", 
             f"{evaluation_metrics['kernel_rmse_mass']:.3f}", 
             f"{evaluation_metrics['improvement_mass']:.1f}%"]
        ]
        
        # –°—Ç–≤–æ—Ä–µ–Ω–Ω—è —Ç–∞–±–ª–∏—Ü—ñ
        table = ax.table(cellText=metrics_data[1:], colLabels=metrics_data[0],
                        cellLoc='center', loc='center')
        
        # –°—Ç–∏–ª—ñ–∑–∞—Ü—ñ—è —Ç–∞–±–ª–∏—Ü—ñ
        table.auto_set_font_size(False)
        table.set_fontsize(12)
        table.scale(1.2, 2)
        
        # –ö–æ–ª—å–æ—Ä–æ–≤–µ –∫–æ–¥—É–≤–∞–Ω–Ω—è –∑–∞–≥–æ–ª–æ–≤–∫—ñ–≤
        for i in range(len(metrics_data[0])):
            table[(0, i)].set_facecolor('#4472C4')
            table[(0, i)].set_text_props(weight='bold', color='white')
        
        # –ö–æ–ª—å–æ—Ä–æ–≤–µ –∫–æ–¥—É–≤–∞–Ω–Ω—è —Å—Ç–æ–≤–ø—Ü—è –ø–æ–∫—Ä–∞—â–µ–Ω–Ω—è
        for i in range(1, len(metrics_data)):
            improvement_val = float(metrics_data[i][3].replace('%', ''))
            if improvement_val >= 15:
                table[(i, 3)].set_facecolor('#D5E8D4')  # –ó–µ–ª–µ–Ω–∏–π –¥–ª—è –¥–æ—Å—è–≥–Ω–µ–Ω–Ω—è —Ü—ñ–ª—ñ
            else:
                table[(i, 3)].set_facecolor('#FFF2CC')  # –ñ–æ–≤—Ç–∏–π –¥–ª—è –Ω–µ–¥–æ—Å—è–≥–Ω–µ–Ω–Ω—è
            table[(i, 3)].set_text_props(weight='bold')
        
        ax.set_title('–ü–æ—Ä—ñ–≤–Ω—è–Ω–Ω—è –ø—Ä–æ–¥—É–∫—Ç–∏–≤–Ω–æ—Å—Ç—ñ –º–æ–¥–µ–ª–µ–π', fontsize=14, fontweight='bold', pad=20)
        ax.axis('off')
        
        # –ó–±–µ—Ä–µ–∂–µ–Ω–Ω—è
        table_plot_path = self.dirs['visualizations'] / 'performance_table.png'
        plt.savefig(table_plot_path, dpi=300, bbox_inches='tight')
        plt.close()
        
        print(f"–¢–∞–±–ª–∏—á–Ω—É –≤—ñ–∑—É–∞–ª—ñ–∑–∞—Ü—ñ—é –∑–±–µ—Ä–µ–∂–µ–Ω–æ —É {table_plot_path}")
        return str(table_plot_path)
    
    def generate_report_summary(self) -> str:
        """
        –ì–µ–Ω–µ—Ä–∞—Ü—ñ—è —Ç–µ–∫—Å—Ç–æ–≤–æ–≥–æ –∑–≤—ñ—Ç—É –¥–ª—è –¥–∏—Å–µ—Ä—Ç–∞—Ü—ñ—ó.
        –í–ò–ü–†–ê–í–õ–ï–ù–û: –ø—Ä–∞–≤–∏–ª—å–Ω–µ –∑–±–µ—Ä–µ–∂–µ–Ω–Ω—è —É –ø–∞–ø–∫—É reports
        """
        if not self.results:
            raise ValueError("–ù–µ–º–∞—î —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ñ–≤ –¥–ª—è –∑–≤—ñ—Ç—É. –°–ø–æ—á–∞—Ç–∫—É –≤–∏–∫–æ–Ω–∞–π—Ç–µ run_comparison()")
        
        perf = self.results['performance_comparison']
        linear = self.results['linear_model']
        kernel = self.results['kernel_model']
        data_info = self.results['data_info']
        
        report = f"""
    –ó–í–Ü–¢ –ü–†–û –ü–û–†–Ü–í–ù–Ø–ù–ù–Ø –ú–û–î–ï–õ–ï–ô –î–õ–Ø –î–ò–°–ï–†–¢–ê–¶–Ü–á
    {'='*55}
    
    –î–ê–ù–Ü –ü–†–û –ï–ö–°–ü–ï–†–ò–ú–ï–ù–¢:
        –ó–∞–≥–∞–ª—å–Ω–∞ –∫—ñ–ª—å–∫—ñ—Å—Ç—å –∑—Ä–∞–∑–∫—ñ–≤: {data_info['samples_total']:,}
        –¢—Ä–µ–Ω—É–≤–∞–ª—å–Ω—ñ –∑—Ä–∞–∑–∫–∏: {data_info['samples_train']:,}
        –í–∞–ª—ñ–¥–∞—Ü—ñ–π–Ω—ñ –∑—Ä–∞–∑–∫–∏: {data_info['samples_val']:,}
        –¢–µ—Å—Ç–æ–≤—ñ –∑—Ä–∞–∑–∫–∏: {data_info['samples_test']:,}
        –ö—ñ–ª—å–∫—ñ—Å—Ç—å –ª–∞–≥—ñ–≤: {data_info['lag_used']}
        –ö—ñ–ª—å–∫—ñ—Å—Ç—å –æ–∑–Ω–∞–∫: {data_info['features']}
    
    –†–ï–ó–£–õ–¨–¢–ê–¢–ò –õ–Ü–ù–Ü–ô–ù–û–á –ú–û–î–ï–õ–Ü (ARX):
        MSE: {linear['mse']:.6f}
        RMSE Fe: {linear['rmse_fe']:.3f}%
        RMSE Mass: {linear['rmse_mass']:.3f} —Ç/–≥–æ–¥
        –ß–∞—Å –Ω–∞–≤—á–∞–Ω–Ω—è: {linear['train_time']:.3f} —Å–µ–∫
    
    –†–ï–ó–£–õ–¨–¢–ê–¢–ò –Ø–î–ï–†–ù–û–á –ú–û–î–ï–õ–Ü (KRR):
        MSE: {kernel['mse']:.6f}
        RMSE Fe: {kernel['rmse_fe']:.3f}%
        RMSE Mass: {kernel['rmse_mass']:.3f} —Ç/–≥–æ–¥
        –ß–∞—Å –Ω–∞–≤—á–∞–Ω–Ω—è: {kernel['train_time']:.3f} —Å–µ–∫
    
    –ü–û–†–Ü–í–ù–Ø–ù–ù–Ø –ü–†–û–î–£–ö–¢–ò–í–ù–û–°–¢–Ü:
        –ü–æ–∫—Ä–∞—â–µ–Ω–Ω—è MSE: {perf['mse_improvement_percent']:.1f}%
        –ü–æ–∫—Ä–∞—â–µ–Ω–Ω—è RMSE Fe: {perf['rmse_fe_improvement_percent']:.1f}%
        –ü–æ–∫—Ä–∞—â–µ–Ω–Ω—è RMSE Mass: {perf['rmse_mass_improvement_percent']:.1f}%
        
    –í–ò–°–ù–û–í–û–ö:
        –¶—ñ–ª—å–æ–≤–∏–π –¥—ñ–∞–ø–∞–∑–æ–Ω (15-20%): {'‚úÖ –î–û–°–Ø–ì–ù–£–¢–û' if perf['target_achieved'] else '‚ùå –ù–ï –î–û–°–Ø–ì–ù–£–¢–û'}
        
    –ù–ï–õ–Ü–ù–Ü–ô–ù–Ü–°–¢–¨ –ü–†–û–¶–ï–°–£:"""
        
        if 'nonlinearity_analysis' in self.results:
            for metric, value in self.results['nonlinearity_analysis'].items():
                report += f"\n    {metric}: {value:.3f}"
        
        report += f"""
    
    –î–ê–¢–ê –ï–ö–°–ü–ï–†–ò–ú–ï–ù–¢–£: {self.results['timestamp']}
    {'='*55}
    """
        
        # –í–ò–ü–†–ê–í–õ–ï–ù–ù–Ø: –∑–±–µ—Ä–µ–∂–µ–Ω–Ω—è —É –≤—ñ–¥–ø–æ–≤—ñ–¥–Ω—É –ø–∞–ø–∫—É
        report_file_path = self.dirs['reports'] / 'analysis_report.txt'
        with open(report_file_path, 'w', encoding='utf-8') as f:
            f.write(report)
        
        print(f"üìù –ó–≤—ñ—Ç –∑–±–µ—Ä–µ–∂–µ–Ω–æ —É {report_file_path}")
        return str(report_file_path)  
    
    def export_metrics_for_latex(self) -> str:
        """
        –ï–∫—Å–ø–æ—Ä—Ç –º–µ—Ç—Ä–∏–∫ —É —Ñ–æ—Ä–º–∞—Ç—ñ LaTeX —Ç–∞–±–ª–∏—Ü—ñ.
        –í–ò–ü–†–ê–í–õ–ï–ù–û: –ø—Ä–∞–≤–∏–ª—å–Ω–µ –∑–±–µ—Ä–µ–∂–µ–Ω–Ω—è —É –ø–∞–ø–∫—É latex
        """
        if not self.results:
            raise ValueError("–ù–µ–º–∞—î —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ñ–≤ –¥–ª—è –µ–∫—Å–ø–æ—Ä—Ç—É. –°–ø–æ—á–∞—Ç–∫—É –≤–∏–∫–æ–Ω–∞–π—Ç–µ run_comparison()")
        
        linear = self.results['linear_model']
        kernel = self.results['kernel_model']
        perf = self.results['performance_comparison']
        
        latex_table = f"""
    \\begin{{table}}[h]
    \\centering
    \\caption{{–ü–æ—Ä—ñ–≤–Ω—è–Ω–Ω—è –ø—Ä–æ–¥—É–∫—Ç–∏–≤–Ω–æ—Å—Ç—ñ –ª—ñ–Ω—ñ–π–Ω–æ—ó —Ç–∞ —è–¥–µ—Ä–Ω–æ—ó –º–æ–¥–µ–ª–µ–π}}
    \\label{{tab:model_comparison}}
    \\begin{{tabular}}{{|l|c|c|c|}}
    \\hline
    \\textbf{{–ú–µ—Ç—Ä–∏–∫–∞}} & \\textbf{{–õ—ñ–Ω—ñ–π–Ω–∞ (ARX)}} & \\textbf{{–Ø–¥–µ—Ä–Ω–∞ (KRR)}} & \\textbf{{–ü–æ–∫—Ä–∞—â–µ–Ω–Ω—è, \\%}} \\\\
    \\hline
    MSE & {linear['mse']:.6f} & {kernel['mse']:.6f} & {perf['mse_improvement_percent']:.1f} \\\\
    \\hline
    RMSE Fe, \\% & {linear['rmse_fe']:.3f} & {kernel['rmse_fe']:.3f} & {perf['rmse_fe_improvement_percent']:.1f} \\\\
    \\hline
    RMSE Mass, —Ç/–≥–æ–¥ & {linear['rmse_mass']:.3f} & {kernel['rmse_mass']:.3f} & {perf['rmse_mass_improvement_percent']:.1f} \\\\
    \\hline
    –ß–∞—Å –Ω–∞–≤—á–∞–Ω–Ω—è, —Å–µ–∫ & {linear['train_time']:.3f} & {kernel['train_time']:.3f} & - \\\\
    \\hline
    \\end{{tabular}}
    \\end{{table}}
    """
        
        # –í–ò–ü–†–ê–í–õ–ï–ù–ù–Ø: –∑–±–µ—Ä–µ–∂–µ–Ω–Ω—è —É –≤—ñ–¥–ø–æ–≤—ñ–¥–Ω—É –ø–∞–ø–∫—É
        latex_file_path = self.dirs['latex'] / 'model_comparison_table.tex'
        with open(latex_file_path, 'w', encoding='utf-8') as f:
            f.write(latex_table)
        
        print(f"üìÑ LaTeX —Ç–∞–±–ª–∏—Ü—é –∑–±–µ—Ä–µ–∂–µ–Ω–æ —É {latex_file_path}")
        return str(latex_file_path)  
    
    def run_full_analysis_with_visualizations(self, **kwargs) -> dict:
        """
        –ü–æ–≤–Ω–∏–π –∞–Ω–∞–ª—ñ–∑ –∑ –≤—ñ–∑—É–∞–ª—ñ–∑–∞—Ü—ñ—è–º–∏ –¥–ª—è –¥–∏—Å–µ—Ä—Ç–∞—Ü—ñ—ó.
        –û–ù–û–í–õ–ï–ù–û: –¥–æ–¥–∞–Ω–æ –∫–æ–º–ø–∞–∫—Ç–Ω—É –≤—ñ–∑—É–∞–ª—ñ–∑–∞—Ü—ñ—é
        """
        # –í–∏–∫–æ–Ω–∞–Ω–Ω—è –æ—Å–Ω–æ–≤–Ω–æ–≥–æ –ø–æ—Ä—ñ–≤–Ω—è–Ω–Ω—è
        results = self.run_comparison(**kwargs)
        
        # –û—Ç—Ä–∏–º–∞–Ω–Ω—è –¥–∞–Ω–∏—Ö –¥–ª—è –≤—ñ–∑—É–∞–ª—ñ–∑–∞—Ü—ñ—ó –∑ –æ—Å—Ç–∞–Ω–Ω—å–æ–≥–æ –∑–∞–ø—É—Å–∫—É
        if hasattr(self, '_last_simulation_data'):
            Y_test, Y_pred_linear, Y_pred_kernel, evaluation_metrics, nonlinearity_metrics, df_sim = self._last_simulation_data
            
            # –°—Ç–≤–æ—Ä–µ–Ω–Ω—è –≤—ñ–∑—É–∞–ª—ñ–∑–∞—Ü—ñ–π
            print("\n–ì–µ–Ω–µ—Ä–∞—Ü—ñ—è –≤—ñ–∑—É–∞–ª—ñ–∑–∞—Ü—ñ–π...")
            
            # –î–µ—Ç–∞–ª—å–Ω—ñ –≤—ñ–∑—É–∞–ª—ñ–∑–∞—Ü—ñ—ó
            figures = self.create_comparison_visualizations(
                Y_test, Y_pred_linear, Y_pred_kernel, 
                evaluation_metrics, nonlinearity_metrics, df_sim
            )
            
            # –ù–û–í–ê: –ö–æ–º–ø–∞–∫—Ç–Ω–∞ –≤—ñ–∑—É–∞–ª—ñ–∑–∞—Ü—ñ—è –¥–ª—è –¥–∏—Å–µ—Ä—Ç–∞—Ü—ñ—ó
            summary_viz_path = self.create_dissertation_summary_visualization(
                Y_test, Y_pred_linear, Y_pred_kernel, evaluation_metrics
            )
            
            # –ù–û–í–ê: –¢–∞–±–ª–∏—á–Ω–∏–π –≥—Ä–∞—Ñ—ñ–∫ (–æ–ø—Ü—ñ–æ–Ω–∞–ª—å–Ω–æ)
            table_viz_path = self.create_performance_table_visualization(evaluation_metrics)
            
            # –ì–µ–Ω–µ—Ä–∞—Ü—ñ—è –∑–≤—ñ—Ç—É
            print("\n–ì–µ–Ω–µ—Ä–∞—Ü—ñ—è –∑–≤—ñ—Ç—É...")
            report_path = self.generate_report_summary()
            
            # –ï–∫—Å–ø–æ—Ä—Ç LaTeX —Ç–∞–±–ª–∏—Ü—ñ
            latex_path = self.export_metrics_for_latex()
            
            # –ó–±–µ—Ä–µ–∂–µ–Ω–Ω—è —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ñ–≤
            results_path = self.save_results()
            
            print("\n–ü–æ–≤–Ω–∏–π –∞–Ω–∞–ª—ñ–∑ –∑–∞–≤–µ—Ä—à–µ–Ω–æ")
            print(f"–í—Å—ñ —Ñ–∞–π–ª–∏ –∑–±–µ—Ä–µ–∂–µ–Ω–æ —É –¥–∏—Ä–µ–∫—Ç–æ—Ä—ñ—ó: {self.output_dir}")
            print("–°—Ç—Ä—É–∫—Ç—É—Ä–∞ —Ñ–∞–π–ª—ñ–≤:")
            print(f"   –í—ñ–∑—É–∞–ª—ñ–∑–∞—Ü—ñ—ó:")
            print(f"     - {summary_viz_path} (–¥–ª—è –¥–∏—Å–µ—Ä—Ç–∞—Ü—ñ—ó)")
            print(f"     - {table_viz_path} (–∞–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤–Ω–∞)")
            print(f"   –î–µ—Ç–∞–ª—å–Ω—ñ –≥—Ä–∞—Ñ—ñ–∫–∏ —Ç–∞ –∑–≤—ñ—Ç–∏ —É –≤—ñ–¥–ø–æ–≤—ñ–¥–Ω–∏—Ö –ø–∞–ø–∫–∞—Ö")
            
            return results
        else:
            print("–î–∞–Ω—ñ —Å–∏–º—É–ª—è—Ü—ñ—ó –Ω–µ–¥–æ—Å—Ç—É–ø–Ω—ñ –¥–ª—è –≤—ñ–∑—É–∞–ª—ñ–∑–∞—Ü—ñ—ó")
            return results
        
    def add_custom_metrics(self, custom_metrics: dict) -> None:
        """
        –î–æ–¥–∞–≤–∞–Ω–Ω—è –∫–æ—Ä–∏—Å—Ç—É–≤–∞—Ü—å–∫–∏—Ö –º–µ—Ç—Ä–∏–∫ –¥–æ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ñ–≤.
        
        Args:
            custom_metrics: –°–ª–æ–≤–Ω–∏–∫ –∑ –¥–æ–¥–∞—Ç–∫–æ–≤–∏–º–∏ –º–µ—Ç—Ä–∏–∫–∞–º–∏
        """
        if not self.results:
            raise ValueError("–ù–µ–º–∞—î –±–∞–∑–æ–≤–∏—Ö —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ñ–≤. –°–ø–æ—á–∞—Ç–∫—É –≤–∏–∫–æ–Ω–∞–π—Ç–µ run_comparison()")
        
        if 'custom_metrics' not in self.results:
            self.results['custom_metrics'] = {}
        
        self.results['custom_metrics'].update(custom_metrics)
        print(f"‚úÖ –î–æ–¥–∞–Ω–æ {len(custom_metrics)} –∫–æ—Ä–∏—Å—Ç—É–≤–∞—Ü—å–∫–∏—Ö –º–µ—Ç—Ä–∏–∫")
    
    def get_performance_summary(self) -> dict:
        """
        –û—Ç—Ä–∏–º–∞–Ω–Ω—è –∫–æ—Ä–æ—Ç–∫–æ–≥–æ –ø—ñ–¥—Å—É–º–∫—É –ø—Ä–æ–¥—É–∫—Ç–∏–≤–Ω–æ—Å—Ç—ñ.
        
        Returns:
            dict: –û—Å–Ω–æ–≤–Ω—ñ –ø–æ–∫–∞–∑–Ω–∏–∫–∏ –ø—Ä–æ–¥—É–∫—Ç–∏–≤–Ω–æ—Å—Ç—ñ
        """
        if not self.results:
            raise ValueError("–ù–µ–º–∞—î —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ñ–≤ –¥–ª—è –ø—ñ–¥—Å—É–º–∫—É. –°–ø–æ—á–∞—Ç–∫—É –≤–∏–∫–æ–Ω–∞–π—Ç–µ run_comparison()")
        
        perf = self.results['performance_comparison']
        
        summary = {
            'mse_improvement': perf['mse_improvement_percent'],
            'target_achieved': perf['target_achieved'],
            'best_metric': max(perf['mse_improvement_percent'], 
                              perf['rmse_fe_improvement_percent'],
                              perf['rmse_mass_improvement_percent']),
            'overall_grade': 'Excellent' if perf['mse_improvement_percent'] > 20 else
                            'Good' if perf['mse_improvement_percent'] > 15 else
                            'Moderate' if perf['mse_improvement_percent'] > 10 else
                            'Poor'
        }
        
        return summary
    
    def compare_multiple_configurations(self, config_list: list) -> pd.DataFrame:
        """
        –ü–æ—Ä—ñ–≤–Ω—è–Ω–Ω—è –∫—ñ–ª—å–∫–æ—Ö –∫–æ–Ω—Ñ—ñ–≥—É—Ä–∞—Ü—ñ–π –ø–∞—Ä–∞–º–µ—Ç—Ä—ñ–≤.
        –í–ò–ü–†–ê–í–õ–ï–ù–û: –ø—Ä–∞–≤–∏–ª—å–Ω–µ –∑–±–µ—Ä–µ–∂–µ–Ω–Ω—è —É –ø–∞–ø–∫—É comparisons
        """
        comparison_results = []
        
        for i, config in enumerate(config_list):
            print(f"\nüîÑ –¢–µ—Å—Ç—É–≤–∞–Ω–Ω—è –∫–æ–Ω—Ñ—ñ–≥—É—Ä–∞—Ü—ñ—ó {i+1}/{len(config_list)}")
            print("-" * 50)
            
            try:
                results = self.run_comparison(**config)
                
                row = {
                    'config_id': i+1,
                    'linear_mse': results['linear_model']['mse'],
                    'kernel_mse': results['kernel_model']['mse'],
                    'mse_improvement': results['performance_comparison']['mse_improvement_percent'],
                    'linear_rmse_fe': results['linear_model']['rmse_fe'],
                    'kernel_rmse_fe': results['kernel_model']['rmse_fe'],
                    'fe_improvement': results['performance_comparison']['rmse_fe_improvement_percent'],
                    'target_achieved': results['performance_comparison']['target_achieved'],
                    'linear_train_time': results['linear_model']['train_time'],
                    'kernel_train_time': results['kernel_model']['train_time']
                }
                
                # –î–æ–¥–∞–≤–∞–Ω–Ω—è –ø–∞—Ä–∞–º–µ—Ç—Ä—ñ–≤ –∫–æ–Ω—Ñ—ñ–≥—É—Ä–∞—Ü—ñ—ó
                for key, value in config.items():
                    if key not in ['time_constants_s', 'dead_times_s', 'nonlinear_config']:
                        row[f'param_{key}'] = value
                        
                comparison_results.append(row)
                
            except Exception as e:
                print(f"‚ùå –ü–æ–º–∏–ª–∫–∞ –≤ –∫–æ–Ω—Ñ—ñ–≥—É—Ä–∞—Ü—ñ—ó {i+1}: {e}")
                continue
        
        df_comparison = pd.DataFrame(comparison_results)
        
        # –í–ò–ü–†–ê–í–õ–ï–ù–ù–Ø: –∑–±–µ—Ä–µ–∂–µ–Ω–Ω—è —É –≤—ñ–¥–ø–æ–≤—ñ–¥–Ω—É –ø–∞–ø–∫—É
        comparison_file_path = self.dirs['comparisons'] / 'configurations_comparison.csv'
        df_comparison.to_csv(comparison_file_path, index=False)
        print(f"\nüìä –ü–æ—Ä—ñ–≤–Ω—è–Ω–Ω—è {len(comparison_results)} –∫–æ–Ω—Ñ—ñ–≥—É—Ä–∞—Ü—ñ–π –∑–±–µ—Ä–µ–∂–µ–Ω–æ —É {comparison_file_path}")
        
        return df_comparison
    
def basic_comparison_example():
    """–ë–∞–∑–æ–≤–∏–π –ø—Ä–∏–∫–ª–∞–¥ –ø–æ—Ä—ñ–≤–Ω—è–Ω–Ω—è –º–æ–¥–µ–ª–µ–π"""
    print("=== –ë–ê–ó–û–í–ò–ô –ü–†–ò–ö–õ–ê–î –ü–û–†–Ü–í–ù–Ø–ù–ù–Ø –ú–û–î–ï–õ–ï–ô ===\n")
    
    # –Ü–Ω—ñ—Ü—ñ–∞–ª—ñ–∑–∞—Ü—ñ—è —Å–µ—Ä–≤—ñ—Å—É
    service = ModelComparisonService()
    
    # –í–∏–∫–æ–Ω–∞–Ω–Ω—è –±–∞–∑–æ–≤–æ–≥–æ –ø–æ—Ä—ñ–≤–Ω—è–Ω–Ω—è –∑ —Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω–∏–º–∏ –ø–∞—Ä–∞–º–µ—Ç—Ä–∞–º–∏
    results = service.run_comparison(
        N_data=5000,           # –ö—ñ–ª—å–∫—ñ—Å—Ç—å —Ç–æ—á–æ–∫ –¥–∞–Ω–∏—Ö
        lag=2,                 # –ö—ñ–ª—å–∫—ñ—Å—Ç—å –ª–∞–≥—ñ–≤  
        anomaly_severity='mild', # –†—ñ–≤–µ–Ω—å –∞–Ω–æ–º–∞–ª—ñ–π
        use_anomalies=True,     # –í–∫–ª—é—á–∏—Ç–∏ –∞–Ω–æ–º–∞–ª—ñ—ó
        seed=42                 # –î–ª—è –≤—ñ–¥—Ç–≤–æ—Ä—é–≤–∞–Ω–æ—Å—Ç—ñ
    )
    
    # –û—Ç—Ä–∏–º–∞–Ω–Ω—è –∫–æ—Ä–æ—Ç–∫–æ–≥–æ –ø—ñ–¥—Å—É–º–∫—É
    summary = service.get_performance_summary()
    print(f"–ü–æ–∫—Ä–∞—â–µ–Ω–Ω—è MSE: {summary['mse_improvement']:.1f}%")
    print(f"–¶—ñ–ª—å–æ–≤–∏–π —Ä—ñ–≤–µ–Ω—å –¥–æ—Å—è–≥–Ω—É—Ç–æ: {summary['target_achieved']}")
    print(f"–ó–∞–≥–∞–ª—å–Ω–∞ –æ—Ü—ñ–Ω–∫–∞: {summary['overall_grade']}")
    
    # –ó–±–µ—Ä–µ–∂–µ–Ω–Ω—è —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ñ–≤
    filename = service.save_results()
    print(f"–†–µ–∑—É–ª—å—Ç–∞—Ç–∏ –∑–±–µ—Ä–µ–∂–µ–Ω–æ —É {filename}")
    
    return results

def full_analysis_example():
    """–ü–æ–≤–Ω–∏–π –ø—Ä–∏–∫–ª–∞–¥ –∞–Ω–∞–ª—ñ–∑—É –∑ –≤—ñ–∑—É–∞–ª—ñ–∑–∞—Ü—ñ—è–º–∏"""
    print("\n=== –ü–û–í–ù–ò–ô –ê–ù–ê–õ–Ü–ó –ó –í–Ü–ó–£–ê–õ–Ü–ó–ê–¶–Ü–Ø–ú–ò ===\n")
    
    # –Ü–Ω—ñ—Ü—ñ–∞–ª—ñ–∑–∞—Ü—ñ—è —Å–µ—Ä–≤—ñ—Å—É
    service = ModelComparisonService()
    
    # –ü–æ–≤–Ω–∏–π –∞–Ω–∞–ª—ñ–∑ –∑ –≤—ñ–∑—É–∞–ª—ñ–∑–∞—Ü—ñ—è–º–∏
    results = service.run_full_analysis_with_visualizations(
        N_data=7000,
        lag=3,
        anomaly_severity='medium',
        anomaly_in_train=False,  # –ê–Ω–æ–º–∞–ª—ñ—ó —Ç—ñ–ª—å–∫–∏ –≤ val/test
        find_optimal_params=True, # –û–ø—Ç–∏–º—ñ–∑–∞—Ü—ñ—è –≥—ñ–ø–µ—Ä–ø–∞—Ä–∞–º–µ—Ç—Ä—ñ–≤
        n_iter_search=30,        # –ë—ñ–ª—å—à–µ —ñ—Ç–µ—Ä–∞—Ü—ñ–π –ø–æ—à—É–∫—É
        seed=123
    )
    
    # –î–æ–¥–∞–≤–∞–Ω–Ω—è –∫–æ—Ä–∏—Å—Ç—É–≤–∞—Ü—å–∫–∏—Ö –º–µ—Ç—Ä–∏–∫
    custom_metrics = {
        'data_quality_score': 0.85,
        'simulation_realism': 0.92,
        'computational_efficiency': 0.78
    }
    service.add_custom_metrics(custom_metrics)
    
    # –û–Ω–æ–≤–ª–µ–Ω–µ –∑–±–µ—Ä–µ–∂–µ–Ω–Ω—è –∑ –∫–æ—Ä–∏—Å—Ç—É–≤–∞—Ü—å–∫–∏–º–∏ –º–µ—Ç—Ä–∏–∫–∞–º–∏
    service.save_results('full_analysis_results.json')
    
    return results

def multiple_configurations_example():
    """–ü—Ä–∏–∫–ª–∞–¥ –ø–æ—Ä—ñ–≤–Ω—è–Ω–Ω—è –∫—ñ–ª—å–∫–æ—Ö –∫–æ–Ω—Ñ—ñ–≥—É—Ä–∞—Ü—ñ–π"""
    print("\n=== –ü–û–†–Ü–í–ù–Ø–ù–ù–Ø –ö–Ü–õ–¨–ö–û–• –ö–û–ù–§–Ü–ì–£–†–ê–¶–Ü–ô ===\n")
    
    service = ModelComparisonService()
    
    # –í–∏–∑–Ω–∞—á–µ–Ω–Ω—è –∫–æ–Ω—Ñ—ñ–≥—É—Ä–∞—Ü—ñ–π –¥–ª—è —Ç–µ—Å—Ç—É–≤–∞–Ω–Ω—è
    configurations = [
        {
            'N_data': 5000,
            'lag': 2,
            'anomaly_severity': 'mild',
            'use_anomalies': True,
            'seed': 42
        },
        {
            'N_data': 5000,
            'lag': 3,
            'anomaly_severity': 'mild',
            'use_anomalies': True,
            'seed': 42
        },
        {
            'N_data': 5000,
            'lag': 2,
            'anomaly_severity': 'medium',
            'use_anomalies': True,
            'seed': 42
        },
        {
            'N_data': 7000,
            'lag': 2,
            'anomaly_severity': 'mild',
            'use_anomalies': True,
            'seed': 42
        },
        {
            'N_data': 5000,
            'lag': 2,
            'anomaly_severity': 'mild',
            'use_anomalies': False,  # –ë–µ–∑ –∞–Ω–æ–º–∞–ª—ñ–π
            'seed': 42
        }
    ]
    
    # –í–∏–∫–æ–Ω–∞–Ω–Ω—è –ø–æ—Ä—ñ–≤–Ω—è–Ω–Ω—è
    comparison_df = service.compare_multiple_configurations(configurations)
    
    # –ê–Ω–∞–ª—ñ–∑ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ñ–≤
    print("\n–¢–û–ü-3 –∫–æ–Ω—Ñ—ñ–≥—É—Ä–∞—Ü—ñ—ó –∑–∞ –ø–æ–∫—Ä–∞—â–µ–Ω–Ω—è–º MSE:")
    top_configs = comparison_df.nlargest(3, 'mse_improvement')
    for idx, row in top_configs.iterrows():
        print(f"–ö–æ–Ω—Ñ—ñ–≥—É—Ä–∞—Ü—ñ—è {row['config_id']}: "
              f"MSE –ø–æ–∫—Ä–∞—â–µ–Ω–Ω—è = {row['mse_improvement']:.1f}%, "
              f"Lag = {row.get('param_lag', 'N/A')}, "
              f"–ê–Ω–æ–º–∞–ª—ñ—ó = {row.get('param_anomaly_severity', 'N/A')}")
    
    # –°—Ç–∞—Ç–∏—Å—Ç–∏—á–Ω–∏–π –∞–Ω–∞–ª—ñ–∑
    print(f"\n–°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –ø–æ–∫—Ä–∞—â–µ–Ω—å MSE:")
    print(f"–°–µ—Ä–µ–¥–Ω—î: {comparison_df['mse_improvement'].mean():.1f}%")
    print(f"–ú–µ–¥—ñ–∞–Ω–∞: {comparison_df['mse_improvement'].median():.1f}%")
    print(f"–ú—ñ–Ω: {comparison_df['mse_improvement'].min():.1f}%")
    print(f"–ú–∞–∫—Å: {comparison_df['mse_improvement'].max():.1f}%")
    
    return comparison_df

def custom_parameters_example():
    """–ü—Ä–∏–∫–ª–∞–¥ –∑ –∫–æ—Ä–∏—Å—Ç—É–≤–∞—Ü—å–∫–∏–º–∏ –ø–∞—Ä–∞–º–µ—Ç—Ä–∞–º–∏ —Å–∏–º—É–ª—è—Ü—ñ—ó"""
    print("\n=== –ö–û–†–ò–°–¢–£–í–ê–¶–¨–ö–Ü –ü–ê–†–ê–ú–ï–¢–†–ò –°–ò–ú–£–õ–Ø–¶–Ü–á ===\n")
    
    service = ModelComparisonService(output_dir)
    
    # –°–ø–µ—Ü—ñ–∞–ª—å–Ω—ñ –ø–∞—Ä–∞–º–µ—Ç—Ä–∏ –¥–ª—è —Å–ø–µ—Ü–∏—Ñ—ñ—á–Ω–æ–≥–æ –¥–æ—Å–ª—ñ–¥–∂–µ–Ω–Ω—è
    results = service.run_comparison(
        N_data=8000,
        lag=4,                    # –ë—ñ–ª—å—à–∞ —ñ—Å—Ç–æ—Ä—ñ—è
        train_size=0.7,          # –ú–µ–Ω—à–µ —Ç—Ä–µ–Ω—É–≤–∞–ª—å–Ω–∏—Ö –¥–∞–Ω–∏—Ö
        val_size=0.2,            # –ë—ñ–ª—å—à–µ –≤–∞–ª—ñ–¥–∞—Ü—ñ–π–Ω–∏—Ö
        test_size=0.1,           # –ú–µ–Ω—à–µ —Ç–µ—Å—Ç–æ–≤–∏—Ö
        anomaly_severity='strong', # –°–∏–ª—å–Ω—ñ –∞–Ω–æ–º–∞–ª—ñ—ó
        anomaly_in_train=True,    # –ê–Ω–æ–º–∞–ª—ñ—ó —ñ –≤ —Ç—Ä–µ–Ω—É–≤–∞–ª—å–Ω–∏—Ö –¥–∞–Ω–∏—Ö
        noise_level='low',        # –î–æ–¥–∞—Ç–∫–æ–≤–∏–π —à—É–º
        find_optimal_params=True,
        n_iter_search=50,         # –†–µ—Ç–µ–ª—å–Ω–∏–π –ø–æ—à—É–∫ –ø–∞—Ä–∞–º–µ—Ç—Ä—ñ–≤
        seed=999
    )
    
    # –ì–µ–Ω–µ—Ä–∞—Ü—ñ—è LaTeX —Ç–∞–±–ª–∏—Ü—ñ
    latex_table = service.export_metrics_for_latex()
    print("LaTeX —Ç–∞–±–ª–∏—Ü—è:")
    print(latex_table)
    
    return results

def dissertation_ready_example():
    """–ü—Ä–∏–∫–ª–∞–¥, –≥–æ—Ç–æ–≤–∏–π –¥–ª—è –≤–∏–∫–æ—Ä–∏—Å—Ç–∞–Ω–Ω—è –≤ –¥–∏—Å–µ—Ä—Ç–∞—Ü—ñ—ó"""
    print("\n=== –ü–†–ò–ö–õ–ê–î –î–õ–Ø –î–ò–°–ï–†–¢–ê–¶–Ü–á ===\n")
    
    # –ù–∞–ª–∞—à—Ç—É–≤–∞–Ω–Ω—è –¥–ª—è –º–∞–∫—Å–∏–º–∞–ª—å–Ω–æ—ó —è–∫–æ—Å—Ç—ñ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ñ–≤
    service = ModelComparisonService()
    
    # –û–ø—Ç–∏–º–∞–ª—å–Ω—ñ –ø–∞—Ä–∞–º–µ—Ç—Ä–∏ –¥–ª—è –¥–∏—Å–µ—Ä—Ç–∞—Ü—ñ–π–Ω–æ–≥–æ –¥–æ—Å–ª—ñ–¥–∂–µ–Ω–Ω—è
    results = service.run_full_analysis_with_visualizations(
        N_data=10000,            # –í–µ–ª–∏–∫–∏–π –Ω–∞–±—ñ—Ä –¥–∞–Ω–∏—Ö
        lag=3,                   # –û–ø—Ç–∏–º–∞–ª—å–Ω–∞ –≥–ª–∏–±–∏–Ω–∞ —ñ—Å—Ç–æ—Ä—ñ—ó
        train_size=0.8,          # –°—Ç–∞–Ω–¥–∞—Ä—Ç–Ω–∏–π —Ä–æ–∑–ø–æ–¥—ñ–ª
        val_size=0.1,
        test_size=0.1,
        anomaly_severity='mild',  # –†–µ–∞–ª—ñ—Å—Ç–∏—á–Ω—ñ –∞–Ω–æ–º–∞–ª—ñ—ó
        anomaly_in_train=False,   # –ß–∏—Å—Ç—ñ —Ç—Ä–µ–Ω—É–≤–∞–ª—å–Ω—ñ –¥–∞–Ω—ñ
        use_anomalies=True,
        find_optimal_params=True,
        n_iter_search=50,        # –ú–∞–∫—Å–∏–º–∞–ª—å–Ω–∞ —è–∫—ñ—Å—Ç—å –æ–ø—Ç–∏–º—ñ–∑–∞—Ü—ñ—ó
        seed=42                   # –í—ñ–¥—Ç–≤–æ—Ä—é–≤–∞–Ω—ñ—Å—Ç—å
    )
    
    # –î–µ—Ç–∞–ª—å–Ω–∏–π –∑–≤—ñ—Ç
    report = service.generate_report_summary()
    
    # –ó–±–µ—Ä–µ–∂–µ–Ω–Ω—è –≤—Å—ñ—Ö —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ñ–≤
    with open('dissertation_report.txt', 'w', encoding='utf-8') as f:
        f.write(report)
    
    service.save_results('dissertation_results.json')
    
    print("‚úÖ –ì–û–¢–û–í–û –î–õ–Ø –î–ò–°–ï–†–¢–ê–¶–Ü–á:")
    print("üìä dissertation_model_comparison.png - –æ—Å–Ω–æ–≤–Ω—ñ –≥—Ä–∞—Ñ—ñ–∫–∏")
    print("üìà dissertation_detailed_analysis.png - –¥–µ—Ç–∞–ª—å–Ω–∏–π –∞–Ω–∞–ª—ñ–∑") 
    print("üìÑ model_comparison_table.tex - —Ç–∞–±–ª–∏—Ü—è –¥–ª—è LaTeX")
    print("üìù dissertation_report.txt - —Ç–µ–∫—Å—Ç–æ–≤–∏–π –∑–≤—ñ—Ç")
    print("üìÅ dissertation_results.json - –ø–æ–≤–Ω—ñ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∏")
    
    return results

def main():
    """–ì–æ–ª–æ–≤–Ω–∞ —Ñ—É–Ω–∫—Ü—ñ—è –∑ –¥–µ–º–æ–Ω—Å—Ç—Ä–∞—Ü—ñ—î—é –≤—Å—ñ—Ö –º–æ–∂–ª–∏–≤–æ—Å—Ç–µ–π"""
    print("üéì –î–ï–ú–û–ù–°–¢–†–ê–¶–Ü–Ø ModelComparisonService –î–õ–Ø –î–ò–°–ï–†–¢–ê–¶–Ü–á")
    print("=" * 60)
    
    try:
        # –ë–∞–∑–æ–≤–∏–π –ø—Ä–∏–∫–ª–∞–¥
        # basic_results = basic_comparison_example()
        
        # –ü–æ–≤–Ω–∏–π –∞–Ω–∞–ª—ñ–∑
        full_results = full_analysis_example()
        
        # –ü–æ—Ä—ñ–≤–Ω—è–Ω–Ω—è –∫–æ–Ω—Ñ—ñ–≥—É—Ä–∞—Ü—ñ–π
        # comparison_df = multiple_configurations_example()
        
        # –ö–æ—Ä–∏—Å—Ç—É–≤–∞—Ü—å–∫—ñ –ø–∞—Ä–∞–º–µ—Ç—Ä–∏
        # custom_results = custom_parameters_example()
        
        # –§—ñ–Ω–∞–ª—å–Ω–∏–π –ø—Ä–∏–∫–ª–∞–¥ –¥–ª—è –¥–∏—Å–µ—Ä—Ç–∞—Ü—ñ—ó
        # dissertation_results = dissertation_ready_example()
        # 
        print(f"\nüéâ –í–°–Ü –ü–†–ò–ö–õ–ê–î–ò –í–ò–ö–û–ù–ê–ù–û –£–°–ü–Ü–®–ù–û!")
        print(f"üìä –ö—Ä–∞—â–∏–π —Ä–µ–∑—É–ª—å—Ç–∞—Ç –ø–æ–∫—Ä–∞—â–µ–Ω–Ω—è MSE: "
              f"{full_results['performance_comparison']['mse_improvement_percent']:.1f}%")
        
    except Exception as e:
        print(f"‚ùå –ü–æ–º–∏–ª–∫–∞ –ø—ñ–¥ —á–∞—Å –≤–∏–∫–æ–Ω–∞–Ω–Ω—è: {e}")
        import traceback
        traceback.print_exc()

if __name__ == "__main__":
    main()

# if __name__ == "__main__":
#     # –Ü–Ω—ñ—Ü—ñ–∞–ª—ñ–∑–∞—Ü—ñ—è —Å–µ—Ä–≤—ñ—Å—É
#     service = ModelComparisonService()
    
#     results = service.run_full_analysis_with_visualizations(
#         N_data=7000,
#         lag=2,
#         use_anomalies=True,
#         anomaly_severity='mild',
#         find_optimal_params=True
#     )