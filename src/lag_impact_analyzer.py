# lag_impact_analyzer.py

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
from pathlib import Path
from datetime import datetime
from sklearn.preprocessing import StandardScaler
from sklearn.metrics import mean_squared_error
from typing import Dict, List, Optional, Tuple
import json

# –Ü–º–ø–æ—Ä—Ç –∑ –º–æ–¥—É–ª—ñ–≤ –ø—Ä–æ–µ–∫—Ç—É (—è–∫ —É ModelComparisonService)
from model import KernelModel
from data_gen import StatefulDataGenerator


class KernelLagAnalyzer:
    """
    –°–ø—Ä–æ—â–µ–Ω–∏–π —ñ–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç –¥–ª—è –∞–Ω–∞–ª—ñ–∑—É –≤–ø–ª–∏–≤—É –∫—ñ–ª—å–∫–æ—Å—Ç—ñ –ª–∞–≥—ñ–≤ –Ω–∞ —è–∫—ñ—Å—Ç—å —è–¥–µ—Ä–Ω–∏—Ö –º–æ–¥–µ–ª–µ–π.
    
    –ü—ñ–¥—Ö—ñ–¥ –∞–Ω–∞–ª–æ–≥—ñ—á–Ω–∏–π ModelComparisonService:
    - –û—Ç—Ä–∏–º—É—î –ø–æ—Å–∏–ª–∞–Ω–Ω—è –Ω–∞ –±–∞–∑–æ–≤–∏–π –¥–∞—Ç–∞—Å–µ—Ç
    - –í–∏–∫–æ—Ä–∏—Å—Ç–æ–≤—É—î create_simulation_data –¥–ª—è –≥–µ–Ω–µ—Ä–∞—Ü—ñ—ó –Ω–µ–æ–±—Ö—ñ–¥–Ω–æ–≥–æ –Ω–∞–±–æ—Ä—É
    - –§–æ–∫—É—Å –Ω–∞ —è–¥–µ—Ä–Ω–∏—Ö –º–æ–¥–µ–ª—è—Ö (KRR, SVR, GPR) –∑ model.py
    """
    
    def __init__(self, 
                 reference_df: Optional[pd.DataFrame] = None,
                 model_types: List[str] = ["krr", "svr"], 
                 lag_range: range = range(1, 11),
                 output_dir: Optional[str] = None):
        """
        –Ü–Ω—ñ—Ü—ñ–∞–ª—ñ–∑–∞—Ü—ñ—è –∞–Ω–∞–ª—ñ–∑–∞—Ç–æ—Ä–∞ –ª–∞–≥—ñ–≤.
        
        Args:
            reference_df: –†–µ—Ñ–µ—Ä–µ–Ω—Ç–Ω–∏–π –¥–∞—Ç–∞—Å–µ—Ç (—è–∫ —É ModelComparisonService)
            model_types: –°–ø–∏—Å–æ–∫ —Ç–∏–ø—ñ–≤ —è–¥–µ—Ä–Ω–∏—Ö –º–æ–¥–µ–ª–µ–π –¥–ª—è —Ç–µ—Å—Ç—É–≤–∞–Ω–Ω—è
            lag_range: –î—ñ–∞–ø–∞–∑–æ–Ω –ª–∞–≥—ñ–≤ –¥–ª—è —Ç–µ—Å—Ç—É–≤–∞–Ω–Ω—è
            output_dir: –î–∏—Ä–µ–∫—Ç–æ—Ä—ñ—è –¥–ª—è –∑–±–µ—Ä–µ–∂–µ–Ω–Ω—è —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ñ–≤
        """
        self.reference_df = self._load_reference_data(reference_df)
        self.model_types = model_types
        self.lag_range = lag_range
        self.results = {}
        
        # –°—Ç–≤–æ—Ä–µ–Ω–Ω—è —Å—Ç—Ä—É–∫—Ç—É—Ä–∏ –¥–∏—Ä–µ–∫—Ç–æ—Ä—ñ–π (—è–∫ —É ModelComparisonService)
        self._setup_directories(output_dir)
        
        print(f"üöÄ –Ü–Ω—ñ—Ü—ñ–∞–ª—ñ–∑–æ–≤–∞–Ω–æ KernelLagAnalyzer")
        print(f"   –†–µ—Ñ–µ—Ä–µ–Ω—Ç–Ω–∏–π –¥–∞—Ç–∞—Å–µ—Ç: {len(self.reference_df)} –∑–∞–ø–∏—Å—ñ–≤")
        print(f"   –ú–æ–¥–µ–ª—ñ: {model_types}")
        print(f"   –õ–∞–≥–∏: {list(lag_range)}")
        print(f"   –í–∏—Ö—ñ–¥–Ω–∞ –¥–∏—Ä–µ–∫—Ç–æ—Ä—ñ—è: {self.output_dir}")
    
    def _load_reference_data(self, reference_df: Optional[pd.DataFrame]) -> pd.DataFrame:
        """–ó–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–Ω—è —Ä–µ—Ñ–µ—Ä–µ–Ω—Ç–Ω–∏—Ö –¥–∞–Ω–∏—Ö (–∞–Ω–∞–ª–æ–≥—ñ—á–Ω–æ ModelComparisonService)"""
        if reference_df is None:
            try:
                reference_df = pd.read_parquet('processed.parquet')
                print(f"‚úÖ –ó–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–æ {len(reference_df)} –∑–∞–ø–∏—Å—ñ–≤ –∑ processed.parquet")
            except FileNotFoundError:
                print("‚ùå –§–∞–π–ª 'processed.parquet' –Ω–µ –∑–Ω–∞–π–¥–µ–Ω–æ")
                raise
        return reference_df
    
    def _setup_directories(self, output_dir: Optional[str]) -> None:
        """–°—Ç–≤–æ—Ä–µ–Ω–Ω—è —Å—Ç—Ä—É–∫—Ç—É—Ä–∏ –¥–∏—Ä–µ–∫—Ç–æ—Ä—ñ–π (–∞–Ω–∞–ª–æ–≥—ñ—á–Ω–æ ModelComparisonService)"""
        if output_dir is None:
            timestamp = datetime.now().strftime("%Y-%m-%d_%H-%M-%S")
            output_dir = f"lag_analysis/{timestamp}"
        
        self.output_dir = Path(output_dir)
        
        # –°—Ç—Ä—É–∫—Ç—É—Ä–∞ –¥–∏—Ä–µ–∫—Ç–æ—Ä—ñ–π
        self.dirs = {
            'data': self.output_dir / 'data',
            'plots': self.output_dir / 'plots', 
            'reports': self.output_dir / 'reports'
        }
        
        # –°—Ç–≤–æ—Ä–µ–Ω–Ω—è –≤—Å—ñ—Ö –¥–∏—Ä–µ–∫—Ç–æ—Ä—ñ–π
        for dir_path in self.dirs.values():
            dir_path.mkdir(parents=True, exist_ok=True)
            
        print(f"üìÅ –†–µ–∑—É–ª—å—Ç–∞—Ç–∏ –∑–±–µ—Ä—ñ–≥–∞—Ç–∏–º—É—Ç—å—Å—è —É: {self.output_dir.absolute()}")

    def _get_default_params(self) -> dict:
        """–ë–∞–∑–æ–≤—ñ –ø–∞—Ä–∞–º–µ—Ç—Ä–∏ –¥–ª—è —Å–∏–º—É–ª—è—Ü—ñ—ó"""
        return {
            'N_data': 5000,
            'control_pts': 500,
            'train_size': 0.8,
            'val_size': 0.1,
            'test_size': 0.1,
            'time_step_s': 5,
            'time_constants_s': {
                'concentrate_fe_percent': 8.0,
                'tailings_fe_percent': 10.0,
                'concentrate_mass_flow': 5.0,
                'tailings_mass_flow': 7.0
            },
            'dead_times_s': {
                'concentrate_fe_percent': 20.0,
                'tailings_fe_percent': 25.0,
                'concentrate_mass_flow': 20.0,
                'tailings_mass_flow': 25.0
            },
            'plant_model_type': 'rf',
            'n_neighbors': 5,
            'noise_level': 'none',
            'enable_nonlinear': False,
            'use_anomalies': False,
            'seed': 42
        }
    
    def create_simulation_data(self, params: dict) -> Tuple[StatefulDataGenerator, pd.DataFrame]:
        """
        –°—Ç–≤–æ—Ä–µ–Ω–Ω—è —Å–∏–º—É–ª—è—Ü—ñ–π–Ω–∏—Ö –¥–∞–Ω–∏—Ö —á–µ—Ä–µ–∑ StatefulDataGenerator.
        –¢–û–ß–ù–ê –ö–û–ü–Ü–Ø –∑ ModelComparisonService.
        """
        true_gen = StatefulDataGenerator(
            self.reference_df,
            ore_flow_var_pct=3.0,
            time_step_s=params['time_step_s'],
            time_constants_s=params['time_constants_s'],
            dead_times_s=params['dead_times_s'],
            true_model_type=params['plant_model_type'],
            seed=params['seed']
        )

        # –ê–Ω–æ–º–∞–ª—ñ—ó (—Å–ø—Ä–æ—â–µ–Ω–æ, –±–µ–∑ –Ω–∏—Ö –¥–ª—è —á–∏—Å—Ç–æ—Ç–∏ –∞–Ω–∞–ª—ñ–∑—É –ª–∞–≥—ñ–≤)
        anomaly_cfg = None
        if params.get('use_anomalies', False):
            anomaly_cfg = self._create_anomaly_config(
                N_data=params['N_data'],
                train_frac=params.get('train_size', 0.8),
                val_frac=params.get('val_size', 0.1),
                test_frac=params.get('test_size', 0.1),
                seed=params['seed'],
                severity=params.get('anomaly_severity', 'mild')
            )

        # –ë–∞–∑–æ–≤—ñ –¥–∞–Ω—ñ
        df_true_orig = true_gen.generate(
            T=params['N_data'],
            control_pts=params['control_pts'],
            n_neighbors=params['n_neighbors'],
            noise_level=params.get('noise_level', 'none'),
            anomaly_config=anomaly_cfg
        )

        # –ù–µ–ª—ñ–Ω—ñ–π–Ω–∏–π –≤–∞—Ä—ñ–∞–Ω—Ç
        if params.get('enable_nonlinear', False):
            df_true = true_gen.generate_nonlinear_variant(
                base_df=df_true_orig,
                non_linear_factors=params['nonlinear_config'],
                noise_level='none',
                anomaly_config=anomaly_cfg
            )
        else:
            df_true = df_true_orig

        return true_gen, df_true
    
    def _create_anomaly_config(self, N_data: int, train_frac: float = 0.7, 
                             val_frac: float = 0.15, test_frac: float = 0.15,
                             seed: int = 42, severity: str = "mild") -> dict:
        """–°–ø—Ä–æ—â–µ–Ω–∞ –≤–µ—Ä—Å—ñ—è create_anomaly_config –∑ ModelComparisonService"""
        # –î–ª—è –∞–Ω–∞–ª—ñ–∑—É –ª–∞–≥—ñ–≤ –∫—Ä–∞—â–µ –±–µ–∑ –∞–Ω–æ–º–∞–ª—ñ–π, –∞–ª–µ –∑–∞–ª–∏—à–∞—î–º–æ –º–æ–∂–ª–∏–≤—ñ—Å—Ç—å
        return {}  # –ü–æ—Ä–æ–∂–Ω—è –∫–æ–Ω—Ñ—ñ–≥—É—Ä–∞—Ü—ñ—è = –±–µ–∑ –∞–Ω–æ–º–∞–ª—ñ–π
    
    def create_lagged_matrices(self, df: pd.DataFrame, lag: int = 2) -> Tuple[np.ndarray, np.ndarray]:
        """
        –°—Ç–≤–æ—Ä–µ–Ω–Ω—è –ª–∞–≥–æ–≤–∏—Ö –º–∞—Ç—Ä–∏—Ü—å (–¢–û–ß–ù–ê –ö–û–ü–Ü–Ø –∑ ModelComparisonService).
        """
        input_vars = ['feed_fe_percent', 'ore_mass_flow', 'solid_feed_percent']
        output_vars = ['concentrate_fe', 'concentrate_mass']
        
        # –ü–µ—Ä–µ–≤—ñ—Ä–∫–∞ –∞–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤–Ω–∏—Ö –Ω–∞–∑–≤
        if 'concentrate_fe' not in df.columns and 'concentrate_fe_percent' in df.columns:
            output_vars = ['concentrate_fe_percent', 'concentrate_mass_flow']
        
        # –ü–µ—Ä–µ–≤—ñ—Ä–∫–∞ –Ω–∞—è–≤–Ω–æ—Å—Ç—ñ –∫–æ–ª–æ–Ω–æ–∫
        missing_vars = [var for var in input_vars + output_vars if var not in df.columns]
        if missing_vars:
            print(f"‚ö†Ô∏è –í—ñ–¥—Å—É—Ç–Ω—ñ –∫–æ–ª–æ–Ω–∫–∏: {missing_vars}")
            print(f"üìã –î–æ—Å—Ç—É–ø–Ω—ñ –∫–æ–ª–æ–Ω–∫–∏: {list(df.columns)}")
            return StatefulDataGenerator.create_lagged_dataset(df, lags=lag)
        
        n = len(df)
        X, Y = [], []
        
        for i in range(lag, n):
            row = []
            for var in input_vars:
                for j in range(lag + 1):
                    row.append(df[var].iloc[i - j])
            X.append(row)
            Y.append([df[var].iloc[i] for var in output_vars])
        
        return np.array(X), np.array(Y)
    
    def run_lag_analysis(self, base_params: Optional[Dict] = None) -> Dict:
        """
        –û—Å–Ω–æ–≤–Ω–∏–π –∞–Ω–∞–ª—ñ–∑ –≤–ø–ª–∏–≤—É –ª–∞–≥—ñ–≤ –Ω–∞ —è–∫—ñ—Å—Ç—å —è–¥–µ—Ä–Ω–∏—Ö –º–æ–¥–µ–ª–µ–π.
        
        Args:
            base_params: –ë–∞–∑–æ–≤—ñ –ø–∞—Ä–∞–º–µ—Ç—Ä–∏ —Å–∏–º—É–ª—è—Ü—ñ—ó (—è–∫ —É ModelComparisonService)
            
        Returns:
            Dict: –†–µ–∑—É–ª—å—Ç–∞—Ç–∏ –∞–Ω–∞–ª—ñ–∑—É
        """
        print(f"üìä –ü–æ—á–∞—Ç–æ–∫ –∞–Ω–∞–ª—ñ–∑—É –≤–ø–ª–∏–≤—É –ª–∞–≥—ñ–≤ –Ω–∞ —è–¥–µ—Ä–Ω—ñ –º–æ–¥–µ–ª—ñ...")
        
        # –ë–∞–∑–æ–≤—ñ –ø–∞—Ä–∞–º–µ—Ç—Ä–∏ —Å–∏–º—É–ª—è—Ü—ñ—ó (—è–∫ —É ModelComparisonService)
        if base_params is None:
            base_params = {
                'N_data': 5000,
                'control_pts': 500,
                'train_size': 0.8,
                'val_size': 0.1,
                'test_size': 0.1,
                'time_step_s': 5,
                'time_constants_s': {
                    'concentrate_fe_percent': 8.0,
                    'tailings_fe_percent': 10.0,
                    'concentrate_mass_flow': 5.0,
                    'tailings_mass_flow': 7.0
                },
                'dead_times_s': {
                    'concentrate_fe_percent': 20.0,
                    'tailings_fe_percent': 25.0,
                    'concentrate_mass_flow': 20.0,
                    'tailings_mass_flow': 25.0
                },
                'plant_model_type': 'rf',
                'seed': 42,
                'n_neighbors': 5,
                'noise_level': 'none',
                'enable_nonlinear': True,
                'nonlinear_config': {
                    'concentrate_fe_percent': ('pow', 2.0),
                    'concentrate_mass_flow': ('pow', 1.5)
                },
                'use_anomalies': False,  # –î–ª—è —á–∏—Å—Ç–æ—Ç–∏ –∞–Ω–∞–ª—ñ–∑—É –ª–∞–≥—ñ–≤
            }
        
        results = {
            'base_params': base_params,
            'lag_results': {},
            'best_lags': {},
            'model_comparison': {}
        }
        
        # –¶–∏–∫–ª –ø–æ –ª–∞–≥–∞–º
        for lag in self.lag_range:
            print(f"\nüîÑ –¢–µ—Å—Ç—É–≤–∞–Ω–Ω—è lag={lag}")
            
            # –°—Ç–≤–æ—Ä–µ–Ω–Ω—è —Å–∏–º—É–ª—è—Ü—ñ–π–Ω–∏—Ö –¥–∞–Ω–∏—Ö –∑ –ø–æ—Ç–æ—á–Ω–∏–º –ª–∞–≥–æ–º
            sim_params = base_params.copy()
            sim_params['current_lag'] = lag
            
            true_gen, df_sim = self.create_simulation_data(sim_params)
            
            # –°—Ç–≤–æ—Ä–µ–Ω–Ω—è –ª–∞–≥–æ–≤–∏—Ö –º–∞—Ç—Ä–∏—Ü—å
            X, Y = self.create_lagged_matrices(df_sim, lag)
            
            if X.shape[0] == 0:
                print(f"   ‚ö†Ô∏è –ù–µ–¥–æ—Å—Ç–∞—Ç–Ω—å–æ –¥–∞–Ω–∏—Ö –¥–ª—è lag={lag}")
                continue
            
            print(f"   –†–æ–∑–º—ñ—Ä–Ω—ñ—Å—Ç—å: X{X.shape}, Y{Y.shape}")
            
            # –†–æ–∑–¥—ñ–ª–µ–Ω–Ω—è –Ω–∞ train/test
            n = X.shape[0]
            n_train = int(sim_params['train_size'] * n)
            
            X_train, X_test = X[:n_train], X[n_train:]
            Y_train, Y_test = Y[:n_train], Y[n_train:]
            
            # –ú–∞—Å—à—Ç–∞–±—É–≤–∞–Ω–Ω—è (—è–∫ —É ModelComparisonService)
            x_scaler = StandardScaler()
            y_scaler = StandardScaler()
            
            X_train_scaled = x_scaler.fit_transform(X_train)
            X_test_scaled = x_scaler.transform(X_test)
            Y_train_scaled = y_scaler.fit_transform(Y_train)
            
            print(f"   –î–∞–Ω—ñ: train={X_train_scaled.shape[0]}, test={X_test_scaled.shape[0]}")
            
            # –¢–µ—Å—Ç—É–≤–∞–Ω–Ω—è –∫–æ–∂–Ω–æ—ó —è–¥–µ—Ä–Ω–æ—ó –º–æ–¥–µ–ª—ñ
            lag_results = {}
            for model_type in self.model_types:
                metrics = self._test_kernel_model(model_type, 
                                         X_train_scaled, Y_train_scaled,
                                         X_test_scaled, Y_test, y_scaler)
                lag_results[model_type] = metrics
                print(f"   {model_type.upper()}: RMSE={metrics['rmse']:.4f}")
            
            results['lag_results'][lag] = lag_results
        
        # –ê–Ω–∞–ª—ñ–∑ –Ω–∞–π–∫—Ä–∞—â–∏—Ö –ª–∞–≥—ñ–≤ –¥–ª—è –∫–æ–∂–Ω–æ—ó –º–æ–¥–µ–ª—ñ
        for model_type in self.model_types:
            best_lag = self._find_best_lag(results['lag_results'], model_type)
            results['best_lags'][model_type] = best_lag
            print(f"\n‚úÖ –ù–∞–π–∫—Ä–∞—â–∏–π lag –¥–ª—è {model_type.upper()}: {best_lag}")
        
        # –ü–æ—Ä—ñ–≤–Ω—è–Ω–Ω—è –º–æ–¥–µ–ª–µ–π
        results['model_comparison'] = self._compare_models(results['lag_results'])
        
        self.results = results
        return results
    
    def _test_kernel_model(self, model_type: str, 
                          X_train: np.ndarray, Y_train: np.ndarray,
                          X_test: np.ndarray, Y_test: np.ndarray, 
                          y_scaler: StandardScaler) -> Dict:
        """–¢–µ—Å—Ç—É–≤–∞–Ω–Ω—è —è–¥–µ—Ä–Ω–æ—ó –º–æ–¥–µ–ª—ñ –∑ –æ–ø—Ç–∏–º—ñ–∑–∞—Ü—ñ—î—é –ø–∞—Ä–∞–º–µ—Ç—Ä—ñ–≤"""
        
        # –ü–†–ê–í–ò–õ–¨–ù–û: –∑ –æ–ø—Ç–∏–º—ñ–∑–∞—Ü—ñ—î—é –ø–∞—Ä–∞–º–µ—Ç—Ä—ñ–≤
        if model_type == "krr":
            model = KernelModel(model_type="krr", kernel="rbf", find_optimal_params=True)  # ‚úÖ
        elif model_type == "svr":
            model = KernelModel(model_type="svr", kernel="rbf", find_optimal_params=True)  # ‚úÖ
        elif model_type == "gpr":
            model = KernelModel(model_type="gpr", find_optimal_params=True)  # ‚úÖ
        else:
            raise ValueError(f"–ù–µ–≤—ñ–¥–æ–º–∏–π —Ç–∏–ø —è–¥–µ—Ä–Ω–æ—ó –º–æ–¥–µ–ª—ñ: {model_type}")
        
        # –ù–∞–≤—á–∞–Ω–Ω—è –∑ –æ–ø—Ç–∏–º—ñ–∑–∞—Ü—ñ—î—é
        start_time = datetime.now()
        model.fit(X_train, Y_train)
        train_time = (datetime.now() - start_time).total_seconds()
        
        # –†–µ—à—Ç–∞ –∫–æ–¥—É –±–µ–∑ –∑–º—ñ–Ω...
        
        # –ü—Ä–æ–≥–Ω–æ–∑—É–≤–∞–Ω–Ω—è
        Y_pred_scaled = model.predict(X_test)
        Y_pred = y_scaler.inverse_transform(Y_pred_scaled)
        
        # –ú–µ—Ç—Ä–∏–∫–∏
        mse = mean_squared_error(Y_test, Y_pred)
        rmse = np.sqrt(mse)
        
        # –ú–µ—Ç—Ä–∏–∫–∏ –ø–æ –∫–æ–∂–Ω—ñ–π —Ü—ñ–ª—å–æ–≤—ñ–π –∑–º—ñ–Ω–Ω—ñ–π
        rmse_per_target = []
        for i in range(Y_test.shape[1]):
            rmse_target = np.sqrt(mean_squared_error(Y_test[:, i], Y_pred[:, i]))
            rmse_per_target.append(rmse_target)
        
        return {
            'mse': mse,
            'rmse': rmse,
            'rmse_per_target': rmse_per_target,
            'train_time': train_time
        }
    
    def _find_best_lag(self, lag_results: Dict, model_type: str) -> int:
        """–ó–Ω–∞—Ö–æ–¥–∂–µ–Ω–Ω—è –Ω–∞–π–∫—Ä–∞—â–æ–≥–æ –ª–∞–≥—É –¥–ª—è –º–æ–¥–µ–ª—ñ"""
        best_rmse = float('inf')
        best_lag = None
        
        for lag, results in lag_results.items():
            if model_type in results:
                rmse = results[model_type]['rmse']
                if rmse < best_rmse:
                    best_rmse = rmse
                    best_lag = lag
        
        return best_lag
    
    def _compare_models(self, lag_results: Dict) -> Dict:
        """–ü–æ—Ä—ñ–≤–Ω—è–Ω–Ω—è —è–¥–µ—Ä–Ω–∏—Ö –º–æ–¥–µ–ª–µ–π –Ω–∞ –∫—Ä–∞—â–∏—Ö –ª–∞–≥–∞—Ö"""
        comparison = {}
        
        for model_type in self.model_types:
            best_lag = self._find_best_lag(lag_results, model_type)
            if best_lag and best_lag in lag_results:
                comparison[model_type] = {
                    'best_lag': best_lag,
                    'best_rmse': lag_results[best_lag][model_type]['rmse'],
                    'best_mse': lag_results[best_lag][model_type]['mse']
                }
        
        return comparison
    
    def plot_lag_analysis(self) -> None:
        """–°—Ç–≤–æ—Ä–µ–Ω–Ω—è –æ—Å–Ω–æ–≤–Ω–∏—Ö –≥—Ä–∞—Ñ—ñ–∫—ñ–≤ –∞–Ω–∞–ª—ñ–∑—É –ª–∞–≥—ñ–≤"""
        if not self.results:
            raise ValueError("–ù–µ–º–∞—î —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ñ–≤ –¥–ª—è –≤—ñ–∑—É–∞–ª—ñ–∑–∞—Ü—ñ—ó. –°–ø–æ—á–∞—Ç–∫—É –∑–∞–ø—É—Å—Ç—ñ—Ç—å run_lag_analysis()")
        
        fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 6))
        
        # –ì—Ä–∞—Ñ—ñ–∫ 1: RMSE vs Lag (–ü–†–ò–ù–¶–ò–ü–û–í–û –í–ê–ñ–õ–ò–í–ò–ô)
        colors = {'krr': 'blue', 'svr': 'red', 'gpr': 'green'}
        
        for model_type in self.model_types:
            lags = []
            rmse_values = []
            
            for lag in self.lag_range:
                if lag in self.results['lag_results']:
                    if model_type in self.results['lag_results'][lag]:
                        lags.append(lag)
                        rmse_values.append(self.results['lag_results'][lag][model_type]['rmse'])
            
            if lags:
                ax1.plot(lags, rmse_values, 
                        marker='o', linewidth=2, markersize=6,
                        color=colors.get(model_type, 'black'),
                        label=f'{model_type.upper()}')
                
                # –ü–æ–∑–Ω–∞—á–µ–Ω–Ω—è –Ω–∞–π–∫—Ä–∞—â–æ–≥–æ –ª–∞–≥—É
                best_lag = self.results['best_lags'].get(model_type)
                if best_lag in lags:
                    best_idx = lags.index(best_lag)
                    ax1.scatter(best_lag, rmse_values[best_idx], 
                              s=100, color=colors.get(model_type), 
                              marker='*', zorder=5)
                    ax1.annotate(f'–û–ø—Ç–∏–º–∞–ª—å–Ω–∏–π lag={best_lag}', 
                               xy=(best_lag, rmse_values[best_idx]),
                               xytext=(10, 10), textcoords='offset points',
                               fontsize=9, alpha=0.8)
        
        ax1.set_xlabel('–ö—ñ–ª—å–∫—ñ—Å—Ç—å –ª–∞–≥—ñ–≤')
        ax1.set_ylabel('RMSE')
        ax1.set_title('–í–ø–ª–∏–≤ –∫—ñ–ª—å–∫–æ—Å—Ç—ñ –ª–∞–≥—ñ–≤ –Ω–∞ —è–∫—ñ—Å—Ç—å —è–¥–µ—Ä–Ω–∏—Ö –º–æ–¥–µ–ª–µ–π')
        ax1.legend()
        ax1.grid(True, alpha=0.3)
        
        # –ì—Ä–∞—Ñ—ñ–∫ 2: –ü–æ—Ä—ñ–≤–Ω—è–Ω–Ω—è —è–¥–µ—Ä–Ω–∏—Ö –º–æ–¥–µ–ª–µ–π –Ω–∞ –æ–ø—Ç–∏–º–∞–ª—å–Ω–∏—Ö –ª–∞–≥–∞—Ö (–ü–†–ò–ù–¶–ò–ü–û–í–û –í–ê–ñ–õ–ò–í–ò–ô)
        model_names = []
        best_rmse = []
        best_lags = []
        
        for model_type in self.model_types:
            if model_type in self.results['model_comparison']:
                model_names.append(model_type.upper())
                best_rmse.append(self.results['model_comparison'][model_type]['best_rmse'])
                best_lags.append(self.results['model_comparison'][model_type]['best_lag'])
        
        if model_names:
            bars = ax2.bar(model_names, best_rmse, 
                          color=[colors.get(m.lower(), 'gray') for m in model_names],
                          alpha=0.7)
            
            # –î–æ–¥–∞–≤–∞–Ω–Ω—è –∑–Ω–∞—á–µ–Ω—å –Ω–∞ —Å—Ç–æ–≤–ø—Ü—ñ
            for bar, rmse, lag in zip(bars, best_rmse, best_lags):
                ax2.text(bar.get_x() + bar.get_width()/2, bar.get_height() + max(best_rmse)*0.01,
                        f'RMSE: {rmse:.4f}\n–û–ø—Ç. lag: {lag}', 
                        ha='center', va='bottom', fontsize=9)
        
        ax2.set_ylabel('–ù–∞–π–∫—Ä–∞—â–∏–π RMSE')
        ax2.set_title('–ü–æ—Ä—ñ–≤–Ω—è–Ω–Ω—è —è–¥–µ—Ä–Ω–∏—Ö –º–æ–¥–µ–ª–µ–π –Ω–∞ –æ–ø—Ç–∏–º–∞–ª—å–Ω–∏—Ö –ª–∞–≥–∞—Ö')
        ax2.grid(True, alpha=0.3, axis='y')
        
        plt.tight_layout()
        
        # –ó–±–µ—Ä–µ–∂–µ–Ω–Ω—è
        plot_path = self.dirs['plots'] / 'kernel_lag_analysis.png'
        plt.savefig(plot_path, dpi=300, bbox_inches='tight')
        plt.show()
        
        print(f"üìà –û—Å–Ω–æ–≤–Ω–∏–π –≥—Ä–∞—Ñ—ñ–∫ –∑–±–µ—Ä–µ–∂–µ–Ω–æ: {plot_path}")
    
    def plot_detailed_comparison(self) -> None:
        """–î–µ—Ç–∞–ª—å–Ω–∏–π –≥—Ä–∞—Ñ—ñ–∫ –ø–æ—Ä—ñ–≤–Ω—è–Ω–Ω—è –ø–æ —Ü—ñ–ª—å–æ–≤–∏—Ö –∑–º—ñ–Ω–Ω–∏—Ö"""
        if not self.results:
            raise ValueError("–ù–µ–º–∞—î —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ñ–≤ –¥–ª—è –≤—ñ–∑—É–∞–ª—ñ–∑–∞—Ü—ñ—ó")
        
        # –í–∏–∑–Ω–∞—á–µ–Ω–Ω—è –∫—ñ–ª—å–∫–æ—Å—Ç—ñ —Ü—ñ–ª—å–æ–≤–∏—Ö –∑–º—ñ–Ω–Ω–∏—Ö
        n_targets = None
        for lag_data in self.results['lag_results'].values():
            for model_data in lag_data.values():
                n_targets = len(model_data['rmse_per_target'])
                break
            if n_targets:
                break
        
        if not n_targets:
            print("‚ö†Ô∏è –ù–µ –∑–Ω–∞–π–¥–µ–Ω–æ –¥–∞–Ω–∏—Ö –¥–ª—è –¥–µ—Ç–∞–ª—å–Ω–æ–≥–æ –ø–æ—Ä—ñ–≤–Ω—è–Ω–Ω—è")
            return
        
        fig, axes = plt.subplots(1, n_targets, figsize=(6*n_targets, 5))
        if n_targets == 1:
            axes = [axes]
        
        colors = {'krr': 'blue', 'svr': 'red', 'gpr': 'green'}
        target_names = ['–ö–æ–Ω—Ü–µ–Ω—Ç—Ä–∞—Ü—ñ—è Fe', '–ú–∞—Å–æ–≤–∏–π –ø–æ—Ç—ñ–∫'] if n_targets == 2 else [f'–¶—ñ–ª—å {i+1}' for i in range(n_targets)]
        
        for target_idx in range(n_targets):
            ax = axes[target_idx]
            
            for model_type in self.model_types:
                lags = []
                rmse_values = []
                
                for lag in self.lag_range:
                    if (lag in self.results['lag_results'] and 
                        model_type in self.results['lag_results'][lag]):
                        lags.append(lag)
                        rmse_values.append(self.results['lag_results'][lag][model_type]['rmse_per_target'][target_idx])
                
                if lags:
                    ax.plot(lags, rmse_values, 
                           marker='o', linewidth=2, markersize=5,
                           color=colors.get(model_type, 'black'),
                           label=f'{model_type.upper()}')
            
            ax.set_xlabel('–ö—ñ–ª—å–∫—ñ—Å—Ç—å –ª–∞–≥—ñ–≤')
            ax.set_ylabel('RMSE')
            ax.set_title(f'{target_names[target_idx]}')
            ax.legend()
            ax.grid(True, alpha=0.3)
        
        plt.tight_layout()
        
        # –ó–±–µ—Ä–µ–∂–µ–Ω–Ω—è
        plot_path = self.dirs['plots'] / 'detailed_kernel_comparison.png'
        plt.savefig(plot_path, dpi=300, bbox_inches='tight')
        plt.show()
        
        print(f"üìä –î–µ—Ç–∞–ª—å–Ω–∏–π –≥—Ä–∞—Ñ—ñ–∫ –∑–±–µ—Ä–µ–∂–µ–Ω–æ: {plot_path}")
    
    def save_results(self, filename: Optional[str] = None) -> str:
        """–ó–±–µ—Ä–µ–∂–µ–Ω–Ω—è —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ñ–≤ —É JSON"""
        if not self.results:
            raise ValueError("–ù–µ–º–∞—î —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ñ–≤ –¥–ª—è –∑–±–µ—Ä–µ–∂–µ–Ω–Ω—è")
        
        if filename is None:
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            filename = f'kernel_lag_analysis_{timestamp}.json'
        
        filepath = self.dirs['data'] / filename
        
        with open(filepath, 'w', encoding='utf-8') as f:
            json.dump(self.results, f, indent=2, default=str, ensure_ascii=False)
        
        print(f"üíæ –†–µ–∑—É–ª—å—Ç–∞—Ç–∏ –∑–±–µ—Ä–µ–∂–µ–Ω–æ: {filepath}")
        return str(filepath)
    
    def generate_report(self) -> str:
        """–ì–µ–Ω–µ—Ä–∞—Ü—ñ—è —Ç–µ–∫—Å—Ç–æ–≤–æ–≥–æ –∑–≤—ñ—Ç—É"""
        if not self.results:
            raise ValueError("–ù–µ–º–∞—î —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ñ–≤ –¥–ª—è –∑–≤—ñ—Ç—É")
        
        report = f"""
–ó–í–Ü–¢ –ü–†–û –ê–ù–ê–õ–Ü–ó –í–ü–õ–ò–í–£ –õ–ê–ì–Ü–í –ù–ê –Ø–î–ï–†–ù–Ü –ú–û–î–ï–õ–Ü
{'='*55}

–ü–ê–†–ê–ú–ï–¢–†–ò –ê–ù–ê–õ–Ü–ó–£:
    –Ø–¥–µ—Ä–Ω—ñ –º–æ–¥–µ–ª—ñ: {', '.join([m.upper() for m in self.model_types])}
    –î—ñ–∞–ø–∞–∑–æ–Ω –ª–∞–≥—ñ–≤: {list(self.lag_range)}
    –î–∞—Ç–∞ –∞–Ω–∞–ª—ñ–∑—É: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}
    –†–µ—Ñ–µ—Ä–µ–Ω—Ç–Ω–∏–π –¥–∞—Ç–∞—Å–µ—Ç: {len(self.reference_df)} –∑–∞–ø–∏—Å—ñ–≤

–ù–ê–ô–ö–†–ê–©–Ü –†–ï–ó–£–õ–¨–¢–ê–¢–ò –ó–ê –ú–û–î–ï–õ–Ø–ú–ò:
"""
        
        for model_type in self.model_types:
            if model_type in self.results['model_comparison']:
                comp_data = self.results['model_comparison'][model_type]
                report += f"""
    {model_type.upper()}:
        –û–ø—Ç–∏–º–∞–ª—å–Ω–∏–π lag: {comp_data['best_lag']}
        –ù–∞–π–∫—Ä–∞—â–∏–π RMSE: {comp_data['best_rmse']:.6f}
        –ù–∞–π–∫—Ä–∞—â–∏–π MSE: {comp_data['best_mse']:.6f}
"""
        
        # –ü–æ—Ä—ñ–≤–Ω—è–Ω–Ω—è –º–æ–¥–µ–ª–µ–π
        report += f"\n–ü–û–†–Ü–í–ù–Ø–ù–ù–Ø –Ø–î–ï–†–ù–ò–• –ú–û–î–ï–õ–ï–ô:\n"
        
        if len(self.model_types) > 1:
            model_performances = []
            for model_type in self.model_types:
                if model_type in self.results['model_comparison']:
                    model_performances.append({
                        'model': model_type.upper(),
                        'rmse': self.results['model_comparison'][model_type]['best_rmse']
                    })
            
            if model_performances:
                best_model = min(model_performances, key=lambda x: x['rmse'])
                worst_model = max(model_performances, key=lambda x: x['rmse'])
                
                improvement = ((worst_model['rmse'] - best_model['rmse']) / worst_model['rmse']) * 100
                
                report += f"    –ù–∞–π–∫—Ä–∞—â–∞ –º–æ–¥–µ–ª—å: {best_model['model']} (RMSE: {best_model['rmse']:.6f})\n"
                report += f"    –ù–∞–π–≥—ñ—Ä—à–∞ –º–æ–¥–µ–ª—å: {worst_model['model']} (RMSE: {worst_model['rmse']:.6f})\n"
                report += f"    –ü–æ–∫—Ä–∞—â–µ–Ω–Ω—è: {improvement:.1f}%\n"
        
        report += f"\n{'='*55}\n"
        
        # –ó–±–µ—Ä–µ–∂–µ–Ω–Ω—è –∑–≤—ñ—Ç—É
        report_path = self.dirs['reports'] / 'kernel_lag_analysis_report.txt'
        with open(report_path, 'w', encoding='utf-8') as f:
            f.write(report)
        
        print(f"üìù –ó–≤—ñ—Ç –∑–±–µ—Ä–µ–∂–µ–Ω–æ: {report_path}")
        return str(report_path)


# =============================================================================
# –ü–û–ó–ê–ö–õ–ê–°–û–í–Ü –ü–†–ò–ö–õ–ê–î–ò –ó –í–ò–ö–û–†–ò–°–¢–ê–ù–ù–Ø–ú –ë–ê–ó–û–í–û–ì–û –î–ê–¢–ê–°–ï–¢–£
# =============================================================================

def example_1_basic_kernel_lag_analysis():
    """–ü—Ä–∏–∫–ª–∞–¥ 1: –ë–∞–∑–æ–≤–∏–π –∞–Ω–∞–ª—ñ–∑ –ª–∞–≥—ñ–≤ –¥–ª—è —è–¥–µ—Ä–Ω–∏—Ö –º–æ–¥–µ–ª–µ–π"""
    print("=== –ü–†–ò–ö–õ–ê–î 1: –ë–ê–ó–û–í–ò–ô –ê–ù–ê–õ–Ü–ó –õ–ê–ì–Ü–í –î–õ–Ø –Ø–î–ï–†–ù–ò–• –ú–û–î–ï–õ–ï–ô ===\n")
    
    # –°—Ç–≤–æ—Ä–µ–Ω–Ω—è –∞–Ω–∞–ª—ñ–∑–∞—Ç–æ—Ä–∞ –∑ –±–∞–∑–æ–≤–∏–º –¥–∞—Ç–∞—Å–µ—Ç–æ–º
    analyzer = KernelLagAnalyzer(
        # reference_df=None,  # –ê–≤—Ç–æ–º–∞—Ç–∏—á–Ω–æ –∑–∞–≤–∞–Ω—Ç–∞–∂–∏—Ç—å processed.parquet
        model_types=["krr", "svr"],
        lag_range=range(1, 8)
    )
    
    # –ó–∞–ø—É—Å–∫ –∞–Ω–∞–ª—ñ–∑—É
    results = analyzer.run_lag_analysis()
    
    # –í—ñ–∑—É–∞–ª—ñ–∑–∞—Ü—ñ—è
    analyzer.plot_lag_analysis()
    
    # –ó–±–µ—Ä–µ–∂–µ–Ω–Ω—è —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ñ–≤
    analyzer.save_results()
    analyzer.generate_report()
    
    return analyzer

def example_2_compare_all_kernel_models():
    """–ü—Ä–∏–∫–ª–∞–¥ 2: –ü–æ—Ä—ñ–≤–Ω—è–Ω–Ω—è –≤—Å—ñ—Ö —è–¥–µ—Ä–Ω–∏—Ö –º–æ–¥–µ–ª–µ–π (KRR, SVR, GPR)"""
    print("\n=== –ü–†–ò–ö–õ–ê–î 2: –ü–û–†–Ü–í–ù–Ø–ù–ù–Ø –í–°–Ü–• –Ø–î–ï–†–ù–ò–• –ú–û–î–ï–õ–ï–ô ===\n")
    
    # –ê–Ω–∞–ª—ñ–∑–∞—Ç–æ—Ä –∑ —É—Å—ñ–º–∞ —è–¥–µ—Ä–Ω–∏–º–∏ –º–æ–¥–µ–ª—è–º–∏
    analyzer = KernelLagAnalyzer(
        model_types=["krr", "svr", "gpr"],
        lag_range=range(1, 10),
        output_dir="kernel_comparison_full"
    )
    
    # –°–ø–µ—Ü—ñ–∞–ª—å–Ω—ñ –ø–∞—Ä–∞–º–µ—Ç—Ä–∏ –¥–ª—è —Å–∫–ª–∞–¥–Ω—ñ—à–æ–≥–æ –ø—Ä–æ—Ü–µ—Å—É
    custom_params = {
        'N_data': 6000,
        'control_pts': 600,
        'enable_nonlinear': True,
        'nonlinear_config': {
            'concentrate_fe_percent': ('pow', 2.2),
            'concentrate_mass_flow': ('pow', 1.8)
        }
    }
    
    # –ê–Ω–∞–ª—ñ–∑
    results = analyzer.run_lag_analysis(custom_params)
    
    # –î–µ—Ç–∞–ª—å–Ω—ñ –≤—ñ–∑—É–∞–ª—ñ–∑–∞—Ü—ñ—ó
    analyzer.plot_lag_analysis()
    analyzer.plot_detailed_comparison()
    
    # –ó–±–µ—Ä–µ–∂–µ–Ω–Ω—è
    analyzer.save_results("full_kernel_lag_comparison.json")
    analyzer.generate_report()
    
    return analyzer

def example_3_focus_on_krr_optimization():
    """–ü—Ä–∏–∫–ª–∞–¥ 3: –§–æ–∫—É—Å –Ω–∞ –æ–ø—Ç–∏–º—ñ–∑–∞—Ü—ñ—ó KRR –¥–ª—è —Ä—ñ–∑–Ω–∏—Ö –ª–∞–≥—ñ–≤"""
    print("\n=== –ü–†–ò–ö–õ–ê–î 3: –û–ü–¢–ò–ú–Ü–ó–ê–¶–Ü–Ø KRR –î–õ–Ø –†–Ü–ó–ù–ò–• –õ–ê–ì–Ü–í ===\n")
    
    # –¢—ñ–ª—å–∫–∏ KRR –¥–ª—è –¥–µ—Ç–∞–ª—å–Ω–æ–≥–æ –∞–Ω–∞–ª—ñ–∑—É
    analyzer = KernelLagAnalyzer(
        model_types=["krr"],
        lag_range=range(1, 15),  # –®–∏—Ä—à–∏–π –¥—ñ–∞–ø–∞–∑–æ–Ω
        output_dir="krr_lag_optimization"
    )
    
    # –ü–∞—Ä–∞–º–µ—Ç—Ä–∏ –∑ –±—ñ–ª—å—à–∏–º –∞–∫—Ü–µ–Ω—Ç–æ–º –Ω–∞ —è–∫—ñ—Å—Ç—å
    quality_params = {
        'N_data': 8000,
        'control_pts': 800,
        'train_size': 0.85,  # –ë—ñ–ª—å—à–µ —Ç—Ä–µ–Ω—É–≤–∞–ª—å–Ω–∏—Ö –¥–∞–Ω–∏—Ö
        'enable_nonlinear': True,
        'nonlinear_config': {
            'concentrate_fe_percent': ('pow', 2.5),
            'concentrate_mass_flow': ('pow', 2.0)
        }
    }
    
    # –ê–Ω–∞–ª—ñ–∑
    results = analyzer.run_lag_analysis(quality_params)
    
    # –í—ñ–∑—É–∞–ª—ñ–∑–∞—Ü—ñ—è
    analyzer.plot_lag_analysis()
    analyzer.plot_detailed_comparison()
    
    # –î–µ—Ç–∞–ª—å–Ω–∏–π –∑–≤—ñ—Ç
    analyzer.generate_report()
    
    print(f"\nüìä –†–ï–ó–£–õ–¨–¢–ê–¢–ò –û–ü–¢–ò–ú–Ü–ó–ê–¶–Ü–á KRR:")
    if 'krr' in analyzer.results['model_comparison']:
        best_result = analyzer.results['model_comparison']['krr']
        print(f"   –û–ø—Ç–∏–º–∞–ª—å–Ω–∏–π lag: {best_result['best_lag']}")
        print(f"   –ù–∞–π–∫—Ä–∞—â–∏–π RMSE: {best_result['best_rmse']:.6f}")
    
    return analyzer

def example_4_realistic_process_conditions():
    """–ü—Ä–∏–∫–ª–∞–¥ 4: –†–µ–∞–ª—ñ—Å—Ç–∏—á–Ω—ñ —É–º–æ–≤–∏ –ø—Ä–æ—Ü–µ—Å—É –º–∞–≥–Ω—ñ—Ç–Ω–æ—ó —Å–µ–ø–∞—Ä–∞—Ü—ñ—ó"""
    print("\n=== –ü–†–ò–ö–õ–ê–î 4: –†–ï–ê–õ–Ü–°–¢–ò–ß–ù–Ü –£–ú–û–í–ò –ü–†–û–¶–ï–°–£ ===\n")
    
    # –ê–Ω–∞–ª—ñ–∑ –¥–ª—è –ø—Ä–∞–∫—Ç–∏—á–Ω–æ–≥–æ –≤–∏–∫–æ—Ä–∏—Å—Ç–∞–Ω–Ω—è
    analyzer = KernelLagAnalyzer(
        model_types=["krr", "svr"],  # –ù–∞–π–±—ñ–ª—å—à –ø—Ä–∞–∫—Ç–∏—á–Ω—ñ
        lag_range=range(2, 12),  # –ü—Ä–∞–∫—Ç–∏—á–Ω–∏–π –¥—ñ–∞–ø–∞–∑–æ–Ω
        output_dir="realistic_process_analysis"
    )
    
    # –†–µ–∞–ª—ñ—Å—Ç–∏—á–Ω—ñ –ø–∞—Ä–∞–º–µ—Ç—Ä–∏ –ø—Ä–æ—Ü–µ—Å—É
    realistic_params = {
        'N_data': 10000,  # –ë–∞–≥–∞—Ç–æ —ñ—Å—Ç–æ—Ä–∏—á–Ω–∏—Ö –¥–∞–Ω–∏—Ö
        'control_pts': 1000,
        'train_size': 0.75,
        'val_size': 0.15,
        'test_size': 0.10,
        'time_step_s': 5,  # 5-—Å–µ–∫—É–Ω–¥–Ω–∏–π —ñ–Ω—Ç–µ—Ä–≤–∞–ª –≤–∏–º—ñ—Ä—é–≤–∞–Ω—å
        'enable_nonlinear': True,
        'nonlinear_config': {
            'concentrate_fe_percent': ('pow', 1.8),  # –†–µ–∞–ª—ñ—Å—Ç–∏—á–Ω–∞ –Ω–µ–ª—ñ–Ω—ñ–π–Ω—ñ—Å—Ç—å
            'concentrate_mass_flow': ('pow', 1.4)
        },
        'noise_level': 'low',  # –†–µ–∞–ª—å–Ω–∏–π —à—É–º –ø—Ä–æ—Ü–µ—Å—É
        'seed': 42
    }
    
    # –ó–∞–ø—É—Å–∫ –∞–Ω–∞–ª—ñ–∑—É
    results = analyzer.run_lag_analysis(realistic_params)
    
    # –°—Ç–≤–æ—Ä–µ–Ω–Ω—è –≤—ñ–∑—É–∞–ª—ñ–∑–∞—Ü—ñ–π
    analyzer.plot_lag_analysis()
    analyzer.plot_detailed_comparison()
    
    # –ó–≤—ñ—Ç
    analyzer.save_results("realistic_process_results.json")
    report_path = analyzer.generate_report()
    
    print(f"\nüìä –ê–ù–ê–õ–Ü–ó –†–ï–ê–õ–Ü–°–¢–ò–ß–ù–û–ì–û –ü–†–û–¶–ï–°–£:")
    for model_type in analyzer.model_types:
        if model_type in analyzer.results['model_comparison']:
            comp = analyzer.results['model_comparison'][model_type]
            print(f"   {model_type.upper()}: –æ–ø—Ç–∏–º–∞–ª—å–Ω–∏–π lag={comp['best_lag']}, RMSE={comp['best_rmse']:.6f}")
    
    return analyzer

def example_5_quick_lag_screening():
    """–ü—Ä–∏–∫–ª–∞–¥ 5: –®–≤–∏–¥–∫–∏–π —Å–∫—Ä–∏–Ω—ñ–Ω–≥ –æ–ø—Ç–∏–º–∞–ª—å–Ω–∏—Ö –ª–∞–≥—ñ–≤"""
    print("\n=== –ü–†–ò–ö–õ–ê–î 5: –®–í–ò–î–ö–ò–ô –°–ö–†–ò–ù–Ü–ù–ì –õ–ê–ì–Ü–í ===\n")
    
    # –®–≤–∏–¥–∫–∏–π —Ç–µ—Å—Ç –¥–ª—è –ø–æ–ø–µ—Ä–µ–¥–Ω—å–æ–≥–æ –≤–∏–±–æ—Ä—É
    analyzer = KernelLagAnalyzer(
        model_types=["krr"],  # –¢—ñ–ª—å–∫–∏ –æ–¥–Ω–∞ –º–æ–¥–µ–ª—å –¥–ª—è —à–≤–∏–¥–∫–æ—Å—Ç—ñ
        lag_range=[2, 4, 6, 8, 10],  # –í–∏–±—ñ—Ä–∫–æ–≤—ñ –ª–∞–≥–∏
        output_dir="quick_lag_screening"
    )
    
    # –í–ò–ü–†–ê–í–õ–ï–ù–Ü –ø–∞—Ä–∞–º–µ—Ç—Ä–∏ –∑ —É—Å—ñ–º–∞ –æ–±–æ–≤'—è–∑–∫–æ–≤–∏–º–∏ –∫–ª—é—á–∞–º–∏
    quick_params = {
        'N_data': 3000,
        'control_pts': 300,
        'train_size': 0.8,
        'val_size': 0.1,
        'test_size': 0.1,
        'time_step_s': 5,  # –î–û–î–ê–ù–û
        'time_constants_s': {  # –î–û–î–ê–ù–û
            'concentrate_fe_percent': 8.0,
            'tailings_fe_percent': 10.0,
            'concentrate_mass_flow': 5.0,
            'tailings_mass_flow': 7.0
        },
        'dead_times_s': {  # –î–û–î–ê–ù–û
            'concentrate_fe_percent': 20.0,
            'tailings_fe_percent': 25.0,
            'concentrate_mass_flow': 20.0,
            'tailings_mass_flow': 25.0
        },
        'plant_model_type': 'rf',  # –î–û–î–ê–ù–û
        'n_neighbors': 5,
        'enable_nonlinear': False,  # –ë–µ–∑ –Ω–µ–ª—ñ–Ω—ñ–π–Ω–æ—Å—Ç—ñ –¥–ª—è —à–≤–∏–¥–∫–æ—Å—Ç—ñ
        'use_anomalies': False,
        'seed': 123
    }
    
    results = analyzer.run_lag_analysis(quick_params)
    analyzer.plot_lag_analysis()
    
    print(f"–®–≤–∏–¥–∫–∏–π —Å–∫—Ä–∏–Ω—ñ–Ω–≥ –∑–∞–≤–µ—Ä—à–µ–Ω–æ. –†–µ–∫–æ–º–µ–Ω–¥–æ–≤–∞–Ω–∏–π lag: {analyzer.results['best_lags']['krr']}")
    
    return analyzer

def run_all_kernel_examples():
    """–ó–∞–ø—É—Å–∫ –≤—Å—ñ—Ö –ø—Ä–∏–∫–ª–∞–¥—ñ–≤ KernelLagAnalyzer"""
    print("üöÄ –ó–ê–ü–£–°–ö –í–°–Ü–• –ü–†–ò–ö–õ–ê–î–Ü–í KERNELLAGANALYZER –ó –ë–ê–ó–û–í–ò–ú –î–ê–¢–ê–°–ï–¢–û–ú")
    print("="*65)
    
    examples = [
        example_1_basic_kernel_lag_analysis,
        example_2_compare_all_kernel_models,
        example_3_focus_on_krr_optimization,
        example_4_realistic_process_conditions,
        example_5_quick_lag_screening
    ]
    
    results = []
    
    for i, example in enumerate(examples, 1):
        try:
            print(f"\nüìä –ü—Ä–∏–∫–ª–∞–¥ {i}:")
            analyzer = example()
            results.append(analyzer)
            print(f"‚úÖ –ü—Ä–∏–∫–ª–∞–¥ {i} –∑–∞–≤–µ—Ä—à–µ–Ω–æ —É—Å–ø—ñ—à–Ω–æ")
        except Exception as e:
            print(f"‚ùå –ü–æ–º–∏–ª–∫–∞ –≤ –ø—Ä–∏–∫–ª–∞–¥—ñ {i}: {e}")
            # import traceback
            # traceback.print_exc()
            continue
    
    print(f"\nüéâ –ó–ê–í–ï–†–®–ï–ù–û {len(results)} –ø—Ä–∏–∫–ª–∞–¥—ñ–≤ –∑ {len(examples)}")
    
    # –ü–æ—Ä—ñ–≤–Ω—è–ª—å–Ω–∏–π –∞–Ω–∞–ª—ñ–∑ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ñ–≤
    if results:
        print("\nüìä –ü–û–†–Ü–í–ù–Ø–õ–¨–ù–ò–ô –ê–ù–ê–õ–Ü–ó –†–ï–ó–£–õ–¨–¢–ê–¢–Ü–í:")
        for i, analyzer in enumerate(results, 1):
            if hasattr(analyzer, 'results') and analyzer.results.get('best_lags'):
                print(f"   –ü—Ä–∏–∫–ª–∞–¥ {i}:")
                for model, lag in analyzer.results['best_lags'].items():
                    rmse = analyzer.results['model_comparison'][model]['best_rmse']
                    print(f"     {model.upper()}: lag={lag}, RMSE={rmse:.6f}")
    
    return results

def example_krr_svr():
    """–ü—Ä–∏–∫–ª–∞–¥ 4: KRR vs SVR –æ–ø—Ç–∏–º—ñ–∑–æ–≤–∞–Ω–∏–π"""
    print("\n=== –ü–†–ò–ö–õ–ê–î KRR vs SVR ===\n")
    
    analyzer = KernelLagAnalyzer(
        model_types=["krr", "svr"],
        lag_range=[2, 4, 6, 8, 10, 12],
        output_dir="evaluation_results/lags"
    )
    
    realistic_params = {
        'N_data': 7000,
        'control_pts': 700,
        'train_size': 0.75,
        'val_size': 0.15,
        'test_size': 0.10,
        'time_step_s': 5,
        'time_constants_s': {
            'concentrate_fe_percent': 8.0,
            'tailings_fe_percent': 10.0,
            'concentrate_mass_flow': 5.0,
            'tailings_mass_flow': 7.0
        },
        'dead_times_s': {  # –î–û–î–ê–ù–û
            'concentrate_fe_percent': 20.0,
            'tailings_fe_percent': 25.0,
            'concentrate_mass_flow': 20.0,
            'tailings_mass_flow': 25.0
        },
        'plant_model_type': 'rf',  # –î–û–î–ê–ù–û
        'n_neighbors': 5,  # –î–û–î–ê–ù–û
        'enable_nonlinear': True,
        'nonlinear_config': {
            'concentrate_fe_percent': ('pow', 1.8),
            'concentrate_mass_flow': ('pow', 1.4)
        },
        'noise_level': 'low',
        'use_anomalies': False,  # –î–û–î–ê–ù–û –¥–ª—è —á–∏—Å—Ç–æ—Ç–∏
        'seed': 42
    }
    
    # –†–µ—à—Ç–∞ –∫–æ–¥—É –∑–∞–ª–∏—à–∞—î—Ç—å—Å—è –±–µ–∑ –∑–º—ñ–Ω
    results = analyzer.run_lag_analysis(realistic_params)
    analyzer.plot_lag_analysis()
    analyzer.plot_detailed_comparison()
    analyzer.save_results("krr_svr_results.json")
    report_path = analyzer.generate_report()
    
    print(f"\nüìä –ê–ù–ê–õ–Ü–ó KRR vs SVR:")
    for model_type in analyzer.model_types:
        if model_type in analyzer.results['model_comparison']:
            comp = analyzer.results['model_comparison'][model_type]
            print(f"   {model_type.upper()}: lag={comp['best_lag']}, RMSE={comp['best_rmse']:.6f}")
    
    return analyzer
if __name__ == "__main__":
    example_krr_svr()
    
    """–ü—Ä–∏–∫–ª–∞–¥ 1: –ë–∞–∑–æ–≤–∏–π –∞–Ω–∞–ª—ñ–∑ –ª–∞–≥—ñ–≤ –¥–ª—è —è–¥–µ—Ä–Ω–∏—Ö –º–æ–¥–µ–ª–µ–π"""
    # example_1_basic_kernel_lag_analysis()
    
    """–ü—Ä–∏–∫–ª–∞–¥ 2: –ü–æ—Ä—ñ–≤–Ω—è–Ω–Ω—è –≤—Å—ñ—Ö —è–¥–µ—Ä–Ω–∏—Ö –º–æ–¥–µ–ª–µ–π (KRR, SVR, GPR)"""
    # example_2_compare_all_kernel_models
    
    """–ü—Ä–∏–∫–ª–∞–¥ 3: –§–æ–∫—É—Å –Ω–∞ –æ–ø—Ç–∏–º—ñ–∑–∞—Ü—ñ—ó KRR –¥–ª—è —Ä—ñ–∑–Ω–∏—Ö –ª–∞–≥—ñ–≤"""
    # example_3_focus_on_krr_optimization()
    
    """–ü—Ä–∏–∫–ª–∞–¥ 4: –†–µ–∞–ª—ñ—Å—Ç–∏—á–Ω—ñ —É–º–æ–≤–∏ –ø—Ä–æ—Ü–µ—Å—É –º–∞–≥–Ω—ñ—Ç–Ω–æ—ó —Å–µ–ø–∞—Ä–∞—Ü—ñ—ó"""
    # example_4_realistic_process_conditions()
        
    """–ü—Ä–∏–∫–ª–∞–¥ 5: –®–≤–∏–¥–∫–∏–π —Å–∫—Ä–∏–Ω—ñ–Ω–≥ –æ–ø—Ç–∏–º–∞–ª—å–Ω–∏—Ö –ª–∞–≥—ñ–≤"""
    # example_5_quick_lag_screening()
    
    
    """–ó–∞–ø—É—Å–∫ –≤—Å—ñ—Ö –ø—Ä–∏–∫–ª–∞–¥—ñ–≤ KernelLagAnalyzer"""
    # run_all_kernel_examples()
